{"name":"生物信息","postlist":[{"title":"Bioconda贡献指南","slug":"Bioconda贡献指南","date":"2019-05-19T09:39:00.000Z","updated":"2022-01-08T02:16:28.392Z","comments":true,"path":"api/articles/Bioconda贡献指南.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/new_pull_request_LI.jpg","content":"<p>本文介绍了如何为软件添加 Bioconda recipe，以便可以通过 conda 安装自己的软件。</p>\n<span id=\"more\"></span>\n<p><strong>注：本文适用于非 Bioconda 成员</strong></p>\n<p><B>Step0：软件开发与 GitHub 操作</B></p>\n<br/>\n(1) 将开发完成的软件上传到GitHub\n<br/>\n(2) 在本地软件目录下创建tag\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> tag v1.0.0 -m <span class=\"token string\">'first version'</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n(3) 上传到GitHub\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> push origin v1.0.0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注</strong>：如果需要删除有 bug 的 tag：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> tag -d tagname\n\n<span class=\"token variable\">$git</span> push origin :refs/tags/tagname\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<br/>\n(4) 存档tag(非必需)\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> archive -v --format<span class=\"token operator\">=</span>tar v1.0.0 <span class=\"token operator\">></span> v1.0.0.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n(5) 计算压缩包的\"sha256\"以供bioconda校验\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$sha256sum</span> v1.0.0.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n<B>Step1：fork bioconda-recipes</B>\n<br/>\n<p>(1) 进入 bio-conda <a href=\"https://github.com/bioconda/bioconda-recipes\">GitHub 页</a>；</p>\n<br/>\n(2)点击右上角的 “Fork”；\n<br/>\n(3)操作完成后在用户自己的 GitHub 内得到了一份 “<USERNAME>/bioconda-recipes”，我的用户名为 “liaochenlanruo”，因此我得到的是 “liaochenlanruo/bioconda-recipes”。\n<br/>\n<B>Step2：将项目克隆到本地</B>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> clone https://github.com/liaochenlanruo/bioconda-recipes.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n<B>Step3: Then add the main bioconda-recipes repo as an upstream remote to more easily update your branch with the upstream master branch:</B>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$cd</span> bioconda-recipes\n<span class=\"token variable\">$git</span> remote <span class=\"token function\">add</span> upstream https://github.com/bioconda/bioconda-recipes.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<br/>\n<B>Step4：更新 repo</B>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> checkout master\n<span class=\"token variable\">$git</span> pull upstream master\n<span class=\"token variable\">$git</span> push origin master<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<br/>\n<B>Step5：写自己的 recipe</B>\n<br/>\n例如，创建并切换到一个名字为 “pgcgap” 的 新分支\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> checkout -b pgcgap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n<p>在 &quot;bioconda-recipes/recipes/&quot; 目录下新建 &quot;pgcgap&quot; 目录，并将撰写好的<a href=\"https://docs.conda.io/projects/conda-build/en/latest/resources/build-scripts.html\"> build.sh</a> 和<a href=\"https://docs.conda.io/projects/conda-build/en/latest/resources/define-metadata.html#architecture-independent-packages\"> meta.yaml</a> 存入其中。</p>\n<br/>\n注：Step6和Step7可以跳过\n<br/>\n<B>Step6：本地测试 recipe</B> （可选，即可以直接在线测试）\n<br/>\n在\"bioconda-recipes/\"目录下依次运行如下命令：\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$./bootstrap.py /tmp/miniconda\n<span class=\"token variable\">$source</span> ~/.config/bioconda/activate\n\n<span class=\"token comment\"># optional linting</span>\n<span class=\"token variable\">$bioconda</span>-utils lint recipes config.yml --git-range master\n\n<span class=\"token comment\"># build and test</span>\n<span class=\"token variable\">$bioconda</span>-utils build recipes config.yml --docker --mulled-test --git-range master<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<br/>\n<B>Step7：更新 recipes</B> (可选）\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$bioconda</span>-utils update-pinning recipes/ config.yml --packages pgcgap --create-pr<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n<B>Step8：推送修改，等待测试通过，提交 pull 请求</B>\n<br/>\n(1) 将本地更改同步到自己的pgcgap分枝\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$git</span> push -u origin pgcgap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<br/>\n<p>(2) 在 “liaochenlanruo/bioconda-recipes” 的 “pgcgap” 分支下点击 “New pull request”。base repository 选择 “liaochenlanruo/bioconda-recipes”，base 选择 “pgcgap”；head repository 选择 “bioconda/bioconda-recipes”，compare 选择 &quot;master&quot;。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/new_pull_request_LI.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/new_pull_request_LI.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"new_pull_request\" /></p>\n<center>Create a new pull request</center>\n<br/>\n<p>比较完成后提交，标题自定义，内容根据提示酌情填写。若存在问题可以 @其<a href=\"https://bioconda.github.io/#core\">核心团队成员</a>中的任何一位，如输入 “@epruesse”，将会 @ Elmar Pruesse。若想成为 bioconda 成员，以及要 merge 自己的分支，同样需要 @核心成员中的任何一位。</p>\n<p>实例：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/create_pull_request_info.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/create_pull_request_info.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"create_pull_request_info\" /></p>\n<center>Request 信息填写</center>\n<br/>\n上述步骤完成后，可以在GitHub项目下的“Pull requests”选项卡下查看处理状态。\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/view_pull_request.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/view_pull_request.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"view_pull_request\" /></p>\n<center>查看pull request</center>\n<br/>\n根据提示修改自己的recipe，再次pull，循环往复，直至修复所有错误（下图表示需要修改）。\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/pull_error.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/pull_error.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"pull_error\" /></p>\n<center>pull出错了</center>\n<br/>\n点击“details”可以查看进程和详细信息。下图所示，正在测试recipe。\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/bioconder_checking2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/bioconder_checking2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"bioconder_checking2\" /></p>\n<center>正在测试recipe</center>\n<br/>\n如下图所示，表明测试成功，等待管理员合并自己的分支。\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/test_success.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/test_success.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"test_success\" /></p>\n<center>所有测试均成功</center>\n<br/>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/bioconda_check.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/bioconda_check.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"bioconda_check\" /></p>\n<center>非Bioconda成员测试成功后的“Pull requests”界面</center>\n<br/>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/squash_and_merge.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/squash_and_merge.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"squash_and_merge\" /></p>\n<center>Bioconda成员测试成功后的“Pull requests”界面</center>\n<br/>\n如上两图分别为非bioconda成员以及bioconda成员测试通过的界面，非成员需要新建一条评论并 @一位核心成员，请求其merge自己的pull requests，bioconda成员则可以点击“Squash and merge”来合并自己的pull requests。\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/merge_successfully.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/merge_successfully.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"merge_successfully\" /></p>\n<center>Bioconda成员“Pull requests”合并成功</center>\n<br/>\n## 附：\n1. 加入bioconda\n<p>1）在第一个 recipe 推送成功后可以在评论中 @ 一位核心成员，要求加入组织<br />\n 2）收到邀请链接，点击加入</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/invited2bioconda.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/papers/invited2bioconda.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"invited2bioconda\" /></p>\n<center>被邀请加入Bioconda</center>\n<br/>\n## 常见错误\n1. If linting fails：\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> checkout master\n<span class=\"token function\">git</span> pull upstream master\n<span class=\"token function\">git</span> checkout pgcgap\n<span class=\"token function\">git</span> merge master<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Github","path":"api/tags/Github.json"},{"name":"Bioconda","path":"api/tags/Bioconda.json"}]},{"title":"CAZy碳水化合物活性酶预测","slug":"CAZy碳水化合物活性酶预测","date":"2021-09-30T01:18:19.000Z","updated":"2022-01-08T02:16:28.396Z","comments":true,"path":"api/articles/CAZy碳水化合物活性酶预测.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg","content":"<h1 id=\"cazy数据库简介\"><a class=\"markdownIt-Anchor\" href=\"#cazy数据库简介\"></a> CAZy 数据库简介</h1>\n<p><a href=\"http://www.cazy.org/Home.html\">CAZy</a> 全称为 Carbohydrate-Active enZYmes Database，碳水化合物酶相关的专业数据库，内容包括能催化碳水化合物降解、修饰、以及生物合成的相关酶系家族。其包含五个主要分类：糖苷水解酶（Glycoside Hydrolases, GHs）、糖基转移酶（GlycosylTransferases, GTs）、多糖裂解酶（Polysaccharide Lyases, PLs）、糖酯酶（Carbohydrate Esterases, CEs）和氧化还原酶（Auxiliary Activities, AAs）。此外，还包含与碳水化合物结合结构域（Carbohydrate-Binding Modules， CBMs）。五大分类和一个结构域下，都分别建立了多个 Family。</p>\n<ul>\n<li>\n<p><a href=\"http://www.cazy.org/Glycoside-Hydrolases.html\">GHs</a>：糖苷键的水解和 / 或重排</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/GlycosylTransferases.html\">GTs</a>：糖苷键的形成</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Polysaccharide-Lyases.html\">PLs</a>：糖苷键的非水解裂解</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Carbohydrate-Esterases.html\">CEs</a>：水解碳水化合物的酯类</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Auxiliary-Activities.html\">AAs</a>：与 CAZymes 协同作用的氧化还原酶</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Carbohydrate-Binding-Modules.html\">CBMs</a>：与碳水化合物结合</p>\n</li>\n</ul>\n<h1 id=\"cazy数据库的准备\"><a class=\"markdownIt-Anchor\" href=\"#cazy数据库的准备\"></a> CAZy 数据库的准备</h1>\n<p>在进行预测之前需要准备数据库，CAZy 貌似没有提供 FASTA 格式的序列数据库，而仅提供了序列的 Assenssion number，需要我们自己从 NCBI 数据库中下载序列。下载方法参照我之前的文章《<a href=\"https://liaochenlanruo.github.io/post/e7e9.html\">根据 assession number 批量从 NCB 下载数据</a>》，在文章中提供了下载 CAZy 序列的方法和脚本，此处不再赘述。</p>\n<p>在上一篇文章结尾获得的 “All.sequences.fas” 文件包含了所有的 CAZy 数据库序列，在正式预测之前需要完成数据库的格式化。后面我们将通过 Diamond 软件从基因组中预测 CAZy 蛋白，因此采用 Diamond 格式化数据库。</p>\n<ul>\n<li>\n<p>序列预处理</p>\n<p>不知道什么原因，下载的序列存在两个问题，其一，下一条序列的 ID 连接着上一条序列的末尾，没有断行；其二，序列中存在着一段网页代码。因此，需要分两步进行修正。</p>\n<ul>\n<li>\n<p>解决断行问题</p>\n<p>撰写脚本 “add_linebreak.pl”，内容如下：</p>\n  <pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span><span class=\"token operator\">=</span><span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"All.sequences.fas\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.fas\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\">$_\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将脚本与 &quot;All.sequences.fas&quot; 放在同一目录下，在终端或者命令行中运行如下命令，得到 “CAZy.fas”。</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl add_linebreak.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>删除无关内容</p>\n<p>用 EmEditor 软件打开 CAZy.fas，Ctrl+F 调出查找功能，搜索 “www.” 可以看到如下内容，手动将其删除，并保存文件。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"数据库中需要手动删除的网页信息\" /></p>\n</li>\n</ul>\n</li>\n<li>\n<p>构建 Diamond 数据库</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond makedb --in CAZy.fas -d CAZy<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"开始序列比对\"><a class=\"markdownIt-Anchor\" href=\"#开始序列比对\"></a> 开始序列比对</h1>\n<p>当然，我们选择用 Perl 进行批量比对</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有后缀为“.faa”的文件，可以自己更改</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".CAZy.diamond\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token comment\"># -p表示线程数，在笔记本上用6个即可</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"diamond blastp -d CAZy -q $_ -e 1e-5 -f 6 -o $out -k 1 --sensitive -p 30 --query-cover 50\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “run_diamond_CAZy.pl”，将其和序列文件放在同一目录下，并在终端中输入如下命令，完成分析，得到 “*.CAZy.diamond”：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_diamond_CAZy.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"比对结果过滤\"><a class=\"markdownIt-Anchor\" href=\"#比对结果过滤\"></a> 比对结果过滤</h1>\n<p>在比对过程中我们控制了 evalue 和 query coverage，但是没有控制 identity。但是很多时候，需要设定一个 identity 的阈值，低于阈值的比对将会被删除，该步骤可以将比对结果拷贝到 Excel 中根据 identity 排序，手动删除阈值以下的行，然而我选择用 Perl 批处理。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@cazy</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.CAZy.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@cazy</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).CAZy.diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".CAZy.diamond.filtered\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">40</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “filter_cazy_diamond.pl”，将其和上一步产生的文件放在同一目录下，并在终端中输入如下命令，完成过滤，保留 identity &gt;= 40% 的行，得到 “*.CAZy.diamond.filtered”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl filter_cazy_diamond.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"你以为完了还得mapping\"><a class=\"markdownIt-Anchor\" href=\"#你以为完了还得mapping\"></a> 你以为完了？还得 mapping！</h1>\n<p>得到的结果如下图所示，第二列的 Hits 是 NCBI 的 Assession number，我们根本只知道这是什么 CAZy 家族，因此需要 mapping！</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Diamond比对结果\" /></p>\n<p>回头找到我们下载的<a href=\"http://www.cazy.org/IMG/cazy_data/cazy_data.zip\"> cazy_data.txt</a>，里面保存的是 CAZy 家族与 Assession number 的对应关系。比较闲的兄弟可以用查找 - 复制 - 粘贴的方法将 “*.CAZy.diamond.filtered” 中的 Assession number 替换为 CAZy 家族。我为比较忙的兄弟准备了下面的代码，批处理。不过我输出的是一个矩阵。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%cazy</span><span class=\"token punctuation\">;</span>\n\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"cazy_data.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@filtered</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.CAZy.diamond.filtered\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@filtered</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).CAZy.diamond.filtered/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sample</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$samples</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@line</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@ids</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@ids</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$ids[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “<a href=\"http://assession2cazy.pl\">assession2cazy.pl</a>“，将其和”cazy_data.txt“，及上一步产生的文件 “*.CAZy.diamond.filtered” 放在同一目录下，并在终端中输入如下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl assession2cazy.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>得到一个矩阵 “CAZy.Matrix.txt”，内容如下，行为 CAZy 家族，列为基因组 / 样本名。拿到本文件后，可以做热图看 CAZy 家族在各样本中的分布情况，然而这个热图将会比鞋帮子脸还要长，可读性不高，因此我选择将这些 family 合并为大类，生成一个新的矩阵。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Mapping后的矩阵\" /></p>\n<p>二话不说，上代码。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%category</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$count</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"CAZy.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$count</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$count</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+?)\\d+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$cate</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$category</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cate</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$i</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cate</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.Category.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@category</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%category</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@category</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$category</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$category</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$category[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “<a href=\"http://cazyfamily2categories.pl\">cazyfamily2categories.pl</a>”，将其和上一步产生的文件 “CAZy.Matrix.txt” 放在同一目录下，并在终端中输入如下命令，得到文件 “CAZy.Category.Matrix.txt”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl cazyfamily2categories.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_4.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_4.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"CAZy.Category.Matrix.txt内容概览\" /></p>\n<p>接下来是要做柱状图还是 heatmap，就随便了。</p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “9052” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"CAZy","path":"api/tags/CAZy.json"},{"name":"SY179","path":"api/tags/SY179.json"}]},{"title":"NCBI上传基因簇之tbl2asn的使用","slug":"NCBI上传基因簇之tbl2asn的使用","date":"2021-11-12T11:47:28.000Z","updated":"2022-01-08T02:16:28.406Z","comments":true,"path":"api/articles/NCBI上传基因簇之tbl2asn的使用.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>向<a href=\"https://www.ncbi.nlm.nih.gov/\"> NCBI</a> 提交基因簇的时候需要提供 sqn 格式的文件，这个文件需要通过<a href=\"https://www.ncbi.nlm.nih.gov/genbank/tbl2asn2/\"> tbl2asn</a> 生成。</p>\n<h1 id=\"文件准备\"><a class=\"markdownIt-Anchor\" href=\"#文件准备\"></a> 文件准备</h1>\n<p>tbl2asn 依赖三个文件来生成 sqn 文件：</p>\n<ul>\n<li>文件 1：fasta 格式的基因组序列文件</li>\n</ul>\n<p>Header 处的中括号部分可以不写。</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">&gt;Toyoncin_biosynthesis_gene_cluster [organism&#x3D;Bacillus toyonensis] [strain&#x3D;XIN-YC13] [topology&#x3D;linear] [moltype&#x3D;DNA] [tech&#x3D;wgs] [gcode&#x3D;11] [country&#x3D;China] Bacillus toyonensis strain XIN-YC13 Toyoncin biosynthesis gene cluster, complete sequence\nttaaaa taatttaata\ngggaagtttt ttagttgttt tggactcttc ccaaacactg ctttaagtgt tggattaaca\n tcatccctat tccccgaaaa cataatgtga ggatttatga ataatgcata tgctctaaca\nttattatcat caacaccact ctctgaacga gccataatac ccttatcaat taattttcta\naccaatggac taactttagt ttcatgtctt ccaatttttt tagctaattc tcgctgagtt\n aatgggattt gttctttcga attaatatca ttaactaaac aattacttaa aaaacctaca\ncacattgaaa tatctactaa aaataccttc tcagcatttg ttaaataatc aatttcgaac\n aaatactgga tattttgttg aataatctga acaaacttcg ctttattttt cactttacgc\n tcaggaacta atttcattcc tcttgaacga gcttttgatt gaagtttatt tgctaaatac\n atctcttctt cagacaagac ctttaaatcc tcaatatctc tcaatcttga atttttttca\n gcttgttcta agttgataaa ctttgacata ttctttttgc tcctcttttc taagattttc\n aactagagaa ggaaaaaatt ttatgttatg attcctgtag aatttacaat tcaatatgta\n caaaagaact ccccttttct aattgatagt ttggtcgctt tcaattataa tacaagggga\n ttttttacat cttaaaattt ttcatttttg aatcaatccc tgaaaatata aagaacacat\n cacataaatt attcttaata ttttataatc gaaaaaataa taggaataaa gaaaaatact\n gcaataaata tattcatctg tttcttactc aaaccggcca ctatatttaa tcccattcct\n ataataatta attcccaaat tgaaaacact tcaaatttac tacaaattat atatagtaat\n gtacctggtt caaatattga acccaaacta gtatacgtta ctatttctcc tcctataaat\n agtgttaata atgtattaat taatttacct aaaatagaaa ttacactagc aaatattgta\n atagatacta actttttata agaaacatct ttactcatca gcatcattac aatctttaaa\n ataatccccc aaataaaagg tgtaattaaa gcaatgaaaa tcgatgcaaa acctcctaac\n atcatttggg aaacaagggg tatttccata tctgcaaata cttctttttg aattttaacc\n aattctggat tgctatgtct tgcatataca gataaaatcc ctattattgc ttgtataact\n gataaataca taagaggaaa ccatatcgga ctaattattt tcatacgctc gaattcagaa\n ataggagatg taatcataaa aattagagat ggtttttcat aattgttttt ttctttattc\n actactaaac tattatccat atattaacac cttctttttt tattcataac gtaatgcttc\n aattggatct aattttgcag ccttattggc tggaatcaat ccaaatataa taccaagcga\n catcgaaaat aatacgccac ccacaacaac ttcccatgaa acaagaggcg gccattttgc\n aaatgtggac acaatgtacg ctccacaata accaagtcca atcccaatca atccaccaag\n aagtgtcaac ataattgctt caattaaaaa ttgcaacaaa attttaccac gcgttgctcc\naagtgcttta cgtaccccaa tctcacgtgt acgctctgtt acagaaacaa gcatgatatt\ncataactcca attccgccta caactaaaga aatacttgca atacctgcaa taatcattgt\ncataatatta gtaactttag aaataccttt ttggatttct tctaaattta caatttcata\n tttcccttta aactcttcag attgtctatc atttaataat tttactccct tttttccagc\ntgtttgtaat tgatcaaccc ctattgcttg aattgtaata gattgttgag agttatcatc\n tccatataat attggccata ttgaaagtgg tattaaaatt tctgacattc caaaaccaag\n ctcttcatct cctgaactga atagaccaat aatttgaagt ggctgacctt taatttctat\n aattttacca atgactgatt catgctcatt aggaaataac tctttcacta atgtttgatt\n aaccattatt acattattac cttgcatcaa atcatcttca ttaagagaac gacctttctc\n tattttcatt ttagtcatat taaaatattc ttttgtaata ccatttatat tagttacaac\nctttttatca tcaccaatta atgtctctgt actagagttt tgaacaatta catttttaat\n ttcttttatc ttttttaact caaaaagatc ttcttcactt acagatggtt ttttgtcatt\n catagatcct gttgttaata actcattaat atcttcttta tatgtaatcg gaatagtgtt\n attgccagaa gcggtaaatt gtgatttaag cattgcttct ccacctttac caatggctac\n aacagtaata atagaaccta caccaataat aattccaagc atcgtaagag ctgagcgcag\n tttatgagct aaaatagaag ataaggcaat ttttatacta tctaataaac tcataccata\n caccttctat cttctgtaat tttcccatct cgcaatatga tgcgacgtga agaataagct\n gctacctctt cttcatgtgt aaccataacg attgtcgtac cttctgcatt taacttcgta\n aagatatcca taacttgtgc accagacttc gtatcaagcg caccagttgg ctcatcagcc\n ataataaacg ttggattatt cgcaatcgat cttgcaatag caacacgctg cttctgtcca\n cctgacagct cactaggtaa atgatgtact ctatccgcta atccaacttt cccaagcgct\n tcgagcgctc tttgacgacg ctctgctttc ttcactccac cataaatcag tggtaattca\n acgttttcca ctgcggaaag gcgcggcaat aaattaaaat gctggaacac aaaaccgata\ntattcattac gaattaaagc aagttttgac tcatctgctg ttaaaatatt cacatcattc\nagcatatatt cgccttctgt tggacgatct aaacaaccga taatattcat aagagttgat\nttaccagaac cagacggtcc cataattgaa acaaattcac caccttgaat agttaaacta\nataccgtgca aaataggaac cgccattttt ccttgataat acgttttagc aatattattt\naacgtaatca tttctctttc acttccattc cgtcatatac gttgtcggaa ggatttttaa\nccaccttttg ccccactgtt gcgccctcta caatctctgt ccaatctcca tcagtagcac\ncttttttcac attttgttta cgaagcttac ctttctcttc gatatataca aatgcatcat\n      cgcctttttc aacaatactc ttacttggaa cagcaatcat tcttttattc tctaaattta\n      cttgtaacga aacatgataa cctggagata aaccatcttg actatcaaga cttgctttat\n      atgtatattg agacatattt tgagtcactt cccccatgcc atcagcttga gccatttcta\n      cacttgttgg gaactcactt acctctgtaa tcttccctgt ccactttttc ttactatttg\n      ctttcgcagt tacagtaaac gtttgatcct tttgaatttg cgacttctga agctcagtta\n      atgttccttg aatttggaat ggatctttag aagcaacttg taaaaaggct ttcccttgac\n      cacctaacgc ttgtgatgaa ctttgtgctg catctttatc taacttttga acaacaccag\n      caaaattgct ataaatcgta agttcgttct gctttttatt taactcttct ttttgtaact\n      tccctttctc tttctcaagg tctgttgtct tttgcgctat ttctaattca cttacttgct\n      cttccatcgg atctattact tctttcccag ctccgctatc tttcgccttc ttaatttctt\n      tcttcaacga atcaatcttc tttttccctt ggtcataacg catatctgcc atcttttgat\n      caagcacagc ttgcttcatt tgcaaattaa tttcttcatt atcgtaagaa aacaatttcg\n      ttcccttttc tatttcttgt ccttctttca cttcaatatc tttcactttt cctttagtca\n      gatccgcgta gaaactttca atattccccg gcttcacttg accagaaatt aactttgtat\n      tattaagatt gcgctctgtg actttttcaa aactaacagt atctattttt gttaccgctt\n      tcttcttact ttgcactacg aaaatattaa taaatgtaac aataacaatt aacgcaataa\n      ctccaataat agctcctttc tttttatttt taaaaataaa aagttctttt ttaatcacaa\n      caatcttctc cttattcata tctaaaattt aaacttttaa attttacata aaaatttaaa\n      acttctaaaa tataacatgt ataatttacc atagatgatt tattttgtat aatataaaaa\n      tatctatata aataatgcta attttcaaac aatggggtgg aagatactaa tgttagaaaa\n      aaaagataga ctaacagaaa tagaggaaca aattatatac ttaatttcaa aggaattagg\n      aaataaagaa atagcggaaa aattaaatta ttcacaacgt agcatcggtt acaaaataaa\n      taatattttt aaaaaattaa atgttaattc aagaatcgga ctgattatag aagctgtaaa\n      aaaaaatata atttaaatat aagaatgctt tcatgttaat attttataga aactaaatat\n      agaggtgatt aaaatgcaaa aattttttga agctattagt gctataggta tagtaggtta\n      ctttttaggt aaattcacaa gtattccttt aatagacaaa tatacattgt atttcggcgt\n      aatgttgatg attggggtta ttggaagatt tattataaaa gtaattaact cagaagaaga\n      gacacatgat tcaaacaaat aaaatactct aataaaaatg gaagaagatt gcacttaagt\n      gcaatcttct tccattttta ttgaaaattg attaaataat gttaatattg caattgtgtg\n      gtgcagatta gggtgattat gtaatagggg gaaattaaaa atgatcaata cagcttggaa\n      aattattaaa gcactacaaa aatacggtac aaaagcatac aatgttatca aaaaaggcgg\n      ccaagcaatg tacgacagct tcatggcagc taaagctaaa ggttggacac atgcagcttg\n      gtggctagta gaacatggtt caactttagg aacattctat gatttattaa aagctgctgg\n      attaatcgac taattacagc aactaaacaa ctaaacaact aaacaactta aaaatacaaa\n      ttaccctaaa ctgtacccct attacatatt aactaattat tttaaaggtt ggatgataat\n      atgtcaaata acatcatatc tgtaaaaaat ttaattaaaa gcttcgataa caaaatagta\n      ttagataaat taaatttcga aatgaaagaa aactccactg ttgtaataat aggtaaaaac\n      ggtgcaggta aaagtgtctt tctaaattgt ttacttggat ttattcatta caaccaaggt\n      tcaatactaa tagatggaca acctgtagaa aatcgattac atctccgcaa gattacatcg\n      ttaatttctt cagaccatca agaacatcta aatttattaa cccccaatga atatttttct\n      tttttacaag atatttacca actaaaaagt aataataaag acaaaattca aaattactca\n     gaagatctat atgttactaa agaactcaat actgtatttt catcactttc ttttggaaca\n     aaaaagaaaa tacaattaat tggtagccta ttatattctc ctaaattatt gatttgcgac\n     gaaatatttg aagggcttga tacagactca gtaaaatggg ttaaaaactt atttcaacaa\n     agaaaacaag aaaatctttc tactttattt acaactcata ttactgaaca tataacagat\n     ataacagaaa aaaattacat acttgaaaat ggaaaattaa ttgtgtaagt ttaaccactt\n     atatttaaag ctaaaattaa ggagcttaaa atatgaattt taatatatat aagagactat\n     atgataaatc aacagaagaa aaaagcaaaa caataacaaa acaaatatta tttggaatta\n     taaatagttc tatattaata ggtatactac tcacatgttt ggagattttc aactttaaaa\n     tttcaactgt aatgtatggt tatttcacta tatatataat actagaactt ttactattat\n     tctctgcaaa tcaactatat gaaagtacag aattcataat aaaattcctt aaatatacac\n     caataaccat aaataaacta tatttctcac attttctaag ttctaaatat tcattttcca\n     atctttttga aataataact ctcacatcaa ttttattaat atataatgtc gatatcttat\n     attcatttat tttcataatt agcttacaaa ttattagctt aataagaaca tatttagaat\n     ttttactatt atattctcaa aaaaaacagg ttaaaatttt tactctaacc cattttgttt\n     tcataatatc tatggttttt tatattattg ttaaaacaaa atcgatagat ttagtattct\n     ttgaaaacac aaatatgtta attatatctg ttcttctcat aacattcttg atatcacttt\n     taacatataa acatattata gaatacttaa tgaaaaataa tgaaattgta tataatgcta\n     tttttatcaa gttaactttt aacacagcta atttaattag taaattattt aaatttaata\n     catcaattgc atctttaata aaaatacata taatacgatt attacgtaat caagactata\n     taagtagatt actaaaaata ggaatattac tatttatttt ttcttctata agctttctat\n     ttttcgataa atcatcaaca aacaatgaaa tgagtgatat actttacttt tcatttttta\n     tttccttatt tagtttttct aacatacgat tagactataa cttagtttct aaattaagct\n     tagaggatta tccaataaca aaattacaat caagattaag cattgatata gcacatggaa\n     ttttactatt tatactatct ttatttcttt tattaacaca atacttattg aatccaacaa\n     atattctaac tctaattgat ggtttattat catttatttg tttttatttt ctaagtcttg\n     gtatagaaaa agcagatatt ataataacac caaaaacaaa atggaaaatg tatccattat\n     tttttgtgat gggattaata attgaagcaa tatttctatt aaaattcaaa atatggataa\n     aattaataac tttattcctt tgtatactgt ggtcatattt acgtgtttat tggaaattaa\n     aaaaacaata aacacaatta aaaagttccc ttcatatttt ttgaagggaa cttttatttt\n     aaacaaaaat tacaaacaag caaagttatt taaaagtaaa cttttaaaat tattgaatta\n     ataacaatta gtctaagata tatcagccaa atttaatttt taaacaaacc gaaaaaccct\n     ttccgttttt gtttctgatt ttggctctgt atttctctaa tgttttcaag caataactga\n     tctcgttttt caaatttttt ctctataaaa acctctaatt caatattttt atcttctact\n     tcctttaatt ttctctccgt attagccaaa tgttcttttg tggtaactaa ttcattcgta\n     atctcttgta atttttgaac aagcgtttga ttgaactgat tttgtaattg ttgattttct\n     aatacttcat ccaacttctt ttctaattcc gatttttcct ctcttgaaac aaacaaatca\n     agttctccat tccgccatgc tcgaacttga tcataagacc atttttgcac ctgtattttt\n     tctttaattg ctatcaattc ttctatattt tcctttgagt acctacgatg ccctccctga\n     cttcgctccg tttgtatatt aaattcgttt gaccatgctt ttaacaagtc aggggtaatc\n     cctaaacgat ccgcaacaat tttcggtgta tacatttctg attttaattc caa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>文件 2：描述基因特征的 feature table 文件（.tbl）</li>\n</ul>\n<p>该文件可以用 prokka 对文件 1 进行注释而得到，但是需要自己加以修改，加上文件前几行以及 gene 相关的信息。</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">&gt;Feature Toyoncin_biosynthesis_gene_cluster\n1\t8409\tsource\n\t\t\torganism\tBacillus toyonensis\n\t\t\tmol_type\tgenomic DNA\n\t\t\tstrain\tXIN-YC13\n585\t1\tgene\n\t\t\tgene\torf1\n585\t1\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00001\n\t\t\tproduct\tMarR family transcriptional regulator\n1476\t811\tgene\n\t\t\tgene\torf2\n1476\t811\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00002\n\t\t\tproduct\tYIP1 family membrane protein\n2710\t1496\tgene\n\t\t\tgene\torf3\n2710\t1496\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00003\n\t\t\tproduct\tABC transporter permease\n3387\t2707\tgene\n\t\t\tgene\torf4\n3387\t2707\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00004\n\t\t\tproduct\tABC transporter ATP-binding protein\n4595\t3384\tgene\n\t\t\tgene\torf5\n4595\t3384\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00005\n\t\t\tproduct\tRND family efflux transporter, MFP subunit\n4746\t4952\tgene\n\t\t\tgene\torf6\n4746\t4952\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00006\n\t\t\tproduct\tHelix-turn-helix transcriptional regulator\n5010\t5198\tgene\n\t\t\tgene\torf7\n5010\t5198\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00007\n\t\t\tproduct\tPutative membrane protein\n5337\t5549\tgene\n\t\t\tgene\ttoyA\n5337\t5549\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00008\n\t\t\tproduct\tToyonsin precusor\n5657\t6304\tgene\n\t\t\tgene\torf9\n5657\t6304\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00009\n\t\t\tproduct\tABC transporter ATP-binding protein\n6349\t7707\tgene\n\t\t\tgene\torf10\n6349\t7707\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00010\n\t\t\tproduct\tPutative membrane protein\n8391\t7849\tgene\n\t\t\tgene\torf11\n8391\t7849\tCDS\n\t\t\tinference\tab initio prediction:Prodigal:002006\n\t\t\tlocus_tag\tToyoncin_biosynthesis_gene_cluster_00011\n\t\t\tproduct\tMarR family transcriptional regulator<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>文件 3：描述作者信息的模板文件（.sbt）</li>\n</ul>\n<p>可以在<a href=\"https://submit.ncbi.nlm.nih.gov/genbank/template/submission/\"> NCBI</a> 上生成该文件。</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">Submit-block ::&#x3D; &#123;\n  contact &#123;\n    contact &#123;\n      name name &#123;\n        last &quot;xin&quot;,\n        first &quot;bingyue&quot;,\n        middle &quot;&quot;,\n        initials &quot;&quot;,\n        suffix &quot;&quot;,\n        title &quot;&quot;\n      &#125;,\n      affil std &#123;\n        affil &quot;Huaibei Normal University&quot;,\n        div &quot;College of Life Sciences&quot;,\n        city &quot;Huaibei&quot;,\n        sub &quot;Anhui&quot;,\n        country &quot;China&quot;,\n        street &quot;Dongshan road No.100&quot;,\n        email &quot;xinbingyuex@163.com&quot;,\n        postal-code &quot;235000&quot;\n      &#125;\n    &#125;\n  &#125;,\n  cit &#123;\n    authors &#123;\n      names std &#123;\n        &#123;\n          name name &#123;\n            last &quot;Xin&quot;,\n            first &quot;Bingyue&quot;,\n            middle &quot;&quot;,\n            initials &quot;&quot;,\n            suffix &quot;&quot;,\n            title &quot;&quot;\n          &#125;\n        &#125;\n      &#125;,\n      affil std &#123;\n        affil &quot;Huaibei Normal University&quot;,\n        div &quot;College of Life Sciences&quot;,\n        city &quot;Huaibei&quot;,\n        sub &quot;Anhui&quot;,\n        country &quot;China&quot;,\n        street &quot;Dongshan road No.100&quot;,\n        postal-code &quot;235000&quot;\n      &#125;\n    &#125;\n  &#125;,\n  subtype new\n&#125;\nSeqdesc ::&#x3D; pub &#123;\n  pub &#123;\n    gen &#123;\n      cit &quot;unpublished&quot;,\n      authors &#123;\n        names std &#123;\n          &#123;\n            name name &#123;\n              last &quot;Xin&quot;,\n              first &quot;Bingyue&quot;,\n              middle &quot;&quot;,\n              initials &quot;&quot;,\n              suffix &quot;&quot;,\n              title &quot;&quot;\n            &#125;\n          &#125;\n        &#125;\n      &#125;,\n      title &quot;Purification and characterization of a novel leaderless bacteriocin, toyoncin, produced by Bacillus toyonensis XIN-YC13 that specifically active against Bacilus cereus and Listeria monocytogenes&quot;\n    &#125;\n  &#125;\n&#125;\nSeqdesc ::&#x3D; user &#123;\n  type str &quot;Submission&quot;,\n  data &#123;\n    &#123;\n      label str &quot;AdditionalComment&quot;,\n      data str &quot;ALT EMAIL:xinbingyuex@163.com&quot;\n    &#125;\n  &#125;\n&#125;\nSeqdesc ::&#x3D; user &#123;\n  type str &quot;Submission&quot;,\n  data &#123;\n    &#123;\n      label str &quot;AdditionalComment&quot;,\n      data str &quot;Submission Title:None&quot;\n    &#125;\n  &#125;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>注意</strong>：文件 1 和文件 2 的序列描述信息必须一致，此例中均为 “Toyoncin_biosynthesis_gene_cluster”。</p>\n<h1 id=\"文件生成\"><a class=\"markdownIt-Anchor\" href=\"#文件生成\"></a> 文件生成</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tbl2asn -t template.sbt -p ./ -V vb -x .fna<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>-t 模板文件<br />\n - p 输入文件所在路径<br />\n - V<br />\n-v 生成验证文件，保存错误信息<br />\n - b 生成 gbf 文件<br />\n - x 文件 1（FASTA 文件）的后缀名</p>\n<p><strong>注意</strong>：不知什么原因，生成的 sqn 和 gbf 文件中的日期通常是 1-JAN-2019，需要自己手动改正为当前时间。</p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/genbank/tbl2asn2/\">tbl2asn</a></li>\n<li><a href=\"http://www.chenlianfu.com/?p=2171\">上传基因组数据到 NCBI</a></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"NCBI","path":"api/tags/NCBI.json"},{"name":"序列处理","path":"api/tags/序列处理.json"},{"name":"生信软件","path":"api/tags/生信软件.json"}]},{"title":"OrthoFinder2—同源蛋白家族聚类","slug":"OrthoFinder2—同源蛋白家族聚类","date":"2019-03-20T02:42:16.000Z","updated":"2022-01-08T02:16:28.408Z","comments":true,"path":"api/articles/OrthoFinder2—同源蛋白家族聚类.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/orthofinder01.png","content":"<p>寻找同源蛋白家族用的比较多的是 Orthomcl，但是该软件多年前已经停止更新，且使用的时候需要安装和使用 MySQL，操作起来比较繁琐。因此 OrthoFinder 应运而生，并且更新到版本 2。后者不但可以寻找同源家族，并且可以构建基因家族进化树。</p>\n<span id=\"more\"></span>\n<ol>\n<li>OrthoFinder 及依赖包的安装</li>\n</ol>\n<ul>\n<li>下载</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/davidemms/OrthoFinder/releases/download/v2.2.7/OrthoFinder-2.2.7.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>解压</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">tar</span> zxvf OrthoFinder-2.2.7.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>安装（加入环境变量即可）</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> ~/.bashrc\n\ni\n\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token environment constant\">$HOME</span>/tools/OrthoFinder-2.2.7\n\nEsc\n\n<span class=\"token builtin class-name\">shift</span> + <span class=\"token punctuation\">;</span>\n\nwq<span class=\"token operator\">!</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>依赖包</p>\n<p>（1）<a href=\"url:https://github.com/bbuchfink/diamond/releases\">DIAMOND</a></p>\n<p>下载对应版本，解压并将主程序拷贝至存在于环境变量的目录下或将其所在的目录加入环境变量：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/bbuchfink/diamond/releases/download/v0.9.24/diamond-linux64.tar.gz\n\n<span class=\"token function\">tar</span> xzf diamond-linux64.tar.gz\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> diamond /usr/local/bin<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>没有 root 权限的可以把 diamond 所在目录加入环境变量。</p>\n<p>(2) <a href=\"url:https://github.com/soedinglab/MMseqs2/releases\">MMseqs2</a></p>\n<p>下载对应版本，解压并将主程序拷贝至存在于环境变量的目录下或将其所在的目录加入环境变量：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/soedinglab/MMseqs2/releases/download/7-4e23d/MMseqs2-Linux-AVX2.tar.gz\n\n<span class=\"token function\">tar</span> xzf MMseqs2-Linux-AVX2.tar.gz\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> mmseqs2/bin/mmseqs /usr/local/bin<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>(3) <a href=\"url:http://micans.org/mcl/\">MCL</a></p>\n<ul>\n<li>Ubuntu, Debian, Linux Mint 安装方法：</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> mcl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Centos, Redhat 安装方法：</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://micans.org/mcl/src/mcl-latest.tar.gz\n<span class=\"token function\">tar</span> zxvf mcl-latest.tar.gz\n<span class=\"token builtin class-name\">cd</span> mcl-14-137（视具体情况而定）\n./configure\n<span class=\"token function\">make</span>\n<span class=\"token function\">make</span> check\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>(4) <a href=\"url:http://www.atgc-montpellier.fr/fastme/binaries.php\">FastME</a></p>\n<p>下载二进制文件，解压并将主程序拷贝至存在于环境变量的目录下或将其所在的目录加入环境变量：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> http://www.atgc-montpellier.fr/download/sources/fastme/fastme-2.1.5.tar.gz\n<span class=\"token function\">tar</span> zxvf fastme-2.1.5.tar.gz\n<span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> fastme-2.1.5/binaries/fastme-2.1.5-linux64 /usr/local/bin/fastme<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>(5) 可选: <a href=\"url:ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/\">BLAST+</a></p>\n<ul>\n<li>Ubuntu, Debian, Linux Mint 安装方法：</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> ncbi-blast+<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Centos, Redhat 安装方法：</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.8.1+-x64-linux.tar.gz\n<span class=\"token function\">tar</span> zxvf ncbi-blast-2.8.1+-x64-linux.tar.gz\n<span class=\"token function\">vim</span> ~/.bashrc\ni\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token environment constant\">$HOME</span>/tools/ncbi-blast-2.8.1+/bin\nEsc\n<span class=\"token builtin class-name\">shift</span> + <span class=\"token punctuation\">;</span>\nwq<span class=\"token operator\">!</span>\n<span class=\"token builtin class-name\">source</span> ~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ol start=\"2\">\n<li>运行 OrthoFinder<br />\n (1) 运行示例数据：</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> OrthoFinder-2.2.7\northofinder -f ExampleData<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>运行结果如下，会显示输出文件的路径，表明运行成功：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/orthofinder01.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/orthofinder01.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"示例数据运行结果\" /></p>\n<p>(2) 运行自己的数据：</p>\n<ul>\n<li>step1：数据准备</li>\n</ul>\n<p>下载氨基酸序列，要求为 fasta 格式，每个物种一个文件。将所有 fasta 文件存于一个目录中（如 Data 目录），如下图所示。文件名要简洁并有区分性，因为文件名会作为最终的物种 ID。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/orthofinder02.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/orthofinder02.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"目录结构与文件准备\" /></p>\n<ul>\n<li>step2：运行程序</li>\n</ul>\n<p>在 Data 目录的上一级目录打开终端，运行如下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">orthofinder -f Data -t 线程数<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ol start=\"3\">\n<li>结果解读</li>\n</ol>\n<p>(1) Results Files: Orthogroups</p>\n<p>包含一个主文件 “Orthogroups.csv” 和两个支持文件：</p>\n<ul>\n<li>\n<p>Orthogroups.csv，每一行为一个 group，每一列为一个物种，行列交汇处为基因名称。</p>\n</li>\n<li>\n<p>Orthogroups_UnassignedGenes.csv，包含所有未分配到任何 group 的基因名称。</p>\n</li>\n<li>\n<p>Orthogroups.txt，OrthoMCL 格式的输出结果，内容等同于 Orthogroups.csv。</p>\n</li>\n</ul>\n<p>（2）Results Files: Orthogroup Statistics</p>\n<p>包含一些统计数据，可用于比较基因组分析、绘图以及质控。</p>\n<ul>\n<li>\n<p>Statistics_Overall.csv 和 Statistics_PerSpecies.csv，提供基本的描述信息</p>\n</li>\n<li>\n<p>Orthogroups_SpeciesOverlaps.csv，两两物种的 group 共享矩阵</p>\n</li>\n<li>\n<p>Species-specific orthogroup：该 group 仅包含一个物种的基因。</p>\n</li>\n<li>\n<p>G50：group 中的基因数，使得 50％的基因处于该大小或更大的 group 中。</p>\n</li>\n<li>\n<p>O50：最小数量的 group，使得 50％的基因处于该大小或更大的 group 中。</p>\n</li>\n<li>\n<p>Single-copy orthogroup：每个物种中只有一个基因的 group（相当于单拷贝核心基因）。这些 group 是构建物种树和许多其他分析的理想选择。</p>\n</li>\n<li>\n<p>Unassigned gene：未与任何其他基因划分到一个 group 的基因。</p>\n</li>\n</ul>\n<p>(3) Results Files: Orthologues</p>\n<p>两两物种间的直系同源基因，每一行为一个 group，第一列为 group 编号，第二列为第一个物种的基因，第三列为第二个物种的基因。同一物种的基因名以 “,” 分割。直向同源物可以是一对一，一对多或多对多。</p>\n<p>(4) Results Files: Gene Trees and Species Tree</p>\n<p>每个 group 的基因树和定根的物种树以 newick 格式输出，可以用各种看树软件展示，如 MEGA、iTOL、Dendroscope 和 FigTree 等，个人推荐用 iTOL。</p>\n<ol start=\"4\">\n<li>高级用法</li>\n</ol>\n<p>（1）添加新物种到之前的分析<br />\n（previous_orthofinder_directory 指的是包含 “SpeciesIDs.txt” 的目录）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">orthofinder -b previous_orthofinder_directory -f new_fasta_directory<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>（2）从之前的分析中移除物种</p>\n<p>从输出目录下找到工作目录 “WorkingDirectory” 中的 “SpeciesIDs.txt” 文件，在要移除的物种那一行最前面加上一个 “#” 并保存，然后运行（previous_orthofinder_directory 指的是包含 “SpeciesIDs.txt” 的目录）：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">orthofinder -b previous_orthofinder_directory<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>（3）同时添加和删除物种</p>\n<p>编辑好 “SpeciesIDs.txt” 后，运行：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">orthofinder -b previous_orthofinder_directory -f new_fasta_directory<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>（4）更多高级功能请阅读官方文档<br />\n主要包括 “Inferring MSA Gene Trees”、并行计算、单独运行 BLAST、使用预先计算的 BLAST 结果以及回归检测。</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"同源家族","path":"api/tags/同源家族.json"}]},{"title":"R语言安装依赖包错误集锦","slug":"R语言安装依赖包错误集锦","date":"2021-11-02T04:56:45.000Z","updated":"2022-01-08T02:16:28.412Z","comments":true,"path":"api/articles/R语言安装依赖包错误集锦.json","excerpt":null,"keywords":null,"cover":null,"content":"<h1 id=\"devtools安装错误\"><a class=\"markdownIt-Anchor\" href=\"#devtools安装错误\"></a> devtools 安装错误</h1>\n<h2 id=\"xml包-安装之-error-configuration-failed-for-package-xml\"><a class=\"markdownIt-Anchor\" href=\"#xml包-安装之-error-configuration-failed-for-package-xml\"></a> XML 包 安装之 ERROR: configuration failed for package ‘XML’</h2>\n<ul>\n<li>\n<p>CentOS 解决方案</p>\n<p>在 Linux 终端中运行如下命令即可：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> -y libxml2-devel<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"qiime2r安装错误\"><a class=\"markdownIt-Anchor\" href=\"#qiime2r安装错误\"></a> qiime2R 安装错误</h1>\n<h2 id=\"rjcommonh1121-fatal-error-jpeglibh-no-such-file-or-directory\"><a class=\"markdownIt-Anchor\" href=\"#rjcommonh1121-fatal-error-jpeglibh-no-such-file-or-directory\"></a> rjcommon.h:11:21: fatal error: jpeglib.h: No such file or directory</h2>\n<p>该错误是安装依赖包 “jpeg” 时发生的。</p>\n<ul>\n<li>\n<p>CentOS 解决方案</p>\n<p>在 Linux 终端中运行如下命令即可：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> <span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> -y libjpeg-turbo-devel.x86_64<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"R语言","path":"api/tags/R语言.json"},{"name":"软件","path":"api/tags/软件.json"}]},{"title":"Swissprot数据库的本地化与序列比对并与其他数据库快速mapping","slug":"Swissprot数据库的本地化与序列比对","date":"2021-09-28T08:13:44.000Z","updated":"2022-01-08T02:16:28.416Z","comments":true,"path":"api/articles/Swissprot数据库的本地化与序列比对.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg","content":"<h1 id=\"数据库下载与构建\"><a class=\"markdownIt-Anchor\" href=\"#数据库下载与构建\"></a> 数据库下载与构建</h1>\n<h2 id=\"下载\"><a class=\"markdownIt-Anchor\" href=\"#下载\"></a> 下载</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"构建\"><a class=\"markdownIt-Anchor\" href=\"#构建\"></a> 构建</h2>\n<ul>\n<li>\n<p>解压缩</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gunzip -d uniprot_sprot.fasta.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>构建 blast + 数据库</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">makeblastdb -in uniprot_sprot.fasta -dbtype prot -out uniprot_sprot -parse_seqids<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>构建 DIAMOND 数据库</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond makedb --in uniprot_sprot.fasta -d uniprot_sprot_diamond<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"比对\"><a class=\"markdownIt-Anchor\" href=\"#比对\"></a> 比对</h1>\n<ul>\n<li>\n<p>blastp 蛋白比对</p>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">blastp -query F01.faa -out F01.swissprot -db /new_data/hualin/db/uniprot_sprot -outfmt <span class=\"token number\">6</span> -num_threads <span class=\"token number\">30</span> -evalue 1e-5<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>diamond 蛋白比对</p>\n<ul>\n<li>\n<p>单个基因组对比</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond blastp -d /new_data/hualin/db/uniprot_sprot_diamond -q F01.faa -e 1e-5 -f <span class=\"token number\">6</span> -o F01.diamond -k <span class=\"token number\">1</span> --sensitive -p <span class=\"token number\">30</span> --query-cover <span class=\"token number\">50</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>多个个基因组对比</p>\n<p>不会 shell 没办法，写 Perl 脚本 (run_diamond.pl) 来完成。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n   <span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n   <span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n   <span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有后缀为“.faa”的文件，可以自己更改</span>\n   <span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".diamond\"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># 将/new_data/hualin/db/uniprot_sprot_diamond换成自己的数据库路径; -p表示线程数，在笔记本上用6个即可</span>\n    system<span class=\"token punctuation\">(</span><span class=\"token string\">\"diamond blastp -d /new_data/hualin/db/uniprot_sprot_diamond -q $_ -e 1e-5 -f 6 -o $out -k 1 --sensitive -p 30 --query-cover 50\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n   <span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “run_diamond.pl”，将其和序列文件放在同一目录下，并在终端中输入如下命令，完成分析：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_diamond.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"将比对结果mapping至其他数据库\"><a class=\"markdownIt-Anchor\" href=\"#将比对结果mapping至其他数据库\"></a> 将比对结果 mapping 至其他数据库</h1>\n<ul>\n<li>\n<p>打开网址<a href=\"https://www.uniprot.org/uploadlists/\"> https://www.uniprot.org/uploadlists/</a>, 上传比对上的 swissprot ID，可以将比对结果转换为诸如 KEGG 等其他数据库的 ID。个人感觉不是很好用。</p>\n</li>\n<li>\n<p>我们可以把 mapping 文件下载下来，自己写脚本来提取信息，虽然麻烦些，但得到的更多。</p>\n<ul>\n<li>\n<p>下载 mapping 文件</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/idmapping_selected.tab.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>解压缩</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gunzip -d idmapping_selected.tab.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>写脚本提取对应信息</p>\n<p>Diamond 比对的结果文件内容如下，第一列是自己的氨基酸序列 ID，第二列是 SwissProt 数据库中序列的 ID，而我们真正需要的是第二列中两个竖线中间的内容，在稍后的脚本中将通过正则表达式把它给揪出来。</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">F01_00001\tsp|Q73G44|MDH_WOLPM\t47.2\t72\t38\t0\t10\t81\t243\t314\t9.55e-16\t72.8\n   F01_00003\tsp|D9PU00|TFRA_METTM\t41.3\t569\t301\t7\t7\t574\t4\t540\t4.89e-131\t397\n   F01_00004\tsp|P9WN88|FRDB_MYCTO\t32.7\t208\t118\t6\t19\t215\t23\t219\t3.84e-28\t110\n   F01_00005\tsp|Q021N6|SUCC_SOLUE\t62.8\t384\t141\t2\t1\t383\t1\t383\t1.45e-155\t446<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>开始写脚本，保存为 “run_mapping.pl”。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%maps</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@diaout</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有的diamond比对后的输出文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@diaout</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\|(.+)\\|.+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"idmapping_selected.tab\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@diaout2</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有的diamond比对后的输出文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@diaout2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".mapped\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"qseqid\\tsseqid\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tUniProtKB-AC\tUniProtKB-ID\tGeneID (EntrezGene)\tRefSeq\tGI\tPDB\tGO\tUniRef100\tUniRef90\tUniRef50\tUniParc\tPIR\tNCBI-taxon\tMIM\tUniGene\tPubMed\tEMBL\tEMBL-CDS\tEnsembl\tEnsembl_TRS\tEnsembl_PRO\tAdditional PubMed\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\|(.+)\\|.+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将脚本与 diamond 比对的结果文件以及下载的 mapping 文件放在同一目录下，在终端里输入如下命令即可得到 mapping 后的结果：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_mapping.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"go-注释\"><a class=\"markdownIt-Anchor\" href=\"#go-注释\"></a> GO 注释</h1>\n<ul>\n<li>\n<p>从 map 后的文件中提取基因 ID 和 GO number，各列以制表符分隔，没有 GO 注释的只输出 gene ID。</p>\n<p>准备脚本，命名为 “get_GO.pl”，与上一步生成的 “*.mapped” 文件放在同一目录下。</p>\n  <pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@mapped</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.mapped\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@mapped</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).mapped/</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".GO\"</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\; /</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@terms</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\; /</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 18代表文件的第19列</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@terms</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\S+/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>在终端或者 Windows 命令行中运行如下命令，得到的 “*.GO” 为输出文件。</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_GO.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>GO 注释与可视化</p>\n</li>\n</ul>\n<p>访问网页<a href=\"https://wego.genomics.cn/\"> WEGO 2.0</a>，在网页中间位置是数据传输接口，将刚刚得到的所有结果文件拖拽上传，<strong>File format</strong> 选择<u>Native Format</u>，如果自己的数据是模式物种，可以在<strong> Reference</strong> 中选择对应的物种，点击<strong> Submit</strong> 即可。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"在WEGO 2.0网页提交数据\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"WEGO 2.0分析结果一览表\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"WEGO 2.0分析结果柱状图\" /></p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “e922” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"}]},{"title":"kSNP3寻找SNPs并构建进化树","slug":"kSNP3寻找SNPs并构建进化树","date":"2018-12-14T06:17:23.000Z","updated":"2022-01-08T02:16:28.422Z","comments":true,"path":"api/articles/kSNP3寻找SNPs并构建进化树.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>kSNP3 可以利用 reads、draft genomes 或 complete genomes 寻找 SNPs，并构建进化树。操作比较简单，小白比较容易上手。</p>\n<span id=\"more\"></span>\n<p><strong>1. kSNP3 安装</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> ~/tools\n\n<span class=\"token function\">wget</span> https://sourceforge.net/projects/ksnp/files/kSNP3.1_Linux_package.zip\n\n<span class=\"token function\">unzip</span> kSNP3.1_Linux_package.zip\n\n<span class=\"token comment\">#加入环境变量：</span>\n\n<span class=\"token function\">vim</span> ~/.bashrc\n\ni\n\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token environment constant\">$HOME</span>/tools/kSNP3.1_Linux_package/kSNP3\n\nESC\n\n<span class=\"token builtin class-name\">shift</span> + ：\n\nwq<span class=\"token operator\">!</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>编辑主程序 kSNP3 的第 8 行：</p>\n<p>将 set kSNP=/usr/local/kSNP3</p>\n<p>改为：set kSNP=/home/lhl/tools/kSNP3.1_Linux_package/kSNP3</p>\n<p>注：根据自己的路径进行修改</p>\n<p><strong>2. 基本用法</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#将所有的基因组文件放于988_ksnp目录之中，在其上一级目录下运行命令创建输入列表：</span>\n\nMakeKSNP3infile 988_ksnp inlist A\n\n<span class=\"token comment\">#运行命令创建输入序列集合：</span>\n\nMakeFasta inlist fastainput_988\n\n<span class=\"token comment\">#计算最佳K值：</span>\n\nKchooser fastainput_988\n\n<span class=\"token comment\">#寻找SNPs并构建进化树：</span>\n\nkSNP3 -in inlist -outdir SNPs_20181214 -k <span class=\"token number\">23</span> -ML -NJ -vcf  -CPU <span class=\"token number\">30</span> -core -min_frac <span class=\"token number\">0.5</span> <span class=\"token operator\">|</span><span class=\"token function\">tee</span> Log_988_20181214.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"SNPs","path":"api/tags/SNPs.json"},{"name":"进化","path":"api/tags/进化.json"}]},{"title":"为PubMed添加功能","slug":"为PubMed添加功能","date":"2019-03-18T03:29:24.000Z","updated":"2022-01-08T02:16:28.425Z","comments":true,"path":"api/articles/为PubMed添加功能.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/PubMed.png","content":"<p>对于搞科研的小伙伴们来说，PubMed 是一个必不可少的文献查阅数据库，然而输入关键字后，出来的文章少则几十篇，多则上百篇。而这些文章的质量却参差不齐，那么如何高效的选择高水平的文章来下载和阅读呢？</br></p>\n<span id=\"more\"></span>\n<p>首先上图，看一下我的 PubMed 界面：</br><br />\n<img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/PubMed.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/news/PubMed.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"PubMed\" /><br />\n</br>从图片中可以看出，文章的影响因子、分区一目了然，甚至提供了全文下载链接，解决了学校图书馆未购买杂志数据库而需付费下载的烦恼。该效果是通过两个谷歌浏览器插件实现的，分别是<a href=\"https://www.novoprolabs.com/support/articles/pubmedy-a-chrome-extension-for-ncbi-201712191285.html\"> PubMedy</a> 和<a href=\"https://www.scholarscope.cn/\"> Scholarscope</a>。前者可以展示影响因子、参考文献格式，并提供全文下载链接；后者可以展示期刊影响因子、领域排名、引用次数及中科院分区。<br />\n</br>这两个插件都可以在谷歌商店中下载，墙内的小伙伴需要想办法科学上网，这里推荐另一款插件 ——“<a href=\"https://www.skyzip.de/\">skyZIP™ Proxy</a>”。<br />\n</br>插件可以自行搜索下载，也可以加入 QQ 群（945751012）下载。</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"PubMed","path":"api/tags/PubMed.json"}]},{"title":"使用DeepARG预测抗生素抗性基因ARGs","slug":"使用DeepARG预测抗生素抗性基因ARGs","date":"2022-01-07T11:50:33.000Z","updated":"2022-01-08T02:16:28.429Z","comments":true,"path":"api/articles/使用DeepARG预测抗生素抗性基因ARGs.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/92eb_1.png","content":"<h1 id=\"介绍\"><a class=\"markdownIt-Anchor\" href=\"#介绍\"></a> 介绍</h1>\n<p>DeepARG 是一种机器学习解决方案，它使用深度学习来表征和注释宏基因组中的抗生素抗性基因。它由两种输入模型组成：短序列 Reads 和 gene-like 序列。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/92eb_1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/92eb_1.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Automatic annotation of highly homologous ARGs\" /></p>\n<h1 id=\"安装软件\"><a class=\"markdownIt-Anchor\" href=\"#安装软件\"></a> 安装软件</h1>\n<ul>\n<li>\n<p>通过 <code>conda</code>  安装</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 创建环境</span>\nconda create -n deeparg_env <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">2.7</span>.18\nconda activate deeparg_env\n\n<span class=\"token comment\"># 安装diamond</span>\nconda <span class=\"token function\">install</span> -c bioconda <span class=\"token assign-left variable\">diamond</span><span class=\"token operator\">==</span><span class=\"token number\">0.9</span>.24\n\n<span class=\"token comment\"># 安装其他依赖</span>\nconda <span class=\"token function\">install</span> trimmomatic vsearch bedtools bowtie2 samtools\n\n<span class=\"token comment\"># 安装DeepARG</span>\npip <span class=\"token function\">install</span> <span class=\"token assign-left variable\">deeparg</span><span class=\"token operator\">==</span><span class=\"token number\">1.0</span>.2\n\n<span class=\"token comment\"># 下载数据库等， -o指定下载路径</span>\ndeeparg download_data -o tools/deeparg<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>通过其他方法安装</p>\n<p>参考<a href=\"https://bitbucket.org/gusphdproj/deeparg-ss/src/master/\">官方文档</a>进行。</p>\n</li>\n</ul>\n<h1 id=\"使用软件\"><a class=\"markdownIt-Anchor\" href=\"#使用软件\"></a> 使用软件</h1>\n<h2 id=\"预测reads中的args\"><a class=\"markdownIt-Anchor\" href=\"#预测reads中的args\"></a> 预测 Reads 中的 ARGs</h2>\n<h3 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h3>\n<p>双端 Reads。</p>\n<h3 id=\"命令\"><a class=\"markdownIt-Anchor\" href=\"#命令\"></a> 命令</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">deeparg short_reads_pipeline --forward_pe_file Reads/LD201221-0003_S20210104-0015_F01_clean.R1.fq.gz --reverse_pe_file Reads/LD201221-0003_S20210104-0015_F01_clean.R2.fq.gz --output_file F01.deeparg -d ~/tools/deeparg/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"primary\"><summary>参数解析</summary><div>\n<p><code>-h, --help</code>             show this help message and exit<br />\n <code>--forward_pe_file</code>  <strong>FORWARD_PE_FILE</strong>:           forward mate from paired end library<br />\n <code>--reverse_pe_file</code>  <strong>REVERSE_PE_FILE</strong>:             reverse mate from paired end library<br />\n <code>--output_file</code>  <strong>OUTPUT_FILE</strong>:           save results to this file prefix<br />\n <code>-d</code>  <strong>DEEPARG_DATA_PATH</strong>:               Path where data was downloaded [see deeparg download-data --help for details]<br />\n <code>--deeparg_identity</code>  <strong>DEEPARG_IDENTITY</strong>:      minimum identity for ARG alignments [default 80]<br />\n <code>--deeparg_probability</code>  <strong>DEEPARG_PROBABILITY</strong>:      minimum probability for considering a reads as ARG-like [default 0.8]<br />\n <code>--deeparg_evalue</code>  <strong>DEEPARG_EVALUE</strong>:     minimum e-value for ARG alignments [default 1e-10]<br />\n <code>--gene_coverage</code>  <strong>GENE_COVERAGE</strong>:        minimum coverage required for considering a full gene in percentage. This parameter looks at the full gene and all hits that align to the gene. If the overlap of all hits is below the threshold the gene is discarded. Use with caution [default 1]</p>\n</div></details>\n<h2 id=\"预测fasta序列中的args\"><a class=\"markdownIt-Anchor\" href=\"#预测fasta序列中的args\"></a> 预测 FASTA 序列中的 ARGs</h2>\n<h3 id=\"输入文件-2\"><a class=\"markdownIt-Anchor\" href=\"#输入文件-2\"></a> 输入文件</h3>\n<p>可以是 <code>核苷酸序列</code> 或者是 <code>氨基酸序列</code> 。</p>\n<h3 id=\"命令-2\"><a class=\"markdownIt-Anchor\" href=\"#命令-2\"></a> 命令</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 1) Annotate gene-like sequences when the input is a nucleotide FASTA file:</span>\n    deeparg predict --model LS --type nucl --input /path/file.fasta --out /path/to/out/file.out\n\n<span class=\"token comment\"># 2) Annotate gene-like sequences when the input is an amino acid FASTA file:</span>\n    deeparg predict --model LS --type prot --input /path/file.fasta --out /path/to/out/file.out\n\n<span class=\"token comment\"># 3) Annotate short sequence reads when the input is a nucleotide FASTA file:</span>\n    deeparg predict --model SS --type nucl --input /path/file.fasta --out /path/to/out/file.out\n\n<span class=\"token comment\"># 4) Annotate short sequence reads when the input is a protein FASTA file (unusual case):</span>\n    deeparg predict --model SS --type prot --input /path/file.fasta --out /path/to/out/file.out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details class=\"primary\"><summary>参数解析</summary><div>\n<p>usage: deeparg predict<br />\n <code>-h, --help</code>             show this help message and exit<br />\n <code>--model</code>  <strong>MODEL</strong>:         Select model to use (short sequences for reads | long sequences for genes) SS|LS [No default]<br />\n <code>-i, --input-file</code>  <strong>INPUT_FILE</strong>:     Input file (Fasta input file)<br />\n <code>-o, --output-file</code>  <strong>OUTPUT_FILE</strong>:    Output file where to store results<br />\n <code>-d, --data-path</code>  <strong>DATA_PATH</strong>:       Path where data was downloaded [see deeparg download-data --help for details]<br />\n <code>--type</code>  <strong>TYPE</strong>:       Molecular data type prot/nucl [Default: nucl]<br />\n <code>--min-prob</code>  <strong>MIN_PROB</strong>:   Minimum probability cutoff [Default: 0.8]<br />\n <code>--arg-alignment-identity</code>  <strong>ARG_ALIGNMENT_IDENTITY</strong>:          Identity cutoff for sequence alignment [Default: 50]<br />\n <code>--arg-alignment-evalue</code>  <strong>ARG_ALIGNMENT_EVALUE</strong>:                  Evalue cutoff [Default: 1e-10]<br />\n <code>--arg-alignment-overlap</code>  <strong>ARG_ALIGNMENT_OVERLAP</strong>:                 Alignment read overlap [Default: 0.8]<br />\n <code>--arg-num-alignments-per-entry</code>  <strong>ARG_NUM_ALIGNMENTS_PER_ENTRY</strong>:    Diamond, minimum number of alignments per entry [Default: 1000]<br />\n <code>--model-version</code>  <strong>MODEL_VERSION</strong>:     Model deepARG version [Default: v2]</p>\n</div></details>\n<h2 id=\"输出\"><a class=\"markdownIt-Anchor\" href=\"#输出\"></a> 输出</h2>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">* ARG_NAME\n* QUERY_START\n* QUERY_END\n* QUERY_ID\n* PREDICTED_ARG_CLASS\n* BEST_HIT_FROM_DATABASE\n* PREDICTION_PROBABILITY\n* ALIGNMENT_BESTHIT_IDENTITY (%)\n* ALIGNMENT_BESTHIT_LENGTH\n* ALIGNMENT_BESTHIT_BITSCORE\n* ALIGNMENT_BESTHIT_EVALUE\n* COUNTS<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://bench.cs.vt.edu/deeparg\">DeepARG 官网</a></li>\n<li><a href=\"https://bitbucket.org/gusphdproj/deeparg-ss/src/master/\">DeepARG Repository</a></li>\n</ul>\n<h1 id=\"代码获取\"><a class=\"markdownIt-Anchor\" href=\"#代码获取\"></a> 代码获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “92eb” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"ARGs","path":"api/tags/ARGs.json"}]},{"title":"使用EffectiveT3预测微生物中的III型分泌系统效应蛋白","slug":"使用EffectiveT3预测微生物中的III型分泌系统效应蛋白","date":"2021-10-13T02:01:56.000Z","updated":"2022-01-08T02:16:28.430Z","comments":true,"path":"api/articles/使用EffectiveT3预测微生物中的III型分泌系统效应蛋白.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg","content":"<p>III 型分泌系统 (Type III secretion system，T3SS) 主要是革兰氏阴性菌的分泌蛋白分泌到细胞外的运输途径，T3SS 效应蛋白 (Type III secretion system Effector protein) 与革兰氏阴性致病菌致病机理有关。</p>\n<p>通常用软件<a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\"> EffectiveT3</a> 预测 T3SS，通过其内部特定的计算模型对每条氨基酸序列进行评分，分值越高，可信度越高，选出评分高于阈值的序列，认为这些序列为 III 型分泌系统效应蛋白。</p>\n<p>EffectiveT3 的更新版本加强了 Effective 中 N 端信号肽的识别。对于更新，开发者收集了新的训练数据集，将来自 T3SEdb 的 504 个经过验证的分泌蛋白与其原始的训练数据结合在一起。新模型同样基于朴素贝叶斯分类器（Naive Bayesian Classifier），只是用了更多数据进行训练。在执行遗漏交叉验证测试（leave-one-taxon-out test ）时，其精度为 0.87，与其之前的报告相当。</p>\n<p>新模型现已嵌入到 Effective 中，也可供下载。在新模型中，朴素贝叶斯分类器对 “secreted” 类的默认最小分数为 0.9999。该默认值在网页上称为 “selective”，而 0.95 称为 “sensitive”。阈值也可以自由选择。</p>\n<h1 id=\"软件\"><a class=\"markdownIt-Anchor\" href=\"#软件\"></a> 软件</h1>\n<ul>\n<li>\n<p>主程序</p>\n<ul>\n<li><a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\">EffectiveT3</a></li>\n</ul>\n</li>\n<li>\n<p>依赖</p>\n<ul>\n<li>openjdk &gt;=6</li>\n</ul>\n</li>\n<li>\n<p>安装</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 使用conda安装时依赖Pyton 2.7，3.5，3.6，需要首先创建相应版本的Python环境（自行创建）</span>\nconda <span class=\"token function\">install</span> effectivet3<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>数据库（modules）配置</p>\n<p><font color=\"#FF0000\">记录一个深坑</font>：程序默认在 module 的路径前加了一个 &quot;./module&quot; 路径，因此，虽然程序安装的过程中自动下载了 modules，然而我们并没有办法调用它们，只能重新下载。用户每次运行软件前需要在当前目录下创建了 module 目录，并下载 modules，然后将其存到 module 目录中。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">mkdir</span> -p module\n\n<span class=\"token function\">curl</span> -o TTSS_STD-2.0.2.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_2.0.2_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_ANIMAL-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_ANIMAL/TTSS_ANIMAL_1.0.1_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_PLANT-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_PLANT/TTSS_PLANT_1.0.1_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_STD-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_1.0.1_src_all.jar\n\n<span class=\"token function\">mv</span> -f TTSS_STD-2.0.2.jar TTSS_ANIMAL-1.0.1.jar TTSS_PLANT-1.0.1.jar TTSS_STD-1.0.1.jar module<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"输入数据\"><a class=\"markdownIt-Anchor\" href=\"#输入数据\"></a> 输入数据</h1>\n<p>包含蛋白序列的 FASTA 格式文件</p>\n<h1 id=\"运行软件\"><a class=\"markdownIt-Anchor\" href=\"#运行软件\"></a> 运行软件</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">effectivet3 -f F02_bin.1.faa -m TTSS_TTSS_STD-2.0.2.jar -t selective -o F02_bin.1.out -q<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>-f: 输入文件</li>\n<li>-m: 模型，可选 &quot;TTSS_ANIMAL-1.0.1.jar&quot;，&quot;TTSS_PLANT-1.0.1.jar&quot;，&quot;TTSS_STD-1.0.1.jar&quot; 和 “TTSS_STD-2.0.2.jar”，建议用 “TTSS_STD-2.0.2.jar”</li>\n<li>-t: 模式，&quot;sensitive&quot; and &quot;selective&quot; 二选一，建议使用 &quot;selective&quot;</li>\n<li>-o: 输出文件</li>\n<li>-q: 启动命令行模式</li>\n</ul>\n<h1 id=\"输出文件解读\"><a class=\"markdownIt-Anchor\" href=\"#输出文件解读\"></a> 输出文件解读</h1>\n<ul>\n<li>\n<p>English: The table of results displays all query proteins sorted by prediction score. Effector classification (true/false) according to the applied threshold is shown in the last column.</p>\n</li>\n<li>\n<p>简体中文：结果包含了输入文件中所有的查询序列 IDs，根据得分进行排序。一共包含 4 列，第一列为序列 ID，第二列为序列描述，第三列为预测得分，第四列描述该序列是否为效应因子。各列间以英文的分号（;）分隔。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"F01_bin.1.out\" /></p>\n</li>\n</ul>\n<h1 id=\"批处理与结果整合\"><a class=\"markdownIt-Anchor\" href=\"#批处理与结果整合\"></a> 批处理与结果整合</h1>\n<p><strong>脚本名</strong>：run_effectiveT3.pl</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Oct 13, 2021</span>\n\n<span class=\"token comment\"># Download modules</span>\n<span class=\"token comment\"># 记录一个深坑，程序默认在module的路径前加了一个\"./module\"路径，因此，虽然程序安装的过程中自动下载了modules，然而我们并没有办法调用它们，只能重新下载。</span>\n<span class=\"token comment\"># 以下代码在当前目录下创建了module目录，并下载modules，然后将其存到module目录中。</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mkdir -p module\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_STD-2.0.2.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_2.0.2_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_ANIMAL-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_ANIMAL/TTSS_ANIMAL_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_PLANT-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_PLANT/TTSS_PLANT_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_STD-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv -f TTSS_STD-2.0.2.jar TTSS_ANIMAL-1.0.1.jar TTSS_PLANT-1.0.1.jar TTSS_STD-1.0.1.jar module\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\"># Predict one by one</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".T3\"</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"effectivet3 -f $_ -m TTSS_STD-2.0.2.jar -t selective -o $out -q\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># information aggregation</span>\n<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">%strain</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$line_num</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen T3<span class=\"token punctuation\">,</span> <span class=\"token string\">\">T3SS.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> T3 <span class=\"token string\">\"Strain\\tId\\tDescription\\tScore\\tis secreted\\tProtein sequences\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@t3</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.T3\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$t3</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">@t3</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$t3</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).T3/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$faa</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".faa\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$strain</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%temp</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token comment\"># Save ID and Sequence to %temp</span>\n\topen FAA<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$faa\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;FAA></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;FAA></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$seq</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$temp</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose FAA<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$t3\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token regex\">/^#/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\;/</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">eq</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$line_num</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> T3 <span class=\"token string\">\"$str\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@lines</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$temp</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose T3<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$line_num</span> <span class=\"token operator\">></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\topen T3NUM<span class=\"token punctuation\">,</span> <span class=\"token string\">\">T3SS.num\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token string\">\"Strain\\tTotal sequences\\tT3S effective true\\tT3S effective false\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span>sort keys <span class=\"token variable\">%strain</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose T3NUM<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mkdir -p T3SS_result\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv *.T3 T3SS.num T3SS.txt T3SS_result\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>用法</strong>：将脚本与含有氨基酸序列的 FASTA 格式文件（后缀名为 &quot;.faa&quot;，如果为其他，需要修改脚本第 19、21 和 31 行）放在同一目录下，在终端里运行如下命令（不需要事先配置数据库）：</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\">perl run_effectiveT3<span class=\"token operator\">.</span>pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>报错</strong>：Use of uninitialized value $seq in substitution (s///) at run_effectiveT3.pl line 47, &lt;FAA&gt; chunk .</p>\n<p><strong>原因</strong>：氨基酸序列 ID/Header 那一行的注释信息中含有”&gt;“。该报错不影响结果的准确性，可以忽略。</p>\n<h1 id=\"结果解读\"><a class=\"markdownIt-Anchor\" href=\"#结果解读\"></a> 结果解读</h1>\n<ul>\n<li>\n<p>T3SS_result/strain_name.T3：（strain_name 代表输入文件的名称）effectiveT3 输出的原始结果，共 4 列，如前文所述。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"CXY008.T3\" /></p>\n</li>\n<li>\n<p>T3SS_result/T3SS.txt：包含了所有菌株的预测得到的效应因子，共 6 列，第一列为菌株名，中间的 4 列同上一个文件，最后一列为对应的氨基酸序列。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"T3SS.txt\" /></p>\n</li>\n<li>\n<p>T3SS_result/T3SS.sum：记录所有菌株中序列总数、效应因子序列数和非效应因子序列数。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"T3SS.sum\" /></p>\n</li>\n</ul>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “fb68” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\">EffectiveDB</a></li>\n<li><a href=\"https://github.com/bioconda/bioconda-recipes/tree/master/recipes/effectivet3\">Bioconda</a></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"T3SS","path":"api/tags/T3SS.json"},{"name":"WGS","path":"api/tags/WGS.json"}]},{"title":"利用GTDB-TK对细菌和古菌基因组进行物种分类","slug":"利用GTDB-TK对细菌和古菌基因组进行物种分类","date":"2021-12-10T03:14:45.000Z","updated":"2022-01-08T02:16:28.432Z","comments":true,"path":"api/articles/利用GTDB-TK对细菌和古菌基因组进行物种分类.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>GTDB-Tk 是一个软件工具包，用于根据<ruby>基因组数据库分类 GTDB<rt>Genome Database Taxonomy GTDB</rt></ruby> 为细菌和古菌基因组<ruby>分配客观分类学分类<rt>assigning objective taxonomic classifications</rt></ruby>。可以用于宏基因组组装基因组 (MAG)、单菌基因组和单细胞基因组。</p>\n<h1 id=\"安装gtdb-tk\"><a class=\"markdownIt-Anchor\" href=\"#安装gtdb-tk\"></a> 安装 GTDB-Tk</h1>\n<ul>\n<li>\n<p>通过 conda 安装主程序</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># latest version</span>\nconda create -n gtdbtk -c conda-forge -c bioconda gtdbtk\n\n<span class=\"token comment\"># specific version (replace 1.7.0 with the version you wish to install, recommended)</span>\nconda create -n gtdbtk -c conda-forge -c bioconda <span class=\"token assign-left variable\">gtdbtk</span><span class=\"token operator\">=</span><span class=\"token number\">1.7</span>.0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>下载 GTDB-Tk 数据库 (~47 G)</p>\n<p>最新版本的数据库为 R202，需要 &gt;=1.5.0 版本的 GTDB-Tk。</p>\n<ul>\n<li>\n<p>自动 (非常慢)</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">download-db.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>手动</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"> \t<span class=\"token comment\"># 找到下载脚本的路径并打开，从中找到数据库的链接</span>\n<span class=\"token function\">which</span> download-db.sh\n  \n<span class=\"token comment\"># 进入数据库默认路径</span>\n<span class=\"token builtin class-name\">cd</span> ~/miniconda3/envs/gtdbtk/share/gtdbtk-1.7.0/db/\n\t  \n   <span class=\"token comment\"># 用wget下载 (非常慢)，推荐在Windows下用其他软件下载，再上传服务器</span>\n<span class=\"token function\">nohup</span> <span class=\"token function\">wget</span> -c https://data.gtdb.ecogenomic.org/releases/release202/202.0/auxillary_files/gtdbtk_r202_data.tar.gz --no-check-certificate <span class=\"token operator\">&amp;</span>\n\n<span class=\"token function\">tar</span> zxvf gtdbtk_r202_data.tar.gz\n\n<span class=\"token function\">mv</span> release202/* ./<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"运行软件\"><a class=\"markdownIt-Anchor\" href=\"#运行软件\"></a> 运行软件</h1>\n<h2 id=\"classify_wf\"><a class=\"markdownIt-Anchor\" href=\"#classify_wf\"></a> classify_wf</h2>\n<div class=\"note default\">\n<p>可以通过 <code>classify_wf</code>  命令完成整个工作流程。</p>\n</div>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gtdbtk classify_wf --genome_dir <span class=\"token operator\">&lt;</span>my_genomes<span class=\"token operator\">></span> --out_dir <span class=\"token operator\">&lt;</span>output_dir<span class=\"token operator\">></span> --extension fna --cpus <span class=\"token number\">20</span> --force<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"primary\"><summary>参数解析</summary><div>\n<ul>\n<li>\n<p>--genome_dir<br />\ndirectory containing genome files in FASTA format</p>\n</li>\n<li>\n<p>--batchfile<br />\npath to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</p>\n</li>\n<li>\n<p>--out_dir<br />\ndirectory to output files</p>\n</li>\n<li>\n<p>-x, --extension<br />\nextension of files to process, gz = gzipped (Default: fna)</p>\n</li>\n<li>\n<p>--min_perc_aa<br />\nexclude genomes that do not have at least this percentage of AA in the MSA (inclusive bound) (Default: 10)</p>\n</li>\n<li>\n<p>--prefix<br />\nprefix for all output files (Default: gtdbtk)</p>\n</li>\n<li>\n<p>--cpus<br />\nnumber of CPUs to use (Default: 1)</p>\n</li>\n<li>\n<p>--pplacer_cpus<br />\nuse pplacer_cpus during placement (default: cpus)</p>\n</li>\n<li>\n<p>--force<br />\ncontinue processing if an error occurs on a single genome</p>\n</li>\n<li>\n<p>--scratch_dir<br />\nReduce pplacer memory usage by writing to disk (slower).</p>\n</li>\n<li>\n<p>--min_af<br />\nminimum alignment fraction to consider closest genome (Default: 0.65)</p>\n</li>\n<li>\n<p>--tmpdir<br />\nspecify alternative directory for temporary files （Default: /tmp</p>\n</li>\n<li>\n<p>--debug<br />\ncreate intermediate files for debugging purposes</p>\n</li>\n</ul>\n</div></details>\n<div class=\"note default\">\n<p>但下面我们演示分步运行。在处理大型管道时，单独运行这些步骤有时会很有用。</p>\n</div>\n<h2 id=\"step-1-准备输入文件\"><a class=\"markdownIt-Anchor\" href=\"#step-1-准备输入文件\"></a> Step 1 准备输入文件</h2>\n<p>以下两个基因组作为示例文件：* Genome A:  <code>GCF_003947435.1</code>  [<a href=\"https://gtdb.ecogenomic.org/genomes?gid=GCA_002011125.1\">GTDB</a> / <a href=\"https://www.ncbi.nlm.nih.gov/assembly/GCF_003947435.1/\">NCBI</a>] * Genome B:  <code>GCA_002011125.1</code>  [<a href=\"https://gtdb.ecogenomic.org/genomes?gid=GCA_002011125.1\">GTDB</a> / <a href=\"https://www.ncbi.nlm.nih.gov/assembly/GCA_002011125.1/\">NCBI</a>]。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># Create the directory.</span>\n<span class=\"token function\">mkdir</span> -p /tmp/gtdbtk <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> /tmp/gtdbtk\n\n<span class=\"token comment\"># Obtain the genomes.</span>\n<span class=\"token function\">mkdir</span> -p /tmp/gtdbtk/genomes\n<span class=\"token function\">wget</span> -q https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/947/435/GCF_003947435.1_ASM394743v1/GCF_003947435.1_ASM394743v1_genomic.fna.gz -O /tmp/gtdbtk/genomes/genome_a.fna.gz\n\n<span class=\"token function\">wget</span> -q https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/011/125/GCA_002011125.1_ASM201112v1/GCA_002011125.1_ASM201112v1_genomic.fna.gz -O /tmp/gtdbtk/genomes/genome_b.fna.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"step-2-gene-calling-identify\"><a class=\"markdownIt-Anchor\" href=\"#step-2-gene-calling-identify\"></a> Step 2 Gene calling (identify)</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gtdbtk identify --genome_dir /tmp/gtdbtk/genomes --out_dir /tmp/gtdbtk/identify --extension gz --cpus <span class=\"token number\">20</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"success\"><summary>Results</summary><div>\n<p>获得的基因和<ruby>标记<rt>marker</rt></ruby>信息可以在每个<ruby>基因组反应中间文件目录<rt>genomes respeective intermediate files directory</rt></ruby>下找到，如下所示。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">ls</span> /tmp/gtdbtk/identify/identify/intermediate_results/marker_genes/genome_a.fna/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">genome_a.fna_pfam_tophit.tsv\ngenome_a.fna_protein.gff.sha256\ngenome_a.fna_pfam_tophit.tsv.sha256\ngenome_a.fna_tigrfam.out\ngenome_a.fna_pfam.tsv\ngenome_a.fna_tigrfam.out.sha256\ngenome_a.fna_pfam.tsv.sha256\ngenome_a.fna_tigrfam_tophit.tsv\ngenome_a.fna_protein.faa\ngenome_a.fna_tigrfam_tophit.tsv.sha256\ngenome_a.fna_protein.faa.sha256\ngenome_a.fna_tigrfam.tsv\ngenome_a.fna_protein.fna\ngenome_a.fna_tigrfam.tsv.sha256\ngenome_a.fna_protein.fna.sha256\nprodigal_translation_table.tsv\ngenome_a.fna_protein.gff\nprodigal_translation_table.tsv.sha256<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<div class=\"note default\">\n<p>大部分情况下只需要读取摘要文件，其中详细说明了从 archaeal 122 或 bacterial 120<ruby>标记集<rt>marker set</rt></ruby>识别的标记。</p>\n</div>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> /tmp/gtdbtk/identify/gtdbtk.ar122.markers_summary.tsv<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">name    number_unique_genes     number_multiple_genes   number_multiple_unique_genes    number_missing_genes    list_unique_genes       list_multiple_genes     list_multiple_unique_genes      list_missing_genes\ngenome_a.fna    109     3       0       10      PF00368.13,PF00410.14,PF00466.15,PF00687.16,PF00827.12,PF00900.15,PF01000.21,PF01015.13,PF01090.14,PF01092.14,PF01157.13,PF01191.14,PF01194.12,PF01198.14,PF01200.13,PF01269.12,PF01280.15,PF01282.14,PF01655.13,PF01798.13,PF01864.12,PF01868.11,PF01984.15,PF01990.12,PF02006.11,PF02978.14,PF03874.11,PF04019.7,PF04104.9,PF04919.7,PF07541.7,PF13656.1,PF13685.1,TIGR00021,TIGR00037,TIGR00042,TIGR00111,TIGR00134,TIGR00240,TIGR00264,TIGR00270,TIGR00279,TIGR00283,TIGR00291,TIGR00293,TIGR00307,TIGR00308,TIGR00323,TIGR00324,TIGR00335,TIGR00336,TIGR00337,TIGR00389,TIGR00392,TIGR00398,TIGR00405,TIGR00408,TIGR00422,TIGR00425,TIGR00432,TIGR00442,TIGR00448,TIGR00456,TIGR00463,TIGR00468,TIGR00471,TIGR00490,TIGR00491,TIGR00501,TIGR00521,TIGR00549,TIGR00670,TIGR00729,TIGR00936,TIGR00982,TIGR01008,TIGR01012,TIGR01018,TIGR01020,TIGR01025,TIGR01028,TIGR01038,TIGR01046,TIGR01052,TIGR01060,TIGR01077,TIGR01080,TIGR01213,TIGR01309,TIGR01952,TIGR02076,TIGR02153,TIGR02236,TIGR02258,TIGR02390,TIGR02651,TIGR03626,TIGR03627,TIGR03628,TIGR03636,TIGR03653,TIGR03665,TIGR03671,TIGR03672,TIGR03674,TIGR03677,TIGR03680,TIGR03683,TIGR03684    PF01496.14,TIGR00458,TIGR00658          PF01866.12,TIGR00064,TIGR00373,TIGR00522,TIGR02338,TIGR02389,TIGR03629,TIGR03670,TIGR03673,TIGR03722\ngenome_b.fna    118     2       0       2       PF00368.13,PF00410.14,PF00466.15,PF00687.16,PF00827.12,PF00900.15,PF01000.21,PF01015.13,PF01090.14,PF01092.14,PF01157.13,PF01191.14,PF01194.12,PF01198.14,PF01200.13,PF01269.12,PF01280.15,PF01282.14,PF01655.13,PF01798.13,PF01864.12,PF01866.12,PF01868.11,PF01984.15,PF01990.12,PF02006.11,PF02978.14,PF03874.11,PF04019.7,PF04104.9,PF04919.7,PF07541.7,PF13656.1,TIGR00021,TIGR00037,TIGR00042,TIGR00064,TIGR00111,TIGR00134,TIGR00240,TIGR00264,TIGR00270,TIGR00279,TIGR00283,TIGR00291,TIGR00293,TIGR00307,TIGR00308,TIGR00323,TIGR00324,TIGR00335,TIGR00336,TIGR00337,TIGR00373,TIGR00389,TIGR00392,TIGR00398,TIGR00405,TIGR00408,TIGR00422,TIGR00425,TIGR00432,TIGR00442,TIGR00448,TIGR00456,TIGR00458,TIGR00463,TIGR00468,TIGR00471,TIGR00490,TIGR00491,TIGR00501,TIGR00521,TIGR00522,TIGR00549,TIGR00658,TIGR00670,TIGR00729,TIGR00936,TIGR00982,TIGR01008,TIGR01012,TIGR01018,TIGR01020,TIGR01025,TIGR01028,TIGR01038,TIGR01046,TIGR01052,TIGR01060,TIGR01077,TIGR01080,TIGR01309,TIGR01952,TIGR02076,TIGR02153,TIGR02236,TIGR02258,TIGR02338,TIGR02389,TIGR02390,TIGR02651,TIGR03626,TIGR03628,TIGR03629,TIGR03636,TIGR03653,TIGR03665,TIGR03670,TIGR03671,TIGR03672,TIGR03673,TIGR03674,TIGR03677,TIGR03680,TIGR03683,TIGR03684,TIGR03722 PF01496.14,PF13685.1            TIGR01213,TIGR03627<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</div></details>\n<h2 id=\"step-3-aligning-genomes-align\"><a class=\"markdownIt-Anchor\" href=\"#step-3-aligning-genomes-align\"></a> Step 3 Aligning genomes (align)</h2>\n<p>该步骤将对齐所有已识别的标记，确定最可能的<ruby>域<rt>domain </rt></ruby>并输出串联的 MSA。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gtdbtk align --identify_dir /tmp/gtdbtk/identify --out_dir /tmp/gtdbtk/align --cpus <span class=\"token number\">20</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"success\"><summary>Results</summary><div>\n<div class=\"note warning\">\n<p>要注意输出，如果一个基因组识别出的标记数量较少，那么在这一步，它将被排除在分析之外。如果出现这种情况，将出现警告。</p>\n</div>\n<p>根据 domain 的不同， <code>ar122</code>  或 <code>bac120</code>  的前缀文件将出现，其中包含用户基因组和 GTDB 基因组的 MSA，或仅包含用户基因组（ <code>gtdbtk.ar122.MSA.fasta</code>  和 <code>gtdbtk.ar122.user_MSA.fasta</code> ）。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">ls</span> /tmp/gtdbtk/align<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">align&#x2F;\ngtdbtk.ar122.user_msa.fasta\nidentify&#x2F;\ngtdbtk.ar122.filtered.tsv\ngtdbtk.log\ngtdbtk.ar122.msa.fasta\ngtdbtk.warnings.log<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</div></details>\n<h2 id=\"step-4-基因组分类-classify\"><a class=\"markdownIt-Anchor\" href=\"#step-4-基因组分类-classify\"></a> Step 4 基因组分类 (classify)</h2>\n<p>将用户的基因组放置于参考树上，然后决定其最为可能的分类。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gtdbtk classify --genome_dir /tmp/gtdbtk/genomes --align_dir /tmp/gtdbtk/align --out_dir /tmp/gtdbtk/classify -x gz --cpus <span class=\"token number\">20</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"success\"><summary>Results</summary><div>\n<p>两个主要的输出文件包括<ruby>总结文件<rt>summary file</rt></ruby>和包含基因组的参考树 ( <code>gtdbtk.ar122.summary.tsv</code>  和 <code>gtdbtk.ar122.classify.tree</code> )。基因组的分类信息呈现于总结文件中。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">ls</span> /tmp/gtdbtk/classify<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">classify&#x2F;\ngtdbtk.ar122.summary.tsv\ngtdbtk.warnings.log\ngtdbtk.ar122.classify.tree\ngtdbtk.log<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</div></details>\n<h2 id=\"错误信息处理\"><a class=\"markdownIt-Anchor\" href=\"#错误信息处理\"></a> 错误信息处理</h2>\n<ul>\n<li>\n<p>OpenBLAS blas_thread_init: pthread_create failed for thread 109 of 128: Resource temporarily unavailable</p>\n<ul>\n<li>解决方案：少调用一些线程就 ok 了。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://ecogenomics.github.io/GTDBTk\">GTBD-Tk Documentation</a></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"WGS","path":"api/tags/WGS.json"}]},{"title":"从GenBank文件中提取Features","slug":"从GenBank文件中提取Features","date":"2021-10-09T06:15:45.000Z","updated":"2022-01-08T02:16:28.429Z","comments":true,"path":"api/articles/从GenBank文件中提取Features.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>二话不说，上代码，需要安装 BioPerl</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> Bio<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>SeqIO<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Oct 9, 2021</span>\n<span class=\"token comment\"># Usage: perl get_gbk_features.pl &lt;in> &lt;out></span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$in</span> <span class=\"token operator\">=</span> shift<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> shift<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$seqin</span> <span class=\"token operator\">=</span> Bio<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>SeqIO<span class=\"token operator\">-></span>new<span class=\"token punctuation\">(</span> <span class=\"token operator\">-</span>format <span class=\"token operator\">=></span> <span class=\"token string\">'genbank'</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>file <span class=\"token operator\">=></span> <span class=\"token string\">\"$in\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$seq</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seqin</span><span class=\"token operator\">-></span>next_seq<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$sf</span> <span class=\"token punctuation\">(</span> <span class=\"token variable\">$seq</span><span class=\"token operator\">-></span>get_SeqFeatures <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>primary_tag <span class=\"token operator\">eq</span> <span class=\"token string\">'CDS'</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@tags</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sf</span> <span class=\"token operator\">-></span>get_all_tags<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token comment\">#print join(\"\\t\", @tags) . \"\\n\";</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'locus_tag'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>start<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>end<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>strand<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'product'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'translation'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>运行：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_gbk_features.pl examples/INPUT/LHL010.gbk LHL010.list<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “3a23” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"序列处理","path":"api/tags/序列处理.json"},{"name":"perl","path":"api/tags/perl.json"},{"name":"编程","path":"api/tags/编程.json"},{"name":"BioPerl","path":"api/tags/BioPerl.json"}]},{"title":"原核生物基因岛预测","slug":"原核生物基因岛预测","date":"2021-10-08T11:27:05.000Z","updated":"2022-01-08T02:16:28.434Z","comments":true,"path":"api/articles/原核生物基因岛预测.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-1.jpg","content":"<h1 id=\"软件-software-needed\"><a class=\"markdownIt-Anchor\" href=\"#软件-software-needed\"></a> 软件 (Software needed)</h1>\n<ul>\n<li><a href=\"https://github.com/brinkmanlab/islandpath\">IslandPath-DIMOB</a></li>\n<li><a href=\"https://bioperl.org/\">BioPerl</a></li>\n</ul>\n<h1 id=\"安装-installation\"><a class=\"markdownIt-Anchor\" href=\"#安装-installation\"></a> 安装 (Installation)</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda <span class=\"token function\">install</span> islandpath\nconda <span class=\"token function\">install</span> perl-bioperl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h1 id=\"输入文件-input-files\"><a class=\"markdownIt-Anchor\" href=\"#输入文件-input-files\"></a> 输入文件 (Input Files)</h1>\n<ul>\n<li>GenBank (.gbk) or an embl (.embl) file</li>\n<li><font color='#ff0000'><strong>注意:</strong> 输入文件中只允许包含一条序列，否则会报错！(Please make sure you are running islandpath on a genbank file with only one contig)。</font>如果一个文件中含有多个序列，那么就要将其分割成为多个文件，然后逐个作为输入文件进行预测。切割方法见我的另一篇文章<a href=\"https://liaochenlanruo.github.io/post/d9f9.html\">按照 Contig 切割 GenBank 文件</a>。</li>\n</ul>\n<h1 id=\"运行软件-run\"><a class=\"markdownIt-Anchor\" href=\"#运行软件-run\"></a> 运行软件 (Run)</h1>\n<h2 id=\"常规运行\"><a class=\"markdownIt-Anchor\" href=\"#常规运行\"></a> 常规运行</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># gbk file</span>\nislandpath example/NC_003210.gbk NC_003210_GIs.txt\n\n<span class=\"token comment\"># embl file</span>\nislandpath example/NC_000913.embl NC_000913_GIs.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>输出结果如下图所示：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"示例输出结果展示\" /></p>\n<h2 id=\"批处理\"><a class=\"markdownIt-Anchor\" href=\"#批处理\"></a> 批处理</h2>\n<p>在得到大量基因组的时候，手动提交并不像打游戏那样让人渴望敲击键盘和鼠标，为了避免烦躁，我们来写脚本 “run_islandpath.pl”，然后让机器做剩下的事情。该脚本可以实现 GenBank 文件的切割，基因岛预测，以及结果的整合，实现了 IslandPath-DIMOB 所无法完成的分析。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> Bio<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>SeqIO<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Oct 8, 2021</span>\n\n<span class=\"token comment\"># Split GenBank files</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@gbk</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.gbk\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 批处理所有后缀为.gbk的文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@gbk</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).gbk/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"LOCUS\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\s+(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$scaf</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$scaf</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".gb\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$assession</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$scaf</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/ACCESSION.+/ACCESSION   $assession/g</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 添加ACCESSION number</span>\n\t\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"LOCUS$_\"</span><span class=\"token punctuation\">;</span>\n\t\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\"># predict Gene Islands</span>\n<span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@gb</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.gb\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@gb</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).gb/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".island\"</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"islandpath $_ $out\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># Get features from GenBank files</span>\n<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$gb</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">@gb</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$gb</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).gb/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".list\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$seqin</span> <span class=\"token operator\">=</span> Bio<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>SeqIO<span class=\"token operator\">-></span>new<span class=\"token punctuation\">(</span> <span class=\"token operator\">-</span>format <span class=\"token operator\">=></span> <span class=\"token string\">'genbank'</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span>file <span class=\"token operator\">=></span> <span class=\"token string\">\"$gb\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$seq</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seqin</span><span class=\"token operator\">-></span>next_seq<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$sf</span> <span class=\"token punctuation\">(</span> <span class=\"token variable\">$seq</span><span class=\"token operator\">-></span>get_SeqFeatures <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>primary_tag <span class=\"token operator\">eq</span> <span class=\"token string\">'CDS'</span> <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@tags</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sf</span> <span class=\"token operator\">-></span>get_all_tags<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token comment\">#print join(\"\\t\", @tags) . \"\\n\";</span>\n\t\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'locus_tag'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>start<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>end<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>strand<span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'product'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$sf</span><span class=\"token operator\">-></span>get_tag_values<span class=\"token punctuation\">(</span><span class=\"token string\">'translation'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># Parser the results</span>\n<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">%gi</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">%list</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">%gif</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">All_island.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"Sequence IDs\tPredictor\tCategory\tGI Start\tGI End\t.\tStrand\t.\tIsland IDs\tGene IDs\tGene Start\tGene End\tStrand\tProducts\tProtein Sequences\\n\"</span><span class=\"token punctuation\">;</span>\nopen LIST<span class=\"token punctuation\">,</span> <span class=\"token string\">\">All_island.list\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> LIST <span class=\"token string\">\"Island IDs\\tGI Start\\tGI End\\tGI Length\\tGene Number\\tGene IDs\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@GI</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.island\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@GI</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).island/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$list</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".list\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$start</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$end</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$gilen</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$end</span> <span class=\"token operator\">-</span> <span class=\"token variable\">$start</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$start</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"-\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$end</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"-\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$id</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$gi</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$gif</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$start</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$end</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$gilen</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\topen GB<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$list\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;GB></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@line</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$ids</span> <span class=\"token punctuation\">(</span>sort keys <span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$start2</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$end2</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$gi</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\-/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token variable\">$start2</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;=</span> <span class=\"token variable\">$end2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$gi</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$gi</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t\tpush <span class=\"token variable\">@</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$list</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$gi</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose GB<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span>sort keys <span class=\"token variable\">%list</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> LIST <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$gif</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">@</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$list</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join <span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$list</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose LIST<span class=\"token punctuation\">;</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将 “run_islandpath.pl” 与 GenBank 文件放在同一目录下，在终端里运行如下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_islandpath.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>结果汇总于<strong> All_island.txt</strong> 和<strong> All_island.list</strong> 中，内容如下面二图所示。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"All_island.txt\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/5324-3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"All_island.list\" /></p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “5324” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"WGS","path":"api/tags/WGS.json"},{"name":"基因岛","path":"api/tags/基因岛.json"}]},{"title":"利用NCycDB数据库从宏基因组中预测氮循环基因","slug":"利用NCycDB数据库从宏基因组中预测氮循环基因","date":"2021-11-25T03:19:20.000Z","updated":"2022-01-08T02:16:28.433Z","comments":true,"path":"api/articles/利用NCycDB数据库从宏基因组中预测氮循环基因.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>氮（N）循环是地球生态系统中重要的生物地球化学途径的集合，在生态学和环境研究中得到了广泛的关注。目前，<ruby>鸟枪法宏基因组测序<rt>Shotgun metagenome sequencing</rt></ruby>已被广泛应用于探索负责 N 循环过程的基因家族。NCycDB 是一个手动管理的综合数据库，用于从鸟枪法宏基因组测序数据中快速准确地分析 N 循环基因（亚）家族。 NCycDB 总共包含 68 个基因（亚）家族，涵盖 8 个 N 循环过程，分别具有 95% 和 100% 一致性阈值的 84 759 和 219 146 个代表性序列。数据库中还包含了 1958 个<ruby>同源直系同源组<rt>Homologous orthology groups</rt></ruby>的序列，以避免由于 “小数据库” 问题导致的假阳性分配。</p>\n<h1 id=\"数据库及脚本\"><a class=\"markdownIt-Anchor\" href=\"#数据库及脚本\"></a> 数据库及脚本</h1>\n<h2 id=\"下载\"><a class=\"markdownIt-Anchor\" href=\"#下载\"></a> 下载</h2>\n<ul>\n<li>\n<p>通过 Git</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/liaochenlanruo/NCyc.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>通过 wget</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/liaochenlanruo/NCyc/archive/refs/heads/master.zip<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h2 id=\"配置\"><a class=\"markdownIt-Anchor\" href=\"#配置\"></a> 配置</h2>\n<ul>\n<li>通过 <code>Git</code>  下载的不需要解压，通过 <code>Wget</code>  下载的需要先解压。</li>\n<li>修改 <code>NCycProfilter.PL</code>  文件的第 8-13 行中 4 个依赖软件的安装路径。</li>\n<li>将 <code>data</code>  目录下的 <code>NCyc_100_2019Jul.7z</code>  解压，将解压得到的 <code>NCyc_100_2019Jul</code>  重命名为 <code>NCyc_100.faa</code>  并移动至 <code>data</code>  目录下。</li>\n</ul>\n<h2 id=\"依赖\"><a class=\"markdownIt-Anchor\" href=\"#依赖\"></a> 依赖</h2>\n<ul>\n<li>Blast</li>\n<li>diamond</li>\n<li>usearch</li>\n<li>Perl</li>\n</ul>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<ul>\n<li>\n<p>序列文件<br />\n宏基因组测序得到的 Reads 文件、组装后的序列文件以及通过基因预测后得到的氨基酸序列文件均可。序列文件可以是压缩的，也可以是解压的。</p>\n</li>\n<li>\n<p>基因组 - 序列数对应文件<br />\n提供一份文本文档，共包含两列，第一列为 <code>样本名称</code>  (即序列文件的名字，不带文件后缀名)，第二列为 <code>样本包含的序列数量</code> 。</p>\n</li>\n</ul>\n<h1 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl NCycProfiler.PL -d ./ -m diamond -f faa -s prot -si SI.txt -o Ncycle.out.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<div class=\"note info\">\n<p>参数解析：</p>\n</div>\n<p>-d 指定工作目录，即序列文件所在目录。<br />\n-m 指定用哪个软件进行序列比对，可选 <code>diamond</code> ， <code>blast</code> ， <code>usearch</code> 。<br />\n-f 指定序列文件的后缀名，不需要带 <code>.</code> 。<br />\n-s 指定序列类型，氨基酸为 <code>prot</code> ，核苷酸为 <code>nucl</code> 。<br />\n-si 基因组 - 序列数对应文件<br />\n - rs 随机取样大小，如果不指定，将取包含序列最少的样本的序列数<br />\n - o 指定输出的文件名称</p>\n<h1 id=\"结果解析\"><a class=\"markdownIt-Anchor\" href=\"#结果解析\"></a> 结果解析</h1>\n<p>得到的结果文件是一个表格，第一行为随机取样大小。第一列为参与 N 循环的基因名，其他列为各样本含有的对应基因的数量。</p>\n<h1 id=\"可视化\"><a class=\"markdownIt-Anchor\" href=\"#可视化\"></a> 可视化</h1>\n<p>可参考本站另一篇文章<a href=\"https://www.liaochenlanruo.fun/post/b68c.html\"> R 语言绘制气泡图 Bubb_Plot</a> 进行数据可视化。</p>\n<ul>\n<li>不带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 做主图</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 修改细节 — 图注，点大小，点shape</span>\nbubble_style <span class=\"token operator\">&lt;-</span> bubble <span class=\"token operator\">+</span> theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    labs<span class=\"token punctuation\">(</span>\n        x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span>\n        y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">,</span>\n        color<span class=\"token operator\">=</span><span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 颜色图注名</span>\n        size<span class=\"token operator\">=</span><span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>    <span class=\"token comment\"># 大小图注名</span>\n    scale_size<span class=\"token punctuation\">(</span>range <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>  <span class=\"token comment\">#等比修改圆圈大小</span>\n    theme<span class=\"token punctuation\">(</span>plot.title<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"Arial\"</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span>\n                                  color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span>face<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>\n                                  hjust<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>lineheight<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n          plot.subtitle <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nbubble_style<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>依据下表获得基因的 <code>Pathways</code>  和 <code>Annotation</code> ，随后依据 <code>Pathways</code>  进行分组并绘图。</p>\n<table>\n<thead>\n<tr>\n<th>Pathways</th>\n<th>Gene (sub) families</th>\n<th>Annotation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"9\">Nitrification</td>\n<td>amoA_A</td>\n<td>Ammonia monooxygenase subunit A (archaea)</td>\n</tr>\n<tr>\n<td>amoB_A</td>\n<td>Ammonia monooxygenase subunit B (archaea)</td>\n</tr>\n<tr>\n<td>amoC_A</td>\n<td>Ammonia monooxygenase subunit C (archaea)</td>\n</tr>\n<tr>\n<td>amoA_B</td>\n<td>Ammonia monooxygenase subunit A (bacteria)</td>\n</tr>\n<tr>\n<td>amoB_B</td>\n<td>Ammonia monooxygenase subunit B (bacteria)</td>\n</tr>\n<tr>\n<td>amoC_B</td>\n<td>Ammonia monooxygenase subunit C (bacteria)</td>\n</tr>\n<tr>\n<td>hao</td>\n<td>Hydroxylamine dehydrogenase</td>\n</tr>\n<tr>\n<td>nxrA</td>\n<td>Nitrite oxidoreductase, alpha subunit</td>\n</tr>\n<tr>\n<td>nxrB</td>\n<td>Nitrite oxidoreductase, beta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"16\">Denitrification</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>nirK</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>nirS</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>norB</td>\n<td>Nitric oxide reductase subunit B</td>\n</tr>\n<tr>\n<td>norC</td>\n<td>Nitric oxide reductase subunit C</td>\n</tr>\n<tr>\n<td>nosZ</td>\n<td>Nitrous-oxide reductase</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"6\">Assimilatory nitrate reduction</td>\n<td>nasA</td>\n<td>Assimilatory nitrate reductase catalytic subunit</td>\n</tr>\n<tr>\n<td>nasB</td>\n<td>Assimilatory nitrate reductase electron transfer subunit</td>\n</tr>\n<tr>\n<td>nirA</td>\n<td>Ferredoxin-nitrite reductase</td>\n</tr>\n<tr>\n<td>NR</td>\n<td>Nitrate reductase (NAD(P)H)</td>\n</tr>\n<tr>\n<td>narB</td>\n<td>Assimilatory nitrate reductase</td>\n</tr>\n<tr>\n<td>narC</td>\n<td>Cytochrome b-561</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Dissimilatory nitrate reduction</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td>nirB</td>\n<td>Nitrite reductase (NADH) large subunit</td>\n</tr>\n<tr>\n<td>nirD</td>\n<td>Nitrite reductase (NADH) small subunit</td>\n</tr>\n<tr>\n<td>nrfA</td>\n<td>Nitrite reductase (cytochrome c-552)</td>\n</tr>\n<tr>\n<td>nrfB</td>\n<td>Cytochrome c-type protein NrfB</td>\n</tr>\n<tr>\n<td>nrfC</td>\n<td>Protein NrfC</td>\n</tr>\n<tr>\n<td>nrfD</td>\n<td>Protein NrfD</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Nitrogen fixation</td>\n<td>anfG</td>\n<td>Nitrogenase delta subunit</td>\n</tr>\n<tr>\n<td>nifD</td>\n<td>Nitrogenase molybdenum-iron protein alpha chain</td>\n</tr>\n<tr>\n<td>nifH</td>\n<td>Nitrogenase iron protein NifH</td>\n</tr>\n<tr>\n<td>nifK</td>\n<td>Nitrogenase molybdenum-iron protein beta chain</td>\n</tr>\n<tr>\n<td>nifW</td>\n<td>Nitrogenase-stabilizing/protective protein</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Anammox</td>\n<td>hzo</td>\n<td>Hydrazine oxidoreductase</td>\n</tr>\n<tr>\n<td>hzsA</td>\n<td>Hydrazine synthase subunit A</td>\n</tr>\n<tr>\n<td>hzsB</td>\n<td>Hydrazine synthase subunit B</td>\n</tr>\n<tr>\n<td>hzsC</td>\n<td>Hydrazine synthase subunit C</td>\n</tr>\n<tr>\n<td>hdh</td>\n<td>Hydrazine dehydrogenase</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Organic degradation and synthesis</td>\n<td>ureA</td>\n<td>Urease subunit gamma</td>\n</tr>\n<tr>\n<td>ureB</td>\n<td>Urease subunit beta</td>\n</tr>\n<tr>\n<td>ureC</td>\n<td>Urease subunit alpha</td>\n</tr>\n<tr>\n<td>nao</td>\n<td>Nitroalkane oxidase</td>\n</tr>\n<tr>\n<td>nmo</td>\n<td>Nitronate monooxygenase</td>\n</tr>\n<tr>\n<td>gdh_K00260</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gdh_K00261</td>\n<td>Glutamate dehydrogenase (NAD(P)+)</td>\n</tr>\n<tr>\n<td>gdh_K00262</td>\n<td>Glutamate dehydrogenase (NADP+)</td>\n</tr>\n<tr>\n<td>gdh_K15371</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gs_K00264</td>\n<td>Glutamate synthase (NADPH/NADH)</td>\n</tr>\n<tr>\n<td>gs_K00265</td>\n<td>Glutamate synthase (NADPH/NADH) large chain</td>\n</tr>\n<tr>\n<td>gs_K00266</td>\n<td>Glutamate synthase (NADPH/NADH) small chain</td>\n</tr>\n<tr>\n<td>gs_K00284</td>\n<td>Glutamate synthase (ferredoxin)</td>\n</tr>\n<tr>\n<td>glsA</td>\n<td>Glutaminase</td>\n</tr>\n<tr>\n<td>glnA</td>\n<td>Glutamine synthetase</td>\n</tr>\n<tr>\n<td>asnB</td>\n<td>Asparagine synthase (glutamine-hydrolysing)</td>\n</tr>\n<tr>\n<td>ansB</td>\n<td>Glutamin-(asparagin-)ase</td>\n</tr>\n<tr>\n<td rowspan=\"4\">Others</td>\n<td>hcp</td>\n<td>Hydroxylamine reductase</td>\n</tr>\n<tr>\n<td>pmoA</td>\n<td>Particulate methane monooxygenase subunit A</td>\n</tr>\n<tr>\n<td>pmoB</td>\n<td>Particulate methane monooxygenase subunit B</td>\n</tr>\n<tr>\n<td>pmoC</td>\n<td>Particulate methane monooxygenase subunit C</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Annotation\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Pathways\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"black\"</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis.text.y <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.grid <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> panel.border <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.spacing <span class=\"token operator\">=</span> unit<span class=\"token punctuation\">(</span><span class=\"token number\">.1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"lines\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>plot.margin<span class=\"token operator\">=</span>unit<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cm\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> facet_grid<span class=\"token punctuation\">(</span>Pathways <span class=\"token operator\">~</span> .<span class=\"token punctuation\">,</span> drop<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span>space<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span> switch <span class=\"token operator\">=</span> <span class=\"token string\">\"y\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>strip.background <span class=\"token operator\">=</span> element_rect<span class=\"token punctuation\">(</span>fill <span class=\"token operator\">=</span> <span class=\"token string\">\"grey95\"</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"white\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text.y.left <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle<span class=\"token operator\">=</span><span class=\"token number\">360</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://doi.org/10.1093/bioinformatics/bty741\">NCycDB: a curated integrative database for fast and accurate metagenomic profiling of nitrogen cycling genes</a></li>\n<li><a href=\"https://github.com/qichao1984/NCyc\">GitHub</a></li>\n</ul>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “18ea” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"宏基因组","path":"api/tags/宏基因组.json"}]},{"title":"在Linux服务器中安装网页版Rstudio","slug":"在Linux服务器中安装网页版Rstudio","date":"2021-11-02T01:37:03.000Z","updated":"2022-01-08T02:16:28.439Z","comments":true,"path":"api/articles/在Linux服务器中安装网页版Rstudio.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_1.jpg","content":"<p>本文演示如何在 CentOS7 服务器上安装 Rstudio server。</p>\n<h1 id=\"安装rstudio\"><a class=\"markdownIt-Anchor\" href=\"#安装rstudio\"></a> 安装 Rstudio</h1>\n<p>访问<a href=\"https://www.rstudio.com/products/rstudio/download-server\"> Rstudio 官网</a>，选择对应的 Linux 发行版，下载 Rstudio 安装包。本文以最常见的 CentOS7 为例演示，<strong>前提是系统中已经安装了 R</strong>。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://download2.rstudio.org/server/centos7/x86_64/rstudio-server-rhel-2021.09.0-351-x86_64.rpm\n<span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> rstudio-server-rhel-2021.09.0-351-x86_64.rpm<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h1 id=\"开启rstudio服务\"><a class=\"markdownIt-Anchor\" href=\"#开启rstudio服务\"></a> 开启 Rstudio 服务</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> systemctl <span class=\"token builtin class-name\">enable</span> rstudio-server.service\n<span class=\"token function\">sudo</span> systemctl start rstudio-server.service\n<span class=\"token function\">sudo</span> systemctl status rstudio-server<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"开启8787端口\"><a class=\"markdownIt-Anchor\" href=\"#开启8787端口\"></a> 开启 8787 端口</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> firewalld\n<span class=\"token function\">sudo</span> firewall-cmd --permanent --add-port<span class=\"token operator\">=</span><span class=\"token number\">8787</span>/tcp\n<span class=\"token function\">sudo</span> firewall-cmd --permanent --add-port<span class=\"token operator\">=</span><span class=\"token number\">8787</span>/udp\n<span class=\"token function\">sudo</span> firewall-cmd --reload<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"远程登录rstudio\"><a class=\"markdownIt-Anchor\" href=\"#远程登录rstudio\"></a> 远程登录 Rstudio</h1>\n<p>在浏览器地址栏输入 <code>http://ip:8787/</code>  打开网页，输入自己的用户名和密码登录即可。</p>\n<h1 id=\"错误处理\"><a class=\"markdownIt-Anchor\" href=\"#错误处理\"></a> 错误处理</h1>\n<h2 id=\"rstudio服务启动失败\"><a class=\"markdownIt-Anchor\" href=\"#rstudio服务启动失败\"></a> Rstudio 服务启动失败</h2>\n<h3 id=\"症状\"><a class=\"markdownIt-Anchor\" href=\"#症状\"></a> 症状</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"sudo rstudio-server status\" /></p>\n<h3 id=\"排雷\"><a class=\"markdownIt-Anchor\" href=\"#排雷\"></a> 排雷</h3>\n<ul>\n<li>\n<p>检查安装</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> rstudio-server verify-installation<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"sudo rstudio-server verify-installation\" /></p>\n<p>提示 “/usr/lib/rstudio-server/bin/rsession: error while loading shared libraries: <a href=\"http://libR.so\">libR.so</a>: cannot open shared object file: No such file or directory”，表明缺少 libR.so 库。</p>\n</li>\n<li>\n<p>安装 R</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> -y R.x86_64<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>再次检查安装情况</p>\n<p>提示找不到 R。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"sudo rstudio-server verify-installation\" /></p>\n<p>可以看到这里进入了 conda 的 base 环境，它影响了程序的判断，退出 conda 环境后再试一下就不再报错了。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda deactivate<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注</strong>：conda 环境一定要退彻底。</p>\n</li>\n<li>\n<p>再次启动 Rstudio 服务，并查看状态</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> rstudio-server start\n<span class=\"token function\">sudo</span> rstudio-server status<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_4.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/ea71_4.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"rstudio-server正常运行\" /></p>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"R语言","path":"api/tags/R语言.json"},{"name":"软件","path":"api/tags/软件.json"}]},{"title":"在FASTA文件中搜索完全匹配的短序列","slug":"在FASTA文件中搜索完全匹配的短序列","date":"2021-10-20T13:12:57.000Z","updated":"2022-01-08T02:16:28.438Z","comments":true,"path":"api/articles/在FASTA文件中搜索完全匹配的短序列.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>有时候需要在 FASTA 格式的文件中搜索短的保守序列，这个时候采用查找法比使用 blast 等序列比对更加人性化。<u>但是要注意避坑，即 FASTA 文档中的序列一般是被打断为许多行的，如果要查找的目标序列恰好在断行处，是没有办法直接揪出它的</u>，所以在查找前需要将序列中间的换行符去掉，将其变为一行。</p>\n<p>该任务可以通过 Perl 脚本<strong> search_short_seqs.pl</strong> 实现。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: Oct 20, 2021</span>\n\n<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$ARGV[0]\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Target_seqs.fa\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$ARGV</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$seq</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$seq</span><span class=\"token operator\">=~</span><span class=\"token regex\">/$str/i</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\">$id\\n$seq\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>运行方法：将<strong> search_short_seqs.pl</strong> 与输入文件（FASTA 文件）放在同一目录中，在终端里运行如下命令</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl search_short_seqs.pl FASTA文件 要查找的序列<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>带有搜索序列的序列将输出到文件<strong> Target_seqs.fa</strong> 中。</p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “6a93” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"序列处理","path":"api/tags/序列处理.json"}]},{"title":"扩增子分析--计算随机过程和决定性过程比例","slug":"扩增子分析-计算随机过程和决定性过程比例","date":"2021-03-25T08:42:06.000Z","updated":"2022-01-08T02:16:28.447Z","comments":true,"path":"api/articles/扩增子分析-计算随机过程和决定性过程比例.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>确定性过程（deterministic processes）和随机性过程（stochastic processes) 是两个影响微生物群落结构系统发育组装的重要过程，本文介绍计算二者所占比例的方法。</p>\n<span id=\"more\"></span>\n<h1 id=\"font-colorff0000-1-软件font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-1-软件font\"></a> <font color=#FF0000 >1. 软件</font></h1>\n<ul>\n<li>NST</li>\n<li>iCAMP</li>\n<li>ape 用于读取进化树文件</li>\n<li>picante</li>\n</ul>\n<h1 id=\"font-colorff0000-2-文件准备font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-2-文件准备font\"></a> <font color=#FF0000 >2. 文件准备</font></h1>\n<h2 id=\"font-colorff0000-21-feature-tablefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-21-feature-tablefont\"></a> <font color=#FF0000 >2.1 Feature Table</font></h2>\n<p>行为 OTUs/ASVs，列为样本。</p>\n<table>\n<thead>\n<tr>\n<th>TaxonID</th>\n<th>Sample 1</th>\n<th>Sample 2</th>\n<th>Sample 3</th>\n<th>Sample 4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OTU1</td>\n<td>232.0</td>\n<td>209.0</td>\n<td>349.0</td>\n<td>256.0</td>\n</tr>\n<tr>\n<td>OTU2</td>\n<td>75.0</td>\n<td>35.0</td>\n<td>44.0</td>\n<td>0.0</td>\n</tr>\n<tr>\n<td>OTU3</td>\n<td>237.0</td>\n<td>224.0</td>\n<td>291.0</td>\n<td>353.0</td>\n</tr>\n<tr>\n<td>OTU4</td>\n<td>371.0</td>\n<td>80.0</td>\n<td>319.0</td>\n<td>345.0</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"font-colorff0000-22-group-filefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-22-group-filefont\"></a> <font color=#FF0000 >2.2 Group File</font></h2>\n<p>该文件描述了所有样本的分组情况，如实验组和对照组，或者其他分组。</p>\n<table>\n<thead>\n<tr>\n<th>Sample_ID</th>\n<th>Group</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Sample 1</td>\n<td>Group x</td>\n</tr>\n<tr>\n<td>Sample 2</td>\n<td>Group x</td>\n</tr>\n<tr>\n<td>Sample 3</td>\n<td>Group y</td>\n</tr>\n<tr>\n<td>Sample 4</td>\n<td>Group y</td>\n</tr>\n<tr>\n<td>...</td>\n<td>...</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"font-colorff0000-23-tree-filefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-23-tree-filefont\"></a> <font color=#FF0000 >2.3 Tree File</font></h2>\n<p>包含 Feature table 中所有 OTUs/ASVs 的系统发育树文件，理想条件下仅包含 Feature table 中的 OTUs/ASVs，不过大部分情况下还会包含数据库中的一些物种，在随后的分析中需要去除多余的物种（后续会讲到）。</p>\n<h1 id=\"font-colorff0000-3-开始分析font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-3-开始分析font\"></a> <font color=#FF0000 >3. 开始分析</font></h1>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\">########################</span>\n<span class=\"token comment\">#!/usr/bin/env R</span>\n<span class=\"token comment\"># version 20200919</span>\n<span class=\"token comment\"># Step 1. 文件、路径和参数</span>\n\n<span class=\"token comment\"># 指定包含输入文件的目录路径，注意区分Windows和Linux的路径写法</span>\nwd<span class=\"token operator\">=</span><span class=\"token string\">\"/mnt/e/Researches/lujia16S/Analysis_20200907/exported-feature-table_2k_abund22/Raup_Crick\"</span>\n\n<span class=\"token comment\"># 指定结果文件的保存路径</span>\nsave.wd<span class=\"token operator\">=</span><span class=\"token string\">\"/mnt/e/Researches/lujia16S/Analysis_20200907/exported-feature-table_2k_abund22/Raup_Crick/Result2\"</span>\n\n<span class=\"token comment\"># 创建文件保存路径</span>\ndir.create<span class=\"token punctuation\">(</span>save.wd<span class=\"token punctuation\">,</span> recursive <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 指定Feature table（OTU表）的文件名</span>\ncom.file<span class=\"token operator\">=</span><span class=\"token string\">\"feature-table.tsv\"</span>\n\n<span class=\"token comment\"># 指定样本分组文件，每行为一个样本</span>\ngroup.file<span class=\"token operator\">=</span><span class=\"token string\">\"treatment.txt\"</span>\n\n<span class=\"token comment\"># 指定NWK格式的系统发育树文件</span>\ntree.file<span class=\"token operator\">=</span><span class=\"token string\">\"tree.nwk\"</span>\n\n<span class=\"token comment\"># 设置并行运算使用的线程数</span>\nnworker<span class=\"token operator\">=</span><span class=\"token number\">8</span>\n\n<span class=\"token comment\"># randomization time for null model analysis. 真实分析的时候一般设置为1000，如果测试的话可以设20</span>\nrand.time<span class=\"token operator\">=</span><span class=\"token number\">999</span>\n\n<span class=\"token comment\"># 输出文件的前缀名，随便设置</span>\nprefix<span class=\"token operator\">=</span><span class=\"token string\">\"Lujia\"</span>\n\n<span class=\"token comment\"># Step 2. 加载R包</span>\n\n<span class=\"token comment\"># 确保已经安装过所需的R包</span>\n<span class=\"token comment\">#install.packages(\"NST\") </span>\n\nlibrary<span class=\"token punctuation\">(</span>ape<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>iCAMP<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>NST<span class=\"token punctuation\">)</span> <span class=\"token comment\"># need to be NST >=3.0.3</span>\nlibrary<span class=\"token punctuation\">(</span>picante<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 3. 加载数据并匹配IDs</span>\n\nsetwd<span class=\"token punctuation\">(</span>wd<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 读入Feature Table，注意自己文件的列与列之间的分隔符是什么，制表符用sep = \"\\t\"，逗号用sep = \",\"</span>\ncomm<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>read.table<span class=\"token punctuation\">(</span>com.file<span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> row.names <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> as.is <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> stringsAsFactors <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 读入分组文件，同样注意设置分隔符</span>\ngroup<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span>group.file<span class=\"token punctuation\">,</span> header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> row.names <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> as.is <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> stringsAsFactors <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#如果tree中的OTUs和Feature Table中的OTUs一一对应，可以直接用下面一个命令读入tree（注意去掉###），否则的话则运行下面LHL加入的3行命令</span>\n<span class=\"token comment\">###tree=ape::read.tree(file = tree.file) # if you have tree</span>\n\n<span class=\"token comment\"># 以下3行是LHL加入的</span>\nphy<span class=\"token operator\">&lt;-</span>read.tree<span class=\"token punctuation\">(</span>tree.file<span class=\"token punctuation\">)</span><span class=\"token comment\"># 读入树文件</span>\nprune_tree<span class=\"token operator\">&lt;-</span>prune.sample<span class=\"token punctuation\">(</span>comm<span class=\"token punctuation\">,</span>phy<span class=\"token punctuation\">)</span><span class=\"token comment\"># 使树文件和OTU表文件一一对齐</span>\ntree<span class=\"token operator\">=</span>prune_tree <span class=\"token comment\"># 此刻的Tree干净了，可用于后续分析而不会报错</span>\n\n<span class=\"token comment\"># 以下命令检测Feature Table中的样本名称是否与分组文件中的样本名一一对应</span>\nsamp.ck<span class=\"token operator\">=</span>NST<span class=\"token operator\">::</span>match.name<span class=\"token punctuation\">(</span>rn.list<span class=\"token operator\">=</span>list<span class=\"token punctuation\">(</span>comm<span class=\"token operator\">=</span>comm<span class=\"token punctuation\">,</span>group<span class=\"token operator\">=</span>group<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ncomm<span class=\"token operator\">=</span>samp.ck<span class=\"token operator\">$</span>comm\ncomm<span class=\"token operator\">=</span>comm<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span>colSums<span class=\"token punctuation\">(</span>comm<span class=\"token punctuation\">)</span><span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>drop<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">]</span>\ngroup<span class=\"token operator\">=</span>samp.ck<span class=\"token operator\">$</span>group\n\n<span class=\"token comment\"># 以下命令检测Feature Table中的OTUs名称是否与Tree中的OTUs名一一对应</span>\ntax.ck<span class=\"token operator\">=</span>NST<span class=\"token operator\">::</span>match.name<span class=\"token punctuation\">(</span>cn.list <span class=\"token operator\">=</span> list<span class=\"token punctuation\">(</span>comm<span class=\"token operator\">=</span>comm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>tree.list <span class=\"token operator\">=</span> list<span class=\"token punctuation\">(</span>tree<span class=\"token operator\">=</span>tree<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># if you have tree</span>\ncomm<span class=\"token operator\">=</span>tax.ck<span class=\"token operator\">$</span>comm\ntree<span class=\"token operator\">=</span>tax.ck<span class=\"token operator\">$</span>tree\n\n<span class=\"token comment\"># Step 4. Grouping way and metacommunity seting</span>\n\n<span class=\"token comment\"># 选择分组，如果拥有多种分组方式，每次运行时选择其中的一组。此处选择的时分组文件中的第二列</span>\ngroupi<span class=\"token operator\">=</span>group<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>drop<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 重新定义输出文件的前缀，以分组的名称来命名，此处以分组文件第二列的表头“Group”为前缀</span>\nprefixi<span class=\"token operator\">=</span>paste0<span class=\"token punctuation\">(</span>prefix<span class=\"token punctuation\">,</span><span class=\"token string\">\".Group\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># if treatment and control are from different metacommunities, you may set meta.groupi=groupi，默认为NULL</span>\n<span class=\"token comment\">#meta.groupi=NULL</span>\nmeta.groupi<span class=\"token operator\">=</span>groupi\n\n<span class=\"token comment\"># Step 5. taxonomic NST</span>\n<span class=\"token comment\"># Step 5.1 calculate tNST</span>\n\n<span class=\"token comment\"># 指定计算距离矩阵的方法，\"jaccard\" and \"bray\" are preferred.</span>\ndist.method<span class=\"token operator\">=</span><span class=\"token string\">\"bray\"</span>\n\n<span class=\"token comment\"># 记录运行时间</span>\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 进入输出目录</span>\nsetwd<span class=\"token punctuation\">(</span>save.wd<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 计算tNST</span>\ntnst<span class=\"token operator\">=</span>tNST<span class=\"token punctuation\">(</span>comm<span class=\"token operator\">=</span>comm<span class=\"token punctuation\">,</span> group<span class=\"token operator\">=</span>groupi<span class=\"token punctuation\">,</span> meta.group<span class=\"token operator\">=</span>meta.groupi<span class=\"token punctuation\">,</span> meta.com<span class=\"token operator\">=</span><span class=\"token keyword\">NULL</span><span class=\"token punctuation\">,</span> dist.method<span class=\"token operator\">=</span>dist.method<span class=\"token punctuation\">,</span> abundance.weighted<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> rand<span class=\"token operator\">=</span>rand.time<span class=\"token punctuation\">,</span> output.rand<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> nworker<span class=\"token operator\">=</span>nworker<span class=\"token punctuation\">,</span> LB<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> null.model<span class=\"token operator\">=</span><span class=\"token string\">\"PF\"</span><span class=\"token punctuation\">,</span> between.group<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> SES<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> RC<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 以R data格式保存tNST的输出 </span>\nsave<span class=\"token punctuation\">(</span>tnst<span class=\"token punctuation\">,</span> file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span> <span class=\"token string\">\".tNST.rda\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 保存其他tNST结果到多个文件中</span>\nwrite.table<span class=\"token punctuation\">(</span>tnst<span class=\"token operator\">$</span>index.grp<span class=\"token punctuation\">,</span> file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span> <span class=\"token string\">\".tNST.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>tnst<span class=\"token operator\">$</span>index.pair.grp<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.pairwise.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>tnst<span class=\"token operator\">$</span>index.pair<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.pairwise.index.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\nwrite.table<span class=\"token punctuation\">(</span>tnst<span class=\"token operator\">$</span>index.between<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.between.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>tnst<span class=\"token operator\">$</span>index.pair.between<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.pairwise.between.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nformat<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 5.2 Bootstrapping test</span>\n\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 计算Bootstrapping</span>\ntnstbt<span class=\"token operator\">=</span>nst.boot<span class=\"token punctuation\">(</span>nst.result<span class=\"token operator\">=</span>tnst<span class=\"token punctuation\">,</span> group<span class=\"token operator\">=</span>groupi<span class=\"token punctuation\">,</span> rand<span class=\"token operator\">=</span>rand.time<span class=\"token punctuation\">,</span> trace<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> two.tail<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> out.detail<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> between.group<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> nworker<span class=\"token operator\">=</span>nworker<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 保存结果</span>\nsave<span class=\"token punctuation\">(</span>tnstbt<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.boot.rda\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 保存结果</span>\nwrite.table<span class=\"token punctuation\">(</span>tnstbt<span class=\"token operator\">$</span>summary<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.boot.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\nwrite.table<span class=\"token punctuation\">(</span>tnstbt<span class=\"token operator\">$</span>compare<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.boot.compare.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">(</span>t<span class=\"token operator\">=</span>format<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 5.3 PERMANOVA</span>\n\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ntnstpaov<span class=\"token operator\">=</span>nst.panova<span class=\"token punctuation\">(</span>nst.result<span class=\"token operator\">=</span>tnst<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> groupi<span class=\"token punctuation\">,</span> rand <span class=\"token operator\">=</span> rand.time<span class=\"token punctuation\">,</span> trace <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>tnstpaov<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".tNST.PERMANOVA.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">(</span>t<span class=\"token operator\">=</span>format<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Steo 6. phylogenetic NST</span>\n\n<span class=\"token comment\"># Step 6.1 phylogentic distance matrix # use bigmemory for big dataset</span>\n\nwd.pd<span class=\"token operator\">=</span>paste0<span class=\"token punctuation\">(</span>save.wd<span class=\"token punctuation\">,</span><span class=\"token string\">\"/pdbig\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>dir.exists<span class=\"token punctuation\">(</span>wd.pd<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>dir.create<span class=\"token punctuation\">(</span>wd.pd<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span>\n\nsetwd<span class=\"token punctuation\">(</span>wd.pd<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>file.exists<span class=\"token punctuation\">(</span><span class=\"token string\">\"pd.desc\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">&#123;</span>\n  <span class=\"token comment\"># if already done before, directly use it.</span>\n  pdbig<span class=\"token operator\">=</span>list<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  pdbig<span class=\"token operator\">$</span>tip.label<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"pd.taxon.name.csv\"</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> row.names <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> stringsAsFactors <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> as.is <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n  pdbig<span class=\"token operator\">$</span>pd.wd<span class=\"token operator\">=</span>wd.pd\n  pdbig<span class=\"token operator\">$</span>pd.file<span class=\"token operator\">=</span><span class=\"token string\">\"pd.desc\"</span>\n  pdbig<span class=\"token operator\">$</span>pd.name.file<span class=\"token operator\">=</span><span class=\"token string\">\"pd.taxon.name.csv\"</span>\n<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span><span class=\"token punctuation\">&#123;</span>\n  pdbig<span class=\"token operator\">=</span>iCAMP<span class=\"token operator\">::</span>pdist.big<span class=\"token punctuation\">(</span>tree <span class=\"token operator\">=</span> tree<span class=\"token punctuation\">,</span> wd <span class=\"token operator\">=</span> wd.pd<span class=\"token punctuation\">,</span> nworker <span class=\"token operator\">=</span> nworker<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># Step 6.2 calculate pNST</span>\n\n<span class=\"token comment\"># to count time cost</span>\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nsetwd<span class=\"token punctuation\">(</span>save.wd<span class=\"token punctuation\">)</span>\n\npnst<span class=\"token operator\">=</span>NST<span class=\"token operator\">::</span>pNST<span class=\"token punctuation\">(</span>comm<span class=\"token operator\">=</span>comm<span class=\"token punctuation\">,</span> pd.desc<span class=\"token operator\">=</span>pdbig<span class=\"token operator\">$</span>pd.file<span class=\"token punctuation\">,</span> pd.wd<span class=\"token operator\">=</span>pdbig<span class=\"token operator\">$</span>pd.wd<span class=\"token punctuation\">,</span>\npd.spname<span class=\"token operator\">=</span>pdbig<span class=\"token operator\">$</span>tip.label<span class=\"token punctuation\">,</span> group<span class=\"token operator\">=</span>groupi<span class=\"token punctuation\">,</span> meta.group<span class=\"token operator\">=</span>meta.groupi<span class=\"token punctuation\">,</span> abundance.weighted<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> rand<span class=\"token operator\">=</span>rand.time<span class=\"token punctuation\">,</span> output.rand<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> taxo.null.model<span class=\"token operator\">=</span><span class=\"token keyword\">NULL</span><span class=\"token punctuation\">,</span> phylo.shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> exclude.conspecifics<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> nworker<span class=\"token operator\">=</span>nworker<span class=\"token punctuation\">,</span> between.group<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> SES<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> RC<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># save pNST output in R data format</span>\nsave<span class=\"token punctuation\">(</span>pnst<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.rda\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnst<span class=\"token operator\">$</span>index.grp<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnst<span class=\"token operator\">$</span>index.pair.grp<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.pairwise.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnst<span class=\"token operator\">$</span>index.pair<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.pairwise.index.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnst<span class=\"token operator\">$</span>index.between<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.between.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnst<span class=\"token operator\">$</span>index.pair.between<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.pairwise.between.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nformat<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 6.3 Bootstrapping test</span>\n\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\npnstbt<span class=\"token operator\">=</span>nst.boot<span class=\"token punctuation\">(</span>nst.result<span class=\"token operator\">=</span>pnst<span class=\"token punctuation\">,</span> group<span class=\"token operator\">=</span>groupi<span class=\"token punctuation\">,</span> rand<span class=\"token operator\">=</span>rand.time<span class=\"token punctuation\">,</span> trace<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> two.tail<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> out.detail<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> between.group<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> nworker<span class=\"token operator\">=</span>nworker<span class=\"token punctuation\">)</span>\n\nsave<span class=\"token punctuation\">(</span>pnstbt<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.boot.rda\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnstbt<span class=\"token operator\">$</span>summary<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.boot.summary.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnstbt<span class=\"token operator\">$</span>compare<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.boot.compare.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">(</span>t<span class=\"token operator\">=</span>format<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 6.4 PERMANOVA</span>\n\nt1<span class=\"token operator\">=</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\npnstpaov<span class=\"token operator\">=</span>nst.panova<span class=\"token punctuation\">(</span>nst.result<span class=\"token operator\">=</span>pnst<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> groupi<span class=\"token punctuation\">,</span> rand <span class=\"token operator\">=</span> rand.time<span class=\"token punctuation\">,</span> trace <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\nwrite.table<span class=\"token punctuation\">(</span>pnstpaov<span class=\"token punctuation\">,</span>file <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span>prefixi<span class=\"token punctuation\">,</span><span class=\"token string\">\".pNST.PERMANOVA.csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span>sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">(</span>t<span class=\"token operator\">=</span>format<span class=\"token punctuation\">(</span>Sys.time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"font-colorff0000-4-结果解读font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-4-结果解读font\"></a> <font color=#FF0000 >4. 结果解读</font></h1>\n<h2 id=\"font-colorff0000-41-确定性过程和随机性过程的相对重要性font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-41-确定性过程和随机性过程的相对重要性font\"></a> <font color=#FF0000 >4.1 确定性过程和随机性过程的相对重要性</font></h2>\n<ul>\n<li>\n<p>An index, normalized stochasticity ratio (NST), was developed with 50% as the boundary point between more deterministic (&lt;50%) and more stochastic (&gt;50%) assembly. <font color=#2196F3>NST &gt; 50% 时 Stochastic Processes 占主导，而 NST &lt; 50% 时，Deterministic Processes 占主导。</font></p>\n</li>\n<li>\n<p>用显著的偏差 (即 |β NTI|&gt; 2) 来表示确定性过程占主导地位和用小的偏差 (即 |β NTI| &lt; 2) 来表明随机过程占主导地位。用显著的偏差 (即 |β NTI| &gt; 2) 来表示确定性过程占主导地位和用小的偏差 (即 |β NTI| &lt; 2) 来表明随机过程占主导地位。同质性和变异性选择应分别造成小于和大于预期的群落更替；βNTI &lt;−2 或 &gt; + 2 进一步解释为表明同质性或变异性选择分别占主导地位；</p>\n</li>\n</ul>\n<h2 id=\"font-colorff0000-42-通过rcbray判断随机过程中各种过程的贡献font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-42-通过rcbray判断随机过程中各种过程的贡献font\"></a> <font color=#FF0000 >4.2 通过 RCbray 判断随机过程中各种过程的贡献</font></h2>\n<p>Modified Raup-Crick index (RCbray) is subsequently calculated by comparing empirically observed Bray-Curtis and simulated null distribution. Thus, according to themodified Raup-Crick index (RCbray), stochastic processes could be classified into 3 ecological processes: 均质分散 homogenizing dispersal (RCbray &lt; −0.95), 分散限制 dispersal limitation (RCbray &gt; +0.95) and 生态漂变 ecological drift (−0.95&lt; RCbray &lt; +0.95) <a href=\"https://doi.org/10.1038/ismej.2012.22\">Stegen et al., 2012</a>;  <a href=\"https://doi.org/10.1038/ismej.2013.93\">Stegen et al., 2013</a>.</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"扩增子","path":"api/tags/扩增子.json"}]},{"title":"按照Contig切割GenBank文件","slug":"按照Contig切割GenBank文件","date":"2021-10-09T02:08:00.000Z","updated":"2022-01-08T02:16:28.449Z","comments":true,"path":"api/articles/按照Contig切割GenBank文件.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>当一个基因组含有多个 Contigs/Scaffolds 的时候，在 GenBank 文件中也会产生多个 LOCUS。某些软件会将 GenBank 文件作为输入，但仅支持一个 GenBank 文件中只包含一条 Contig/Scaffold，如基因岛预测软件<a href=\"https://github.com/brinkmanlab/islandpath\"> islandpath</a>。这个时候就需要我们将 GenBank 文件进行切割。手动切是体力活，也不像钓鱼那样有成就感，因此提供一个脚本 &quot;split_GenBank.pl&quot; 来完成。</p>\n<p><font color=\"#FF0000\"><strong>敬告</strong>：使用该脚本请引用本文网址，请尊重本人的劳动成果，谢谢！</font></p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Oct 9, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@gbk</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.gbk\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 批处理所有后缀为.gbk的文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@gbk</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).gbk/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"LOCUS\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\s+(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$scaf</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$scaf</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".gb\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$assession</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$scaf</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/ACCESSION.+/ACCESSION   $assession/g</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 添加ACCESSION number</span>\n\t\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"LOCUS$_\"</span><span class=\"token punctuation\">;</span>\n\t\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将脚本与后缀名为 “.gbk” 的 GenBank 文件放在同一目录下，运行如下代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl split_GenBank.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>得到的后缀名为 “.gb” 的文件即为切割后的 GenBank 文件。</p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “d9f9” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"序列处理","path":"api/tags/序列处理.json"},{"name":"perl","path":"api/tags/perl.json"},{"name":"编程","path":"api/tags/编程.json"}]},{"title":"根据基因组预测表型 —— traitar的安装与使用","slug":"根据基因组预测表型-traitar的安装与使用","date":"2018-12-13T12:22:16.000Z","updated":"2022-01-08T02:16:28.456Z","comments":true,"path":"api/articles/根据基因组预测表型-traitar的安装与使用.json","excerpt":null,"keywords":null,"cover":"https://upload-images.jianshu.io/upload_images/11790868-82b7bc9d8c442804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","content":"<p>Traitar 用于从基因组序列中提取表型，它提供了表型分类器，可以预测与碳和能源使用、氧气需求、形态学、抗生素易感性、蛋白水解和酶活性等有关的67个性状。</p>\n<span id=\"more\"></span>\n<p>1. 软件安装——<a href=\"https://github.com/hzi-bifo/traitar\" target=\"_blank\">traitar</a></p><p>安装基本依赖：</p><blockquote><p>sudo apt-get install python-scipy python-matplotlib python-pip python-pandas</p></blockquote><p>进入要安装软件的目录，我的为家目录下的tools：</p><blockquote><p>cd ~/tools</p></blockquote><p>=======================================================</p><p>安装主程序到家目录下</p><blockquote><p>pip install traitar --user</p></blockquote><p>将添加到环境变量中：</p><blockquote>\n<p>vim ~/.zshrc</p>\n<p>i</p>\n</blockquote><p>文档末尾添加：</p><p>PATH=$PATH:$HOME/.local/bin/</p><p>ESC</p><blockquote><p>shift + :</p></blockquote><blockquote><p>wq!</p></blockquote><blockquote><p>source ~/.zshrc</p></blockquote><p>安装依赖软件（parallel， prodigal， hmmer）</p><blockquote><p>sudo apt-get install parallel prodigal hmmer</p></blockquote><p>下载pfam数据库到家目录下并建库</p><blockquote><p>traitar pfam ~/</p></blockquote><p>也可以手动下载pfam数据库（如果上一条不出错可以不运行后面的几条命令）：</p><blockquote><p>cd ~/</p></blockquote><p>官方提供的为Pfam27.0，我下载的为最新的Pfam32.0（下面两个命令选一个运行即可）：</p><blockquote><p>wget ftp://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam27.0/Pfam-A.hmm.gz</p></blockquote><blockquote><p>wget ftp://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam32.0/Pfam-A.hmm.gz</p></blockquote><p>将Pfam-A.hmm.gz解压缩，然后运行下面的命令建库：</p><blockquote><p>traitar pfam --local ~/</p></blockquote><p>软件运行出错的话：</p><p>错误提示：ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.</p><p>运行：</p><blockquote><p>conda install -c conda-forge numpy</p></blockquote><p>错误提示：AttributeError: 'DataFrame' object has no attribute 'sort'</p><p>pandas降级：</p><blockquote><p>conda install pandas=0.19.2</p></blockquote><p>错误提示：Python的最大递归深度错误 “maximum recursion depth exceeded while calling a Python object”</p><p>编辑脚本（~/miniconda3/lib/python2.7/site-packages/scipy/cluster/hierarchy.py），第183行加入两行，将默认的1000改大，比如2000（因为我有1000多个基因组）</p><blockquote><p>import sys</p></blockquote><p>#print sys.getrecursionlimit()</p><blockquote><p>sys.setrecursionlimit(2000)</p></blockquote><p>错误提示：RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility</p><blockquote>\n<p>pip uninstall -y scipy scikit-learn</p>\n<p>pip install --no-binary scipy scikit-learn</p>\n</blockquote><hr><p>2. 软件使用</p><p>首先进入含有基因组文件目录的上一级目录，输入命令执行：</p><blockquote><p>traitar phenotype &lt;in dir&gt; &lt;sample file&gt; from_nucleotides &lt;out_dir&gt; -c 2</p></blockquote><p>&lt;in dir&gt;：包含基因组的输入目录</p><p>&lt;sample file&gt;：描述文件，置于&lt;in dir&gt;的父目录下。共3列，第一列为基因组文件的全名（包含文件扩展名），第二列为菌株名称（一般为第一列去掉扩展名，可随意更改），第三列为分组信息（可以将所有的菌株划分到不同的组别）。三列之间以制表符分隔。三列的抬头为“sample_file_name      sample_name       category”，如下面文本框所示：</p><blockquote>\n<p>sample_file_name\tsample_name\tcategory</p>\n<p>1457190.3.RefSeq.faa\tListeria_ivanovii_WSLC3009\tenvironment_1</p>\n<p>525367.9.RefSeq.faa\tListeria_grayi_DSM_20601\tenvironment_2</p>\n</blockquote><p>&lt;out_dir&gt;：结果输出目录</p><p>-c 2：使用两个线程运行，提高预测速度</p><p><br></p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"https://upload-images.jianshu.io/upload_images/11790868-82b7bc9d8c442804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"https://upload-images.jianshu.io/upload_images/11790868-82b7bc9d8c442804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">文件存放示意图</div>\n</div><p>我的命令（在phenotype目录下，使用4个线程运行）：</p><blockquote><p>traitar phenotype scaffolds samplefile.txt from_nucleotides output -c 4</p></blockquote><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"https://upload-images.jianshu.io/upload_images/11790868-132fcd1bdd4eb6ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"https://upload-images.jianshu.io/upload_images/11790868-132fcd1bdd4eb6ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\"><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5192078/pdf/mSystems.00101-16.pdf\" target=\"_blank\">软件工作流程</a></div>\n</div><p><br></p><hr><h2>输出效果图：<br>\n</h2><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"https://upload-images.jianshu.io/upload_images/11790868-9aee151bc9b10869.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"https://upload-images.jianshu.io/upload_images/11790868-9aee151bc9b10869.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">输出效果图_combined</div>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"https://upload-images.jianshu.io/upload_images/11790868-e1661fe61c8e5783.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"https://upload-images.jianshu.io/upload_images/11790868-e1661fe61c8e5783.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">输出效果图_phypat</div>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"https://upload-images.jianshu.io/upload_images/11790868-7793acf090cb7d72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"https://upload-images.jianshu.io/upload_images/11790868-7793acf090cb7d72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">输出效果图_phypat+PGL</div>\n</div><p><br></p><hr><p>引用 Traitar</p><p>If you use Traitar in your research, please cite our paper:</p><p><b>From genomes to phenotypes: Traitar, the microbial trait analyzer</b></p><p>Aaron Weimann, Kyra Mooren, Jeremy Frank, Phillip B Pope, Andreas Bremges, Alice C McHardy</p><p><i>mSystem</i> (2016) doi:<a href=\"http://dx.doi.org/10.1128/mSystems.00101-16\" target=\"_blank\">10.1101/043315</a></p><p><br></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"表型预测","path":"api/tags/表型预测.json"}]},{"title":"根据assession number批量从NCB下载数据","slug":"根据assession-number批量从NCB下载数据","date":"2021-09-28T03:26:24.000Z","updated":"2022-01-08T02:16:28.455Z","comments":true,"path":"api/articles/根据assession-number批量从NCB下载数据.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>有时候我们手里会得到一些 NCBI 的 assession number，且数量比较多，而我们真正需要的是序列，这时候手动挨个搜索和下载是不太现实的，除非是你闲得无事可做。其实有一个网页是可以批量下载序列的，即<a href=\"https://www.ncbi.nlm.nih.gov/sites/batchentrez\"> https://www.ncbi.nlm.nih.gov/sites/batchentrez</a> ，下面演示一下其用法。<strong>请就着文末视频食用。</strong></p>\n<ul>\n<li>\n<p>首先，<u>准备一份列表文件，其中包含需要下载序列的 IDs，每行一个 ID</u>。这里有一个从网上下载的 CaZY 数据库，本以为是序列文件，下载后才发现里面没有序列。这个文件包含三列，以制表符分隔各列，最后一列是 Assession number，因此前两列可以删掉。可以将文件内容复制到 Excel 中，删除前两列，将最后一列复制到一个新的文本文档中。也可以在支持正则表达式的文本编辑器中直接查找替换。<strong>刚刚的示例文件可以从<a href=\"http://www.cazy.org/IMG/cazy_data/cazy_data.zip\">这里</a>下载</strong>。正则表达式查找的公式为 “.+\\t (.+)”，其中 “.+” 代表的是任意多个字符，“\\t” 匹配的是制表符，+ 是贪婪的，一直遇到最后一个 “\\t” 才终止匹配。即 “.+\\t” 匹配的是前两列以及第二列后面的制表符，最后的 “(.+)” 匹配的是第三列。小括号的作用是捕获匹配的内容。替换的公式为 “$1”，表示第一个小括号内的内容，即第三列。</p>\n</li>\n<li>\n<p>接下来将得到的列表文件提交至网站上以下载序列，需要选择对应的数据库，这里选择 protein，点击 “Retrieve” 开始下载。由于序列较多，因此反应比较慢，需要耐心等待。估计是崩了，再试一遍，文件包含 2650471 个 ID，估计服务器吃不消，实在不行就拆分成几个文件，分批次下载。我这里用的是 EmEditor 软件，按照 10000 行每个文件对整个文件进行了拆分，得到了 266 个文件，现在拿其中的一个做演示，看看服务器是否吃得消。看来一万个也太多，二十几个试了一下，莫得问题。方法就是酱紫的，至于可以一次性下载多少，各位自己去试吧。搞定！</p>\n</li>\n<li>\n<p><strong>兄弟们不用试了，我已经试过了，一次只能搞几百个</strong>，对于几十万行的列表来说，手动逐个提交也是要命的，因此我写了一个 Perl 脚本 (download_NCBI.pl) 来完成该任务，<u>不过只能在 Linux 下运行</u>，代码如下：</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> LWP<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>Simple<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n<span class=\"token comment\"># Usage: perl download_NCBI.pl 列表文件 序列类型（参照https://www.ncbi.nlm.nih.gov/sites/batchentrez数据库填写，常用的包括nucleotide, protein）</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@ids</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$dbtype</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$ARGV</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># nucleotide, protein</span>\n\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"split -l 300 $ARGV[0] splited_\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@splited</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"splited_*\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@splited</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/splited_(.+)/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"seqs.$1.fasta\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\tpush <span class=\"token variable\">@ids</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tgetstore<span class=\"token punctuation\">(</span><span class=\"token string\">\"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=$dbtype&amp;rettype=fasta&amp;retmode=text&amp;id=\"</span><span class=\"token operator\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@ids</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"$out\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">@ids</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"cat seqs.* > All.sequences.fas\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"rm splited_* seqs.*\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>运行方法也贼简单，将脚本和列表文件放在同一目录下，然后在 Linux 终端里输入如下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl download_NCBI.pl cazy_ids.txt protein<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>其中 cazy_ids.txt 为包含 assession number 的列表文件，protein 表示列表里的 ID 是蛋白。最后面的这个参数可以在<a href=\"https://www.ncbi.nlm.nih.gov/sites/batchentrez\"> https://www.ncbi.nlm.nih.gov/sites/batchentrez</a> 左上角的 Database 查询，<strong>但是要全部小写</strong>。</p>\n<p>运行一下，看看效果！</p>\n<p><font color=\"#FF0000\">2000 years later...</font></p>\n<p>2650471/300=8835 个文件，最终生成的序列文件名称为 “All.sequences.fas”，中间过程文件会被自动删除。千年以后拿结果，不管怎么说，总算解放了双手，让电脑慢慢去跑吧！</p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"><iframe src=\"//player.bilibili.com/player.html?aid=378319348&page=\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\"></iframe></div>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “e7e9” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"CAZy","path":"api/tags/CAZy.json"},{"name":"NCBI","path":"api/tags/NCBI.json"},{"name":"下载","path":"api/tags/下载.json"}]},{"title":"生物信息学1：VMware虚拟机及Bio-linux安装与配置","slug":"生物信息学1：虚拟机及Bio-linux安装与配置","date":"2018-11-15T09:11:21.000Z","updated":"2022-01-08T02:16:28.460Z","comments":true,"path":"api/articles/生物信息学1：虚拟机及Bio-linux安装与配置.json","excerpt":null,"keywords":null,"cover":"http://upload-images.jianshu.io/upload_images/11790868-2a735eb4a37c7f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","content":"<h4>前言：大家按照步骤从头看到尾，末尾有常见错误解决办法，如果有其他问题，大家先看错误提示，根据提示自行百度，很多问题都可以得到解决，实在解决不了的可以问我，谢谢！</h4>\n<span id=\"more\"></span>\n<p></p>\n<p></p>\n<h4>\n<b>找我远程的，先</b>下载一个teamviewer，账号密码发我QQ！</h4>\n<p></p>\n</blockquote><h4><b>一、虚拟机安装（VMware）</b></h4><p><b>（1）下载 <a href=\"http://download3.vmware.com/software/wkst/file/VMware-workstation-full-15.0.1-10737736.exe\" target=\"_blank\">VMware</a></b></p><p>        32位系统请下载<a href=\"http://www.uzzf.com/soft/65978.html\" target=\"_blank\">VMware10</a></p><p><b>（2）安装 VMware：根据提示安装即可。</b></p><p><b>        许可证</b>（来自 <a href=\"https://www.nocmd.com/740.html\" target=\"_blank\">https://www.nocmd.com/740.html</a>）：</p><p>        ZC10K-8EF57-084QZ-VXYXE-ZF2XF</p><p>        UF71K-2TW5J-M88QZ-8WMNT-WKUY4</p><p>        AZ7MK-44Y1J-H819Z-WMYNC-N7ATF</p><p>        CU702-DRD1M-H89GP-JFW5E-YL8X6</p><p>        YY5EA-00XDJ-480RP-35QQV-XY8F6</p><p>        VA510-23F57-M85PY-7FN7C-MCRG0</p><p><b>（3）工作区配置</b></p><p>        依次点击菜单栏中的“Edit”——“Preferences”，打开设置窗口。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-2a735eb4a37c7f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-2a735eb4a37c7f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 1 工作区配置1</div>\n</div><p>        选择左侧的“工作区”，右侧“Browse”，选择系统镜像存放位置，注意选择剩余空间大于60G的分区。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-af6ce78c2a7b7457.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-af6ce78c2a7b7457.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 2 工作区配置2</div>\n</div><hr><h4><b>二、Bio-linux安装与配置</b></h4><p><b>（1）下载：</b></p><p>安装版：<a href=\"http://nebc.nerc.ac.uk/downloads/bio-linux-8-latest.iso\" target=\"_blank\">http://nebc.nerc.ac.uk/downloads/bio-linux-8-latest.iso</a></p><p>虚拟机版：<a href=\"http://nebc.nerc.ac.uk/downloads/bio-linux-8-latest.ova\" target=\"_blank\">http://nebc.nerc.ac.uk/downloads/bio-linux-8-latest.ova</a></p><blockquote><p><b>注：</b>虚拟机版不需要安装，可直接导入虚拟机，大部分用户可选择此版本。如果想装双系统，可以下载安装版。以下讲到的均以虚拟机版为例。</p></blockquote><blockquote><p><b>        首先检查ova文件的完整性，即验证MD5值，用群里的“MD5批量校验工具”。bio-linux-8-latest.ova 正确的MD5值为“4c3b5aea740f5334d9775cc31533a387”，若不对应，表明下载错误，需重新下载。</b></p></blockquote><p><b>（2）系统导入虚拟机</b></p><p>        若下载的是压缩文件，则解压缩，解压缩后进入文件夹，右击“Bio-Linux-8.0.7.ovf”，选择“VMware Player”打开。</p><p>        若下载的是.ova后缀的，则直接导入虚拟机即可，不需要解压。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-d77bd01708c5c312.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-d77bd01708c5c312.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 3 导入系统</div>\n</div><p>        选择剩余空间比较大的分区作为存放路径，然后导入。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-62d48c257aba00cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-62d48c257aba00cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 4 选择系统存放路径</div>\n</div><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-d6abdb679af2cbe0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-d6abdb679af2cbe0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 5 等待系统导入</div>\n</div><p><b>（3）虚拟机配置</b></p><p>        导入完成后会自动打开“VMware Workstation Player”，左侧选择刚导入的“Bio-Linux-8.0.7”，右侧选择“编辑虚拟机设置”。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-b12838b49940089f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-b12838b49940089f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 6 进入虚拟机设置</div>\n</div><p>        左侧“硬件”选项卡中选择“内存”，右侧可输入或者托选内存的大小。此处根据自己电脑的内存大小而设置，大部分电脑的内存为4G，此处可以设为2G。内存大的电脑可适当增加此值。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-13e86567a1c3d1a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-13e86567a1c3d1a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 7 内存设置</div>\n</div><p>        处理器内核数量亦需根据自己的电脑配置而设置。双核四线程的可以设置为2，四核八线程的可以设置为4.建议设置为2的整数倍。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-6ed7759fc7c4a2fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-6ed7759fc7c4a2fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 8 处理器设置</div>\n</div><p>        网络适配器按照下图所示设置，启动系统后可通过浏览器检测是否可以上网,若不能上网，可以设置为“NAT模式”。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-6a517339f86d6aab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-6a517339f86d6aab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 9 网络设置</div>\n</div><p><b>（4）启动 Bio-Linux</b></p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-d7bea03f01ddced8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-d7bea03f01ddced8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 10 播放虚拟机</div>\n</div><blockquote><p>注：启动错误，需要手动开启 “VMware Authorization Service”。</p></blockquote><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-78481c384ff49df5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-78481c384ff49df5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 11 播放错误</div>\n</div><p>        按照如下3图所示，手动开启 “VMware Authorization Service”。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-d2342fb3b84f389f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-d2342fb3b84f389f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 12 搜索Services</div>\n</div><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-0d5c9228a7e4bc8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-0d5c9228a7e4bc8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 13 右键选择“开启”</div>\n</div><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-57f38df1e9a13554.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-57f38df1e9a13554.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 14 依旧报错</div>\n</div><p>        如果报“6000009”错误，尝试重新安装 “VMware Workstation”（新安装的用户一般不会出现上述错误）。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-6d8fe325a8ee6b61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-6d8fe325a8ee6b61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 15 更新 “VMware Workstation Player”</div>\n</div><p><b>（5）全屏显示</b></p><p>        系统启动后，默认为小窗口显示，不便于操作，点击菜单栏上的“全屏”按钮，以便全屏显示。若无法全屏，则需要安装 “VMware-tools”。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-8789d5887344b994.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-8789d5887344b994.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 7 全屏</div>\n</div><p><b>（6）安装 VMware-tools</b></p><p>        如下图所示依次点击，未曾安装过VMware Tools时会显示“安装VMware Tools”。点击之后按照提示下载。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-48519484db56bd57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-48519484db56bd57.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 8 启动 VMware Tools安装</div>\n</div><p>        下载后，打开文件管理，左侧的“Devices”下多出一个“VMware tools”，点击后在右侧窗口可以看到 “VMware Tools-*.tar.gz”，此压缩包便是安装文件。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-c500f096f70c4517.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-c500f096f70c4517.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 9 VMware tools安装包</div>\n</div><p>        将 “VMware Tools-*.tar.gz”压缩包拷贝至“Downloads”目录下，并解压缩。按住 “Ctrl + Alt + T”，打开终端，输入“cd Downloads/vmware-tools-distrib”进入刚刚解压的目录下（如下图，cd后有空格，路径根据实际情况而定，“/home/lhl/”是我的家目录，可以不必输入）。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-be42781ff555d6e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-be42781ff555d6e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 10 cd命令进入目录</div>\n</div><p>        终端内输入“sudo perl vmware-install.pl”命令，回车后要求输入密码，密码为“manager”。输入密码时，光标处不显示字符，尽管输入，完成后回车即可。回车后看到一句提示语“Do you still want to proceed with this installation? [ no ]”，在其后输入“yes”，继续一路回车，直到安装完毕。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-06f006a967b87716.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-06f006a967b87716.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 11 安装VMware Tools</div>\n</div><p>        安装完毕后重启一下linux系统即可全屏显示。关机时请勿直接关闭VMware，而是如下图箭头所示的位置，点击后选择“Shut Down”，避免损坏Linux系统而导致无法开机。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-e3c241a2a819389f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-e3c241a2a819389f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 12 关机与重启</div>\n</div><hr><h3><b>三、问题集锦</b></h3><p>1. Intel 虚拟化技术未开启（Figure 13），需要进BIOS开启“Intel Virtualization Technology”，可参考网友的解决方案<a href=\"https://jingyan.baidu.com/article/fc07f98976710e12ffe519de.html\" target=\"_blank\">https://jingyan.baidu.com/article/fc07f98976710e12ffe519de.html</a></p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-252182874ccd07de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-252182874ccd07de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 13 Intel NT 未开启错误提示</div>\n</div><p>2. 终端内某些字符（如~，#）无法输入的问题</p><p>        该问题是由于本虚拟系统的键盘配置有错误，需要我们手动改正，方法如下：</p><p>        在系统左侧点击打开终端，输入“sudo dpkg-reconfigure keyboard-configuration”，回车（不包含引号），输入密码“manager”回车，会出现图形界面。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-ab22cb6d470676d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-ab22cb6d470676d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 14 输入配置键盘命令</div>\n</div><p>        在弹出的图形界面中，按住向下的光标键，找到微软键盘（箭头所示），回车进入下一步。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-b4800a54fbfd2143.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-b4800a54fbfd2143.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 15 切换微软键盘</div>\n</div><p>        在接下来的界面选择美式英语（箭头所示），回车，后面的几项一路回车即可。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-f7be766e2d301c0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-f7be766e2d301c0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 16 切换美式英语</div>\n</div><p>3. 虚拟系统无法联网</p><p>        主要是因为VMware DHCP服务没有开启，我每次重启电脑之后都需要手动开启  VMware 相关服务。首先将虚拟机的联网方式设置为“NAT”，然后在windows下搜索“services”，打开服务。win10可以直接搜索，其他版本windows可以按“win+R”组合键开启搜索。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-8a7832bba7dd71f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-8a7832bba7dd71f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 17 打开services设置</div>\n</div><p>        向下拖动滚动条，找到VMware相关服务项，右键开启。启动方式可以设置为自动，但我设置了，并没什么效果，重启仍旧变为手动，win10 v1809 最近bug一波接一波，不知道是否与系统bug有关。所有服务开启后，虚拟系统应该可以上网了。我就是这么解决的，如果还是不能上网，各位去问问度娘吧，我是没辙了。</p><div class=\"image-package\">\n<img name=\"\" src=\"http://upload-images.jianshu.io/upload_images/11790868-19d53ef881a58c18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-19d53ef881a58c18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\"><br><div class=\"image-caption\">Figure 18 开启VMware相关所有服务</div>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"虚拟机","path":"api/tags/虚拟机.json"}]},{"title":"生物信息学2：VirtualBox虚拟机及Bio-Linux安装","slug":"生物信息学2：VirtualBox及Bio-Linux","date":"2018-11-20T02:40:21.000Z","updated":"2022-01-08T02:16:28.460Z","comments":true,"path":"api/articles/生物信息学2：VirtualBox及Bio-Linux.json","excerpt":null,"keywords":null,"cover":"http://upload-images.jianshu.io/upload_images/11790868-571d4d7ddba3e076.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","content":"<p>前言：<a href=\"https://www.jianshu.com/p/2f765a81e7dd\" target=\"_blank\">上一篇</a>文章讲到了利用 Vmware 虚拟机加载 Bio-Linux，但有的小伙伴表示 Vmware 无法安装，也未见有效的错误提示，因此推荐第二款常用的老牌虚拟机软件 ——VirtualBox。</p>\n<span id=\"more\"></span>\n<p>1. <a href=\"https://www.virtualbox.org/\" target=\"_blank\">VirtualBox</a>下载与安装。</p><p>    该软件的安装比较简单，双击后根据提示一步步往下走即可。安装完毕后打开软件。</p><p><br></p><hr><p>2. 导入及配置Bio-Linux</p><p>（1）依次点击菜单栏的 “管理”——“导入虚拟电脑”</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-571d4d7ddba3e076.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-571d4d7ddba3e076.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">Figure 1 导入虚拟电脑1</div>\n</div><p>（2）在弹出的窗口中选择下载的 “Bio-Linux-8.0.7.ovf”进行导入</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-a6c955cec07389b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-a6c955cec07389b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">Figure 2 选择系统文件</div>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-ce38f58eb9d87d98.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-ce38f58eb9d87d98.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">Figure 3 准备导入虚拟电脑</div>\n</div><p>（3）虚拟电脑导入设置：此处有三项可以设置，分别是处理器的数量、内存大小和最后面的虚拟硬盘位置。前两者根据自己的电脑配置情况进行设置，硬盘位置一定要选择剩余容量大于50-60G的分区。点击“导入”等待完成即可，此时电脑可能会断网，重新连接一下即可。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-bbda5c1ad0811dcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-bbda5c1ad0811dcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 4 处理器及内存设置</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-140370931dbc3b86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-140370931dbc3b86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 5 虚拟硬盘位置自设</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-5b261a13f79e7291.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-5b261a13f79e7291.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 6 等待虚拟电脑导入完毕</div></p>\n</div><p>（4）鼠标单击导入完成的系统，菜单栏的 “设置”变成彩色可点击状态，点击进行系统设置。所有设置按如下5图（Figure 7-Figure 11）进行。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-7136bffed8701961.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-7136bffed8701961.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 7 粘贴板与拖放共享</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-520fee7dd398e306.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-520fee7dd398e306.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 8 存储控制 器输入输出</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-ca76c38fb47dc821.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-ca76c38fb47dc821.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 9 开启固态驱动器</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-75ccf98fbbf97d75.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-75ccf98fbbf97d75.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 10 显存设置（根据配置自设大小）</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-333bd34368d9b4ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-333bd34368d9b4ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 11 创建虚拟光盘</div></p>\n</div><p>（5）保存设置后，启动系统。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-f26c49cedf490ca3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-f26c49cedf490ca3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 12 启动虚拟电脑</div></p>\n</div><p>（6）进入系统后不需要更新，可以通过浏览器测试是否可以上网。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-6e83ecb2661fc193.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-6e83ecb2661fc193.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 13 系统启动完成</div></p>\n</div><p>（7）安装增强功能，参照如下4图（Figure12-Figure 15）</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-ba16243bb4520ca3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-ba16243bb4520ca3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 14 安装增强功能 1</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-1626909ed7b36761.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-1626909ed7b36761.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 15 安装增强功能 2</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-83e661db9b1fde93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-83e661db9b1fde93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 16 安装增强功能 3（密码：manager）</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-0e3aa0b41841928b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-0e3aa0b41841928b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 17 安装增强功能 4（输入 yes 回车）</div></p>\n</div><p>（8）提示按 “Press Return to close this window ...”的时候按一下回车键即可，重启Linux。</p><h3>问题：目前无法实现从windows到虚拟机的文件拷贝，暂时未找到解决方案，可通过共享文件夹解决。</h3><p>(9)共享文件夹设置</p><p>通过设置共享文件夹可以实现windows和虚拟机之间的同步，而不需要复制粘贴。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-8032463856bf4c85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-8032463856bf4c85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 18 共享文件夹设置 1</div></p>\n</div><p>        点击右上角的 “文件夹+”图标，选择共享文件夹路径（windows上的一个文件夹），共享文件夹名称会自动分配，勾选 “自动挂载” 和 “固定分配”。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-ead5f24448be0c36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-ead5f24448be0c36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 19 共享文件夹设置 2</div></p>\n</div><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-054fbf18099da74d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-054fbf18099da74d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 20 共享文件夹设置 3</div></p>\n</div><p>        设置完成后重启Linux系统，打开目录，即可看到共享文件夹 “sf_softwares”。若不成功可重新安装增强功能并重启。</p><div class=\"image-package\">\n<img class=\"uploaded-img lazyload placeholder\" src=\"http://upload-images.jianshu.io/upload_images/11790868-6dfe1cdbe1153fd6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" class=\"lazyload placeholder\" data-srcset=\"http://upload-images.jianshu.io/upload_images/11790868-6dfe1cdbe1153fd6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" width=\"auto\" height=\"auto\"><br><div class=\"image-caption\">\n<p>Figure 21 共享文件夹设置 4</div></p>\n</div><p>以上为基于VirtualBox 的 Bio-Linux配置，有问题的可以在下方留言，统一解答。</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"虚拟机","path":"api/tags/虚拟机.json"}]},{"title":"构建样本vs基因矩阵","slug":"构建样本vs基因矩阵","date":"2021-09-29T04:17:04.000Z","updated":"2022-01-08T02:16:28.453Z","comments":true,"path":"api/articles/构建样本vs基因矩阵.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg","content":"<p>承接上一篇文章<a href=\"https://liaochenlanruo.github.io/post/e922.html\"> Swissprot 数据库的本地化与序列比对</a>。</p>\n<h1 id=\"应用场景\"><a class=\"markdownIt-Anchor\" href=\"#应用场景\"></a> 应用场景</h1>\n<p>分别预测了多个样本 / 基因组中某些基因的存在与否即数量，需要将这些样本 / 基因组中的基因数量情况合并在一起构建矩阵，此时，手动是非常困难和无趣的。又该请出 Perl 神了。</p>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<p>在上一篇文章中，我们将多个宏基因组蛋白序列与 SwissProt 数据库做了比对，并根据比对到的 ID 与其他数据库做了 mapping，得到了多个输出文件，保存为 “sample.mapped”。其中 “sample” 可以是样本名，也可以是基因组名，它将出现在最后构建的矩阵中。这些文件既可作为本例的输入文件，其内容大概是下面酱紫的，各列以制表符分隔。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"输入文件长酱紫\" /></p>\n<h1 id=\"写脚本\"><a class=\"markdownIt-Anchor\" href=\"#写脚本\"></a> 写脚本</h1>\n<p>上图是其中一个文件的内容的一部分，接下来我们将提取第 19 列的 GO number 来构建矩阵。将以下代码保存到文件中，命名为 “get_matrix.pl”。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 29, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@files</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.mapped\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@files</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).mapped/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sample</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$samples</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 忽略第一行，如果第一行不是标题行，请将该行注释掉</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\; /</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@terms</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\; /</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 18代表文件的第19列，若想提取其他列，可以自行修改该数字为“列号-1”，因为第一列代号为0</span>\n\t\t\t<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@terms</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\S+/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@ids</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@ids</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$ids[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"构建矩阵\"><a class=\"markdownIt-Anchor\" href=\"#构建矩阵\"></a> 构建矩阵</h1>\n<p>将脚本与输入文件放在同一目录下，在终端或 Windows 命令行中运行如下命令，得到的 “Matrix.txt” 即为输出文件。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_matrix.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"输出文件长酱紫\" /></p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “412a” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"SY179","path":"api/tags/SY179.json"},{"name":"perl","path":"api/tags/perl.json"},{"name":"编程","path":"api/tags/编程.json"}]},{"title":"用wget批量下载含有链接的文件/目录","slug":"用wget批量下载含有链接的文件-目录","date":"2019-01-31T11:58:40.000Z","updated":"2022-01-08T02:16:28.462Z","comments":true,"path":"api/articles/用wget批量下载含有链接的文件-目录.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>本文讲述了如何利用 Linux 下载工具 wget 根据链接批量下载文件或者目录。</p>\n<span id=\"more\"></span>\n<p>wget 为 Linux 自带的下载工具，windows 下也可以安装</p>\n<p><strong>一：windows 下安装 wget：</strong></p>\n<ol>\n<li>安装 Chocolatey<br />\n 方案 A：以管理员身份运行 cmd.exe<br />\n 输入：</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">@<span class=\"token string\">\"%SystemRoot%\\System32\\WindowsPowerShell<span class=\"token entity\" title=\"\\v\">\\v</span>1.0\\powershell.exe\"</span> -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command <span class=\"token string\">\"iex <span class=\"token variable\"><span class=\"token punctuation\">((</span>New<span class=\"token operator\">-</span>Object System.Net.WebClient<span class=\"token punctuation\">)</span>.DownloadString<span class=\"token punctuation\">(</span>'https<span class=\"token operator\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>chocolatey.org<span class=\"token operator\">/</span>install.ps1'<span class=\"token punctuation\">))</span></span>\"</span> <span class=\"token operator\">&amp;&amp;</span> SET <span class=\"token string\">\"PATH=%PATH%;%ALLUSERSPROFILE%<span class=\"token entity\" title=\"\\c\">\\c</span>hocolatey<span class=\"token entity\" title=\"\\b\">\\b</span>in\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>回车等待安装完成。</p>\n<p>方案 B：PowerShell 用户输入：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Set-ExecutionPolicy Bypass -Scope Process -Force<span class=\"token punctuation\">;</span> iex <span class=\"token variable\"><span class=\"token punctuation\">((</span>New<span class=\"token operator\">-</span>Object System.Net.WebClient<span class=\"token punctuation\">)</span>.DownloadString<span class=\"token punctuation\">(</span>'https<span class=\"token operator\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>chocolatey.org<span class=\"token operator\">/</span>install.ps1'<span class=\"token punctuation\">))</span></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>测试是否安装成功，在命令行中输入 “choco” 看到 help 信息表明安装成功。</p>\n<ol start=\"2\">\n<li>安装 wget</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">choco <span class=\"token function\">install</span> <span class=\"token function\">wget</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>升级 wget</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">choco upgrade <span class=\"token function\">wget</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>二、用 wget 下载数据</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> -r -c -nH -nc --cut-dirs<span class=\"token operator\">=</span><span class=\"token number\">3</span> -i file_contain_url_lists <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>-i file_contain_url_lists：含有文件 / 目录链接的文件，每个链接一行</p>\n<p>-nc：不覆盖已下载的文件</p>\n<p>-c：断点续传</p>\n<p>--cut-dirs=3：忽略 NUMBER 层远程目录</p>\n<p>-nH：不创建主机目录</p>\n<p>-r：递归下载</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"下载","path":"api/tags/下载.json"}]},{"title":"计算蛋白质等电点并绘制全局pI图","slug":"计算蛋白质等电点","date":"2022-01-03T02:49:17.000Z","updated":"2022-01-08T02:16:28.468Z","comments":true,"path":"api/articles/计算蛋白质等电点.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/85d7_1.png","content":"<h1 id=\"蛋白质组的全局-pis\"><a class=\"markdownIt-Anchor\" href=\"#蛋白质组的全局-pis\"></a> 蛋白质组的全局 pIs</h1>\n<p>细胞全局蛋白质组 pI 图的变化取决于氨基酸的总电荷，并对蛋白质的结构和特性具有重要意义。</p>\n<p>普遍认为原核基因组具有两个最大的双峰形状，一个在酸性 pH 值下主要对应于溶解的蛋白质（细胞质蛋白或分泌蛋白），另一种在膜蛋白的碱性 pH 值下，具有细胞内碱性（带正电荷）结构域以促进质子动力的产生。在这两个峰之间，有一个最小的中性值，对应于细胞内的 pH 值（如下图）。</p>\n<p>蛋白质氨基酸组成和 pI 水平的显着变化提供了一种工具来预测培养物或宏基因组组装基因组 (MAG) 的首选栖息地。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/85d7_1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/85d7_1.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"蛋白质组的全局 pIs\" /><br />\n<a href=\"https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-019-0731-5#Abs1\">Pedro J. et al., 2019, Microbiome</a></p>\n<h1 id=\"安装emboss\"><a class=\"markdownIt-Anchor\" href=\"#安装emboss\"></a> 安装 EMBOSS</h1>\n<ul>\n<li>下载</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span>  ftp://emboss.open-bio.org/pub/EMBOSS/emboss-latest.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>安装</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 解压</span>\n<span class=\"token function\">tar</span> zxvf emboss-latest.tar.gz\n\n<span class=\"token comment\"># 防止报错 (error while loading shared libraries: libnucleus.so.6)</span>\n<span class=\"token function\">sudo</span> /sbin/ldconfig\n\n<span class=\"token comment\"># 配置、编译与安装</span>\n<span class=\"token builtin class-name\">cd</span> emboss-latest\n./configure\n<span class=\"token function\">make</span>\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<p>输入文件为含有一条或多条氨基酸序列的 FASTA 格式文件。</p>\n<h1 id=\"ruby计算氨基酸序列的各特征数据rtcalculate-statistics-of-protein-propertiesrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby计算氨基酸序列的各特征数据rtcalculate-statistics-of-protein-propertiesrtruby\"></a> <ruby>计算氨基酸序列的各特征数据<rt>Calculate statistics of protein properties</rt></ruby></h1>\n<h2 id=\"逐个文件计算\"><a class=\"markdownIt-Anchor\" href=\"#逐个文件计算\"></a> 逐个文件计算</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pepstats -sequence F01_bin.1.faa -outfile F01_bin.1.out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<div class=\"note primary 参数解析\">\n<ul>\n<li>\n<p>Standard (Mandatory) qualifiers:</p>\n<ul>\n<li>[-sequence]          seqall     Protein sequence(s) filename and optional<br />\nformat, or reference (input USA)</li>\n<li>[-outfile]           outfile    [*.pepstats] Pepstats program output file</li>\n</ul>\n</li>\n<li>\n<p>Advanced (Unprompted) qualifiers:</p>\n<ul>\n<li>-aadata             datafile   [Eamino.dat] Amino acid properties</li>\n<li>-mwdata             datafile   [Emolwt.dat] Molecular weight data for amino<br />\nacids</li>\n<li>-pkdata             datafile   [Epk.dat] Values of pKa for amino acids</li>\n<li>-[no]termini        boolean    [Y] Include charge at N and C terminus</li>\n<li>-mono               boolean    [N] Use monoisotopic weights</li>\n</ul>\n</li>\n</ul>\n</div>\n<h2 id=\"批量计算与pi提取并输出为相对丰度\"><a class=\"markdownIt-Anchor\" href=\"#批量计算与pi提取并输出为相对丰度\"></a> 批量计算与 pI 提取并输出为相对丰度</h2>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># name: print_pI.pl</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: 2022.01.03</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@genome</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@genome</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".pepstats\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$pi</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".pI\"</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"pepstats -sequence $_ -outfile $out\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$seqnum</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token regex\">/^(Isoelectric Point = )(\\S+)/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$pi</span> <span class=\"token operator\">=</span> sprintf <span class=\"token string\">\"%.1f\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$2</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$pi</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$seqnum</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\n\t<span class=\"token comment\">#my @records = values %hash;</span>\n\t<span class=\"token comment\">#my $seqnum = @records;</span>\n\t<span class=\"token comment\">#print $seqnum . \"\\n\";</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$pi\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"Isoelectric point\\tRelative frequency\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span>keys <span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$frequency</span> <span class=\"token operator\">=</span> sprintf <span class=\"token string\">\"%.2f\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">/</span><span class=\"token variable\">$seqnum</span><span class=\"token punctuation\">;</span><span class=\"token comment\">#@records;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$_\\t$frequency\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"选择性忽略-这是我自己用的\"><a class=\"markdownIt-Anchor\" href=\"#选择性忽略-这是我自己用的\"></a> 选择性忽略 （这是我自己用的）</h2>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># name: co_sample_pI.pl</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: 2022.01.03</span>\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">F06.pi\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"MAGs\\tIsoelectric point\\tRelative frequency\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@pI</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"F06*.pI\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@pI</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).pI/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$mag</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$mag\\t$_\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"可视化\"><a class=\"markdownIt-Anchor\" href=\"#可视化\"></a> 可视化</h1>\n<h2 id=\"绘制蛋白质组的全局-pis图\"><a class=\"markdownIt-Anchor\" href=\"#绘制蛋白质组的全局-pis图\"></a> 绘制蛋白质组的全局 pIs 图</h2>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># Step 1 读入数据</span>\nsetwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/Results/Annotations/AAs\"</span><span class=\"token punctuation\">)</span>\n\nF1 <span class=\"token operator\">&lt;-</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"F01_bin.1.pI\"</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> header <span class=\"token operator\">=</span> T<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 2 绘图，以下5选1</span>\n<span class=\"token comment\">## 单组加点，运行完后跳到Step 3</span>\np1 <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>F1<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>Isoelectric.point<span class=\"token punctuation\">,</span> Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_point<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>shape<span class=\"token operator\">=</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_smooth<span class=\"token punctuation\">(</span>method<span class=\"token operator\">=</span> <span class=\"token string\">\"gam\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## 单组无点，运行完后跳到Step 3</span>\np1 <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>F1<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>Isoelectric.point<span class=\"token punctuation\">,</span> Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_smooth<span class=\"token punctuation\">(</span>method<span class=\"token operator\">=</span> <span class=\"token string\">\"gam\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\">## 多组加点</span>\np1 <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>F1<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>Isoelectric.point<span class=\"token punctuation\">,</span> Relative.frequency<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span>MAGs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_point<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>shape<span class=\"token operator\">=</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_smooth<span class=\"token punctuation\">(</span>method<span class=\"token operator\">=</span> <span class=\"token string\">\"gam\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\">## 多组无点显示置信区间</span>\np1 <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>F1<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>Isoelectric.point<span class=\"token punctuation\">,</span> Relative.frequency<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span>MAGs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_smooth<span class=\"token punctuation\">(</span>method<span class=\"token operator\">=</span> <span class=\"token string\">\"gam\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## 多组无点去除置信区间</span>\np1 <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>F1<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>Isoelectric.point<span class=\"token punctuation\">,</span> Relative.frequency<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span>MAGs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>geom_smooth<span class=\"token punctuation\">(</span>method<span class=\"token operator\">=</span> <span class=\"token string\">\"gam\"</span><span class=\"token punctuation\">,</span>se <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># Step 3 美化，看下图</span>\np1 <span class=\"token operator\">+</span> scale_x_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_y_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span> <span class=\"token string\">\"Isoelectric point\"</span><span class=\"token punctuation\">,</span>y <span class=\"token operator\">=</span> <span class=\"token string\">\"Relative frequency\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## ==============以下代码为自用========================</span>\n<span class=\"token comment\">## F04自定义颜色</span>\np1 <span class=\"token operator\">+</span> scale_x_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_y_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span> <span class=\"token string\">\"Isoelectric point\"</span><span class=\"token punctuation\">,</span>y <span class=\"token operator\">=</span> <span class=\"token string\">\"Relative frequency\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_color_manual<span class=\"token punctuation\">(</span>name<span class=\"token operator\">=</span><span class=\"token string\">\"MAGs\"</span><span class=\"token punctuation\">,</span> values<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## F05自定义颜色</span>\np1 <span class=\"token operator\">+</span> scale_x_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_y_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span> <span class=\"token string\">\"Isoelectric point\"</span><span class=\"token punctuation\">,</span>y <span class=\"token operator\">=</span> <span class=\"token string\">\"Relative frequency\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_color_manual<span class=\"token punctuation\">(</span>name<span class=\"token operator\">=</span><span class=\"token string\">\"MAGs\"</span><span class=\"token punctuation\">,</span> values<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## F06自定义颜色</span>\np1 <span class=\"token operator\">+</span> scale_x_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_y_continuous<span class=\"token punctuation\">(</span>limits<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>max<span class=\"token punctuation\">(</span>F1<span class=\"token operator\">$</span>Relative.frequency<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span> <span class=\"token string\">\"Isoelectric point\"</span><span class=\"token punctuation\">,</span>y <span class=\"token operator\">=</span> <span class=\"token string\">\"Relative frequency\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> scale_color_manual<span class=\"token punctuation\">(</span>name<span class=\"token operator\">=</span><span class=\"token string\">\"MAGs\"</span><span class=\"token punctuation\">,</span> values<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#5254a3\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#000000\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/85d7_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/85d7_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"蛋白质组的全局 pIs\" /></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li>\n<p><a href=\"https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-019-0731-5#Abs1\">Pedro J. et al., 2019, Microbiome</a></p>\n</li>\n<li>\n<p><a href=\"http://emboss.sourceforge.net/\">EMBOSS</a></p>\n</li>\n</ul>\n<h1 id=\"代码获取\"><a class=\"markdownIt-Anchor\" href=\"#代码获取\"></a> 代码获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “85d7” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"WGS","path":"api/tags/WGS.json"},{"name":"蛋白质组","path":"api/tags/蛋白质组.json"}]},{"title":"生物信息学3：微生物基因组学常用软件安装","slug":"生物信息学3：微生物基因组学常用软件安装","date":"2018-12-04T13:42:18.000Z","updated":"2022-01-08T02:16:28.461Z","comments":true,"path":"api/articles/生物信息学3：微生物基因组学常用软件安装.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>本文详细介绍了 Linux 各发行版通用的几种软件安装方案，并有实例，主要是微生物基因组学常用软件的安装。</p>\n<span id=\"more\"></span>\n<p><strong>一、Linux 安装软件的常用方法：</strong><br />\n（1）将可执行程序加入环境变量</p>\n<p>一些软件包内包含的是可执行程序，不需要进行编译，这类程序可以在软件目录中通过终端 “./ 主程序名” 命令运行。所以可以将主程序所在的目录加入到环境变量中即可。常见的环境变量配置文件包括家目录下的 “zshrc”、“bashrc” 以及 /etc 目录下的 “profile”。</p>\n<p>（2）创建可执行程序的软连接到已在环境变量的目录下</p>\n<p>可以视为方法一的另一种实现策略，通过 “ln -s A B” 进行创建，软连接可以理解为 Windows 下的快捷方式。A 为主程序的绝对路径（包含主程序名称），B 为目标路径，即放置软件快捷方式的地方（包含主程序名），一般可存于 “/usr/loacl/bin” 下。</p>\n<p>（3）源码配置编译及安装</p>\n<p>特点为解压源码包之后，存在 “configure” 文件，一般分三步安装，即在软件目录下打开终端，依次运行：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">./configure\n\n<span class=\"token function\">make</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>（4）通过源进行安装</p>\n<p>不同的 Linux 发行版含有不同的源和软件安装工具，只要联网，一条命令即可安装源中含有的软件。</p>\n<p>Ubuntu 可以通过 “sudo apt-get install 程序名” 进行安装</p>\n<p>Centos 可以通过 “sudo yum install 程序名” 进行安装</p>\n<blockquote>注：前三种方法适合任意Linux发行版，安装软件前可以先通过方法4进行，若源中不包含此软件再用前三种方法。</blockquote>\n<p><strong>二、软件下载及存储</strong><br />\n首先在 Home 目录下创建 Tools 目录，所有下载的软件均存放于 tools 目录之下，此处我的家目录为 “manager”，即我软件存放目录为 “/home/manager/Tools”。</p>\n<p><strong>三、软件安装</strong><br />\n<strong> 1. ABySS</strong></p>\n<p>首先安装依赖包：</p>\n<p>Open MPI</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">tar</span> zxvf openmpi-4.0.0.tar.gz\n\n<span class=\"token builtin class-name\">cd</span> openmpi-4.0.0\n\n./configure\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> all <span class=\"token function\">install</span>\n\n<span class=\"token builtin class-name\">cd</span> <span class=\"token punctuation\">..</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Git（可以不安装）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev <span class=\"token function\">git</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>sparsehash</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/sparsehash/sparsehash.git\n\n<span class=\"token builtin class-name\">cd</span> sparsehash\n\n./configure\n\n<span class=\"token function\">make</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span>\n\n<span class=\"token builtin class-name\">cd</span> <span class=\"token punctuation\">..</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>ABySS</p>\n<p>首先删除旧版本（Bio-Linux 自带的）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> remove abyss\n\n<span class=\"token function\">tar</span> zxvf abyss-2.1.4.tar.gz\n\n<span class=\"token builtin class-name\">cd</span> abyss-2.1.4\n\n<span class=\"token function\">wget</span> http://downloads.sourceforge.net/project/boost/boost/1.56.0/boost_1_56_0.tar.bz2\n\n<span class=\"token function\">tar</span> jxf boost_1_56_0.tar.bz2\n\n./configure --enable-maxk<span class=\"token operator\">=</span><span class=\"token number\">160</span> --with-mpi<span class=\"token operator\">=</span>/usr/local/lib/openmpi\n\n<span class=\"token comment\">#（注：openmpi的路径用“whereis openmpi”寻找）</span>\n\n<span class=\"token function\">make</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>不能多线程运行时（np=2），错误提示为 “/usr/local/bin/mpirun: error while loading shared libraries: libopen-rte.so.40: cannot open shared object file: No such file or directory”，则需运行如下命令解决。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> ldconfig<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>2. SPAdes</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">tar</span> -zxvf SPAdes-3.13.0-Linux.tar.gz\n\n<span class=\"token function\">vim</span> ~/.zshrc\n\n<span class=\"token environment constant\">$HOME</span>/Tools/SPAdes-3.13.0-Linux/bin<span class=\"token comment\">#(加入环境变量)</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>3. prokka</strong></p>\n<p>先安装依赖</p>\n<p>aragorn</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> ~/.zshrc\n\ni<span class=\"token comment\">#(进入插入模式），在文末建立新的一行</span>\n\n输入：\n\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token environment constant\">$HOME</span>/Tools/prokka/aragorn.1.2.38\n\nesc <span class=\"token comment\">#(退出插入模式）</span>\n\n<span class=\"token builtin class-name\">shift</span> + <span class=\"token builtin class-name\">:</span>\n\nwq<span class=\"token operator\">!</span> <span class=\"token comment\">#(w,write; q,quit, !强制）</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>barrnap</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> ~/.zshrc\n\ni\n\n<span class=\"token environment constant\">$HOME</span>/Tools/prokka/barrnap-0.6/bin\n\nesc\n\n<span class=\"token builtin class-name\">shift</span> + <span class=\"token builtin class-name\">:</span>\n\nwq<span class=\"token operator\">!</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>tbl2asn</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#删除旧版本：</span>\n<span class=\"token function\">sudo</span> <span class=\"token function\">rm</span> -f /usr/bin/tbl2asn\n\n<span class=\"token comment\">#安装新版本。解压，把主程序的名称改为 tbl2asn</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">ln</span> -s /home/manager/Tools/prokka/tbl2asn /usr/local/bin/tbl2asn<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>minced</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压，进入程序所在的目录中</span>\n\n<span class=\"token function\">make</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">ln</span> -s /home/manager/Tools/prokka/minced-master/minced /usr/local/bin/minced<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>parallel</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压缩，进入目录</span>\n\n./configure\n\n<span class=\"token function\">make</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>prodigal</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压缩，进入目录</span>\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>signalp</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压缩，用文本编辑器打开signalp主程序，改路径（第13行），并保存：</span>\n\n<span class=\"token variable\">$ENV</span><span class=\"token punctuation\">&#123;</span>SIGNALP<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token string\">'/home/manager/Tools/prokka/signalp-4.1'</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token function\">vim</span> ~/.zshrc\n\n<span class=\"token environment constant\">$HOME</span>/Tools/prokka/signalp-4.1\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>rnammer</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压后进入文件夹，用文本编辑器打开rnammer主程序，修改第35行路径如下：</span>\n\nmy <span class=\"token variable\">$INSTALL_PATH</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"/home/manager/Tools/prokka/rnammer-1.2.src\"</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">#通过whereis hammsearch命令查看其所在路径，修改第50行和53行，如下：</span>\n\n<span class=\"token variable\">$HMMSEARCH_BINARY</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"/usr/bin/hmmsearch\"</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token function\">vim</span> ~/.zshrc\n\n<span class=\"token environment constant\">$HOME</span>/Tools/prokka/rnammer-1.2.src\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>prokka</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> ~/.zshrc\n\n<span class=\"token environment constant\">$HOME</span>/Tools/prokka/prokka-1.12/bin\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc\n\nprokka --setupdb<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ol start=\"4\">\n<li>Parsnp</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/marbl/parsnp/releases/download/v1.2/parsnp-Linux64-v1.2.tar.gz\n\n<span class=\"token function\">tar</span> -xvf parsnp-Linux64-v1.2.tar.gz\n\n<span class=\"token function\">vim</span> ~/.zshrc\n\n<span class=\"token environment constant\">$HOME</span>/Tools/Parsnp-Linux64-v1.2<span class=\"token comment\">#(加入环境变量)</span>\n\n<span class=\"token builtin class-name\">source</span> ~/.zshrc <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ol start=\"5\">\n<li>roary（blast+, fasttree）</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> bedtools cd-hit ncbi-blast+ mcl parallel cpanminus prank mafft fasttree\n\n<span class=\"token function\">sudo</span> cpanm -f Bio::Roary\n\n<span class=\"token comment\">#出错的话运行：</span>\n\n<span class=\"token function\">sudo</span> cpan -f Bio::Roary<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ol start=\"6\">\n<li>RAxML</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#解压</span>\n\n<span class=\"token builtin class-name\">cd</span> standard-RAxML-master \n\n<span class=\"token function\">make</span> -f Makefile.gcc\n\n<span class=\"token function\">sudo</span> <span class=\"token function\">ln</span> -s /home/manager/Tools/standard-RAxML-master/raxmlHPC /usr/local/bin/raxmlHPC<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ol start=\"7\">\n<li>Prottest</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> prottest<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ol start=\"8\">\n<li>jModelTest</li>\n</ol>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> jmodeltest<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"软件","path":"api/tags/软件.json"}]},{"title":"Linux和基因组测序技术初识","slug":"Linux和基因组测序技术初识","date":"2019-10-31T14:05:49.000Z","updated":"2022-01-08T02:16:28.404Z","comments":true,"path":"api/articles/Linux和基因组测序技术初识.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Terminal.png","content":"<p>该文档可以帮助读者入门 Linux 系统，掌握常用命令和多种软件安装方式。此外还简述了全基因组测序技术，希望读者可以通过此文档初步了解生物信息学。</p>\n<span id=\"more\"></span>\n<h1 id=\"linux初识\"><a class=\"markdownIt-Anchor\" href=\"#linux初识\"></a> Linux 初识</h1>\n<h2 id=\"目录结构与路径\"><a class=\"markdownIt-Anchor\" href=\"#目录结构与路径\"></a> 目录结构与路径</h2>\n<h3 id=\"根目录\"><a class=\"markdownIt-Anchor\" href=\"#根目录\"></a> 根目录</h3>\n<p>根目录（root）是系统最顶级目录，以 “/” 表示，其他目录均为根目录的下级目录。</p>\n<h3 id=\"家目录\"><a class=\"markdownIt-Anchor\" href=\"#家目录\"></a> 家目录</h3>\n<p>家目录（home）是用户的最顶级目录，以 “~/” 表示，用户所有的目录均为家目录的下级目录。</p>\n<h3 id=\"绝对路径\"><a class=\"markdownIt-Anchor\" href=\"#绝对路径\"></a> 绝对路径</h3>\n<p>绝对路径指的是目录或文件的绝对位置，是从根目录开始的完整路径，如 “/home/bio/”。可通过 “pwd” 命令获取当前目录的绝对路径。</p>\n<h3 id=\"相对路径\"><a class=\"markdownIt-Anchor\" href=\"#相对路径\"></a> 相对路径</h3>\n<p>相对路径不需要从根目录开始，只要指定与当前目录的相对位置即可。</p>\n<h3 id=\"当前目录\"><a class=\"markdownIt-Anchor\" href=\"#当前目录\"></a> 当前目录</h3>\n<p>当前所在的路径，以 “./“表示。</p>\n<h3 id=\"上级目录\"><a class=\"markdownIt-Anchor\" href=\"#上级目录\"></a> 上级目录</h3>\n<p>也称为父目录，以 “../“表示向上一级的目录，以 “../../” 表示向上两级的目录，以此类推。</p>\n<h2 id=\"命名法则\"><a class=\"markdownIt-Anchor\" href=\"#命名法则\"></a> 命名法则</h2>\n<ul>\n<li>文档与目录均以英文命名，可使用字母、数字和下划线；</li>\n<li>文档与目录的名称不允许存在空格；</li>\n<li>名称区分大小写。</li>\n</ul>\n<h2 id=\"终端工具\"><a class=\"markdownIt-Anchor\" href=\"#终端工具\"></a> 终端工具</h2>\n<p>终端（terminal）是运行 Linux 命令的工具，类似于 Windows 的命令行工具。Linux 各发行版均自带终端。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Terminal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Terminal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Linux自带终端\" /></p>\n<p>远程操控 Linux 服务器时，可以使用第三方的终端工具，如 PuTTy 软件。输入 IP 地址即可远程登录服务器运行命令。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/putty.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/putty.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Putty\" /></p>\n<p>本地计算机与服务器之间的文件传输可以通过 FTP 软件实现，如 FileZilla。输入服务器的 IP 地址、用户名、密码以及端口即可链接服务器。如果服务器采用的时 FTP 协议，则端口填写 21，若采用的是 SFTP 协议，则端口设置为 22。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/filezilla.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/filezilla.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"FileZilla\" /></p>\n<h2 id=\"常用的命令\"><a class=\"markdownIt-Anchor\" href=\"#常用的命令\"></a> 常用的命令</h2>\n<p><strong>pwd：</strong> 获取当前位置的绝对路径</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">pwd</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/pwd.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/pwd.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"获取当前位置的绝对路径\" /></p>\n<p><strong>mkdir：</strong> 创建目录</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">mkdir</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/mkdir.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/mkdir.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"创建tools目录\" /></p>\n<p><strong>ls：</strong> 查看当前目录包含的内容</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls1.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看当前目录包含的内容\" /></p>\n<p>查看所有的目录和文件（包含隐藏的内容）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> -a<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsa.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsa.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看当前目录包含的所有内容\" /></p>\n<p>查看根目录所含内容</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> /<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsroot.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsroot.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看根目录所含内容\" /></p>\n<p>查看家目录所含内容</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> ~/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lshome.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lshome.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看家目录所含内容\" /></p>\n<p><strong>cd：</strong> 切换路径</p>\n<p>进入 “tools” 目录</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> tools<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cdtools.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cdtools.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"进入“tools”目录\" /></p>\n<p><strong>vim：</strong> 创建 / 编辑文档</p>\n<p>以下所有操作均需在英文输入法状态下进行。首先创建一个新文档 “example.txt”，并输入内容。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> example.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimexample.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimexample.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"创建“example.txt”文档\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/unwritable.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/unwritable.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"此时无法输入内容\" /></p>\n<p>此时无法输入内容，需要按一下字母 “i” 键切换到输入模式。当左下角出现 “--NSERT --” 字样时，可以输入文字。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/viminsert.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/viminsert.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"vim插入模式\" /></p>\n<p>输入相关的内容。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/inputsth.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/inputsth.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"vim输入内容\" /></p>\n<p>输入完毕时需要先按一下 “ESC” 键退出编辑模式，此时 “--NSERT --” 字样消失。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimesc.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimesc.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"退出vim编辑模式\" /></p>\n<p>按住组合键 “shift + :” 切换到 vim 操作模式，此时左下角出现一个 “:”。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimshift.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimshift.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"shift + :\" /></p>\n<p>输入 “wq!” 保存修改并退出。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimquit.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimquit.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"保存并退出vim\" /></p>\n<p>查看创建的文件是否在于目录下。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls2.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls2.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看当前目录下的文件及目录\" /></p>\n<p><strong>cp：</strong> 复制目录或文件</p>\n<p>将创建的 “example.txt” 文档复制到上一级目录下。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">cp</span> example.txt <span class=\"token punctuation\">..</span>/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cpup.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cpup.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"向上级目录复制文件\" /></p>\n<p>查看上一级目录下是否存在刚刚复制的文档。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> <span class=\"token punctuation\">..</span>/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsup.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsup.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看父目录下的文件及目录\" /></p>\n<p><strong>rm：</strong> 删除目录或文件</p>\n<p>删除 tools 目录下的 “example.txt” 文档。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">rm</span> example.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/rmexample.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/rmexample.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"删除tools目录下的“example.txt”文档\" /></p>\n<p>查看文档是否被删除。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls3.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls3.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看是否成功删除文件\" /></p>\n<p><strong>mv：</strong> 移动 / 重命名</p>\n<p>将上一级目录下的 “example.txt” 文档移动到当前目录下。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">mv</span> <span class=\"token punctuation\">..</span>/example.txt ./<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/mv1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/mv1.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"移动文件\" /></p>\n<p>查看文档是否移动成功。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> <span class=\"token punctuation\">..</span>/\n$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls4.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/ls4.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看是否成功移动文件\" /></p>\n<p>将 “example.txt” 文档重命名为 “examp2.txt”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">mv</span> example.txt examp2.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/rename.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/rename.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"文档重命名\" /></p>\n<p>查看重命名结果。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsrename.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsrename.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看重命名结果\" /></p>\n<p><strong>wget：</strong> 下载</p>\n<p>使用 wget 工具下载基因组拼接软件 “AbySS” 到 tools 目录下。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> http://www.bcgsc.ca/platform/bioinfo/software/abyss/releases/2.1.5/abyss-2.1.5.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/wgetabyss.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/wgetabyss.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"下载AbySS软件\" /></p>\n<p><strong>tar：</strong> 压缩 / 解压缩</p>\n<p>tar.gz 格式的文件可用 “tar zxvf” 进行解压，将刚才下载的 “abyss-2.1.5.tar.gz” 解压缩。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">tar</span> zxvf abyss-2.1.5.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/tar.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/tar.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"解压缩AbySS软件\" /></p>\n<p><strong>top：</strong> 查看系统进程</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">top</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/top.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/top.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"通过top查看系统进程\" /></p>\n<p>按字母键 “q” 退出。Ubuntu 还带有另一个更加直观的查看系统进程的工具 “htop”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">htop</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/htop.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/htop.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"通过htop查看系统进程\" /></p>\n<h2 id=\"环境变量\"><a class=\"markdownIt-Anchor\" href=\"#环境变量\"></a> 环境变量</h2>\n<p>在软件安装的时候经常需要设置环境变量，所谓的环境变量就是告诉计算机软件的安装位置。存放环境变量的文件在用户的家目录下，为隐藏文件，可通过 “ls -a” 命令查看。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> -a ~/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsahome.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsahome.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看家目录中的所有文档和目录\" /></p>\n<p>“.bashrc” 和 “.profile” 均为环境变量配置文件，通常我们只需要编辑 “.bashrc”。</p>\n<h2 id=\"软件安装\"><a class=\"markdownIt-Anchor\" href=\"#软件安装\"></a> 软件安装</h2>\n<h3 id=\"源码编译安装\"><a class=\"markdownIt-Anchor\" href=\"#源码编译安装\"></a> 源码编译安装</h3>\n<p>源码安装适合于所有的 Linux 发行版以及 macOS。以刚下载的 “AbySS” 基因组拼接软件为例演示源码编译安装，一共分三步：配置（./configure）、编译（make）和安装（sudo make install）。首先进入 “AbySS” 软件目录下，并查看目录中的文件，找到配置文件 “configure”，根据 “<a href=\"http://README.md\">README.md</a>” 中的指示对软件进行配置。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> abyss-2.1.5/\n$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsabyss.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsabyss.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"进入AbySS目录并查看其所含内容\" /></p>\n<p>“./configure” 表示运行 configure 进行安装前配置。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ ./configure<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>进行编译</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">make</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>进行安装，需要 “sudo” 命令提供对系统目录的写入权限。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注意：</strong> 以上只演示了一般的安装方法，但是 “AbySS” 软件依赖其他的一些软件，需要先安装依赖包，最后安装 “AbySS”，否则会安装失败。</p>\n<h2 id=\"通过包管理工具安装\"><a class=\"markdownIt-Anchor\" href=\"#通过包管理工具安装\"></a> 通过包管理工具安装</h2>\n<p>不同的 Linux 发行版具有各自的软件包管理器。目前常用的 Linux 发行版主要是基于 “RedHat” 和 “Debian” 而制作的。<br />\nRedHat 系列的包管理器为 “yum”，使用方法为在终端输入 “sudo yum install -y 软件名称”。</p>\n<p>Debian 系列的包管理器为 “apt-get”，使用方法为在终端输入 “sudo apt-get install 软件名称”。</p>\n<p>示例：通过 apt-get 在 Ubuntu 中安装 AbySS 软件，输入命令和密码后，根据提示输入 “Y” 并按回车键进行自动安装。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> abyss<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/aptabyss1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/aptabyss1.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"通过apt-get安装AbySS\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/aptabyss2.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/aptabyss2.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"通过apt-get安装AbySS\" /></p>\n<h2 id=\"添加环境变量\"><a class=\"markdownIt-Anchor\" href=\"#添加环境变量\"></a> 添加环境变量</h2>\n<p>以原核生物基因预测软件 “Prodigal” 为例演示。首先在 Github 上找到 prodigal 的源码，点击 “Clone or download”，并按照图示点击链接右侧的图标以复制 git 地址。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/githubprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/githubprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"复制prodigal链接\" /></p>\n<p>在终端中进入 tools 目录，并输入克隆命令将项目克隆到本地计算机。命令公式为 “git clone link”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> clone https://github.com/hyattpd/Prodigal.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cloneprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cloneprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"克隆prodigal\" /></p>\n<p>克隆完成后进入 “Prodigal” 目录。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> Prodigal<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cdprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/cdprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"进入Prodigal目录\" /></p>\n<p>编译软件</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">make</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/makeprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/makeprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"编译prodigal\" /></p>\n<p>报错信息提示找不到 gcc 命令，因此需要首先安装 gcc，输入命令后根据提示输入密码，直至安装完成。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> gcc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/installgcc.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/installgcc.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"安装gcc\" /></p>\n<p>重新编译 prodigal</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">make</span>\n$ <span class=\"token function\">ls</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/lsprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看prodigal编译结果\" /></p>\n<p>编译完成后得到了可执行程序，但是系统无法找到 prodigal 的路径，因此需要我们将其所在的路径加入到环境变量中。通过 vim 打开环境变量配置文件 “.bashrc”，进入编辑模式。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> ~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimbashrc.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/vimbashrc.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"打开环境变量文件\" /></p>\n<p>在文档末尾添加配置语句 <strong>“export PATH=<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>:</mo></mrow><annotation encoding=\"application/x-tex\">PATH:</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span></span></span>HOME/tools/Prodigal”</strong> 。$HOME 代表家目录，“$HOME/tools/Prodigal” 代表 prodigal 可执行程序所在的目录。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/prodigalpath.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/prodigalpath.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"在环境变量中添加prodigal路径\" /></p>\n<p>编辑完成后保存并退出。然后执行 “source ~/.bashrc” 命令刷新，通知系统 “.bashrc” 文档已经更改。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">source</span> ~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/sourcebashrc.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/sourcebashrc.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"刷新环境变量\" /></p>\n<p>测试配置是否成功。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ prodigal -h<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/prodigalhelp.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/prodigalhelp.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看prodigal帮助信息\" /></p>\n<p>若要将其他软件加入到环境变量，只需在后面加入其他软件所在路径即可，各软件的路径间以英文 “:“分割，不得有空格。下图为将多个软件加入到环境变量的示例。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/multiplepath.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/multiplepath.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"添加多个软件路径\" /></p>\n<h2 id=\"创建软链接\"><a class=\"markdownIt-Anchor\" href=\"#创建软链接\"></a> 创建软链接</h2>\n<p>软链接（Soft Link）相当于 Windows 系统中的快捷方式，可以将可执行程序的软链接存放至系统默认的环境变量之中，如 “/usr/bin/” 或 “/usr/local/bin” 之中。仍旧以刚编译好的 prodigal 软件为例，创建软链接的公式为 <strong>“sudo ln -s /home/bio/tools/Prodigal/prodigal /usr/local/bin/prodigal”</strong> ，根据提示输入密码完成创建。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">ln</span> -s /home/bio/tools/Prodigal/prodigal /usr/local/bin/prodigal<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>通过 “whereis” 命令查看软链接是否创建成功。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">whereis</span> prodigal<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/whereisprodigal.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/whereisprodigal.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看prodigal安装路径\" /></p>\n<p><strong>注意：</strong> 创建软链接时要输入绝对路径，否则会报错 “Too many levels of symbolic links”。</p>\n<h2 id=\"通过anaconda包管理器进行安装\"><a class=\"markdownIt-Anchor\" href=\"#通过anaconda包管理器进行安装\"></a> 通过 Anaconda 包管理器进行安装</h2>\n<p><a href=\"https://www.anaconda.com/\">Anaconda</a> 是一款比较易用的跨平台软件包管理器，<a href=\"http://bioconda.github.io/\">Bioconda</a> 是 conda 的一个通道，专门管理生物信息学软件。通过 conda 安装软件时可以一键安装所有的依赖包，大大节约了时间并降低了安装难度。Bioconda 目前有超过 600 个贡献者和 500 个成员，大部分生物信息学软件都被包含其中。用户可以到其官网搜索需要的软件是否被囊括其中。</p>\n<p><strong>（1）安装 conda</strong></p>\n<p>此处，我们安装 Miniconda，进入<a href=\"https://docs.conda.io/en/latest/miniconda.html\">官网</a>，选择适应自身系统及 python 版本的安装文件。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Minicondapackages.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Minicondapackages.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看Miniconda安装包\" /></p>\n<p>查看系统 python 版本</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ python -v<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/pythonv.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/pythonv.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"查看python版本\" /></p>\n<p>可以看出该系统已经安装了 python3，因此下载 Linux Python 3.7 64-bit (bash installer)。右键单击相应安装包获取链接，使用 wget 下载至 tools 目录下。建议用户安装 Python 3，因为 Python 软件基金会将于 2020 年元旦停止对 Python 2 的维护（<a href=\"https://pythonclock.org/%EF%BC%89%E3%80%82\">https://pythonclock.org/）。</a></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/DownloadMiniconda.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/DownloadMiniconda.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"下载Miniconda\" /></p>\n<p>开始安装 Miniconda</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">bash</span> Miniconda3-latest-Linux-x86_64.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>根据提示按 “Enter” 键查看 license，并输入 “yes” 按 “Enter” 继续，按 “Enter” 确认安装位置，miniconda 被安装到家目录下的 miniconda3 目录中。最后输入 “yes”，按 “Enter” 进行初始化。最后，通过 “source ~/.bashrc” 命令刷新。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/initialMiniconda.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/initialMiniconda.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"初始化Miniconda\" /></p>\n<p><strong>（2）设置 bioconda channel</strong></p>\n<p>在终端中输入以下三条命令添加 channels：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda config --add channels defaults\n$ conda config --add channels bioconda\n$ conda config --add channels conda-forge<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>至此，bioconda 配置完毕，可以通过 conda 安装生物信息学软件。下面通过 conda 安装 mapping 软件 “bwa”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> bwa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/installbwa.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/installbwa.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"安装bwa\" /></p>\n<p>根据提示输入 “y” 完成安装。</p>\n<h2 id=\"macos相关操作\"><a class=\"markdownIt-Anchor\" href=\"#macos相关操作\"></a> MacOS 相关操作</h2>\n<p>MacOS 与 Linux 系统相似，基本命令相同，但是软件安装存在一些差异。</p>\n<h3 id=\"macos安装生物信息学软件\"><a class=\"markdownIt-Anchor\" href=\"#macos安装生物信息学软件\"></a> MacOS 安装生物信息学软件</h3>\n<h3 id=\"源码安装\"><a class=\"markdownIt-Anchor\" href=\"#源码安装\"></a> 源码安装</h3>\n<p>源码安装方式与 Linux 安装方式一致。</p>\n<h3 id=\"创建软链接-2\"><a class=\"markdownIt-Anchor\" href=\"#创建软链接-2\"></a> 创建软链接</h3>\n<p>配置方法与 Linux 一致。</p>\n<h3 id=\"环境变量-2\"><a class=\"markdownIt-Anchor\" href=\"#环境变量-2\"></a> 环境变量</h3>\n<p>MacOS 环境变量配置方法与 Linux 配置方法一致，但配置文件为家目录下的 “.bash_profile”，即运行如下命令进行编辑。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> ~/.bash_profile<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>编辑完成并保存后需要运行 source 命令。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">source</span> ~/.bash_profile<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"包管理器\"><a class=\"markdownIt-Anchor\" href=\"#包管理器\"></a> 包管理器</h3>\n<p>MacOS 的软件包管理器为 Homebrew，可以在终端中通过以下命令安装 Homebrew。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ ruby -e <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install<span class=\"token variable\">)</span></span>\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>通过 Homebrew 安装 mapping 软件 “bwa”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ brew <span class=\"token function\">install</span> bwa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"macos配置anaconda\"><a class=\"markdownIt-Anchor\" href=\"#macos配置anaconda\"></a> MacOS 配置 Anaconda</h3>\n<p>安装 Miniconda</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n$ <span class=\"token function\">sh</span> Miniconda3-latest-MacOSX-x86_64.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>添加 Bioconda 通道</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda config --add channels defaults\n$ conda config --add channels bioconda\n$ conda config --add channels conda-forge<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>安装软件 bwa</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> bwa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"现代测序技术\"><a class=\"markdownIt-Anchor\" href=\"#现代测序技术\"></a> 现代测序技术</h1>\n<h2 id=\"二代测序next-generation-sequencing-technology\"><a class=\"markdownIt-Anchor\" href=\"#二代测序next-generation-sequencing-technology\"></a> 二代测序 (&quot;Next-generation&quot; sequencing technology)</h2>\n<p>第二代测序技术的核心思想是边合成边测序（Sequencing by Synthesis），即通过捕捉新合成的末端的标记来确定 DNA 的序列。应用最广的技术平台主要为 Illumina 公司的产品。其优点为高通量、错误率低、成本低等。</p>\n<ul>\n<li>Illumina 测序中的几个名词</li>\n<li><strong>Read length：</strong> 测序的 DNA 片段的碱基长度。</li>\n<li><strong>Insert size：</strong> 双端测序时接头（adapter）中间序列的长度。</li>\n<li><strong>Junction：</strong> insert 序列中间未被测序的部分。</li>\n<li><strong>Flowcell：</strong> 是指 Illumina 测序时，测序反应发生的位置，1 个 flowcell 含有 8 条 lane。</li>\n<li><strong>Lane：</strong> 每一个 flowcell 上都有 8 条泳道，用于测序反应，可以添加试剂，洗脱等等。</li>\n<li><strong>Raw data：</strong> 测序完成后未去接头、引物以及去除低质量序列的数据。</li>\n<li><strong>Clean data：</strong> 去除 Raw data 中的接头序列、linker、低质量 reads、长度较短的 reads 及核糖体 RNA 和 ncRNA 产生的 reads。</li>\n<li><strong>数据量：</strong> read 长度乘以 reads 数目。</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/nextseqs.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/nextseqs.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"二代测序名词示意图\" /></p>\n<h2 id=\"三代测序\"><a class=\"markdownIt-Anchor\" href=\"#三代测序\"></a> 三代测序</h2>\n<p>三代测序又称为单分子测序，测序过程无需进行 PCR 扩增，可以产生超长的 reads，因此能够跨越高 GC 含量区域和高度重复区域。目前常用的测序平台包括 Pacific Biosciences（PacBio）和 Oxford Nanopore。</p>\n<p>PacBio 以 SMRT Cell 为载体进行测序反应，SMRT Cell 是一张带有纳米孔的超薄金属片。PacBio 采用边合成便测序的方式，测序反应在纳米孔中进行，一个纳米孔中固定一个 DNA 聚合酶和一条 DNA 模板。延伸反应的过程中检测 dNTP 荧光信号以确定碱基顺序。</p>\n<p>Oxford 开发的纳米单分子测序技术属于真正的实时测序，它基于电信号来判读碱基。</p>\n<caption>Table 1. Characteristics, strengths and weaknesses of commonly used sequencing platforms (Besser et al. 2018)</caption>\n<table border=\"1\">\n<tr>\n<th>Platform\\Instrument</th>\n<th>Throughput (Gb)</th>\n<th>Read length (bp)</th>\n<th>Strength</th>\n<th>Weakness</th>\n</tr>\n<tr>\n<td><B>Sanger sequencing</B></td>\n</tr>\n<tr>\n<td>ABI 3500/3730</td>\n<td>0.0003</td>\n<td>Up to 1 kb</td>\n<td>Read accuracy and length</td>\n<td>Cost and throughput</td>\n</tr>\n<tr>\n<td><B>Illumina</B></td>\n</tr>\n<tr>\n<td>MiniSeq</td>\n<td>1.7–7.5</td>\n<td>1×75 to ×150</td>\n<td>Low initial investment</td>\n<td>Run and read length</td>\n</tr>\n<tr>\n<td>MiSeq</td>\n<td>0.3–15</td>\n<td>1×36 to 2×300</td>\n<td>Read length, scalability</td>\n<td>Run length</td>\n</tr>\n<tr>\n<td>NextSeq</td>\n<td>10–120</td>\n<td>1×75 to 2×150</td>\n<td>Throughput</td>\n<td>Run and read length</td>\n</tr>\n<tr>\n<td>HiSeq (2500)</td>\n<td>10–1000</td>\n<td>×50 to ×250</td>\n<td>Read accuracy, throughput</td>\n<td>High initial investment, run</td>\n</tr>\n<tr>\n<td>NovaSeq 5000/6000</td>\n<td>2000–6000</td>\n<td>2×50 to ×150</td>\n<td>Read accuracy, throughput</td>\n<td>High initial investment, run</td>\n</tr>\n<tr>\n<td><B>IonTorrent</B></td>\n</tr>\n<tr>\n<td>PGM</td>\n<td>0.08–2</td>\n<td>Up to 400</td>\n<td>Read length, speed</td>\n<td>Throughput, homopolymers</td>\n</tr>\n<tr>\n<td>S5</td>\n<td>0.6–15</td>\n<td>Up to 400</td>\n<td>Read length, speed</td>\n<td>Homopolymers</td>\n</tr>\n<tr>\n<td>Proton</td>\n<td>10–15</td>\n<td>Up to 200</td>\n<td>Speed, throughput</td>\n<td>Homopolymers</td>\n</tr>\n<tr>\n<td><B>Pacific BioSciences</B></td>\n</tr>\n<tr>\n<td>PacBio RSII</td>\n<td>0.5–1</td>\n<td>Up to 60 kb</td>\n<td>ead length, speed (Average 10 kb, N50 20 kb)</td>\n<td>High error rate and initial</td>\n</tr>\n<tr>\n<td>Sequel</td>\n<td>5–10</td>\n<td>Up to 60 kb</td>\n<td>Read length, speed (Average 10 kb, N50 20 kb)</td>\n<td>High error rate</td>\n</tr>\n<tr>\n<td><B>Oxford Nanopore</B></td>\n</tr>\n<tr>\n<td>MInION</td>\n<td>0.1–1</td>\n<td>Up to 100 kb</td>\n<td>Read length, portability</td>\n<td>High error rate, run length</td>\n</tr>\n</table>\n<h2 id=\"常见序列格式\"><a class=\"markdownIt-Anchor\" href=\"#常见序列格式\"></a> 常见序列格式</h2>\n<h3 id=\"fastq\"><a class=\"markdownIt-Anchor\" href=\"#fastq\"></a> Fastq</h3>\n<p>我们得到的下机序列一般为 fastq 格式，每一条 read 包含 4 行，第一行为测序仪器信息以及测序信息，第二行为碱基序列，第三行一般无信息，第四行为对应第二行中每个碱基的测序质量信息。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/fastq.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/fastq.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"fastq文件内容\" /></p>\n<caption>Table 2. Descriptions of the first line of the fastq file</caption>\n<table border=\"1\">\n<tr>\n<th>Strings</th>\n<th>Description</th>\n</tr>\n<tr>\n<td>@ST-E00310</td>\n<td>The unique instrument name</td>\n</tr>\n<tr>\n<td>147</td>\n<td>The run id</td>\n</tr>\n<tr>\n<td>HVT25CCXX</td>\n<td>The flowcell id</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Flowcell lane</td>\n</tr>\n<tr>\n<td>1011</td>\n<td>The number within the flowcell lane</td>\n</tr>\n<tr>\n<td>13382</td>\n<td>‘x’-coordinate of the cluster within the title</td>\n</tr>\n<tr>\n<td>1819</td>\n<td>‘y’-coordinate of the cluster within the title</td>\n</tr>\n<tr>\n<td>1</td>\n<td>The number of a pair, 1 or 2 (paired-end or mate-pair reads only)</td>\n</tr>\n<tr>\n<td>N</td>\n<td>Y if the read fails filter (read is bad), N otherwise</td>\n</tr>\n<tr>\n<td>0</td>\n<td>0 when none of the control bits are on, otherwise it is an even number</td>\n</tr>\n<tr>\n<td>TGAAGACA</td>\n<td>Index sequence</td>\n</tr>\n</table>\n<h3 id=\"fasta\"><a class=\"markdownIt-Anchor\" href=\"#fasta\"></a> Fasta</h3>\n<p><a href=\"http://scikit-bio.org/docs/0.5.2/generated/skbio.io.format.fasta.html?highlight=fasta#module-skbio.io.format.fasta\">FASTA</a> 格式为文本文档，内含核苷酸或氨基酸序列以及其 IDs。每条序列包含两部分，第一部分为 ID 及注释信息，以 <strong>&quot;&gt;&quot;</strong> 开头，at the start, 第二部分为核苷酸序列或氨基酸序列。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/fasta.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/fasta.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"fasta文件内容\" /></p>\n<h3 id=\"genbank\"><a class=\"markdownIt-Anchor\" href=\"#genbank\"></a> Genbank</h3>\n<p><a href=\"http://scikit-bio.org/docs/0.5.2/generated/skbio.io.format.genbank.html\">GenBank</a> 格式包含了基因组序列和注释信息。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Genbank.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/Genbank.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Genbank文件内容\" /></p>\n<h3 id=\"gff3\"><a class=\"markdownIt-Anchor\" href=\"#gff3\"></a> GFF3</h3>\n<p><a href=\"http://scikit-bio.org/docs/0.5.2/generated/skbio.io.format.gff3.html?highlight=gff#module-skbio.io.format.gff3\">GFF3</a> (Generic Feature Format version 3) 格式描述了序列的特征，每一行含有 9 列数据，列与列之间以制表符分割。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/GFF3.PNG\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/custom/pgcgap/Linux_WGS/GFF3.PNG\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"GFF3文件内容\" /></p>\n<h2 id=\"基因组拼接基本概念\"><a class=\"markdownIt-Anchor\" href=\"#基因组拼接基本概念\"></a> 基因组拼接基本概念</h2>\n<h3 id=\"测序深度\"><a class=\"markdownIt-Anchor\" href=\"#测序深度\"></a> 测序深度</h3>\n<p>测序深度（Sequencing depth）指测序得到的总碱基数（read 长度 x reads 数目）与待测基因组大小的比值。假设一个基因组大小为 2M，测序深度为 10X，那么获得的总数据量为 20M。</p>\n<h3 id=\"测序覆盖度\"><a class=\"markdownIt-Anchor\" href=\"#测序覆盖度\"></a> 测序覆盖度</h3>\n<p>指测序获得的序列占整个基因组的比例。由于基因组中的高 GC、重复序列等复杂区域的存在，测序获得的序列经常无法覆盖基因组上所有的区域。例如覆盖度是 96%，表明还有 4% 的序列区域未测到。</p>\n<h3 id=\"read-contig-scaffold\"><a class=\"markdownIt-Anchor\" href=\"#read-contig-scaffold\"></a> Read、Contig、Scaffold</h3>\n<p>测序得到的序列被称作 reads，在一个 read 中连续的 N 个碱基所组成的序列称作 k-mer，把 k-mer 集合拼接起来形成的长 DNA 序列称为 contig。通过 pair ends 信息将 contigs 按顺序进行排列得到 scaffold。</p>\n<h3 id=\"n50\"><a class=\"markdownIt-Anchor\" href=\"#n50\"></a> N50</h3>\n<p>将 contigs 或 scaffolds 根据长度从大到小排列并累加，当其累计长度达到全部组装序列总长度的 50% 时，加上去的最后一个 contig 或 scaffold 的大小即为 N50 的大小，N50 是评价基因组拼接质量的重要参数。</p>\n<h1 id=\"参考文献\"><a class=\"markdownIt-Anchor\" href=\"#参考文献\"></a> 参考文献</h1>\n<p>Besser J, Carleton HA, Gerner-Smidt P, Lindsey RL, Trees E. Next-generation sequencing technologies and their application to the study and control of bacterial infections. <em>Clinical Microbiology and Infection</em>, 2018, 24: 335-341</p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"WGS","path":"api/tags/WGS.json"}]},{"title":"SignalP+TMHMM预测微生物分泌蛋白","slug":"SignalP-TMHMM预测微生物分泌蛋白","date":"2021-10-14T01:09:45.000Z","updated":"2022-01-08T02:16:28.415Z","comments":true,"path":"api/articles/SignalP-TMHMM预测微生物分泌蛋白.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg","content":"<p>Subtitle: Predict Secretory Protein in microbes with SignalP and TMHMM</p>\n<p><ruby>分泌蛋白<rt>Secretory Protein</rt></ruby>是指在细胞内合成后，分泌到细胞外起作用的蛋白质。分泌蛋白的 N 端有一般由 15～30 个氨基酸组成的信号肽。信号肽是引导新合成的蛋白质向分泌通路转移的短（长度 5-30 个氨基酸）肽链。常指新合成多肽链中用于指导蛋白质的跨膜转移（定位）的 N - 末端的氨基酸序列（有时不一定在 N 端）。<u>使用<strong> SignalP</strong> 注释蛋白序列是否含有信号肽结构，使用<strong> TMHMM</strong> 注释蛋白序列是否含有跨膜结构，最终筛选出含有信号肽结构并且不含跨膜结构的蛋白为分泌蛋白</u>。</p>\n<h1 id=\"ruby软件-rtsoftwarertruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件-rtsoftwarertruby\"></a> <ruby>软件 <rt>Software</rt></ruby></h1>\n<ul>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\">SignalP V6.0</a></p>\n</li>\n<li>\n<p>SignalP 6.0 <ruby>预测来自古细菌、革兰氏阳性细菌、革兰氏阴性细菌和真核生物的蛋白质中存在的信号肽<rt>predicts signal peptides and the location of their cleavage sites in proteins from Archaea,  Gram-positive Bacteria,</rt></ruby><ruby>及其切割位点的位置。<rt> Gram-negative Bacteria and Eukarya.</rt></ruby><ruby>在细菌和古细菌中，SignalP 6.0 可以区分五种类型的信号肽：<rt>In Bacteria and Archaea, SignalP 6.0 can discriminate between five types of signal peptides:</rt></ruby></p>\n<ul>\n<li>\n<p>Sec/SPI：<ruby>由 Sec 转座转运，并由信号肽酶 I (Lep) 切割的 “标准” 分泌信号肽；<rt>&quot;Standard&quot; secretory signal peptides transported by Sec translocon and cleaved by Signal Peptidase I (Lep).</rt></ruby></p>\n</li>\n<li>\n<p>Sec/SPII：<ruby>由 Sec 转座子运输，并由信号肽酶 II (Lsp) 切割的脂蛋白信号肽；<rt>lipoprotein signal peptides transported by the Sec translocon and cleaved by Signal Peptidase II (Lsp).</rt></ruby></p>\n</li>\n<li>\n<p>Tat/SPI：<ruby>由 Tat 转座子转运，并由信号肽酶 I (Lep) 切割的 Tat 信号肽；<rt>Tat signal peptides transported by the Tat translocon and cleaved by Signal Peptidase I (Lep).</rt></ruby></p>\n</li>\n<li>\n<p>Tat/SPII：<ruby>由 Tat 转位子转运，并由信号肽酶 II (Lsp) 切割的 Tat 脂蛋白信号肽；<rt>Tat lipoprotein signal peptides transported by Tat translocon &amp; cleaved by Signal Peptidase II (Lsp).</rt></ruby></p>\n</li>\n<li>\n<p>Sec/SPIII：<ruby>由 Sec 转位子运输，并由信号肽酶 III (PilD/PibD) 切割的菌毛蛋白和菌毛蛋白样信号肽。<rt>Pilin &amp; pilin-like signal peptides transported by Sec translocon &amp; cleaved by Signal Peptidase III (PilD/PibD).</rt></ruby></p>\n</li>\n<li>\n<p><ruby>此外，SignalP 6.0 预测信号肽的区域。<rt>Additionally, SignalP 6.0 predicts the regions of signal peptides.</rt></ruby><ruby>根据类型，预测 n、h 和 c 区域以及其他显着特征的位置。<rt> Depending on the type, the positions of n-, h- and c-regions as well as of other distinctive features are predicted.</rt></ruby></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?TMHMM-2.0\">TMHMM V2.0c</a></p>\n<ul>\n<li>用于预测蛋白质中的跨膜螺旋。</li>\n</ul>\n</li>\n<li>\n<p>Python</p>\n</li>\n</ul>\n<p>SignalP 和 TMHMM 对于学术用户免费，但是需要填写相关信息和邮箱，以接收下载链接（4h 有效时间）。</p>\n<h1 id=\"ruby软件安装-rtinstallation-of-softwaresrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件安装-rtinstallation-of-softwaresrtruby\"></a> <ruby>软件安装 <rt>Installation of Softwares</rt></ruby></h1>\n<h2 id=\"安装signalp-60\"><a class=\"markdownIt-Anchor\" href=\"#安装signalp-60\"></a> 安装 SignalP 6.0</h2>\n<ul>\n<li>\n<p>下载</p>\n<p>访问<a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\"> SignalP V6.0</a> 网站，找到 “Download”，填写相关信息，获取下载链接，下载得到 “signalp-6.0.fast.tar.gz”。有两个模式可以选择 ——“slow_sequential” 和 “fast&quot;。前者 runs the full model sequentially, taking the same amount of RAM as  <code>fast</code>  but being 6 times slower；后者 uses a smaller model that approximates the performance of the full model, requiring a fraction of the resources and being significantly faste。本教程下载的是 fast 模式。</p>\n</li>\n<li>\n<p><ruby>安装 <rt>Installation</rt></ruby></p>\n<ul>\n<li>\n<p><ruby>安装依赖 <rt>Dependencies</rt></ruby></p>\n<ul>\n<li>\n<p>Python</p>\n</li>\n<li>\n<p>matplotlib&gt;3.3.2</p>\n</li>\n<li>\n<p>numpy&gt;1.19.2</p>\n</li>\n<li>\n<p>torch&gt;1.7.0</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> torch<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>tqdm&gt;4.46.1</p>\n</li>\n</ul>\n</li>\n<li>\n<p>安装 SignalP 6.0</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 解压缩安装文件</span>\n<span class=\"token function\">tar</span> zxvf signalp-6.0.fast.tar.gz\n\n<span class=\"token comment\"># 进入解压后的软件目录，在终端运行</span>\npython setup.py <span class=\"token function\">install</span>\n\n<span class=\"token comment\"># 测试安装</span>\nsignalp6 --help<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装tmhmm-v20c\"><a class=\"markdownIt-Anchor\" href=\"#安装tmhmm-v20c\"></a> 安装 TMHMM V2.0c</h2>\n<ul>\n<li>\n<p>下载</p>\n<p>访问<a href=\"https://services.healthtech.dtu.dk/service.php?TMHMM-2.0\"> TMHMM V2.0c</a> 网站，找到 “Download”，填写相关信息，获取下载链接，下载得到 “tmhmm-2.0c.Linux.tar.gz”。</p>\n</li>\n<li>\n<p>安装</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 解压缩</span>\n<span class=\"token function\">tar</span> zxvf tmhmm-2.0c.Linux.tar.gz\n\n<span class=\"token comment\"># 进入解压后的目录</span>\n<span class=\"token builtin class-name\">cd</span> tmhmm-2.0c\n\n<span class=\"token comment\"># 获取当前路径，我的是“/home/liu/tools/tmhmm-2.0c/bin”</span>\n<span class=\"token builtin class-name\">pwd</span>\n\n<span class=\"token comment\"># 将该路径加入到系统的环境变量中，参考我之前的文章来（编辑~/.bashrc）https://liaochenlanruo.github.io/post/f6c9.html#%E6%B7%BB%E5%8A%A0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F</span>\n\n<span class=\"token comment\"># 修改bin目录下的tmhmm和tmhmmformat.pl的首行为“#!/usr/bin/perl”</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><font color=\"#FF0000\">运行错误</font></p>\n<p>运行软件时总报 <code>Segmentation fault (core dumped)</code>  错误，暂时无解。各位可以使用其<a href=\"http://www.cbs.dtu.dk/services/TMHMM/\">在线版</a>。</p>\n</li>\n</ul>\n<h1 id=\"ruby软件用法-rtusagertruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件用法-rtusagertruby\"></a> <ruby>软件用法 <rt>Usage</rt></ruby></h1>\n<h2 id=\"signalp-60\"><a class=\"markdownIt-Anchor\" href=\"#signalp-60\"></a> SignalP 6.0</h2>\n<h3 id=\"ruby预测-rtpredictionrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby预测-rtpredictionrtruby\"></a> <ruby>预测 <rt>Prediction</rt></ruby></h3>\n<p>A command takes the following form</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">signalp6 --fastafile /path/to/input.fasta --organism other --output_dir path/to/be/saved --format txt --mode fast<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>\n<p><code>fastafile</code>  <ruby>输入文件为 FASTA 格式的蛋白序列文件<rt>Specifies the fasta file with the sequences to be predicted.</rt></ruby>。</p>\n</li>\n<li>\n<p><code>organism</code>  is either  <code>other</code>  or  <code>Eukarya</code> . Specifying  <code>Eukarya</code>  triggers post-processing of the SP predictions to prevent spurious results (only predicts type Sec/SPI).</p>\n</li>\n<li>\n<p><code>format</code>  can take the values  <code>txt</code> ,  <code>png</code> ,  <code>eps</code> ,  <code>all</code> . It defines what output files are created for individual sequences.  <code>txt</code>  produces a tabular  <code>.gff</code>  file with the per-position predictions for each sequence.  <code>png</code> ,  <code>eps</code> ,  <code>all</code>  additionally produce probability plots in the requested format. For larger prediction jobs, plotting will slow down the processing speed significantly.</p>\n</li>\n<li>\n<p><code>mode</code>  is either  <code>fast</code> ,  <code>slow</code>  or  <code>slow-sequential</code> . Default is  <code>fast</code> , which uses a smaller model that approximates the performance of the full model, requiring a fraction of the resources and being significantly faster.  <code>slow</code>  runs the full model in parallel, which requires more than 14GB of RAM to be available.  <code>slow-sequential</code>  runs the full model sequentially, taking the same amount of RAM as  <code>fast</code>  but being 6 times slower. If the specified model is not installed, SignalP will abort with an error.</p>\n</li>\n</ul>\n<h3 id=\"ruby输出rt-outputsrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby输出rt-outputsrtruby\"></a> <ruby>输出<rt> Outputs</rt></ruby></h3>\n<ul>\n<li>\n<p>output_dir/output.gff3：仅包含含有信号肽的序列信息；</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"output.gff3\" /></p>\n</li>\n<li>\n<p>output_dir/prediction_results.txt：包含了输入文件中的所有序列（不重要）；</p>\n</li>\n<li>\n<p>output_dir/region_output.gff3：包含所有的信号肽区域信息。</p>\n<ul>\n<li>\n<p>n-region: The n-terminal region of the signal peptide. Reported for Sec/SPI, Sec/SPII, Tat/SPI and Tat/SPII. Labeled as N</p>\n</li>\n<li>\n<p>h-region: The center hydrophobic region of the signal peptide. Reported for Sec/SPI, Sec/SPII, Tat/SPI and Tat/SPII. Labeled as H</p>\n</li>\n<li>\n<p>c-region: The c-terminal region of the signal peptide, reported for Sec/SPI and Tat/SPI.</p>\n</li>\n<li>\n<p>Cysteine: The conserved cysteine in +1 of the cleavage site of Lipoproteins that is used for Lipidation. Labeled as c.</p>\n</li>\n<li>\n<p>Twin-arginine motif: The twin-arginine motif at the end of the n-region that is characteristic for Tat signal peptides. Labeled as R.</p>\n</li>\n<li>\n<p>Sec/SPIII: These signal peptides have no known region structure.</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"region_output.gff3\" /></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"批处理与结果优化\"><a class=\"markdownIt-Anchor\" href=\"#批处理与结果优化\"></a> 批处理与结果优化</h3>\n<p>脚本名：run_SignalP.pl</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: Oct 14, 2021</span>\n\n\nopen IDNOSEQ<span class=\"token punctuation\">,</span> <span class=\"token string\">\">IDNOSEQ.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".nodesc\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sigseq</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".sigseq\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$outdir</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_signalp\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token regex\">/^(>\\S+)/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span> <span class=\"token operator\">=</span> idseq<span class=\"token punctuation\">(</span><span class=\"token variable\">$out</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"signalp6 --fastafile $out --organism other --output_dir $outdir --format txt --mode fast\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$gff</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$outdir</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/output.gff3\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span> <span class=\"token operator\">-z</span> <span class=\"token variable\">$gff</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$gff\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$sigseq\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> IDNOSEQ <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"$lines[0]\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t\tclose IN<span class=\"token punctuation\">;</span>\n\t\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"rm $out\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv $sigseq $outdir\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IDNOSEQ<span class=\"token punctuation\">;</span>\n\n\n<span class=\"token function\"><span class=\"token keyword\">sub</span> idseq</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token variable\">@_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将 run_SignalP.pl 与后缀名为 “.faa” 的 FASTA 格式文件放在同一目录下，在终端中运行如下代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_SignalP.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"ruby结果解读rtoutput-interpretationrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby结果解读rtoutput-interpretationrtruby\"></a> <ruby>结果解读<rt>Output interpretation</rt></ruby></h3>\n<p>* 代表输入文件的名字。</p>\n<ul>\n<li>\n<p>*_signalp/output.gff3：仅包含含有信号肽的序列信息；</p>\n</li>\n<li>\n<p>*_signalp/prediction_results.txt：包含了输入文件中的所有序列（不重要）；</p>\n</li>\n<li>\n<p>*_signalp/region_output.gff3：包含所有的信号肽区域信息；</p>\n</li>\n<li>\n<p><strong>*_signalp/*.sigseq</strong>：存储所有信号肽的氨基酸序列文件，可用作 TMHMM 的输入文件。</p>\n</li>\n</ul>\n<h2 id=\"tmhmm\"><a class=\"markdownIt-Anchor\" href=\"#tmhmm\"></a> TMHMM</h2>\n<h3 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h3>\n<p>离线版总是报错，找不出原因，因此使用网页服务器进行，输入文件为上述生成的 “*_signalp/*.sigseq”，将其上传至网页版<a href=\"http://www.cbs.dtu.dk/services/TMHMM/\"> TMHMM</a>，提交任务，等待结果即可。</p>\n<h3 id=\"结果展示\"><a class=\"markdownIt-Anchor\" href=\"#结果展示\"></a> 结果展示</h3>\n<p>TMHMM 可以输出多种格式的结果文件，具体请参考其<a href=\"http://www.cbs.dtu.dk/services/TMHMM-2.0/TMHMM2.0.guide.html#output\">官方说明</a>。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.5.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.5.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"在TMHMM网站提交任务\" /></p>\n<ul>\n<li>\n<p><strong>Long output format</strong></p>\n<ul>\n<li>\n<p>Length： <ruby>蛋白序列的长度。<rt>The length of the protein sequence.</rt></ruby></p>\n</li>\n<li>\n<p>Number of predicted TMHs：<ruby>预测到的跨膜螺旋的数量。<rt>The number of predicted transmembrane helices.</rt></ruby></p>\n</li>\n<li>\n<p>Exp number of AAs in TMHs：<ruby>跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids intransmembrane helices. </rt></ruby> <ruby>如果此数字大于 18，则很可能是跨膜蛋白（或具有信号肽）。<rt>If this number is larger than 18 it is very likely to be a transmembrane protein (OR have a signal peptide).</rt></ruby></p>\n</li>\n<li>\n<p>Exp number, first 60 AAs：<ruby>在蛋白的前 60 个氨基酸中跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids in transmembrane helices in the first 60 amino acids of the protein.</rt></ruby><ruby>如果该数字超过几个，你应该被警告在 N 端预测的跨膜螺旋可能是一个信号肽。<rt>If it more than a few, you are warned that a predicted transmembrane helix in the N-term could be a signal peptide.</rt></ruby></p>\n</li>\n<li>\n<p>Total prob of N-in：<ruby>N 端在膜的细胞质一侧的总概率。<rt> The total probability that the N-term is on the cytoplasmic side of the membrane.</rt></ruby></p>\n</li>\n<li>\n<p>POSSIBLE N-term signal sequence：<ruby>当 “Exp number, first 60 AAs” 大于 10 时产生的警告。 <rt> A warning that is produced when &quot;Exp number, first 60 AAs&quot; is larger than 10.</rt></ruby></p>\n</li>\n</ul>\n</li>\n<li>\n<p>蛋白 F01_bin.1_00110 共计 436 个氨基酸，有 5 个跨膜螺旋结构。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"含有跨膜结构的蛋白\" /></p>\n</li>\n<li>\n<p>蛋白 F01_bin.1_00142 共计 557 个氨基酸，所有序列均在膜外，即该序列编码的是分泌蛋白。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_4.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_4.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"不含跨膜结构的蛋白\" /></p>\n</li>\n<li>\n<p><strong>Short output format</strong></p>\n<ul>\n<li>\n<p>&quot;len=&quot;： <ruby>蛋白序列的长度。 <rt>The length of the protein sequence.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;ExpAA=&quot;：<ruby>跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids intransmembrane helices.</rt></ruby><ruby>如果此数字大于 18，则很可能是跨膜蛋白（或具有信号肽）。<rt>If this number is larger than 18 it is very likely to be a transmembrane protein (OR have a signal peptide).</rt></ruby></p>\n</li>\n<li>\n<p>&quot;First60=&quot;：<ruby>在蛋白的前 60 个氨基酸中跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids in transmembrane helices in the first 60 amino acids of the protein.</rt></ruby><ruby>如果该数字超过几个，你应该被警告在 N 端预测的跨膜螺旋可能是一个信号肽。<rt>If it more than a few, you are warned that a predicted transmembrane helix in the N-term could be a signal peptide.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;PredHel=&quot;：<ruby>预测到的跨膜螺旋的数量。 <rt>The number of predicted transmembrane helices by N-best.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;Topology=&quot;：<ruby>N-best 预测的拓扑结构。<rt>The topology predicted by N-best.</rt></ruby>拓扑是由跨膜螺旋的位置给出的，如果螺旋在内部，则由 “i” 分隔，如果螺旋在外部，则由 “o” 分隔。'i7-29o44-66i87-109o' 意味着它从膜内开始，在位置 7 到 29 有一个预测的 TMH，30-43 在膜外，然后是位置 44-66 的 TMH。</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_5.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_5.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Short output format\" /></p>\n</li>\n</ul>\n<h3 id=\"结果汇总\"><a class=\"markdownIt-Anchor\" href=\"#结果汇总\"></a> 结果汇总</h3>\n<p>通过网页版预测我们仅得到了一个列表文件（Short output format），该文件需要自己复制网页内容粘贴到新文件中，我将其命名为<b>*_TMHMM_SHORT.txt</b>，并将其存放在<b>*_signalp</b>目录中，该目录是由<strong> run_SignalP.pl</strong> 生成的。下面我将会统计各个基因组中信号肽蛋白的总数量、分泌蛋白数量和跨膜蛋白数量到文件<strong> Statistics.txt</strong> 中，并分别提取每个基因组的分泌蛋白序列到<b>*_signalp/*.secretory.faa</b>文件中，提取跨膜蛋白序列到<b>*_signalp/*.membrane.faa</b>文件中。该过程将通过<strong> tmhmm_parser.pl</strong> 完成。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: Oct 15, 2021</span>\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Statistics.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"Strain name\\tSignal peptide numbers\\tSecretory protein numbers\\tMembrane protein numbers\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@sig</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*_signalp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$sig</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">@sig</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$sig</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+)_signalp/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$tmhmm</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sig</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/$str\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_TMHMM_SHORT.txt\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sig</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/$str\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".sigseq\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$secretory</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".secretory.faa\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$membrane</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".membrane.faa\"</span><span class=\"token punctuation\">;</span>\n\topen SEC<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$secretory\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen MEM<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$membrane\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$on</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span> <span class=\"token operator\">=</span> idseq<span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$tmhmm</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">#\t\tprint $_ . \"\\n\";</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">eq</span> <span class=\"token string\">\"Topology=o\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$out</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> SEC <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$on</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> MEM <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose SEC<span class=\"token punctuation\">;</span>\n\tclose MEM<span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv $secretory $membrane $sig\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$on</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$str\\t$total\\t$out\\t$on\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nclose OUT<span class=\"token punctuation\">;</span>\n\n<span class=\"token function\"><span class=\"token keyword\">sub</span> idseq</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token variable\">@_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>运行方法</strong>：将<b>tmhmm_parser.pl</b>放在<b>*_signalp</b>的上一级目录下，<b>*_signalp</b>目录中必须包含<b>*_TMHMM_SHORT.txt</b>文件和<b>*.sigseq</b>文件。在终端运行如下代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl tmhmm_parser.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “c886” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\">SignalP V6.0</a></p>\n</li>\n<li>\n<p><a href=\"http://www.cbs.dtu.dk/services/TMHMM/\">TMHMM</a></p>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"WGS","path":"api/tags/WGS.json"}]},{"title":"宏病毒组分析流程1-VirSorter2","slug":"宏病毒组分析流程1-VirSorter2","date":"2021-12-02T01:35:30.000Z","updated":"2022-01-08T02:16:28.444Z","comments":true,"path":"api/articles/宏病毒组分析流程1-VirSorter2.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<h1 id=\"安装软件\"><a class=\"markdownIt-Anchor\" href=\"#安装软件\"></a> 安装软件</h1>\n<ul>\n<li>\n<p>安装主程序及依赖</p>\n<div class=\"note default\">\n<ul>\n<li><a href=\"https://bitbucket.org/MAVERICLab/virsorter2/src/master\">VirSorter2</a> (version &gt;=2.2.3)</li>\n<li><a href=\"https://bitbucket.org/berkeleylab/checkv/src/master\">CheckV</a> (version &gt;=0.7.0)</li>\n<li><a href=\"https://github.com/shafferm/DRAM\">DRAMv</a> (version &gt;=1.2.0)</li>\n</ul>\n</div>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda create -n virome <span class=\"token assign-left variable\">virsorter</span><span class=\"token operator\">=</span><span class=\"token number\">2</span> checkv dram\nconda activate virome<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>下载数据库</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># vs2 db: db-vs2 ~ 10 min</span>\nvirsorter setup -d /new_data/hualin/db/db-vs2 -j <span class=\"token number\">50</span>\n\n<span class=\"token comment\"># checkv db: checkv-db-v1.0  &lt; 5 mins</span>\ncheckv download_database /new_data/hualin/db/checkv\n\n<span class=\"token comment\"># DRAMv: db-dramv ~5h and ~60GB of memory</span>\nDRAM-setup.py prepare_databases --skip_uniref --output_dir db-dramv<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h1>\n<ul>\n<li>\n<p>获取测试数据</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> -O test.fa https://bitbucket.org/MAVERICLab/virsorter2/raw/15a21fa9c1ee1d2af52b0148b167292e549d356e/test/test-for-sop.fa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>运行 VirSorter2</p>\n<details class=\"info\"><summary>命令解析</summary><div>\n<ul>\n<li>首先以 0.5 的 score 阈值运行 VirSorter2 以保证最大的灵敏度。</li>\n<li>只关注噬菌体 (dsDNA and ssDNA phage)，可选 dsDNAphage,NCLDV,RNA,ssDNA,lavidaviridae。</li>\n<li>序列最小长度为 5000 bp，后续病毒分类的最低要求如此。</li>\n<li>可根据自己的 CPU 核心数自行调整 &quot;-j&quot;。</li>\n<li>&quot;--keep-original-seq&quot; 保留了环状和接近完整的病毒 contigs (score&gt;0.8 as a whole sequence)，后续将通过 checkV 修剪其尾端的潜在宿主基因并处理重复的环状 contigs 片段。</li>\n</ul>\n</div></details>\n<div class=\"note default\">\n<p>Time: 31m7.310s with a real dataset of 90.52 MB and 207,544 sequences</p>\n</div>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">virsorter run --keep-original-seq -w vs2-pass1 -i test.fa --include-groups dsDNAphage,ssDNA --min-length <span class=\"token number\">5000</span>  --min-score <span class=\"token number\">0.5</span> -j <span class=\"token number\">50</span> all<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"primary\"><summary>参数解析</summary><div>\n<p>-w 指定输出目录<br />\n - i 指定输入序列<br />\n --min-length 过滤短序列<br />\n --min-score 分数阈值<br />\n --keep-original-seq 保留环状和接近完整的病毒 contigs<br />\n--include-groups 指定包含的病毒类型，用 “,” 分隔。可选：dsDNAphage,NCLDV,RNA,ssDNA,lavidaviridae<br />\n-j 线程数<br />\n all 直接写上就可以</p>\n</div></details>\n<details class=\"success\"><summary>结果解析</summary><div>\n<ul>\n<li>\n<p>final-viral-combined.fa: 病毒序列</p>\n<ul>\n<li>鉴定为病毒的完整序列（标识为后缀 ||full）；</li>\n<li>鉴定为病毒的部分序列（用后缀 ||{i}_partial 标识）； {i} 可以是从 0 到该 Contig 中发现的最大病毒片段数的数字；</li>\n<li>带有<ruby>标志基因<rt>hallmark gene</rt></ruby>的短序列（少于两个基因）被鉴定为病毒（用后缀 ||lt2gene 标识）；</li>\n</ul>\n</li>\n<li>\n<p>final-viral-score.tsv: 每个病毒序列的评分跨组和一些关键特征，这可以用于进一步过滤</p>\n<ul>\n<li>sequence name</li>\n<li>score of each viral sequences across groups (多列)</li>\n<li>max score across groups</li>\n<li>max score group</li>\n<li>contig length</li>\n<li>hallmark gene count</li>\n<li>viral gene %</li>\n<li>nonviral gene %</li>\n</ul>\n</li>\n</ul>\n  <div style=\"width:100%;overflow:scroll;\">\n  \t<table border=\"1\" rules=\"all\" style=\"width:2000px; height:100px; text-align:center\">\n  \t    <tr>\n  \t\t<td>seqname</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>NCLDV</td>\n  \t\t<td>RNA</td>\n  \t\t<td>ssDNA</td>\n  \t\t<td>lavidaviridae</td>\n  \t\t<td>max_score</td>\n  \t\t<td>max_score_group</td>\n  \t\t<td>length</td>\n  \t\t<td>hallmark</td>\n  \t\t<td>viral</td>\n  \t\t<td>cellular</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_5_length_17317_cov_8.385876&#124;&#124;full</td>\n  \t\t<td>0.993</td>\n  \t\t<td>0.847</td>\n  \t\t<td>0.005</td>\n  \t\t<td>0.060</td>\n  \t\t<td>0.467</td>\n  \t\t<td>0.993</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>17315</td>\n  \t\t<td>2</td>\n  \t\t<td>64.700</td>\n  \t\t<td>5.900</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_6_length_16611_cov_115.615064&#124;&#124;full</td>\n  \t\t<td>0.920</td>\n  \t\t<td>0.207</td>\n  \t\t<td>0.035</td>\n  \t\t<td>0.087</td>\n  \t\t<td>0.053</td>\n  \t\t<td>0.920</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>16610</td>\n  \t\t<td>0</td>\n  \t\t<td>3.200</td>\n  \t\t<td>0.000</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_8_length_14848_cov_778.417157&#124;&#124;full</td>\n  \t\t<td>1.000</td>\n  \t\t<td>0.220</td>\n  \t\t<td>0.105</td>\n  \t\t<td>0.380</td>\n  \t\t<td>0.627</td>\n  \t\t<td>1.000</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>14848</td>\n  \t\t<td>15</td>\n  \t\t<td>100.000</td>\n  \t\t<td>0.000</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_16_length_12563_cov_14.331948&#124;&#124;full</td>\n  \t\t<td>0.973</td>\n  \t\t<td>0.200</td>\n  \t\t<td>0.165</td>\n  \t\t<td>0.273</td>\n  \t\t<td>0.227</td>\n  \t\t<td>0.973</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>12083</td>\n  \t\t<td>0</td>\n  \t\t<td>8.000</td>\n  \t\t<td>0.000</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_17_length_11885_cov_350.043956&#124;&#124;full</td>\n  \t\t<td>0.653</td>\n  \t\t<td>0.513</td>\n  \t\t<td>0.050</td>\n  \t\t<td>0.080</td>\n  \t\t<td>0.047</td>\n  \t\t<td>0.653</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>11885</td>\n  \t\t<td>0</td>\n  \t\t<td>9.100</td>\n  \t\t<td>0.000</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_21_length_11527_cov_216.405073&#124;&#124;full</td>\n  \t\t<td>0.620</td>\n  \t\t<td>0.407</td>\n  \t\t<td>0.000</td>\n  \t\t<td>0.013</td>\n  \t\t<td>0.060</td>\n  \t\t<td>0.620</td>\n  \t\t<td>dsDNAphage</td>\n  \t\t<td>11526</td>\n  \t\t<td>0</td>\n  \t\t<td>10.500</td>\n  \t\t<td>5.300</td>\n  \t    </tr>\n  \t    <tr>\n  \t\t<td>NODE_23_length_11316_cov_8.144303&#124;&#124;full</td>\n  \t\t<td>0.367</td>\n  \t\t<td>0.540</td>\n  \t\t<td>0.010</td>\n  \t\t<td>0.000</td>\n  \t\t<td>0.400</td>\n  \t\t<td>0.540</td>\n  \t\t<td>NCLDV</td>\n  \t\t<td>11313</td>\n  \t\t<td>1</td>\n  \t\t<td>23.100</td>\n  \t\t<td>7.700</td>\n  \t    </tr>\n  \t</table>\n  </div>\n<div class=\"note warning\">\n<p>不同病毒类群的分类器并非相互排斥，它们的<ruby>目标病毒序列空间<rt>target viral sequence space</rt></ruby>可能存在重叠，这意味着该信息不应被使用或当作<ruby>可靠的分类<rt>reliable taxonomic classification</rt></ruby>。VirSorter2 的用途仅限于病毒鉴定。</p>\n</div>\n<ul>\n<li>\n<p>final-viral-boundary.tsv: 带有边界信息的表 (与其他两个文件相比，可能有额外的记录，应该忽略)。</p>\n<p>only some of the columns in this file might be useful:</p>\n<ul>\n<li>seqname: original sequence name</li>\n<li>trim_orf_index_start, trim_orf_index_end: start and end ORF index on orignal sequence of identified viral sequence</li>\n<li>trim_bp_start, trim_bp_end: start and end position on orignal sequence of identified viral sequence</li>\n<li>trim_pr: score of final trimmed viral sequence</li>\n<li>partial: full sequence as viral or partial sequence as viral; this is defined when a full sequence has score &gt; score cutoff, it is full (0), or else any viral sequence extracted within it is partial (1)</li>\n<li>pr_full: score of the original sequence</li>\n<li>hallmark_cnt: hallmark gene count</li>\n<li>group: the classifier of viral group that gives high score; this should NOT be used as reliable classification</li>\n</ul>\n</li>\n</ul>\n  <div style=\"width:100%;overflow:scroll;\">\n  \t<table border=\"1\" rules=\"all\" style=\"width:2000px; height:100px; text-align:center\">\n  \t    <tr>\n  \t<td>seqname</td>\n  \t<td>trim_orf_index_start</td>\n  \t<td>trim_orf_index_end</td>\n  \t<td>trim_bp_start</td>\n  \t<td>trim_bp_end</td>\n  \t<td>trim_pr</td>\n  \t<td>trim_pr_max</td>\n  \t<td>prox_orf_index_start</td>\n  \t<td>prox_orf_index_end</td>\n  \t<td>prox_bp_start</td>\n  \t<td>prox_bp_end</td>\n  \t<td>prox_pr</td>\n  \t<td>prox_pr_max</td>\n  \t<td>partial</td>\n  \t<td>full_orf_index_start</td>\n  \t<td>full_orf_index_end</td>\n  \t<td>full_bp_start</td>\n  \t<td>full_bp_end</td>\n  \t<td>pr_full</td>\n  \t<td>arc</td>\n  \t<td>bac</td>\n  \t<td>euk</td>\n  \t<td>vir</td>\n  \t<td>mix</td>\n  \t<td>unaligned</td>\n  \t<td>hallmark_cnt</td>\n  \t<td>group</td>\n  \t<td>shape</td>\n  \t<td>seqname_new</td>\n  \t    </tr>\n  \t    <tr>\n  \t<td>NODE_999_length_4026_cov_7.610929</td>\n  \t<td>1</td>\n  \t<td>12</td>\n  \t<td>1</td>\n  \t<td>4025</td>\n  \t<td>0.547</td>\n  \t<td>0.547</td>\n  \t<td>1</td>\n  \t<td>12</td>\n  \t<td>1</td>\n  \t<td>4025</td>\n  \t<td>nan</td>\n  \t<td>nan</td>\n  \t<td>0</td>\n  \t<td>1</td>\n  \t<td>12</td>\n  \t<td>1</td>\n  \t<td>4025</td>\n  \t<td>0.547</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>100.0</td>\n  \t<td>0</td>\n  \t<td>dsDNAphage</td>\n  \t<td>linear</td>\n  \t<td>NODE_999_length_4026_cov_7.610929||full</td>\n  \t    </tr>\n  \t    <tr>\n  \t<td>NODE_9999_length_1276_cov_11.598690</td>\n  \t<td>1</td>\n  \t<td>3</td>\n  \t<td>3</td>\n  \t<td>1274</td>\n  \t<td>0.955</td>\n  \t<td>0.955</td>\n  \t<td>1</td>\n  \t<td>3</td>\n  \t<td>3</td>\n  \t<td>1274</td>\n  \t<td>nan</td>\n  \t<td>nan</td>\n  \t<td>0</td>\n  \t<td>1</td>\n  \t<td>3</td>\n  \t<td>3</td>\n  \t<td>1274</td>\n  \t<td>0.955</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>100.0</td>\n  \t<td>0</td>\n  \t<td>RNA</td>\n  \t<td>linear</td>\n  \t<td>NODE_9999_length_1276_cov_11.598690||full</td>\n  \t    </tr>\n  \t    <tr>\n  \t<td>NODE_99999_length_314_cov_4.000000</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>287</td>\n  \t<td>0.57</td>\n  \t<td>0.57</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>287</td>\n  \t<td>nan</td>\n  \t<td>nan</td>\n  \t<td>0</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>287</td>\n  \t<td>0.57</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>50.0</td>\n  \t<td>50.0</td>\n  \t<td>0</td>\n  \t<td>RNA</td>\n  \t<td>linear</td>\n  \t<td>NODE_99999_length_314_cov_4.000000||full</td>\n  \t    </tr>\n  \t    <tr>\n  \t<td>NODE_99992_length_314_cov_4.389961</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>275</td>\n  \t<td>0.747</td>\n  \t<td>0.747</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>275</td>\n  \t<td>nan</td>\n  \t<td>nan</td>\n  \t<td>0</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>275</td>\n  \t<td>0.747</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>100.0</td>\n  \t<td>0</td>\n  \t<td>ssDNA</td>\n  \t<td>linear</td>\n  \t<td>NODE_99992_length_314_cov_4.389961||full</td>\n  \t    </tr>\n  \t    <tr>\n  \t<td>NODE_9997_length_1276_cov_44.113841</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>1240</td>\n  \t<td>0.98</td>\n  \t<td>0.98</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>1240</td>\n  \t<td>nan</td>\n  \t<td>nan</td>\n  \t<td>0</td>\n  \t<td>1</td>\n  \t<td>2</td>\n  \t<td>1</td>\n  \t<td>1240</td>\n  \t<td>0.98</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>0.0</td>\n  \t<td>50.0</td>\n  \t<td>50.0</td>\n  \t<td>0</td>\n  \t<td>RNA</td>\n  \t<td>linear</td>\n  \t<td>NODE_9997_length_1276_cov_44.113841||full</td>\n  \t    </tr>\n  \t</table>\n  </div>\n<div class=\"note warning\">\n<p>在<ruby>原病毒<rt>provirus </rt></ruby>提取过程中，为了获得更好的敏感性，VirSorter2 有时会高估病毒序列的大小。建议清除这些前病毒预测，以去除预测病毒区域边缘的潜在宿主基因，例如使用<a href=\"https://bitbucket.org/berkeleylab/checkv\"> CheckV</a> 等工具。</p>\n</div>\n<div class=\"note primary\">\n<p>How to pick a score cutoff?</p>\n</div>\n<p>一般来说，score&gt;0.9 的人为高置信度。得分在 0.5 到 0.9 之间的可能是病毒和非病毒的混合体。很难确定区分病毒和非病毒的最佳分数，因为它取决于宿主序列和未知序列的百分比。因此，<span class=\"rainbow\">建议使用默认截止值 (0.5) 以获得最大灵敏度，然后使用 checkV 应用质量检查步骤以消除误报（预测完整性除外）</span>。<mark>请继续下面的流程。</mark></p>\n</div></details>\n</li>\n<li>\n<p>运行 checkV</p>\n<details class=\"info\"><summary>命令解析</summary><div>\n<p>Score 阈值设为 0.5 时，VirSorter2 结果中可能存在一些非病毒序列或区域。因此，使用 CheckV 对 VirSorter2 的结果进行质量控制，并修剪在<ruby>原病毒<rt>proviruses</rt></ruby>末端留下的潜在宿主区域。可以根据 CPU 内核的可用性调整 - t 选项。</p>\n</div></details>\n<div class=\"note default\">\n<p>Time: 0m28.795s</p>\n</div>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">checkv end_to_end vs2-pass1/final-viral-combined.fa checkv -t <span class=\"token number\">50</span> -d /new_data/hualin/db/checkv/checkv-db-v1.0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details class=\"success\"><summary>结果解析</summary><div>\n<ul>\n<li>./checkv/</li>\n<li>completeness.tsv</li>\n<li>complete_genomes.tsv</li>\n<li>contamination.tsv</li>\n<li>proviruses.fna</li>\n<li>quality_summary.tsv</li>\n<li>viruses.fna</li>\n<li>tmp</li>\n</ul>\n</div></details>\n</li>\n<li>\n<p>再次运行 VirSorter2</p>\n<details class=\"info\"><summary>命令解析</summary><div>\n<ul>\n<li>再次利用 checkV-trimmed 序列运行 VirSorter2 以得到 &quot;affi-contigs.tab&quot; 文件，该文件将作为 DRAMv 的输入以鉴定 AMGs。</li>\n<li>注意 &quot;--seqname-suffix-off&quot; 选项保留了原始的输入序列名称，因为我们确信在本步骤中，不可能从同一条 contig 中获得 &gt; 1 个原病毒。</li>\n<li>“--viral-gene-enrich-off” 选项关闭了病毒基因要多于宿主基因的要求，以确保 VirSorter2 在这一步不做任何筛查。</li>\n<li>以上两个选项需要 VirSorter2 版本 &gt;=2.2.1。</li>\n<li>可选所有病毒：dsDNAphage,NCLDV,RNA,ssDNA,lavidaviridae</li>\n</ul>\n</div></details>\n<div class=\"note default\">\n<p>Time: 18m30.896s</p>\n</div>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> checkv/proviruses.fna checkv/viruses.fna <span class=\"token operator\">></span> checkv/combined.fna\n\nvirsorter run --seqname-suffix-off --viral-gene-enrich-off --provirus-off --prep-for-dramv -i checkv/combined.fna -w vs2-pass2 --include-groups dsDNAphage,ssDNA --min-length <span class=\"token number\">5000</span> --min-score <span class=\"token number\">0.5</span> -j <span class=\"token number\">50</span> all<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<details class=\"success\"><summary>结果解析</summary><div>\n<ul>\n<li>./vs2-pass2/</li>\n<li>inal-viral-combined.fa</li>\n<li>final-viral-score.tsv</li>\n<li>for-dramv/final-viral-combined-for-dramv.fa</li>\n<li>for-dramv/viral-affi-contigs-for-dramv.tab</li>\n</ul>\n</div></details>\n</li>\n<li>\n<p>运行 DRAMv</p>\n<details class=\"info\"><summary>命令解析</summary><div>\n<p>使用 DRAMv 注释鉴定的病毒序列，以用于后续<ruby>人工整理<rt>manual curation</rt></ruby>。可通过 &quot;--threads&quot; 控制调用的 CPU 核心数。</p>\n</div></details>\n<div class=\"note default\">\n<p>Time: 8.81h</p>\n</div>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># step 1 annotate 耗时步骤，建议投后台运行</span>\nDRAM-v.py annotate -i vs2-pass2/for-dramv/final-viral-combined-for-dramv.fa -v vs2-pass2/for-dramv/viral-affi-contigs-for-dramv.tab -o dramv-annotate --skip_trnascan --threads <span class=\"token number\">50</span> --min_contig_size <span class=\"token number\">1000</span>\n\n<span class=\"token comment\">#step 2 summarize anntotations</span>\nDRAM-v.py distill -i dramv-annotate/annotations.tsv -o dramv-distill<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details class=\"success\"><summary>结果解析</summary><div>\n<ul>\n<li>dramv-annotate/annotations.tsv</li>\n<li>dramv-annotate/genbank 各条 contig 的 gbk 文件</li>\n<li>dramv-annotate/genes.faa</li>\n<li>dramv-annotate/genes.fna</li>\n<li>dramv-annotate/genes.gff</li>\n<li>dramv-annotate/rrnas.tsv</li>\n<li>dramv-annotate/scaffolds.fna</li>\n<li>dramv-annotate/vMAGs 各条 contig 的 fasta 文件</li>\n</ul>\n</div></details>\n</li>\n</ul>\n<h1 id=\"过滤\"><a class=\"markdownIt-Anchor\" href=\"#过滤\"></a> 过滤</h1>\n<h2 id=\"依据病毒和宿主基因数-分数-hallmark基因数以及contig长度进行筛选\"><a class=\"markdownIt-Anchor\" href=\"#依据病毒和宿主基因数-分数-hallmark基因数以及contig长度进行筛选\"></a> 依据病毒和宿主基因数、分数、hallmark 基因数以及 contig 长度进行筛选</h2>\n<p>来自 checkV 的病毒和宿主基因计数可用于假阳性筛查。由于 checkV 在预测病毒基因方面非常保守，那些由 checkV 预测的病毒基因的序列应该是病毒的，而那些没有被 checkV 预测到病毒基因的序列更可能是非病毒的。</p>\n<p>基于我们对土壤宏基因组的基准测试，(1) 那些没有预测到病毒和宿主基因的序列是病毒；(2) 没有病毒基因但有 2 个或 2 个以上宿主基因的大多数为非病毒基因；(3) 那些没有病毒基因和具有 1 个宿主基因的很难区分其为病毒还是非病毒（可能是可移动的基因元件，类似于 VirSorter1 中的第 3 类），除非手动检查，否则应该丢弃。</p>\n<p>只选择那些大于 10kb 的用于手动检查，因为太短的无法分辨。还有那些 VirSorter2 得分≥0.95 或 hallmark 基因计数 &gt; 2 的大多数是病毒。<mark>这些经验筛选标准总结如下：</mark></p>\n<div class=\"note success\">\n<p>Keep1: viral_gene &gt;0</p>\n</div>\n<div class=\"note success\">\n<p>Keep2: viral_gene =0 AND (host_gene =0 OR score &gt;=0.95 OR hallmark &gt;2)</p>\n</div>\n<div class=\"note warning\">\n<p>Manual check: (NOT in Keep1 OR Keep2) AND viral_gene =0 AND host_gene =1 AND length &gt;=10kb</p>\n</div>\n<div class=\"note danger\">\n<p>Discard: the rest</p>\n</div>\n<p><span class=\"aqua\">要查看病毒基因、宿主基因、评分和<ruby>序列的特征标记<rt>hallmark of sequences</rt></ruby>，您可以合并 &quot;vs2-pass1/final-viral-score.tsv&quot; 和 &quot;checkv/contamination.tsv&quot;，并在电子表格中过滤。</span>本尊为各位提供了 Perl 脚本<a href=\"https://github.com/liaochenlanruo/myScripts/tree/main/1551%20Virome\"> cat_tsv.pl</a> 以实现机动合并！直接在终端运行 <code>perl cat_tsv.pl</code>  即可得到合并后的文件 <code>forCheck.txt</code> 。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$head_checkv</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$head_pass1</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$count</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$num</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"checkv/contamination.tsv\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$_</span> <span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$count</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$count</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">$head_checkv</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"vs2-pass1/final-viral-score.tsv\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">forCheck.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$_</span> <span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$num</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$num</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">$head_pass1</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$head_pass1\\t$head_checkv\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@line</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$_\\t$hash&#123;$line[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$_\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>接下来按照上面的四条规则对 <code>forCheck.txt</code>  进行拆分，得到病毒 <code>Virus.txt</code> 、手动核对 <code>Manual_check.txt</code>  及抛弃的 <code>Discard.txt</code> 。可以自己看，也可以用 <code>get_virus.pl</code>  来完成。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$count</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"forCheck.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen VIRUS<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Virus.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen MANUAL<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Manual_check.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen DISCARD<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Discard.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$_</span> <span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$count</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$count</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">print</span> VIRUS <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> MANUAL <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> DISCARD <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># virus keep1</span>\n\t\t\t<span class=\"token keyword\">print</span> VIRUS <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">16</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># virus keep2</span>\n\t\t\t<span class=\"token keyword\">print</span> VIRUS <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">0.95</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># virus keep2</span>\n\t\t\t<span class=\"token keyword\">print</span> VIRUS <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># virus keep2</span>\n\t\t\t<span class=\"token keyword\">print</span> VIRUS <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">16</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># manual check</span>\n\t\t\t<span class=\"token keyword\">print</span> MANUAL <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token comment\"># discard</span>\n\t\t\t<span class=\"token keyword\">print</span> DISCARD <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose VIRUS<span class=\"token punctuation\">;</span>\nclose MANUAL<span class=\"token punctuation\">;</span>\nclose DISCARD<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>用法：脚本与 <code>forCheck.txt</code>  放在同一目录，终端运行如下命令。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_virus.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>对于 <code>Manual_check.txt</code>  中的序列，需要用眼睛和脑袋去 <code>dramv-annotate/annotations.tsv</code>  中找注释信息，然后根据下面的方法判断其属于病毒还是细胞，如果是病毒，就将其所在的那行信息复制到 <code>Virus.txt</code>  文件的末尾，并保存。</p>\n<h2 id=\"依据dramv注释筛选\"><a class=\"markdownIt-Anchor\" href=\"#依据dramv注释筛选\"></a> 依据 DRAMv 注释筛选</h2>\n<p>在病毒和宿主中都有一些共同的基因 (如<ruby>脂多糖<rp> (</rp><rt>LPS</rt><rp>)</rp></ruby> 相关) 和移动元件，这些基因可能导致上述 “Keep2” 类别中的假阳性。因此，<ins class=\"dot\">要谨慎对待带有这些基因的 contigs</ins>。专家们已经编制了一份与此相关的<span class=\"red\"> “可疑”</span> 基因列表。我们可以使用 “Keep2” 类别中的 contigs 对 DRAMv 表取子集，并在 DRAMv 子集表中筛选 “可疑” 基因 (忽略大小写，例如在 “grep” 中使用 “-i” 选项)，然后将带有这些基因的 contigs 放入 “手动检查” 类别中。</p>\n<h2 class=\"tabset\" id=\"手动检查\"><a class=\"markdownIt-Anchor\" href=\"#手动检查\"></a> 手动检查</h2>\n<p>对于存在于<ruby>“手动检查”<rt>manual check</rt></ruby>类别中的序列，可以观察其在 &quot;dramv-annotate/annotations.tsv&quot; 中的注释信息。本步骤很难标准化，下面是一些经验之谈：</p>\n<div class=\"tabs\" id=\"tab-id\"><ul class=\"nav-tabs\"><li class=\"tab active\"><a class=\"#tab-id-1\">判定contig为病毒的标准</a></li><li class=\"tab\"><a class=\"#tab-id-2\">判定contig为非病毒的标准</a></li></ul><div class=\"tab-content\"><div class=\"tab-pane active\" id=\"tab-id-1\"><div class=\"tab\" data-id=\"id1\" data-title=\"判定contig为病毒的标准\">\n<ul>\n<li>结构基因、hallmark 基因、<ruby>注释缺失或假设性富集<rt>depletion in annotations or enrichment for hypotheticals</rt> (~10% 的基因具有 non-hypothetical 注释)。</li>\n<li>缺乏 hallmarks，但 &gt;=50% 已注释的基因为病毒，且其中至少一半以上的 viral bitcore &gt;100，且 contig 的长度 &lt; 50kb。</li>\n<li>Provirus: <ruby>整合酶 / 重组酶 / 切除酶 / 阻遏子<rt>Integrase/recombinase/excisionase/repressor</rt></ruby>，在一侧富集了病毒基因。</li>\n<li>Provirus: 基因组中存在 “break”：两个基因之间的<ruby>间隙<rt>gap</rt></ruby>对应于一个<ruby>链开关<rt>strand switch</rt></ruby>，更高的编码密度，注释缺失，以及在一侧噬菌体基因的富集。</li>\n<li><ruby>仅有～1-3 个基因有注释，但至少一半命中病毒，且命中基因的 bitscore 不超过病毒 bitscore 的 150% ，<rt>Few annotations only ~1-3 genes, but with at least half hitting to viruses, and where the genes hitting cells have a bitscore no more than 150% that of the viral bitscores</rt></ruby> <ruby>且 / 或病毒的 bitscore &gt;100 <rt> and/or viral bitscores are &gt;100</rt></ruby>。</li>\n<li>LPS (脂多糖) <ruby>外观区域对病毒基因的命中率也非常高<rt>looking regions if also has very strong hits to viral genes</rt></ruby>，bitscore&gt;100。</li>\n</ul>\n</div></div><div class=\"tab-pane\" id=\"tab-id-2\"><div class=\"tab\" data-id=\"id1\" data-title=\"判定contig为非病毒的标准\">\n<ul>\n<li><ruby>细胞样基因<rt>cellular like genes</rt></ruby>是病毒基因的 3 倍，几乎所有基因都有注释，没有基因只命中病毒，也没有病毒<ruby>标志基因<rt>hallmark genes</rt></ruby>。</li>\n<li>缺乏任何病毒 hallmark genes，且长度 &gt;50kb。</li>\n<li>许多明显的细胞基因字符串，没有其他病毒标志基因。 在基准测试中遇到的例子包括 1) CRISPR Cas, 2) ABC transporters, 3) Sporulation proteins, 4) Two-component systems, 5) Secretion system。这其中一些可能是由病毒编码的，但在没有进一步证据的情况下并不表明是病毒 contig。</li>\n<li>多个质粒基因或转座酶，但没有明确的只命中病毒的基因。</li>\n<li>注释信息很少，仅有～1-3 个基因同时命中了病毒和细胞基因，但有 stronger bitscores 支持其为细胞基因。</li>\n<li><ruby>没有强有力的命中病毒的脂多糖样区域<rt>LPS looking regions if no strong viral hits</rt></ruby>。富含通常与脂多糖相关的基因，如<ruby>外聚酶<rp> (</rp><rt>epimerases</rt><rp>)</rp></ruby>、<ruby>糖<rp> (</rp><rt>glycosyl</rt><rp>)</rp> 基转移酶<rp> (</rp><rt>transferases</rt><rp>)</rp></ruby>、<ruby>酰基转移酶<rp> (</rp><rt>acyltransferase</rt><rp>)</rp></ruby>、<ruby>短<rp> (</rp><rt>dehydrogenase</rt><rp>)</rp> 链<rp> (</rp><rt>reductase</rt><rp>)</rp> 脱氢酶<rp> (</rp><rt>short-ch</rt><rp>)</rp>/<rt></rt> 还原酶<rp> (</rp><rt>ain</rt><rp>)</rp></ruby>、<ruby>脱水酶<rp> (</rp><rt>dehydratase</rt><rp>)</rp></ruby>。</li>\n<li>注释为 Type IV 和 / 或 Type VI 分析系统，并被非病毒基因围绕。</li>\n<li>注释信息很少，仅有～1-3 个基因全部命中细胞基因 (即使 bitscore &lt;100) ，且没有命中病毒的基因。</li>\n</ul>\n</div></div></div></div>\n<div class=\"note warning\">\n<p>最后，用户要注意，VirSorter 2 和 / 或 checkV 预测的任何原病毒边界只是一个近似的估计 (寻找 “ends” 在前噬菌体发现中是一个相当具有挑战性的问题)，也需要仔细地手工检查，特别是在 AMG 研究中。</p>\n</div>\n<p>最终我们需要拿到病毒 contig 的序列，用 <code>get_virus_seqs.pl</code>  完成。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token shebang important\">#!/usr/bin/perl</span>\nuse strict<span class=\"token punctuation\">;</span>\nuse warnings<span class=\"token punctuation\">;</span>\n\nmy %hash<span class=\"token punctuation\">;</span>\n<span class=\"token function\">open</span> IN, <span class=\"token string\">\"checkv/combined.fna\"</span> <span class=\"token operator\">||</span> die<span class=\"token punctuation\">;</span>\n<span class=\"token builtin class-name\">local</span> $/ <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">&lt;</span>IN<span class=\"token operator\">></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&lt;</span>IN<span class=\"token operator\">></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\tmy <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span>, <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">(</span>/<span class=\"token punctuation\">\\</span>n/, <span class=\"token variable\">$_</span>, <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tmy <span class=\"token variable\">$id</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span> <span class=\"token operator\">=~</span>/<span class=\"token punctuation\">(</span><span class=\"token punctuation\">\\</span>S+<span class=\"token punctuation\">)</span><span class=\"token punctuation\">\\</span><span class=\"token operator\">|</span><span class=\"token punctuation\">\\</span><span class=\"token operator\">|</span>.+/<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>else <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$header</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\n<span class=\"token builtin class-name\">local</span> $/ <span class=\"token operator\">=</span> <span class=\"token string\">\"<span class=\"token entity\" title=\"\\n\">\\n</span>\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">open</span> IN, <span class=\"token string\">\"Virus.txt\"</span> <span class=\"token operator\">||</span> die<span class=\"token punctuation\">;</span>\n<span class=\"token function\">open</span> OUT, <span class=\"token string\">\">Virus.fas\"</span> <span class=\"token operator\">||</span> die<span class=\"token punctuation\">;</span>\n<span class=\"token function\">open</span> NO, <span class=\"token string\">\">NoSeqs.ids\"</span> <span class=\"token operator\">||</span> die<span class=\"token punctuation\">;</span>\n<span class=\"token operator\">&lt;</span>IN<span class=\"token operator\">></span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&lt;</span>IN<span class=\"token operator\">></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\tmy @lines <span class=\"token operator\">=</span> <span class=\"token function\">split</span> /<span class=\"token punctuation\">\\</span>t/<span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=~</span>/<span class=\"token punctuation\">(</span><span class=\"token punctuation\">\\</span>S+<span class=\"token punctuation\">)</span><span class=\"token punctuation\">\\</span><span class=\"token operator\">|</span><span class=\"token punctuation\">\\</span><span class=\"token operator\">|</span>/<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tprint OUT <span class=\"token string\">\"><span class=\"token variable\">$lines</span>[0]<span class=\"token entity\" title=\"\\n\">\\n</span><span class=\"token variable\">$hash</span>&#123;<span class=\"token variable\">$1</span>&#125;<span class=\"token entity\" title=\"\\n\">\\n</span>\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>else <span class=\"token punctuation\">&#123;</span>\n\t\tprint NO <span class=\"token string\">\"<span class=\"token variable\">$lines</span>[0]<span class=\"token entity\" title=\"\\n\">\\n</span>\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose OUT<span class=\"token punctuation\">;</span>\nclose NO<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>用法：终端运行如下命令即可得到序列文件 <code>Virus.fas</code> 。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\">perl get_virus_seqs<span class=\"token operator\">.</span>pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “1551” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://github.com/jiarong/VirSorter2\">VirSorter2</a></li>\n<li><a href=\"https://www.protocols.io/view/viral-sequence-identification-sop-with-virsorter2-bwm5pc86\">Viral sequence identification SOP with VirSorter2 V.3</a></li>\n</ul>\n<div class=\"mermaid\">graph TD\n\tA [Reads] --&gt; B((MetaSpaDES))\n\tB --&gt; C [Contigs]\n\tC --&gt; D ((VirSorter))\n\tC --&gt; E ((VirFinder))\n\tE --&gt; F {Score &gt;&#x3D; 0.7 &amp; p &lt; 0.05}\n\tF -- YES --&gt; G [Virus]\n\tF -- NO --&gt; H [Contigs]\n\tD --&gt; G\n\tH --&gt; I ((CAT))\n\tI --&gt; J {&lt; 40%}\n\tJ -- YES --&gt; G\n\tJ -- NO --&gt; K [Not Virus]\n\tG --&gt; L ((Nucmer))\n\tL --&gt; M {Identity &gt;&#x3D; 95% &amp; Coverage &gt;&#x3D; 80%}\n\tM -- YES --&gt; N [Grouped]\n\tM -- NO --&gt; O [Not Grouped]\n\tG --&gt; P ((Prodigal))\n\tP --&gt; Q [Amino Acid Sequences]\n\tQ --&gt; R {Length &lt; 10 kb}\n\tR -- YES --&gt; S ((Blastp))\n\tR -- NO --&gt; T ((vConTACT2))\n\tS --&gt; U [Annotated Genes]\n\tT --&gt; U</div>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"ST179","path":"api/tags/ST179.json"},{"name":"宏病毒组","path":"api/tags/宏病毒组.json"}]},{"title":"BtToxin_Digger--A high-throughput Bacillus thuringiensis toxin mining pipeline","slug":"BtToxin_Digger","date":"2020-11-04T07:38:43.000Z","updated":"2022-01-08T02:16:28.395Z","comments":true,"path":"api/articles/BtToxin_Digger.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>BtToxin_Digger is the latest high-throughput Bacillus thuringiensis virulence factor mining pipeline on the whole network, including the basic web version and the local advanced version.</p>\n<span id=\"more\"></span>\n<h2 id=\"what-is-bttoxin_digger\"><a class=\"markdownIt-Anchor\" href=\"#what-is-bttoxin_digger\"></a> What is BtToxin_Digger?</h2>\n<p>BtToxin_Digger is a high-throughput, automatic gene mining tool that can mine toxin genes, such as Cry, Cyt and Vip, etc, from <em>Bacillus thuringiensis</em>. The pipeline accepts multiple forms of input data including Reads, assembled genomes, CDSs, and protein sequences and can output rich and useful results. It is derived from the re-design of the tool <a href=\"https://bcam.hzau.edu.cn/BtToxin_Digger/\">BtToxin_Digger</a> we developed previously. Compared with BtToxin_Digger, BtToxin_Digger has many improvements, as follows:</p>\n<ul>\n<li>\n<p>Can be run in batches, suitable for large-scale genome analysis.</p>\n</li>\n<li>\n<p>Added genome assembly functions, including second-generation short-reads assembly, third-generation long-reads assembly, and hybrid assembly of short-reads and long-reads, to realize the full-automatic mining of genes from Reads to virulence factors. The previous three input files (assembled genomes, ORFs and protein sequences) are still supported, and genome assembly can be used independently.</p>\n</li>\n<li>\n<p>Fixed a bug where BtToxin_Digger often reported errors when processing assembled genomes.</p>\n</li>\n<li>\n<p>Added support for CDSs and not limited to ORFs.</p>\n</li>\n<li>\n<p>The database has been updated, adding support for App, Gpp, Mcf, Mpf, Mpp, Mtx, Pra, Prb, Spp, Tpp, Cyt, Vip, Vpa, Vpb, Xpp and other virulence factors.</p>\n</li>\n<li>\n<p>BtToxin_Digger generates comprehensive and readable outputs including toxin list and sequence for each input; a matrix of all strains and the virulence factors it contains (behavior strain names, listed as virulence factor names), which can be used as virulence factors contained in the strain Database; and a file writes the information and sequences of all toxins (Table 1) to facilitate centralized processing and downstream analysis and experiment designs.</p>\n</li>\n<li>\n<p>Added multi-thread support, greatly improving the running speed of the pipeline.</p>\n</li>\n</ul>\n<h2 id=\"installation\"><a class=\"markdownIt-Anchor\" href=\"#installation\"></a> Installation</h2>\n<ul>\n<li>\n<p>Required dependencies<br />\n-- <a href=\"http://metacpan.org/pod/BioPerl\">BioPerl</a><br />\n-- <a href=\"https://www.ebi.ac.uk/Tools/hmmer/\">HMMER</a><br />\n-- <a href=\"https://github.com/cjlin1/libsvm\">libsvm</a><br />\n-- <a href=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download\">NCBI-blast+</a><br />\n-- <a href=\"http://www.perl.org/get.html\">Perl</a><br />\n-- <a href=\"https://liaochenlanruo.hzaubmb.org/pgcgap\">PGCGAP</a></p>\n</li>\n<li>\n<p>Source codes</p>\n</li>\n</ul>\n<p>The BtToxin_Digger codes can be downloaded from <a href=\"https://github.com/liaochenlanruo/BtToxin_Digger\">GitHub</a>.</p>\n<ul>\n<li>Install with Bioconda - OSX/Linux/WSL</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda create -n toxin <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3</span>\nconda activate toxin\nconda <span class=\"token function\">install</span> bttoxin_digger<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>Install with the docker container</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">docker pull quay.io/biocontainers/bttoxin_digger:<span class=\"token operator\">&lt;</span>tag<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>(See <a href=\"https://quay.io/repository/biocontainers/bttoxin_digger?tab=tags\">bttoxin_digger/tags</a> for valid values for <tag>)</p>\n<h2 id=\"usage\"><a class=\"markdownIt-Anchor\" href=\"#usage\"></a> Usage</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger <span class=\"token punctuation\">[</span>Options<span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Options:</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">[--help]                      Print the help message and exit\n[--version]                   Show version number of BtToxin_Digger and exit\n[--threads (INT)]             Number of threads to be used ( Default 4 )\n[--SeqPath (PATH)]            [Required] The path of input sequences ( Default &quot;the current directory&quot; )\n[--SequenceType (STRING)]     [Required] Sequence type for inputs. &quot;reads&quot;, &quot;nucl&quot;, &quot;orfs&quot;, and &quot;prot&quot; avaliable ( Default nucl )\n[--platform (STRING)]         [Required] Sequencing Platform, &quot;illumina&quot;, &quot;pacbio&quot;, &quot;oxford&quot; and &quot;hybrid&quot; available ( Default illumina )\n[--assemble_only (STRING)]    Only perform genome assembly without predicting toxins.\n[--reads1 (STRING)]           [Required by &quot;reads&quot;] The suffix name of reads 1 ( for example: if the name of reads 1 is &quot;YBT-1520_L1_I050.R1.clean.fastq.gz&quot;, &quot;YBT-1520&quot; is the strain same, so the suffix name should be &quot;.R1.clean.fastq.gz&quot; )\n[--reads2 (STRING)]           [Required by &quot;reads&quot;] The suffix name of reads 2( not required by &quot;oxford&quot; and &quot;pacbio&quot;. For example: if the name of reads 2 is &quot;YBT-1520_2.fq&quot;, the suffix name should be _2.fq&quot; )\n[--suffix_len (INT)]          [Required by &quot;reads&quot;] (Strongly recommended) The suffix length of the reads file, that is the length of the reads name minus the length of the strain name. For example the --suffix_len of &quot;YBT-1520_L1_I050.R1.clean.fastq.gz&quot; is 26 ( &quot;YBT-1520&quot; is the strain name ) ( Default 0 )\n[--short1 (STRING)]           [Required] FASTQ file of first short reads in each pair. Needed by hybrid assembly ( Default Unset )\n[--short2 (STRING)]           [Required] FASTQ file of second short reads in each pair. Needed by hybrid assembly ( Default Unset )\n[--long (STRING)]             [Required] FASTQ or FASTA file of long reads. Needed by hybrid assembly ( Default Unset )\n[--hout (STRING)]             [Required] Output directory for hybrid assembly ( Default &quot;..&#x2F;..&#x2F;Results&#x2F;Assembles&#x2F;Hybrid&quot; )\n[--genomeSize (STRING)]       [Required] An estimate of the size of the genome. Common suffixes are allowed, for example, 3.7m or 2.8g. Needed by PacBio data and Oxford data ( Default 6.07m )\n[--Scaf_suffix (STRING)]      The suffix of scaffolds or genomes ( Default &quot;.filtered.fas&quot; )\n[--orfs_suffix (STRING)]      The suffix of orfs files ( Default &quot;.ffn&quot; )\n[--prot_suffix (STRING)]      The suffix of protein files ( Default &quot;.faa&quot; )<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"examples\"><a class=\"markdownIt-Anchor\" href=\"#examples\"></a> Examples</h2>\n<ul>\n<li>Processing Illumina paired-end Reads</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>Illumina Reads <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType reads --platform illumina --reads1 <span class=\"token operator\">&lt;</span>suffix name of reads <span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>></span> -reads2 <span class=\"token operator\">&lt;</span>suffix name of reads <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span> --suffix_len <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing PacBio long Reads</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>PacBio Reads <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType reads --platform pacbio --reads1 <span class=\"token operator\">&lt;</span>suffix name of PacBio reads<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span> --suffix_len <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing Oxford long Reads</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>Oxford Reads <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType reads --platform oxford --reads1 <span class=\"token operator\">&lt;</span>suffix name of Oxford reads<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span> --suffix_len <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing Hybrid Reads (Long reads + illumina short reads)</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>Reads <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType reads --platform hybrid --short1 <span class=\"token operator\">&lt;</span>short reads <span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>></span> --short2 <span class=\"token operator\">&lt;</span>short reads <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span> --long <span class=\"token operator\">&lt;</span>long reads<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing Assembled genomes</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>Assembled genome <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType nucl --Scaf_suffix <span class=\"token operator\">&lt;</span>suffix of genomes<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing Protein sequences</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>Protein <span class=\"token function\">file</span> <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType prot --prot_suffix <span class=\"token operator\">&lt;</span>suffix of protein files<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>Processing Coding sequences</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">BtToxin_Digger --SeqPath <span class=\"token operator\">&lt;</span>CDSs <span class=\"token function\">file</span> <span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --SequenceType orfs --orfs_suffix <span class=\"token operator\">&lt;</span>suffix of orfs files<span class=\"token operator\">></span> --threads <span class=\"token operator\">&lt;</span>INT<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"outputs\"><a class=\"markdownIt-Anchor\" href=\"#outputs\"></a> Outputs</h2>\n<ul>\n<li>\n<p><strong>Results/Assembles/*</strong>: Genome assembly results;</p>\n</li>\n<li>\n<p><strong>Results/Toxins/*.list</strong>: Toxin list of each strain;</p>\n</li>\n<li>\n<p><strong>Results/Toxins/*.gbk</strong>: Toxin sequences in Genbank format of each strain;</p>\n</li>\n<li>\n<p><strong>Results/Toxins/Btallgenes.table</strong>: A matrix describes Strains vs. Toxins;</p>\n</li>\n<li>\n<p><strong>Results/Toxins/All_Toxins.txt</strong>: A table containing all information and sequences of all toxin genes. See table 1 for details.</p>\n</li>\n</ul>\n<h2 id=\"contents-of-list\"><a class=\"markdownIt-Anchor\" href=\"#contents-of-list\"></a> Contents of *.list:</h2>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">Overview of prediction \t Sequence type: nucl\nName\tCry\tCyt\tVip\tOthers\tSummary\nRank1\t1\t0\t0\t0\t1\nRank2\t0\t0\t0\t0\t0\nRank3\t0\t0\t0\t0\t0\nRank4\t10\t0\t1\t1\t12\nHMM_SVM\t0\t0\t0\t0\nSummary\t11\t0\t1\t1\t13\n&#x2F;&#x2F;\n\n\nToxin type: Cry protein\nID\tProtein_ID\t\tProtein_description\tLength\tRank\tBLAST\tBest_hit\tHit length\tCoverage\tIdentity\tSVM\tHMM\n1\tNHPK02000085.1_00018\t+2 19034-20206 len&#x3D;391\t391\tRank1\tYES\tCry78Aa1\t359\t\t97.21\t\t32.66\t\tNO\tNO\n2\tNHPK02000099.1_00001\t-1 5374-7407 len&#x3D;678\t678\tRank4\tYES\tCry2Ab35\t633\t\t100.00\t\t100.00\t\tNO\tYES\n3\tNHPK02000115.1_00002\t+2 2-1342 len&#x3D;447\t447\tRank4\tYES\tCry1Da2\t\t1165\t\t38.37\t\t100.00\t\tNO\tYES\n4\tNHPK02000115.1_00006\t+3 4275-7898 len&#x3D;1208\t1208\tRank4\tYES\tCry1Ca15\t1189\t\t100.00\t\t100.00\t\tNO\tYES\n5\tNHPK02000153.1_00001\t-1 4176-6365 len&#x3D;730\t730\tRank4\tYES\tCry1Ia40\t719\t\t100.00\t\t100.00\t\tYES\tYES\n6\tNHPK02000168.1_00002\t-3 1673-5146 len&#x3D;1158\t1158\tRank4\tYES\tCry9Ea9\t\t1150\t\t100.00\t\t100.00\t\tYES\tYES\n7\tNHPK02000196.1_00001\t+3 723-2942 len&#x3D;740\t740\tRank4\tYES\tCry1Da2\t\t1165\t\t63.43\t\t100.00\t\tNO\tYES\n8\tNHPK02000240.1_00001\t+2 2-1813 len&#x3D;604\t604\tRank4\tYES\tCry1Ac16\t1178\t\t51.27\t\t100.00\t\tNO\tYES\n9\tNHPK02000243.1_00001\t+2 2-1738 len&#x3D;579\t579\tRank4\tYES\tCry1Aa18\t1225\t\t47.27\t\t100.00\t\tNO\tYES\n10\tNHPK02000256.1_00001\t+2 2-1294 len&#x3D;431\t431\tRank4\tYES\tCry1Ac30\t1178\t\t36.59\t\t100.00\t\tNO\tYES\n11\tNHPK02000386.1_00001\t-2 3-530 len&#x3D;176\t176\tRank4\tYES\tCry1Ab11\t695\t\t25.32\t\t99.43\t\tNO\tYES\n&#x2F;&#x2F;\n\n\nToxin type: Cyt protein\nID\tProtein_ID\tProtein_description\tLength\tRank\tBLAST\tBest_hit\tHit length\tCoverage\tIdentity\tSVM\tHMM\n&#x2F;&#x2F;\n\n\nToxin type: Vip protein\nID\tProtein_ID\t\tProtein_description\tLength\tRank\tBLAST\tBest_hit\tHit length\tCoverage\tIdentity\tSVM\tHMM\n1\tNHPK02000099.1_00004\t-3 10013-12397 len&#x3D;795\t795\tRank4\tYES\tVip3Aa12\t789\t\t100.00\t\t100.00\t\tNO\tYES\n&#x2F;&#x2F;\n\n\nToxin type: Other toxins\nID\tProtein_ID\t\tProtein_description\tLength\tRank\tBLAST\tBest_hit\tHit length\tCoverage\tIdentity\tSVM\tHMM\n1\tNHPK02000017.1_00027\t-3 15272-16258 len&#x3D;329\t329\tRank4\tYES\tZwa5B-other\t322\t\t100.00\t\t99.07\t\tNO\tNA\n&#x2F;&#x2F;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"contents-of-gbk-partial\"><a class=\"markdownIt-Anchor\" href=\"#contents-of-gbk-partial\"></a> Contents of *.gbk (Partial):</h2>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">LOCUS       NHPK02000017.1_00027        77664 bp    dna     linear   UNK\nACCESSION   NHPK02000017.1_00027\nFEATURES             Location&#x2F;Qualifiers\n     Segment         complement(15272..16258)\n                     &#x2F;ETX_MTX2&#x3D;&quot;NO&quot;\n                     &#x2F;Endotoxin_C&#x3D;&quot;NO&quot;\n                     &#x2F;Endotoxin_M&#x3D;&quot;NO&quot;\n                     &#x2F;Endotoxin_N&#x3D;&quot;NO&quot;\n                     &#x2F;Endotoxin_mid&#x3D;&quot;NO&quot;\n                     &#x2F;Rank&#x3D;&quot;Rank4&quot;\n                     &#x2F;Segment_name&#x3D;&quot;NHPK02000017.1_00027&quot;\n                     &#x2F;Toxin_10&#x3D;&quot;NO&quot;\n                     &#x2F;blast_detail&#x3D;&quot;Query_desc:-3 15272-16258 len&#x3D;329\n                     Query_Length:329\tQuery_Start-End:8-329\tHit_id:Zwa5B-other\n                     Hit_desc:AAZ67352.1\tHit_length:322\tHit_Start-End:1-322\n                     Aln_length:322\tPercent_identity:99.0683229813665\n                     E-value:0.0&quot;\n                     &#x2F;blast_prediction&#x3D;&quot;YES&quot;\n                     &#x2F;hmm_detail&#x3D;&quot;&quot;\n                     &#x2F;hmm_prediction&#x3D;&quot;NA&quot;\n                     &#x2F;locus_tag&#x3D;&quot;NHPK02000017.1_00027&quot;\n                     &#x2F;protein_desc&#x3D;&quot;-3 15272-16258 len&#x3D;329&quot;\n                     &#x2F;protein_id&#x3D;&quot;NHPK02000017.1_00027&quot;\n                     &#x2F;protein_len&#x3D;&quot;329&quot;\n                     &#x2F;svm_prediction&#x3D;&quot;NO&quot;\n                     &#x2F;translation&#x3D;&quot;YRNEEAIMMYLNTKHINEMGVNWEETINVISKAVQSLDAEDFSQ\n                     PIKPYLRFDDPANRIIAMPAYIGGEFKVSGIKWIASFPKNIEKGIQRAHSVTILNDAM\n                     TGKPFATLNTAMVSVIRTASVTGLMIREFAKLRDLNNVKVGIIGFGPIGQMHLKMVTA\n                     LLGDKIESVYLYDINGIKDELIPEDIYSKTQKVNAYEEAYNDADIFITCTVSAEGYID\n                     KKPKDGALLLNVSLRDFKPDILEYTKSLVVDNWEEVCREKTDVERMHLERGLQKEDTV\n                     SIADVVIRGALQNFPYDKAILFNPMGMAIFDVAIAAYYYQRAREKEIGVLLED&quot;\nORIGIN      \n        1 cttctaaccg caaggactgc ggggttagcc taatcaatta gagttcgata gaactcttta\n       61 cttaggaatc cctcacttct aaacgaagtg aaagtggggt tagttcaaaa ctattaacta\n      121 taatataccc tttcaagaaa ttttaaaaag gttgaagtag ccaaaaaata ttttccggaa\n      181 taattagatt aatttctctt ttttgtatat ttatgttaaa ttattgttat cactacaaat\n      241 ttattgaata attttaatac tctccccttt atactatggt aatatgtttt tcacaataca\n      301 tattaccact ataattgcaa acatatataa acccatattt agaattttta agattctttc\n      361 atagcattaa gatatttttt accttttagt ttgtttattc ttaattttta aactaaaata\n      421 atatatattg gtaataatta aataaaattc caataattat aggaaggaga aaattatgaa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"table-1-description-of-all_toxinstxt\"><a class=\"markdownIt-Anchor\" href=\"#table-1-description-of-all_toxinstxt\"></a> Table 1. Description of &quot;All_Toxins.txt&quot;</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Header</th>\n<th style=\"text-align:left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Strain</td>\n<td style=\"text-align:left\">The name of your input</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Protein_id</td>\n<td style=\"text-align:left\">The protein ID</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Protein_len</td>\n<td style=\"text-align:left\">The length of protein sequence</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Strand</td>\n<td style=\"text-align:left\">Positive or negative strand where the gene comes from</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Gene location on scaffold</td>\n<td style=\"text-align:left\">Gene coordinates on the genome</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">SVM</td>\n<td style=\"text-align:left\">Is the protein predicted by SVM</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">BLAST</td>\n<td style=\"text-align:left\">Is the protein predicted by BLAST</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">HMM</td>\n<td style=\"text-align:left\">Is the protein predicted by HMM</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Hit_id</td>\n<td style=\"text-align:left\">The subject sequence ID</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Hit_length</td>\n<td style=\"text-align:left\">The length of subject sequence</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Aln_length</td>\n<td style=\"text-align:left\">alignment length (sequence overlap)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Query start-end</td>\n<td style=\"text-align:left\">Start and end of alignment in query</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Hit stard-end</td>\n<td style=\"text-align:left\">Start and end of alignment in subject</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Identity</td>\n<td style=\"text-align:left\">Percentage of identical matches</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Evalue of blast</td>\n<td style=\"text-align:left\">Expect value of BLAST</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Hmm hit</td>\n<td style=\"text-align:left\">The subject model ID</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Hmm hit length</td>\n<td style=\"text-align:left\">The length of subject model sequence</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Evalue of Hmm</td>\n<td style=\"text-align:left\">Expect value of HMM</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Nomenclature</td>\n<td style=\"text-align:left\"><a href=\"http://www.lifesci.sussex.ac.uk/home/Neil_Crickmore/Bt\">Bt nomenclature</a> containing 4 Ranks</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Endotoxin_N</td>\n<td style=\"text-align:left\">Whether the Cry protein contain Endotoxin_N domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Endotoxin_M</td>\n<td style=\"text-align:left\">Whether the Cry protein contain Endotoxin_M domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Endotoxin_C</td>\n<td style=\"text-align:left\">Whether the Cry protein contain Endotoxin_C domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Endotoxin_mid</td>\n<td style=\"text-align:left\">Whether the Cry protein contain Endotoxin_mid domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Toxin_10</td>\n<td style=\"text-align:left\">Whether the Cry protein contain Toxin_10 domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ETX_MTX2</td>\n<td style=\"text-align:left\">Whether the Cry protein contain ETX_MTX2 domain</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Gene sequence</td>\n<td style=\"text-align:left\">The nucleotide sequence of the toxin</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Protein sequence</td>\n<td style=\"text-align:left\">Amino acid sequence of the toxin</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Scaffold sequence</td>\n<td style=\"text-align:left\">The scaffold sequence where the toxin gene is located</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"table-2-the-contents-of-all_toxinstxt-partial\"><a class=\"markdownIt-Anchor\" href=\"#table-2-the-contents-of-all_toxinstxt-partial\"></a> Table 2. The contents of &quot;All_Toxins.txt&quot; (Partial)</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Strain</th>\n<th style=\"text-align:center\">Protein_id</th>\n<th style=\"text-align:center\">Protein_len</th>\n<th style=\"text-align:center\">Strand</th>\n<th style=\"text-align:center\">Gene location on scaffold</th>\n<th style=\"text-align:center\">SVM</th>\n<th style=\"text-align:center\">BLAST</th>\n<th style=\"text-align:center\">HMM</th>\n<th style=\"text-align:center\">Hit_id</th>\n<th style=\"text-align:center\">Hit_length</th>\n<th style=\"text-align:center\">Aln_length</th>\n<th style=\"text-align:center\">Query start-end</th>\n<th style=\"text-align:center\">Hit stard-end</th>\n<th style=\"text-align:center\">Identity</th>\n<th style=\"text-align:center\">Evalue of blast</th>\n<th style=\"text-align:center\">Hmm hit</th>\n<th style=\"text-align:center\">Hmm hit length</th>\n<th style=\"text-align:center\">Evalue of Hmm</th>\n<th style=\"text-align:center\">Nomenclature</th>\n<th style=\"text-align:center\">Endotoxin_N</th>\n<th style=\"text-align:center\">Endotoxin_M</th>\n<th style=\"text-align:center\">Endotoxin_C</th>\n<th style=\"text-align:center\">Endotoxin_mid</th>\n<th style=\"text-align:center\">Toxin_10</th>\n<th style=\"text-align:center\">ETX_MTX2</th>\n<th style=\"text-align:center\">Gene sequence</th>\n<th style=\"text-align:center\">Protein sequence</th>\n<th style=\"text-align:center\">Scaffold sequence</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1126_1</td>\n<td style=\"text-align:center\">NHPK02000017.1_00027</td>\n<td style=\"text-align:center\">329</td>\n<td style=\"text-align:center\">-3</td>\n<td style=\"text-align:center\">10001-10987</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">YES</td>\n<td style=\"text-align:center\">NA</td>\n<td style=\"text-align:center\">Zwa5B-other</td>\n<td style=\"text-align:center\">322</td>\n<td style=\"text-align:center\">322</td>\n<td style=\"text-align:center\">8-329</td>\n<td style=\"text-align:center\">1-322</td>\n<td style=\"text-align:center\">99.0683229813665</td>\n<td style=\"text-align:center\">0.0</td>\n<td style=\"text-align:center\">NA</td>\n<td style=\"text-align:center\">NA</td>\n<td style=\"text-align:center\">NA</td>\n<td style=\"text-align:center\">Rank4</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">NO</td>\n<td style=\"text-align:center\">GTCTTCTAATAAAACACCTATTTCCTTTTCCCTAGCCCTTTGATAGTAATAAGCAGCAATGGCTACATCAAAAATGGCCATACCCATTGGATTAAATAATATTGCTTTGTCATAAGGGAAGTTTTGCAGTGCTCCTCGGATTACAACGTCAGCAATTGATACTGTATCTTCTTTTTGTAAACCTCTTTCAAGGTGCATCCTTTCAACATCAGTTTTTTCACGACAGACTTCTTCCCAATTATCAACAACTAGGGATTTTGTATATTCTAAGATATCAGGCTTAAAATCACGAAGAGAAACATTGAGTAGTAGCGCTCCATCTTTAGGTTTCTTATCAATATAACCTTCTGCAGAAACAGTACAAGTAATAAAAATATCAGCATCATTATAGGCTTCTTCATAAGCATTAACCTTTTGAGTTTTAGAATAAATATCCTCAGGAATTAATTCGTCTTTAATTCCATTGATATCATATAGGTAAACACTTTCGATTTTATCGCCTAATAGGGCAGTTACCATCTTTAAATGCATCTGACCAATAGGTCCAAATCCAATAATTCCAACTTTAACATTATTTAAATCTCTTAACTTGGCAAACTCTCGAATCATTAACCCTGTTACAGAAGCTGTTCGTATTACACTGACCATTGCTGTATTAAGCGTCGCAAATGGTTTTCCAGTCATAGCATCATTTAATATAGTAACTGAATGAGCACGTTGAATACCTTTCTCAATATTCTTCGGAAAACTAGCTATCCATTTGATTCCTGAAACCTTAAATTCTCCTCCAATATAAGCTGGCATAGCAATAATTCTATTAGCCGGATCATCAAAACGTAAGTATGGCTTAATTGGCTGAGAAAAATCTTCTGCATCAAGACTTTGTACTGCCTTTGAAATGACATTTATTGTTTCTTCCCAATTAACACCCATTTCATTGATATGTTTAGTATTTAAATACATCATAATTGCTTCCTCATTTCTATA</td>\n<td style=\"text-align:center\">YRNEEAIMMYLNTKHINEMGVNWEETINVISKAVQSLDAEDFSQPIKPYLRFDDPANRIIAMPAYIGGEFKVSGIKWIASFPKNIEKGIQRAHSVTILNDAMTGKPFATLNTAMVSVIRTASVTGLMIREFAKLRDLNNVKVGIIGFGPIGQMHLKMVTALLGDKIESVYLYDINGIKDELIPEDIYSKTQKVNAYEEAYNDADIFITCTVSAEGYIDKKPKDGALLLNVSLRDFKPDILEYTKSLVVDNWEEVCREKTDVERMHLERGLQKEDTVSIADVVIRGALQNFPYDKAILFNPMGMAIFDVAIAAYYYQRAREKEIGVLLED</td>\n<td style=\"text-align:center\">TCTCAATACGAACCAGTAAAAATGGTTCAGGGCGTTGAAGATACTGGACGTAATTCTTTTAGCCAAGCTAGTTTTTCAAACGTACTTCTAAGAACAGATACATCTGGAGCTACCTACAAAAGTTGGAACGGTTCAATTTCTTCCTCATTTTCTAAACACGGTACTTATGGTAACAGTTTCACAGTTTATTCTCAAGTGCCATTAAGCGCAAGTTTACGCTAAAATTGTTCTTGTATACGAATAATTTTGTGAAAAAGGTAGCTGTACTTTTGTACAGCTACCTTTTTCATATGGTGAATTTTTAATAGATATTGTATCAGACATAAGTTACATTCTTCATATTTTAACTTCTTTGAATTCAATAATACTTAATCAGCTTGTCTTATTACTTCACTTAACGTATCGAGATACAGCTTATAGCAACTACAACACGCTTTATTATTAATAATACCACTCTTCTTAATTTAACTTTAATTCCATTGCATTGATTTTTTAATAATAAATATACAACTTAGTAATGATAATAGATATACAATAAGAATAATATACAACTGTTTTGGTTCAATGCTATCGATATAAAGACTCATAATTGGATATGACCAAGGAAACAGTATCCAATAGTTTGTATGCGAGATAAAAAAGCTACCCAACCCGCCTATAACCCCTACTAATAATGAAAGTAACGGGATTTTATAAAATATTATATTTATTAAAAAATGTAAATTCACAATAGTTAAAGAGCTAATCACCATAAAAAGTATAGAAAAAATTAATCTTTGATAAACAGTCCCAAGATTATCAACCGTTAATACTATAGGTATACTAGTTATGACTAAAGCACATATTAAATAACCAAAAGTAATTATTAAGCAAAACAAAAACTTATTACTTAATATAGTTTTTAAAGTGATTCCGTGATAAATAGCAGACATATATCCTTTTCTTCTGAACTCGTTTACAAAAGAAAATGACACTAATAGACCTATTGCAATAGGTAAAAATAATCTACAAAAAAGACTTAGAATCGCTATATGCATGAAAACGCCATCTTTTGATTGAGATGATACAGTTAGAAAGATTTGAAAACTAATTGGTATCAACAGAAATACTAGTAACAGGATATACAATCCATTATGAAGACTTTTTTTATATTCACCTAATATACCCACTTATTTCACCCTTTATTATTCATATGTATAATATTTAAAACTCACAGCTAATAACATAATTCCTAAAATATAGATTGAAGAACTTGCAAGATATATTAAAATAGTTGTTTCTTTCATCATTACATCACTTACTATATTCAATGCATAAAATATTGGAAATGTCTTTGTGAATACTACAGGAAATAATCCATAAGTTACGCTAAAAAAAATCCAAATAACTGACAAGGACGCCGCAAGAATTCCCTTTTTTATAATCAAATGAAAAAGTAATTGAGAATATGGTATTGCTAAAGATAGAATTGTACAAAGCATCAACATTTTCAAAAAATAAAGTATAGATATTTCATATCCATTTATAAAAATATAGATACCCATAACTGAAAAATTTAAAATATTAAAGATTAAATAAAACAGTATAAACAATAAATTTTTAGCTACCAATAATTTAAATTTTGAAATTGGCTTTGTATAGATAATGGCCCAAGTACCATATTTATTTTCAGAAGAAATGATAAAATACCACATACAAGCAGAAAAAATGCTTAATGTTAGTGTATTAAAGTTTACTGTAATTGCTATAAGATTGGTAGATTGAAACATATCGGGATTATTCTTGTTAAAAATAAAATAACTTATACACAAAAAGCTTGATAATAATGAAAAAAACAAAGAAAATAACAATAATTTTCTCCCACCAATTTTCCTCATCTCACTATTCACACTTTTAAAGATAAATTGCATTATGATAGTAACTCCTTTTGTTTAGTTAAAGATAAAAATACTTCCTCTAATGTTAGCTTTTTAGGGCTAACTTCAAAAATATCTATATCATTTTCAATTAATATTCTGGTTAAATTAGGAACACTATTTTGATCTATCATTAGTTTGAATACCCCTTCTTTTTCTATGCTATAAGGTATATCCTTTGTATTTAAAATCCTTTCTGTGGCAGTAGTGTCATTAACATGAACAATATATTCTCTAGAAGTAATAATACTGTTTAAATTCCCTTCATAGAGTAAGTTACCCTTATGCAGTAATGCTATGTAATCTGCTATCATTTCGATTTCAGCTAAATTATGACTAGAAATAAATATTGTCTTCCCCTCATTTTTTACTAAATGAAGTAATAAGCGCCTTATCTCGTGTACTCCCTCTGGGTCTAATCCATTTGTCGGCTCATCAAGAATTAGTATTTTAGGATCATTAAGAATAGCAAAGGAAATACCTAGCCTTTGTTTCATTCCTAAAGAAAAATCTTTCACTTTTTTATCTTTTGCTTTATATATTCCTGTAATTTTTAATACTCTGTCTATTTCATCTAAAGGCTTATTAATCATTTTTTGTACATAGGCTAAATTTTCATATGCTGTCAAATTAGGATAGTAGGTAGGTGAATCAATAAAACAACCCACATTTTCAAATAATTCTTCTTTCCAATCTTTGATATCTTTATTATTAAATAATATCGTTCCTTTATCTAATGGAATTAATCCTAATAGCATTCGCATTGTTGTTGTTTTTCCTGCACCATTTGGTCCAATAAAAGCATATAAACTTCCTTCAGGAACAGATAAGTTTAAATCCCTTACAATGGATTGATTGTCAAAAGACTTTGTTAAATTTTTAGTTTGGATTGCTAATTTCATTTTGTTCCTCACTTTCTTATTCTCAAATAAAAGTAAGTATCTATTAAATTCTTGATCTATTAGATATTCTATTTACCCTTTACCTAATGTTTGCAATTTGGATTTAGAAAATATTTCTCGTTGTTTTAATTTTTTATCAGTAAGTTCATAAACTCTATCTACACGCTCTAAAATATTTTCATCATGAGTGATAATAATCTTAGTGGATGGTATGGCAAATATATTTTCAATAACAGCATTTGCCGTTTCCCTATCTAAATGGTTAGTTGGTTCATCCAAAATAAGAATCGGATATTCTTTCATGAACAATCGTAACATAGCCAACCTTTGTCTTTGGCCACCGGAGAAATTTGTTCCTCCCTCTGAGATTAAAATATCATTTATACTTTGAAATTGAATATAATTACTCAGATTCAATTTATCAATAGACTCCTGGATTTTTGAAGGATCATAATTTATATCAAAGTAAGATAAATTCTCAGATAAACTTCCTCTAAATAAAACTCCATCCTGAGTCATTAGTCCTACATTTTTTCTTAGTTCCTCACTGTTCCAATCTTTAATATCTCTATCGTCTATTAATATATTACCCTTATCGGGAGTATGCAATTTTAATAATAAGTTAGCTAAAGTGGACTTACCACTGCCACTTTCTCCAACAATAGCAATACTTTCGTTATTTTTAATGTTCAAACTTAAGTTTTCTATTATTTTTTTGTCATCAAAACTAAACGAAATATTATTAAATTGAATCGATCCTCTAAGAATGTTTACTTTAGTATCCGATCCATCTTTTTCTAGTTCCTCTTCCAAGATATCTAAAGTTCTTAATAAAAGTGGTTTAACTGAATTCCAATTTAAAATTGATCCTATAATTGTTGAAACCGGAGAAAATATAATACTAGATATAGCAATAAAGAAGAAAATATTACTTAAATCCCCTTCTCCTTTACTAAAATTATAAAATCCTACAGCAAGCATTATGATAATAAATATTGTTGATAGGGAACTATTAAATGATTCTAAAGCATTTTGTTTTAGCGCTCGTTTATGTACTGTATCTAAGTATTTATTATAATCTTTTTGCCATACAGATTTAATTCTAGAAAAAATCCCTGTAGCCTTTACATAATACATCGCTTTTAATGATTCATTAATTTTCCCTCTATGTTCTCCTAGGTAATACGTTTCGACTAAATTAGCATTATATATGAATTTCCCTAAGGAAATATTGATAAATAGGGAACTAGCAATAAAAAACATCAATATTAAAGTATAAAAAGTCTCAGTATATAATAGATACATCAATAATGGAATGATAACTACTATTGATATAATCATTTCAATTAGATCCTCTAAAATATATCCTCGTATTGATTCTAGGCTCATGATTCTTACATTTAAATCCCCTGCATGACGTGTAGTAATTTTTTCTATGGGGGTATTAAACATATGCTCAAAAACTTTTGTTGTACTTTTTCTATCAATTTCTTTCTGAAAGTTTACTTTTATAATAGAAGTTATAGATTTTATCCCTATAACAACGATTAAACTTCCCAAAATAATTAAAAGGTATCTTACATCCACTTCCTTTGAAGCATTCAAAATATCCATAAACTTTTTCAAAATAAAGGGGAAAGCAAGAATTGAGATTTGTGCTAACAATGCTAATAGTGCTAATAAAACAATCTGGCTAGGAGATACAAAATGATCAATATATCTAAGTAATATATGTTTTTCACGCCTTTTAGTATTTGGCTGTATATCTTTTTTGTTTTCTATTACTAGGATATAGTCACAGAACATTTCCTCAAAACTTCTTATATCAATTATCATCGGCCCTGCCTTAGGATCTACAATATAAAATTTATTTGCTTTAACCCTTTCAATAATTACAAAGTGATTAAAGCCCCAAAATGCTATCATCGGCTTTTGTATCCTTTGTAAATCAGTTATATTTTCTATCCTATATGCAGTTGCAGAAAGTCCATACGATTTACTAACTTTTTTAATATCCAACAAACTCCATGCCGATTTTTTATTGATAATTTTACTATTTCTAATTTCCGAAGCTTGTACTGCTGAACCATAATAATGCATAATCATTGCTAGACAACTAGGCCCACAATCAAAAGATGTCATTTGCGGTATAAATTTAATTTTCTTCCTTAACATATTTATCACCTATTCTAGGCATTAAAGTATAAAATGCTATTTAGTTTATTATCCTCTAACCTTTGTAAAAAATACAAAATACTTCCTAGCCCTGTAAATAATGCGATTTTATGAGGATTAAAATCTTCTATATCAAAATTATTCAAAAAGTTATTTGTTACTTTCATAACAATTTGTTTTTCATTGCGCTCGAGCATACCTCTATTTTCTAGCTCCAATAAAAAGTCTAGTTTCCCCATTAAACCATGACATAAACAATAATCACTATTTTCATGTAATGTACTTAAGATTTGTTTTTTAAAAAAAATTAAATCTGATTGTATATCCTCATTTTGATACGATTCTAAAATTTTAATTCTCGAGATTCCCATTCCACTAAATCCTTTACACCAGCTATCTGTATACTCATATTCACTCATACTCATTTTCTCACTTTTATGTATACCATGTATTACTCTATCGTACTTATTTGTTTTTAATATGCCTTTTAACTTATAAAATGCGAGAAGTTGTCCTGATAATCCATGAACAAACCCCTTTAATGAATCCTCTAAATTTAGAGTATCGTGAGCTTTCCAATATACAAATTCATTATGTGTTTGCATATTATTGACAATGTAGTCACCGAGATTTTCAGCCACTTTAAGCAATATTTTATAATTAGGATTAATTTGATAGAACTTAACTGCCGTTAAAATTAGACCAGCTGAACCCCCTAATATATCAAAATGCTTATCGCTATATTTACCTTTTTCAATATCAGAGTTGACATCCATAAATATTTGCAATATCAATCTTTCATCGATAGATGTTATATGTGGTAAATTTGTTAAATAGTAAGAAATAATTGCATTAACACCATTTACAAAACCATAATTATTTTTATTTTTGTTTAATATTTCTTGCAGGGCTTTTTGTTCAAGTTTATTTATAATTTCAATCTGATTAGGATCAGCATTATTTCTCAATAATGAACTTATTCCCAATAATCCATCATATATTCCACTATTCAAATGGTTTATCTCAAGCTCCCCTTGCCAATTTGTTTTTAATCCAATAAAATCTACAGCACCGTCTTTTGATATATAACTGCCATCAAGAATTTTCCCTGTAATTGCTTCCTTTATTTTATTTGTAGGTAAATTAGTTCGAAAATTAATTGTTTCCTTTACTGTATTCAGCTTATATAGATTGTCATTTTGATTAGAAAGGGATATTTCTATAATTTTTCTTTGTAATAAAAAGTCAGCATATGAAATTTTTTTAAATTTTGTTTCTAGATCTATTTCATTATTTGATAAACTTTCGCAAGACTCCCATTCATACTTATTAAAGAAATATGGAACATCATAGGATAATAGTGCCTCTATCTCTTTTTGAATAATATCTTTCCTAGTAGCCAAGTATATGTTTTTTTCAAGAATATTCCGCAAATATTTTATAGTCTTTAATTTATTCTCTAATAAATCCGGAACATTTAGTCTATCTAATAAAAGGGTATAGACTTTTGTATTTCGATATACTTTTCGATAATTCCATTTAGAAACACTATTTTTTAATATACACATATACTCCTCTTTGTTTTTTAAAACTGAGTTATATGCATTCTCAAAACCTTTAATAATATCATCTATATAATTATCATACTCGTATATATCATCGTTAAGAAACGGTAAATTCTGAACCGTATCTTCTACTATTGTCTCTTCTCTTATTTCAATTGGATTCGATGTAAATTCATTTTTTATTTTAATTGTTTTTACCAAAGACTTCATTACTCTCCCAATTGCACTGTAATCTCTTATTACCTCCCTACCTCCACTAAACCTTATAGGTAGCATTCTAGAATTTAATACTGAATTAGATAATATAAAACTACTGGTTTCTTCAGTAACACTTGGATTTAATGTACTTCCTAATGTCTCAAAATCAATTATGACTGGTGAGGATTGTTTAGCTATGATATTTTCATTATGTATGTCACTTCCATTAATCAAATACATTACCGAAAGCACTACACCTAAATTATAATAATAATCTTTAATTTGCTCATTAGATTCACATGATTCATGATTAATGTATTCCATATATCCATAATTTCTTTTATTAACTACTTGCGGAATAAAGATATCCGTATTTAAATCTTTATTCAGTTGATTAATTAAACTATGATATAGTATAGAATTTTTCAAATCGACTGGTTTTAAAATTACCTTATTATTAAATTTATCTTCTAAAAGAATTGTTCTCTTTCCATTATTATGGTAGTCACCTAGGTTAATAACTTTTTCTACATGCATAATATTAAAACCCGACATTTTATGAATTTCTTTTTGATCTTTTTCAAGAGCACCTTGCAACCAAATCATATAATTTATTTCATTTTCAATGATTGTAAAAATTTTTTCGTTTAATACGGGTAATATTTTAAAAAAATTCATATAAAATTTTTTAAAATGAAAGAAGTTCTTTGTAAAATACTTATATTCTTCATTGGTATCCATTCCTCTTAAAGCATTTTCTACCCTAAGTTTATTTATGTATACAATTAAGGATGGCCTTAATACTTGGTATAGTCTTTTTTCTAAATCAAACATTATCGATTCAGAAACCTTCTCAAAATTACCAAAAAAATCAATTTTATTTATTATCATATTTTTAAAGAATACTACATATGTTTGTATTATTTTTTGAAAGTTATAGTTTTCGTCATCCTTAATGACATCATTACATGAAAAACCCTCTAAAAAGATAACAAAATTTTTTTCTAGATATTCTTTTGTTACTAAAGAATGTGATCCATTATCTATTGTATTCAAAATTCCATGTGAATTATTTTTCATAATAACCTCTTCTTTTTATAGGTAGGAGAAACAGTTAGAAATTCATTCTCATTAAAGAGAGTAAGGCCTTTCGCCTTACTCTCTTTAACTATTAGTAGCATTTTTTACAAATTCTTTGTCCCATAATCGTGACACATGCTACAGGCACATTCCAAGGACAATCTTTAGTTAAAGTTTCAACCCAACCAGGTCCTGCTCCACCAACTAATTGTTCAATCTCTTCATCTTCTACGACTTGTAAATATTTTTCAGTTTCCATTTCAATACCTACCTTTTATTTTTTTGAAAATGATGTTATAAATTCAATAATTTACCACAACATTATCTAAAAACAATATACCATTAAATGTTAATAAAAAAAAGATATATTTATAGAAAAATAAAATAATAGGATATTTAACTATATTAATATAATTAAAGGAGACTCACTTACTATATCATTAAAATTTAAAGGCTATTTTCCAAGTTAATATTTTTAAAATTTTATAAATTTATTAATAATCAATGCTGTTTAATAATTTAAATAATTCTTCTAATACCTGAATAACGATTAAGAATATTAATTAAACTTGTAAAAAATAGATTTTCAGAAGATATAGCTCAAGAATATTTTACCATAAAATAGGATAATCAATTCTTTTTTTAATAGTATAATGCTTCGTCAGAAAATTTTAATCATGAATTGCAAAAAGCATGTTAAAAATAAAAAGATGAAATTGCAAGTATATTCACTTCACAATCCCATCTCTTCTAAAAATTGTATATCATCAACTCTCTTGATCCTCGCAATTCTACCAAATTAATAGCAACACATTATGTAGATATAGGTTTATACTATTCTACATTTAAATACATGTAATATTGCCTATACTTTGTTATTTTCATGTGAAACTAATTCACTATATATCTCTTTCTCTATATTTTTCAAGAGAATTTCCAACCTATTTTTTGTAGCTAGATTAAAATGTGGATTTAATTCTTTTATTATAAATTCAAGTATCTCAAAGCTTATGTAATCTCCTAATTCAAGTGAATATTGATCACCCAAGAAAGTTTTTAATTTTTTAGAGATCTCCACTTTATCTTTTTTGGTAATATTTACCCCATCCGATAACAAACCTCTCTTAGATTAGTCTTAAATACTAATTCAAAAAGTTTTTATAACATAATAAAAATATTTTGGAATTAATATAAATCATATAATGAAATTTTTACAAATAAATAAAAAATATACATCATAATCATTAAACAATATATTAAGCATCGTAAACATATATTGGCTCGTCATAAAGGCGTAAACATTTTGACCAATTTCCACATAACGTTTCCCATTCACCAGCAGGATATACTTCCGTACGCAATATATGAAGTGGTATACGTAAATTCAATAACCGACCACTAAGCGTCGTACGAGTAACTCCCGCTGGCATTAAAAACTTTGCTTCAATTACCTTTTTCAGTTCCATCAACGAGTATTCTGGATAACTCATCAATATTTCATTTGAATGAGGCCAGACCTCAGTATCATTTGAATGACGGCGTACCGTATACTCATGTTGATATAAGCTGACAATACGATGCCATATCTCTAAATGATTAAATAAATCGCTATTTAAATCCCTTGCATATAAAAAATGTACTTGTTTATTTGCTTCTGTAATTTTTGCAAGCAAACGTTTATTAGCAATAATCTTACCTGACCAAATTATTGTAGGTTCTTTCTTTAAATTATTTACCCATTCCCCCATTGGTAATAAATGATTCCAAGCACGAATTTTTATTTTTTCATCAGGTACTACCTGTACAGCAACGCGTTTACAACCTAATGCCATCATAGCCTTCATACGATGGGCACCATCAAGTAACAGATAATTACCATCACTAAGCTCAGATACTAAGGGAGGATTCCGTAAAACACCTTCGCTTTCCATTACACGACAAATTTGTTCCAATCTTTTGTGTTCATATGATTCATGAAAGCGAATTTGCTTGGGATGTAAGAGATCTAAGGCCGAAATAATTTCACTCATAAAAACAGCTCCTCAAATAATTACATAAATTCTAAGCTTATCAAATAACTAATTTTCTATAATGATTAGTCGTGTTTACCGATATTTAGCAGCTATTAGACAATTATTTCAAACTACGTTTAATAATTTTACTAGTCTTCTAATAAAACACCTATTTCCTTTTCCCTAGCCCTTTGATAGTAATAAGCAGCAATGGCTACATCAAAAATGGCCATACCCATTGGATTAAATAATATTGCTTTGTCATAAGGGAAGTTTTGCAGTGCTCCTCGGATTACAACGTCAGCAATTGATACTGTATCTTCTTTTTGTAAACCTCTTTCAAGGTGCATCCTTTCAACATCAGTTTTTTCACGACAGACTTCTTCCCAATTATCAACAACTAGGGATTTTGTATATTCTAAGATATCAGGCTTAAAATCACGAAGAGAAACATTGAGTAGTAGCGCTCCATCTTTAGGTTTCTTATCAATATAACCTTCTGCAGAAACAGTACAAGTAATAAAAATATCAGCATCATTATAGGCTTCTTCATAAGCATTAACCTTTTGAGTTTTAGAATAAATATCCTCAGGAATTAATTCGTCTTTAATTCCATTGATATCATATAGGTAAACACTTTCGATTTTATCGCCTAATAGGGCAGTTACCATCTTTAAATGCATCTGACCAATAGGTCCAAATCCAATAATTCCAACTTTAACATTATTTAAATCTCTTAACTTGGCAAACTCTCGAATCATTAACCCTGTTACAGAAGCTGTTCGTATTACACTGACCATTGCTGTATTAAGCGTCGCAAATGGTTTTCCAGTCATAGCATCATTTAATATAGTAACTGAATGAGCACGTTGAATACCTTTCTCAATATTCTTCGGAAAACTAGCTATCCATTTGATTCCTGAAACCTTAAATTCTCCTCCAATATAAGCTGGCATAGCAATAATTCTATTAGCCGGATCATCAAAACGTAAGTATGGCTTAATTGGCTGAGAAAAATCTTCTGCATCAAGACTTTGTACTGCCTTTGAAATGACATTTATTGTTTCTTCCCAATTAACACCCATTTCATTGATATGTTTAGTATTTAAATACATCATAATTGCTTCCTCATTTCTATATCATTTTTATAAAGAAACTAATTGGTCTTCTACTGATTTTTTTGTATTAAGCCATTCTACCCATTCTACGTTGTAAATAGTTGATGTGTAAGCTTGTCCATTATCAGGACACAAGAAAACAACATTAGGTGTATTTTGAACATCCCTATTTTCAAAATACTTTTGGATTGCATAATATGAAGTCCCTGATGATCCACCAGCAAATATTGCATGTTTATTAAATAGCTCATAACAACCTGCAACAGTATGGACCTCCGGTACAATCATTACATCATCAATCAATGCTTTTTTAACCATACCAGGTATCATACTGGCACCAATTCCTGGTATGTACCGTTTACGAGGCTTATCACCAAAAATAATGGACCCTTGACTATCTACCGCAATAATTTTAATATTAGGGAATTTTTCTTTTAATCGTGTAGATACCCCAGCGATAGTTCCTCCAGTACTCACTCCAATGAAGGCATAATCTAACTGTTTAAAATCATTAGATATTTCTTCACCAATTCCTTGATAATGGGCTTCAAAGTTATCAGCATTATTATATTGATTTGTCCAGTATGCATTAGGAATAGTATTTAAAAGTTCTTCCACCTTATTTAAACGCGTTAATAAATAGCCACCTGTTTCATCTCGTTCATCCACTTTAGCTACTTGATAGGAAGTTGCTCTCAAAAAATTCTCATAACTATCATTAATATTTGGATCAATAACTGGTATGAATTTCAGGCCGATATACCTACAAAGAGTAGCAAGAGCAACCGCAAAGTTACCAGATGAAGATTCGATAATTGTAGAATTTTCAGTCACTTCACCGCGACTTATTGCTGATTTTAAAATATGGTGAGCAGCACGCACTTTAACACTATTCATTAAATTGTGATATTCTAGTTTTGCATACAGATTAATCTTTTCATGCTCTAATTTAATCATAGGTGTGTTGCCGATTACCCTTTCTAAACTCTCTAATTTCTTGAGCATAATTTGCTTCCTTTCTTGGTTAAAATCTAAAAAAATAATTAAAGATAAATAGTTGTAAATGTTCTTTCGAATGTATTTCAAATAGAACTTATACCTGAAAGACAATAAATGCTAGATTCTTTAGTATCGATAAGCTAAGCACCATTCAAGTACTGCCATAGCACTATTTAGCTTGTTTTCGGCCTGGGTAAATACAATACTTTTCGGTCCATCAATAACTGTTGCTGCTACTTCTTCCCCCCGGTGTGCTGGGAGGTCATGCATGAAAGTAGCTTCCGGATATAAAGTCAAAATTCTCTCTGTCACTGCAAATGGATTAAAGGCATCTTTCCATAAAGGATCTATTTTGCTTGTCCCTGTTGTTTGCCACCTTGTTGTATATACAACATCCACTTCACTAGGTAACATTTTTATATCATGACATTCAATAACTTTAGCACCAGATAATCGTGCATATTCTTTTGATTTTTCAAGCACACTTGGAGACACTCCATAACCAGCAGGTGTAAAAAGATATAACTCCGTACCTGGAAAACGAGATAAAGAAAGAGCTAGAGCTGCAGCACTGTTATTACCTTCTCCCATATATAAAACCCGTAATCCAGCTATTTCACCAAATTTTTGTTTCATTGTTGTTAAGTCTGTTAGCGCTTGTGTTGGATGTTCTTCCGTACTCATTGCATTAATGACTGCCATACGACTTTGAGATGCCAGCTTTTCCATTTCCTTTTGACTATCTGCAGTTCTTGCTACTAGTGCATCCAGCATTCGCGAAAGTACTTGAGTAGTGTCTTCTATAGACTCCCCTGTATTTTCTTGCAAATCATTTGGACCATACGTTACAATTTGTGCACCCATCTTTAATGCTGCAACAGAAAATGCCGATCGAGTTCTAGTCGATGTTTTACGGAAGTAAATCCCAATTATATTTCCCGCTAATATTTGATTAGGTTGTGATTTACCTGTGGCAAACTCTACCCCACGAGTTACAATTTGGTTAATATCACTATCAGTAAGATCCTCAAGAGTAATTAAATGTTTTCGAATAGCCATTATTATATTACCTCCCTTTTGAATAATTGCATGTAACAAAAATGTATTTACATATGTATGTAAATAAAAACTACTAAACAGCTAAAGTAAAAATAATAGATTGGAAATATAATTCATGTGGATCCATTACCACACTTTTCTATAATTTTTTTTAAACTAATGTATAGCAGTTGATATATAGCCTATATGAACTCGAATACTATTTTTACTCAGAAATACTTACATATAATTCTATTGTTAGTCTATATTCCTATTTTTTATGATATAGCTCTGCTGAATATATTACACACTACAACACTAAAAATATACTCAAAATACAGAATTTTCAGCTTTCTCAATTCTTTCATCAATTTTCTGTCAATTCATACTCAAATTATCTTTTTTACTAATAATATACATACAATGTTGGCTGTTTCTTTTATAGCCCACTTCTAAAAAATCCACCCATTCAAAAATAACGTTTTCCGGATTGTCAGTTAAGATACAAATTACTGCTGCAGTCATTAAAGAGTCCTCTTTAAAAGAGATATACTCCTTCTACTGGCTCGCTATTTTTAGTTATGATAACCTCTTAATTGTTACAGCTATAACGCTAACAATTGTTATTGCAACCATTGATCTAAGTAAACAAACAATGAATGACATACTAATATATACACAAAGTAATCTATTAAGCGTAAAATGATTGCATCTCCAGCAAGTTTAATTACTTATTCAGATCTTTGCTTTTATAATTTTCAAAATTAAATTTCCGAAAATTTTCTTTCCTTAAGGAAATATCGATCATTTTAAACTATGTAAGAATGCTTATCTTCTATAAAGTAATTACACAAATCAACAAAGTCAATTTCAATTATTGATTCTGGAAAACTATCTAAAGAAGCACAACAAGAAAGCTTATAATCTTTACCAATAGTAAACTTTTTATAATAAACCTCATTAGATAGCATGTCACCATAAAATATTATATTTTTTTTAATAACAAAAGAGTTTAAAGGTATAGTTAGTCCTTTCCCTATCCATTTAACAAAGCTTTCTTTTATAGTCCATAATTCATAAAACACATCTAATTGTTGTTCTACATTTAATGAATTTAAATAATTAAATTCTTCCTCAGTAAATATATTTTTAATCATTGTAGTATCCATGGGCCGGACTTTTTCTACATCTATTCCTACTTCTTCCTCATGAATAGCTCCAACAACCCAACTTTCGGAATGCGATATATTAAAATGAAAATTATTTAACTCATCCACATAAGGCTTTCCGTATTCATTGTATTTATATTTAATATCTTTATTTTCTTTTGAGAAATTTGTAATAATTAAATATCTTATTATAATGTCTCCAATTAAGGCGCTATATTGGTCGGGCTTTCTTTTATATTTCTGTATTTTCATCTGCTTTTCTTTTGAGACCAAACTCATAAGTTTCTGCATAATGTTATGTTCTATATTTCCTGGCACACGTACCTTATATATATTCATTATTTCCTTCCCACCTAACTTCTTATATAAATATAAAAAACTCTCAATGAATAATTCCTATTTATTTTTGATTAGTAAAAAACATTTTCAGAGGATAATATTCTATTTTACATTCATATTTTCGACTTATTTTCTAACCTCTTTATGTCTATTATTGAATGGGCTCAAAGAAAAAAGTCTCATAATATGTTATACACGAATTTATGAGACTTTTAGAAAACTAATAGTGTACAATTTCAAATAATATTTCACCTATTTACATGTGCTAATAAGAGCATTTGTTTAAAACTCATTTTTATACTCTTTACCAACTCATGAATATGCGGTTTCTCTAACATACTCAGATGGGAACCTGGCACTTGCAAAGCGTATACTTCCCCTGATGTATATTCATTCCATCTGTTATAATCTACTAGTGGGTGAATGTCATTAATAGATGCATTAAATAGAAAGATATCTGCTTTTATTTTTTGTTTACAATTATATTTTAGGTATGCATATCTATTAGCTATCATTACTTTTAACTTATTCATCATTGGATCTTCAAAATTTTGCTGACAACTATTTTTATTCAATGTAAATTTTTTCAGTAAAGATTCTATTAATTGTTCTTCACTCATTTGCTCAAAACTAATTTTCTCAATCCCTAACTGATCATTGAATTTTTCCAATTCTTCAAAGGCATTCTTAATATTTAAACTAAGAATCTCCTTACCTTGTTCAATAGGATGAACATCAAGTAAACCTAGAAAACTAACTTTATCACCTAGTTCTTCTAATTTTCTAGCCATTTCAAATGCAACTATTCCTCCAAAAGACCATCCTAATAAGGCATATGGCCCTTCTTTTTTTACTTGTTTAATCTCTTCTATATATCTTACCGCCATTTCCTCTACAGATAAGTTTGAAAATCTATTATCATCATATCCTATAGATTGTAACCCATATACAGTCTTATCCTCTCCTAATTCTCTAGCCAAATCATAATAGTTTAATATGCCCCCTCCTTGTCCATGAACAATGAACCATTGACTATCCTTGTTTGTCCCATTTTGAATTGGAATTAAACACTCACTGTCTATTCCTTTATTCCTACTTATTACATCACTTAATTGTTCAATAGTAGCATTTTGAAATAATAAACTTAATGGCAGTTGCACATTAAACATTCTCTTGATATTTTCGAATAACTTTAATCCCTTAAGAGAATGACCACCTAATTCAAAGAAATTATCATTTATACCAATATTATTTACGCCTAATATACTACTCCAAATATCAATTAAACTACTATCTATGTCATTTCTTGGTGGTACATAATTACTATTGTCCAGTGTATTTAGCTTCGGTAACTTACTTCTATCTATTTTCCCATTTTGTGTTAATGGTATATTGTGAATTGGTATGAGTTGTTGAGGTATCATATAATGTGGTAACTTTGTTGCCAAATATGCTCTTACCTCTGGAATAGGAATATCTTTTTCTGTAACTACGTATGCACATAAATACTTTTCCCCAGCTTCATCTTCTTGATCTATTACTACGGCCGTTTTGATTGTCTCATATTTTAACAAACTCGCTTCTATCTCACCTAGTTCTATTCGATATCCCCTTATTTTTACTTGATGATCGACTCGGCCCAAGTATTCAATGTTACCATCAGGTAGCCACCTTGCTATATCCCCTGTTTTATATAGTTTCTCACCTCGTTCAAATGGATGATCAATAAATTTATCTGCTGTTAATTCTGTTCGATTGATGTATCCTCTAGCTAACCCTATGCCAGAGATACATATTTCACCTGGAACACCTATAGGTTGTATCCTATAAAATGAATCCAATATATAAATTTTAGTATTTAACAATGGTGAACCTATCGGTACGTTTTGTGTTGTAATTTCTTTATTACTCTCATATCGATAAGATGTACAACAAACTGTAGCCTCTGTAGGTCCGTATCCATTTAATATTTGGAGGTTCCCCCTAAATAGATGATCGTATTTTGCGAGTAATTCTGTTTTAATGGGTTCTACTCCCACAAGTAGCTTATTTAACACTATCTTCTGGTTATCTCTAACAAAATAATCATATATTTCATTTAATAAAGTAGGTGGAATATATGATAATGTAACCTGTTCTTCAAGAATAACTTGTACAAGTTTTGATACATCAAACTTCTCACCTTGATAAATAGTCATTCTTGCGCCATATATCAATGGGACAAATATCTCAAAAATAGTAACATCAAAAGAAATACTACTTGAGAATAGAACGTTATCAGTTATCCCTATATCTTGAGAGAAATCTTCATACATTGCACACAAAAAATTAGTCAAGGATCGATGTTCAATCATTACTCCTTTAGGTTGTCCTGTAGAACCTGATGTATAAATAACATACGCTAAGTTGTGAGGTTCTATCATCATTTGCATGTCTTCTCCTGGTTCTTCTTCAAAAGACATATCCATTAGATCTATTACATTACCTTGGAATTCTATCCCCTTTATAATAGAGTTTTGATGTACTAATACATGTGAACACCCACTGTCTGTCAGCATATATTCCACTCTTTGTTTTGGTAAGGCGGTATCAATTGGTAAATACGCCCCACCTGCTTTTAAAACACCTAATATACCTATAACCATCTCGATGGATCGTTCCATCATCACACCAACAATGGATTCTCTTTTAACTCCTTGGTCTAATAACCTTCTCGCCAACTGATTAGCTTTTATATTTAATTCATTATATGTAATTCCTTTTTCATTACATACAACGGCTATTTGATTAGGGTTCCGTTTTACTTGTTCTTCAAACATTTTATGCACTAATAAATGATTAGAATTTGAATTCTCTTTTTTGTTAAATTCATTCATAATACAATGTTCTTCTTCTATAGATAACATATTAATATTACGCAATCGTACTCTAGGGTTATTAGTTACTTCCTCAACTATATTTGTAAAATGTACCATTAACCTTTCTATTGTCTCCGCTTTAAATAACTTAGTACTATATTCTACTTTTAAATGAATGTTATTATCTATTTCCGTTGCTACTAATGACAAATCAAATTTTGAAACTGACTGCTTAAACGGATACGGTGTAAATTCTAATTCACCAATAGATATTGGATTCATATCCATGTTTTGAAAAACAAACATGGTATCAAATAATGGATTTCTACTTGTATCCCTATGCAAGTCTAAACCTTCTAATAGTTCTTCAAAAGGATAGTCTTGATTTTCATAAGCTTCTAATGTATTGAGTTTTAATCTACTCAAAAACTCAATAAACTCATCGTCATTTTCTAGATAATTTCTCATTACCAAAGTATTAATAAACATACCAATCATATGATTAGTATCAGAATGAGACCTTCCAGCAATAGGCGAACCTACAATAATGTCTTCTTGACCTGTGTATCTAGATAAAAGTATGTTATAAATGGCCAATAAAATCATATATGGCGTAGTACCAGTTTCAGTTGCTAGCTTATTTACTTTAAAAGTTAAATCTCTTCCCAAATTAAAAGAACAAACATTACCTTTAAAGCTTTGTATAGTCGGTCTTTGAAAATCGGTTGGAAAATTTAAAACCGGGAGTTCTCCTTTTAAAGTTGTTAACCAATAATTCTTTTGTTCACTAATTAGATTCTTATAGTAAGGTCCATTTTGCCACATCACATAGTCTTTGTACTGCACTCTCAATTTTGGAAGCTCATTTCCTTTATACAATTCTACAAACTCTTTTATTAATATCCCCATTGATAAACCATCAGATATTATATGATGCATATCTACTACAAGGATATGTCTTTCTTCTGCTATCCTTAAAAGCAACACCCTTAATAATGGAGGTTTTGATAAATCAAATGGACTTATAAACTCATGTATTAAATAATCCGCATCTTTTTCATTTACATGAACGTATTCAATATTGAAATCTACATTAGGCTCAATTTTCTGCACTAATTCCCCATCTAAAATTTGAAAAGAAGTTCTTAATATTTCATGTCTCTCAATTAAAGATTGAAATATATTTTCAAACTTATCTTTACAAATATCCCCTTCTACTTTAAGTATTGTGGGCATATTATAAGTTGTATTTGTACCATCTTCGAATTGATCTACTATAAACATTCTCTTTTGTGACGTAGAAGCTAAATAATACTCTTGTTGTTTTACAGGTTCTATGGAAATATAATTACTTTTTTCCATTTCTAATATACATTTTGAAAAATCAACCAAAATAGGAAACTTAAATAGGGATTTAATAGATAATTGCACATTAAATTCTTTATTAACGATAGAAATTAGCCTAGCAGCCTTTAATGAATGACCACCTATCTCAAAAAAATTATCCCGTATTCCTACCCTTTGTATTCCTAATACATCTTTCCAAATCTCAACTAATTTTCTTTCTGTAGAATTTGTCGGCTCTAGATGACTAGATTTCAAATTATTTATAGGTTGAGGTAATTTTTTTCTATCTATTTTTCCGTTTTGTGTTAACGGTATGTTTTGAATGGATATGATTTGTTGAGGTATCATATAATATGGTAACTTGGTTGCTAAATATGCTCTTACCTCTGGAATAGGAATATCTTTTTCGGTAACTACATACGCACATAAATACTTTTCTCCACTTTCATCTTCTCGCTGTATTACTACGGCGGTTTTGATTGTCTCATATTTTAACAAACTTGCTTCTATCTCACCTAGTTCTATTCGATATCCCCTTATTTTCACTTGATGATCAACTCGTCCCAAGTATTCTATGTTACCATCAGGTAGCCATCTCGCTATATCTCCTGTTTTATATAATTTCTCACCATGTTCAAATGGATGATCAATAAATTTATCTGCTGTTAATTCTTTTCGATTGATGTATCCCCTAGCTAACCCTATGCCAGAAATACATATTTCTCCTGGAACACCTATAGGTTGTAGCCTGTGAAATGAATCCAATATATAAATTTTAGTATTTAACAATGGCGAACCTATTGGTACGTTTTGTATTGTAATTTCTTTATCCCTCTCATATTGATAAGATGTACAACAGACTGTAGCCTCTGTAGGTCCGTATAAATTTAATATTTGGAGGTTCCCCCTAAATAGATGATCGTATTTTGCAAGTAATTCTGTTTTAATTGGTTCTACTCCCACGAAAAGTTTATTTAACGATATCTTCTGATTCGCCCTTACAAAATAATCATATATTTCATTTAATAAGGTAGGTGGAATATATGCTAACGTGACCTGTTCCTCAAGAATGACTTGTACAAGTTTTGGTACATCAAACTTCTCACCTTGATAAATAGTCATTCTTGCTCCATATACCAATGGGACAAATATTTCAAATATAGTAACATCAAAAGAAATACTACTTGAGAATAGTACATTATCACTTATCCCTATATCTTGAGAGAAGTCCTCATACATTGCACACAAAAAATTAGTTAAGGAACGATGTTCAATCATTACCCCTTTGGGCTGGCCTGTAGAACCTGATGTATAAATAACATATGCCAAATTTTGAGGTTCCATCGTTATCTGCAAATCTTCTACTTGTTCTTCTTCAAAAGGAATATCCATTAGATTTATTACACTACCTTGAAATGCTACTCCCTTTATAATAGAGTTTTGATATGTTAGTACATGTGAACACCCGCTGTCTGTCAGCATATATTCCACTCTTTGTTTTGGTAACTCGGTATCAATCGGTAAATACGCCCCACCCGCTTTTAAGATACCTAATATGCCTACAATCATCTCAATAGAGCGTTCCATCATCACACCAACAATGGATTCTCTTTTAACTCCCTGGTCTAATAACCTTCTCGCCAACTGATTAGCTTTTATATTTAATTGTTTATATGTAATTTCTTTTCCATTACATACAATCGCTATTTGATTAGGATTCTGTTTTACCTGCTCTTCAAATAATTGAGGAGCTGTTACAGTCTCACAAAGTAATGTTTTATGAACTCTAGTCGTATGATTGAAATCAAATAATATTTGATTCTTTTCTGTTTTAGGCATTACATCTAGATCCATTGCAGATTTATTTGGATCTTTCATTAATATATCTAAAATATTATATAAATGATTAACTATTCTACTAACTAATCCTTCACTATATAAAATAGAATTGTAATCCACTTGAACCTTTAACTGTTCTTCATTTTTCATAAACCTAATAACCATATCAGAGTTTATTTTATCTGTACTCTCATAACAATGAATATCATCTAACATTACTATTGTATTTAATAAGGGAAGATTATTACTCTCTCCATCTAGACTTAATAATTGAGTAAGTTTATTAAAAGGAAAATGACAATGTTCATTTGACTCTAAAATTGTTTCTTTAATTTTATATATTATTTCTTTAAAATTATCTTCTTGATTTATTTGAGTACGTAATAATAAAAAGTTGTTTTGAAAAACCGTCTCTTCTTGACCTTGTTTAAA</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"table-3-the-contents-of-bt_all_genestable\"><a class=\"markdownIt-Anchor\" href=\"#table-3-the-contents-of-bt_all_genestable\"></a> Table 3. The contents of &quot;Bt_all_genes.table&quot;</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">-</th>\n<th style=\"text-align:center\">Cry1Ac16</th>\n<th style=\"text-align:center\">Cry1Ca15</th>\n<th style=\"text-align:center\">Cry1Da2</th>\n<th style=\"text-align:center\">Cry1Ia40</th>\n<th style=\"text-align:center\">Cry2Aa10</th>\n<th style=\"text-align:center\">Cry2Ab35</th>\n<th style=\"text-align:center\">Cry78Aa1</th>\n<th style=\"text-align:center\">Cry9Ea9</th>\n<th style=\"text-align:center\">HMM_Cry_len_492</th>\n<th style=\"text-align:center\">HMM_Cyt_len_531</th>\n<th style=\"text-align:center\">HMM_Cyt_len_533</th>\n<th style=\"text-align:center\">HMM_Cyt_len_615</th>\n<th style=\"text-align:center\">Sip1A2-other</th>\n<th style=\"text-align:center\">Vip1Aa2</th>\n<th style=\"text-align:center\">Vip3Aa12</th>\n<th style=\"text-align:center\">Zwa5B-other</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1126_1</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\" colspan=\"2\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">32.66</td>\n<td style=\"text-align:center\" colspan=\"7\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">99.07</td>\n</tr>\n<tr>\n<td style=\"text-align:center\" colspan=\"7\">AFS094730</td>\n<td style=\"text-align:center\" colspan=\"2\">36.14</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\" colspan=\"3\">1</td>\n<td style=\"text-align:center\">92.41</td>\n<td style=\"text-align:center\" colspan=\"3\">29.46</td>\n</tr>\n<tr>\n<td style=\"text-align:center\" colspan=\"10\">AFS095482</td>\n<td style=\"text-align:center\" colspan=\"2\">1</td>\n<td style=\"text-align:center\" colspan=\"5\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\" colspan=\"4\">AK47</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\" colspan=\"5\">100.00</td>\n<td style=\"text-align:center\" colspan=\"4\">1</td>\n<td style=\"text-align:center\">100.00</td>\n<td style=\"text-align:center\">100.00</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Footnote:</strong> The float number represent the identity of blast search, and the integer number represent the number of toxins predicted by HMM and SVM.</p>\n<h2 id=\"license\"><a class=\"markdownIt-Anchor\" href=\"#license\"></a> License</h2>\n<p>BtToxin_Digger is free software, licensed under <a href=\"https://github.com/liaochenlanruo/BtToxin_Digger/blob/master/LICENSE\">GPLv3</a>.</p>\n<h2 id=\"feedbackissues\"><a class=\"markdownIt-Anchor\" href=\"#feedbackissues\"></a> Feedback/Issues</h2>\n<p>Please report any issues about usage of the software to the <a href=\"https://github.com/liaochenlanruo/BtToxin_Digger/issues\">issues page</a>.</p>\n<h2 id=\"citation\"><a class=\"markdownIt-Anchor\" href=\"#citation\"></a> Citation</h2>\n<ul>\n<li>\n<p>If you use this software please cite: <strong>Hualin Liu</strong>, Jinshui Zheng, Dexin Bo, Yun Yu, Weixing Ye, Donghai Peng, Ming Sun. (2021) BtToxin_Digger: a comprehensive and high-throughput pipeline for mining toxin protein genes from <em>Bacillus thuringiensis</em>. <em><strong>Bioinformatics</strong></em>, 2021;, btab506, <a href=\"https://doi.org/10.1093/bioinformatics/btab506\">https://doi.org/10.1093/bioinformatics/btab506</a>.</p>\n</li>\n<li>\n<p>If you used the genome assembly function, please also cite: Liu H, Xin B, Zheng J, Zhong H, Yu Y, Peng D, Sun M. Build a bioinformatics analysis platform and apply it to routine analysis of microbial genomics and comparative genomics. Protocol exchange, 2021. DOI: <a href=\"https://dx.doi.org/10.21203/rs.2.21224/v5\">10.21203/rs.2.21224/v5+</a>.</p>\n</li>\n</ul>\n<h2 id=\"faqs\"><a class=\"markdownIt-Anchor\" href=\"#faqs\"></a> FAQs</h2>\n<h2 id=\"updates\"><a class=\"markdownIt-Anchor\" href=\"#updates\"></a> Updates</h2>\n<ul>\n<li>\n<p>v1.0.2</p>\n<ul>\n<li>Fixed a &quot;Can not find path&quot; error.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.3</p>\n<ul>\n<li>Fixed a bug of &quot;get_all_info_nucl.pl&quot;, which can not get the gene location and strand information of some toxins.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.4</p>\n<ul>\n<li>Updated the database and models to support <a href=\"https://www.bpprc.org/\">the latest clasiffication of Bt toxins</a>.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.5</p>\n<ul>\n<li>The name of strains with no toxin found will be outputed into the file &quot;Strains_without_toxins_found.txt&quot;.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.6</p>\n<ul>\n<li>Update to adapt to PGCGAP v1.0.23, and to delete the intermediate files.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.7</p>\n<ul>\n<li>To delete the intermediate files.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.8</p>\n<ul>\n<li>To delete the intermediate files.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.9</p>\n<ul>\n<li>Update the database to keep it consistent with the BPPRC (to 2021-06-07).<br />\nMore HMM models are added.<br />\nThe filter length of amino acid sequence was reduced from 115 to 75.<br />\nSolved a problem: BioPerl reported an error when the length of the sequence in the input file was inconsistent.</li>\n</ul>\n</li>\n<li>\n<p>v1.0.10</p>\n<ul>\n<li>Users can use the command &quot;BtToxin_Digger --update-db&quot; to update their local database.<br />\nThe toxin database was updated to 2021.08.02.</li>\n</ul>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"}]},{"title":"Use microeco分析扩增子数据","slug":"Use_microeco分析扩增子数据","date":"2021-03-14T07:01:45.000Z","updated":"2022-01-08T02:16:28.417Z","comments":true,"path":"api/articles/Use_microeco分析扩增子数据.json","excerpt":null,"keywords":null,"cover":"#/images/lujia/show_15_taxa_at_Class_level.jpg","content":"<p>本文阐述使用 microeco 分析扩增子数据……</p>\n<span id=\"more\"></span>\n<h1 id=\"font-colorff0000-1-安装microecofont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-1-安装microecofont\"></a> <font color=#FF0000 >1. 安装 microeco</font></h1>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># If devtools package is not installed, first install it</span>\ninstall.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># then install microeco</span>\ndevtools<span class=\"token operator\">::</span>install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"ChiLiubio/microeco\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">,</span> quietly <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span>\ndevtools<span class=\"token operator\">::</span>install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"jbisanz/qiime2R\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"font-colorff0000-2-准备数据font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-2-准备数据font\"></a> <font color=#FF0000 >2. 准备数据</font></h1>\n<h2 id=\"font-colorff9800-otu_tablefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-otu_tablefont\"></a> <font color=#FF9800 >otu_table</font></h2>\n<p>OTU 表</p>\n<table>\n<thead>\n<tr>\n<th>Sample 1</th>\n<th>Sample 2</th>\n<th>Sample 3</th>\n<th>Sample 4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OTU1</td>\n<td>232.0</td>\n<td>209.0</td>\n<td>349.0</td>\n<td>256.0</td>\n</tr>\n<tr>\n<td>OTU2</td>\n<td>75.0</td>\n<td>35.0</td>\n<td>44.0</td>\n<td>0.0</td>\n</tr>\n<tr>\n<td>OTU3</td>\n<td>237.0</td>\n<td>224.0</td>\n<td>291.0</td>\n<td>353.0</td>\n</tr>\n<tr>\n<td>OTU4</td>\n<td>371.0</td>\n<td>80.0</td>\n<td>319.0</td>\n<td>345.0</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"font-colorff9800-taxonomy_tablefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-taxonomy_tablefont\"></a> <font color=#FF9800 >taxonomy_table</font></h2>\n<p>分类表</p>\n<div style=\"overflow-x:auto;\">\n<table>\n<table>\n<thead>\n<tr>\n<th>Kingdom</th>\n<th>Phylum</th>\n<th>Class</th>\n<th>Order</th>\n<th>Family</th>\n<th>Genus</th>\n<th>Species</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OTU1</td>\n<td>d__Bacteria</td>\n<td>p__Desulfobacterota</td>\n<td>c__Desulfobacteria</td>\n<td>o__Desulfatiglandales</td>\n<td>f__Desulfatiglandaceae</td>\n<td colspan=\"2\">g__Desulfatiglans</td>\n</tr>\n<tr>\n<td>OTU2</td>\n<td>d__Bacteria</td>\n<td>p__Sva0485</td>\n<td>c__Sva0485</td>\n<td>o__Sva0485</td>\n<td>f__Sva0485</td>\n<td>g__Sva0485</td>\n<td>s__uncultured_hydrocarbon</td>\n</tr>\n<tr>\n<td>OTU3</td>\n<td>d__Bacteria</td>\n<td>p__Desulfobacterota</td>\n<td>c__Syntrophobacteria</td>\n<td>o__Syntrophobacterales</td>\n<td>f__uncultured</td>\n<td>g__uncultured</td>\n<td>s__uncultured_delta</td>\n</tr>\n<tr>\n<td>OTU4</td>\n<td>d__Bacteria</td>\n<td>p__Myxococcota</td>\n<td>c__Polyangia</td>\n<td>o__Polyangiales</td>\n<td>f__Sandaracinaceae</td>\n<td colspan=\"2\">g__uncultured</td>\n</tr>\n</tbody>\n</table>\n</table>\n</div>\n<h2 id=\"font-colorff9800-sample_infofont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-sample_infofont\"></a> <font color=#FF9800 >sample_info</font></h2>\n<p>样本元数据</p>\n<table>\n<thead>\n<tr>\n<th>SampleID</th>\n<th>Group</th>\n<th>Type</th>\n<th>Saline</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Sample 1</td>\n<td>G1</td>\n<td>T1</td>\n<td>Non-saline</td>\n</tr>\n<tr>\n<td>Sample 2</td>\n<td>G1</td>\n<td>T1</td>\n<td>Non-saline</td>\n</tr>\n<tr>\n<td>Sample 3</td>\n<td>G2</td>\n<td>T1</td>\n<td>Saline</td>\n</tr>\n<tr>\n<td>Sample 4</td>\n<td>G2</td>\n<td>T2</td>\n<td>Saline</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"font-colorff9800-env_datafont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-env_datafont\"></a> <font color=#FF9800 >env_data</font></h2>\n<p>环境因子</p>\n<table>\n<thead>\n<tr>\n<th>SampleID</th>\n<th>Depth</th>\n<th>Longitude</th>\n<th>Latitude</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Sample 1</td>\n<td>0</td>\n<td>23.0</td>\n<td>20</td>\n</tr>\n<tr>\n<td>Sample 2</td>\n<td>10</td>\n<td>35.0</td>\n<td>44.0</td>\n</tr>\n<tr>\n<td>Sample 3</td>\n<td>20</td>\n<td>43.0</td>\n<td>70.0</td>\n</tr>\n<tr>\n<td>Sample 4</td>\n<td>30</td>\n<td>60.0</td>\n<td>69.0</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"font-colorff9800-phylo_treefont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-phylo_treefont\"></a> <font color=#FF9800 >phylo_tree</font></h2>\n<p>进化树</p>\n<h1 id=\"font-colorff0000-3-导入数据font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-3-导入数据font\"></a> <font color=#FF0000 >3. 导入数据</font></h1>\n<ul>\n<li>\n<p>加载 R 包</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">library<span class=\"token punctuation\">(</span>microeco<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>ape<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>qiime2R<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># use pipe operator in magrittr package</span>\nlibrary<span class=\"token punctuation\">(</span>magrittr<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># set.seed is used to fix the random number generation to make the results repeatable</span>\nset.seed<span class=\"token punctuation\">(</span><span class=\"token number\">123</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># make the plotting background same with the tutorial</span>\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\ntheme_set<span class=\"token punctuation\">(</span>theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>导入数据</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 单独导入环境因子文件</span>\nenv_data <span class=\"token operator\">&lt;-</span> read.delim<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/lujia16S/Analysis_20200907/Ordination_analyses/env4.txt\"</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> row.names <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 定义数据导入函数</span>\nqiimed2meco <span class=\"token operator\">&lt;-</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span>ASV_data<span class=\"token punctuation\">,</span> sample_data<span class=\"token punctuation\">,</span> taxonomy_data<span class=\"token punctuation\">,</span> phylo_tree <span class=\"token operator\">=</span> <span class=\"token keyword\">NULL</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token comment\"># Read ASV data</span>\n\tASV <span class=\"token operator\">&lt;-</span> as.data.frame<span class=\"token punctuation\">(</span>read_qza<span class=\"token punctuation\">(</span>ASV_data<span class=\"token punctuation\">)</span><span class=\"token operator\">$</span>data<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\">#  Read metadata</span>\n\tmetadata <span class=\"token operator\">&lt;-</span> read_q2metadata<span class=\"token punctuation\">(</span>sample_data<span class=\"token punctuation\">)</span>\n\trownames<span class=\"token punctuation\">(</span>metadata<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;-</span> as.character<span class=\"token punctuation\">(</span>metadata<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># Read taxonomy table</span>\n\ttaxa_table <span class=\"token operator\">&lt;-</span> read_qza<span class=\"token punctuation\">(</span>taxonomy_data<span class=\"token punctuation\">)</span>\n\ttaxa_table <span class=\"token operator\">&lt;-</span> parse_taxonomy<span class=\"token punctuation\">(</span>taxa_table<span class=\"token operator\">$</span>data<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># Make the taxonomic table clean, this is very important.</span>\n\ttaxa_table <span class=\"token percent-operator operator\">%&lt;>%</span> tidy_taxonomy\n\t<span class=\"token comment\"># Read phylo tree</span>\n\t<span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>is.null<span class=\"token punctuation\">(</span>phylo_tree<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>\n\t\tphylo_tree <span class=\"token operator\">&lt;-</span> read_qza<span class=\"token punctuation\">(</span>phylo_tree<span class=\"token punctuation\">)</span><span class=\"token operator\">$</span>data\n\t<span class=\"token punctuation\">&#125;</span>\n\tdataset <span class=\"token operator\">&lt;-</span> microtable<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>sample_table <span class=\"token operator\">=</span> metadata<span class=\"token punctuation\">,</span> tax_table <span class=\"token operator\">=</span> taxa_table<span class=\"token punctuation\">,</span> otu_table <span class=\"token operator\">=</span> ASV<span class=\"token punctuation\">,</span> phylo_tree <span class=\"token operator\">=</span> phylo_tree<span class=\"token punctuation\">)</span>\n\tdataset\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># 导入本地数据，包括OTU表、样本元数据、分类表、tree文件。这几个文件均有QIIME2生成。</span>\nmeco_dataset <span class=\"token operator\">&lt;-</span> qiimed2meco<span class=\"token punctuation\">(</span>ASV_data <span class=\"token operator\">=</span> <span class=\"token string\">\"E:/Researches/lujia16S/Analysis_20200907/dada2_table.qza\"</span><span class=\"token punctuation\">,</span> sample_data <span class=\"token operator\">=</span> <span class=\"token string\">\"E:/Researches/lujia16S/Analysis_20200907/metadata.tsv\"</span><span class=\"token punctuation\">,</span> taxonomy_data <span class=\"token operator\">=</span> <span class=\"token string\">\"E:/Researches/lujia16S/Analysis_20200907/taxonomy.qza\"</span><span class=\"token punctuation\">,</span> phylo_tree <span class=\"token operator\">=</span> <span class=\"token string\">\"E:/Researches/lujia16S/Analysis_20200907/tree.qza\"</span><span class=\"token punctuation\">)</span>\n\nmeco_dataset<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-4-数据预处理font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-4-数据预处理font\"></a> <font color=#FF0000 >4. 数据预处理</font></h1>\n<ul>\n<li>\n<p>移除未被分配到 &quot;k__Archaea&quot; 或 &quot;k__Bacteria&quot; 的 OTUs</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">meco_dataset<span class=\"token operator\">$</span>tax_table <span class=\"token percent-operator operator\">%&lt;>%</span> base<span class=\"token operator\">::</span>subset<span class=\"token punctuation\">(</span>Kingdom <span class=\"token operator\">==</span> <span class=\"token string\">\"k__Archaea\"</span> <span class=\"token operator\">|</span> Kingdom <span class=\"token operator\">==</span> <span class=\"token string\">\"k__Bacteria\"</span><span class=\"token punctuation\">)</span>\nprint<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>移除注释为线粒体和叶绿体的 OTUs</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 移除tax_table中包含taxa名字的行，无论分类等级（taxonomic ranks），不区分大小写字母。简言之，taxa = c(\"mitochondria\", \"chloroplast\")定义了删除包含mitochondria和chloroplast的行。</span>\n\nmeco_dataset<span class=\"token operator\">$</span>filter_pollution<span class=\"token punctuation\">(</span>taxa <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"mitochondria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"chloroplast\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nprint<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>为了使 otu_table、tax_table 和 phylo_tree 中的 OTUs 相同，我们再次使用 tidy_dataset () 函数</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">meco_dataset<span class=\"token operator\">$</span>tidy_dataset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nprint<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>调用 sample_sums () 检查各样本中的序列数量</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">meco_dataset<span class=\"token operator\">$</span>sample_sums<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> range<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>有时，为了减少物种数目对多样性度量的影响，我们需要进行重采样，使每个样本中的序列数量相等。函数 rarefy_samples 可以在稀疏（rarefying）前后自动调用函数 tidy_dataset。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># As an example, we use 20001 sequences in each sample</span>\nmeco_dataset<span class=\"token operator\">$</span>rarefy_samples<span class=\"token punctuation\">(</span>sample.size <span class=\"token operator\">=</span> <span class=\"token number\">20001</span><span class=\"token punctuation\">)</span>\nmeco_dataset<span class=\"token operator\">$</span>sample_sums<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> range<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-5-alpha多样性font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-5-alpha多样性font\"></a> <font color=#FF0000 >5. alpha 多样性</font></h1>\n<ul>\n<li>\n<p>然后，我们使用 cal_abund () 计算每个分类等级的分类单元丰度（taxa abundance）。此函数返回一个名为 taxa_abund 的列表，其中包含每个分类等级上的丰度信息的多个数据框。列表自动存储在 microtable object 中。</p>\n <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">meco_dataset<span class=\"token operator\">$</span>cal_abund<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return dataset$taxa_abund</span>\nclass<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token operator\">$</span>taxa_abund<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>通过 save_abund () 将 taxa abundance 保存至本地文件</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">dir.create<span class=\"token punctuation\">(</span><span class=\"token string\">\"taxa_abund\"</span><span class=\"token punctuation\">)</span>\nmeco_dataset<span class=\"token operator\">$</span>save_abund<span class=\"token punctuation\">(</span>dirpath <span class=\"token operator\">=</span> <span class=\"token string\">\"taxa_abund\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>计算 alpha 多样性。结果自动存储在 microtable object 中。<font color=#2196F3>作为示例，此处未计算系统发育多样性（phylogenetic diversity）</font>。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 若要计算Faith's phylogenetic diversity，设置PD = TRUE，计算速度会较慢</span>\nmeco_dataset<span class=\"token operator\">$</span>cal_alphadiv<span class=\"token punctuation\">(</span>PD <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># return dataset$alpha_diversity</span>\nclass<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token operator\">$</span>alpha_diversity<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># save dataset$alpha_diversity to a directory</span>\ndir.create<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_diversity\"</span><span class=\"token punctuation\">)</span>\nmeco_dataset<span class=\"token operator\">$</span>save_alphadiv<span class=\"token punctuation\">(</span>dirpath <span class=\"token operator\">=</span> <span class=\"token string\">\"alpha_diversity\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-6-β多样性font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-6-β多样性font\"></a> <font color=#FF0000 >6. β 多样性</font></h1>\n<ul>\n<li>\n<p>利用函数 cal_betadiv () 计算 beta - 多样性的距离矩阵。我们提供了四个最常用的索引：Bray-curtis、Jaccard、加权 Unifrac 和未加权 Unifrac。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># If you do not want to calculate unifrac metrics, use unifrac = FALSE</span>\n<span class=\"token comment\"># 需要GUniFrac package</span>\ninstall.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"GUniFrac\"</span><span class=\"token punctuation\">)</span>\n\nmeco_dataset<span class=\"token operator\">$</span>cal_betadiv<span class=\"token punctuation\">(</span>unifrac <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return dataset$beta_diversity</span>\nclass<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token operator\">$</span>beta_diversity<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># save dataset$beta_diversity to a directory</span>\ndir.create<span class=\"token punctuation\">(</span><span class=\"token string\">\"beta_diversity\"</span><span class=\"token punctuation\">)</span>\nmeco_dataset<span class=\"token operator\">$</span>save_betadiv<span class=\"token punctuation\">(</span>dirpath <span class=\"token operator\">=</span> <span class=\"token string\">\"beta_diversity\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-7-trans_abund-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-7-trans_abund-classfont\"></a> <font color=#FF0000 >7. trans_abund class</font></h1>\n<ul>\n<li>\n<p>绘制 Barplot。转换分类丰度数据，以便使用 ggplot2 包绘制分类单元丰度。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># create trans_abund object</span>\n<span class=\"token comment\"># use 12 Phyla with the highest abundance in the dataset.</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1 object now include the transformed abundance data t1$abund_data and other elements for the following plotting</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>绘制 Barplot. We remove the sample names in x axis and add the facet to show abundance according to groups.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>plot_bar<span class=\"token punctuation\">(</span>others_color <span class=\"token operator\">=</span> <span class=\"token string\">\"grey70\"</span><span class=\"token punctuation\">,</span> facet <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> xtext_keep <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> legend_text_italic <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return a ggplot2 object</span>\n\n<span class=\"token comment\"># 获取组内平均值。The groupmean parameter can be used to obtain the group-mean barplot.</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> groupmean <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_bar<span class=\"token punctuation\">(</span>others_color <span class=\"token operator\">=</span> <span class=\"token string\">\"grey70\"</span><span class=\"token punctuation\">,</span> legend_text_italic <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Then alluvial plot is implemented in the plot_bar function.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"ggalluvial\"</span><span class=\"token punctuation\">)</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># use_alluvium = TRUE make the alluvial plot, clustering =TRUE can be used to reorder the samples by clustering</span>\nt1<span class=\"token operator\">$</span>plot_bar<span class=\"token punctuation\">(</span>use_alluvium <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> clustering <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> xtext_type_hor <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> xtext_size <span class=\"token operator\">=</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>The box plot is an excellent way to intuitionally show data distribution across groups.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># show 15 taxa at Class level</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Class\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">15</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_box<span class=\"token punctuation\">(</span>group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/show_15_taxa_at_Class_level.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/show_15_taxa_at_Class_level.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"show 15 taxa at Class level\" /></p>\n<ul>\n<li>\n<p>Then we show the heatmap with the high abundant genera.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># show 40 taxa at Genus level</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">40</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_heatmap<span class=\"token punctuation\">(</span>facet <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> xtext_keep <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> withmargin <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Then, we show the pie chart.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> groupmean <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># all pie chart in one row</span>\nt1<span class=\"token operator\">$</span>plot_pie<span class=\"token punctuation\">(</span>facet_nrow <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-8-trans_venn-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-8-trans_venn-classfont\"></a> <font color=#FF0000 >8. trans_venn class</font></h1>\n<ul>\n<li>\n<p>The trans_venn class is used for venn analysis. To analyze the unique and shared OTUs of groups, we first merge samples according to the “Group” column of sample_table.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># merge samples as one community for each group</span>\ndataset1 <span class=\"token operator\">&lt;-</span> meco_dataset<span class=\"token operator\">$</span>merge_samples<span class=\"token punctuation\">(</span>use_group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># dataset1 is a new microtable object</span>\n<span class=\"token comment\"># create trans_venn object</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_venn<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset1<span class=\"token punctuation\">,</span> ratio <span class=\"token operator\">=</span> <span class=\"token string\">\"seqratio\"</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_venn<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># The integer data is OTU number</span>\n<span class=\"token comment\"># The percentage data is the sequence number/total sequence number</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>When the groups are too many to show with venn plot, we can use petal plot.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># use \"Type\" column in sample_table</span>\ndataset1 <span class=\"token operator\">&lt;-</span> meco_dataset<span class=\"token operator\">$</span>merge_samples<span class=\"token punctuation\">(</span>use_group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_venn<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset1<span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_venn<span class=\"token punctuation\">(</span>petal_plot <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Sometimes, we are interested in the unique and shared species. In another words, the composition of the unique or shared species may account for the different and similar parts of ecological characteristics across groups[10]. For this goal, we first transform the results of venn plot to the traditional species-sample table, that is, another object of microtable class.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">dataset1 <span class=\"token operator\">&lt;-</span> meco_dataset<span class=\"token operator\">$</span>merge_samples<span class=\"token punctuation\">(</span>use_group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_venn<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset1<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># transform venn results to the sample-species table, here do not consider abundance, only use presence/absence information.</span>\nt2 <span class=\"token operator\">&lt;-</span> t1<span class=\"token operator\">$</span>trans_venn_com<span class=\"token punctuation\">(</span>use_OTUs_frequency <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t2 is a new microtable class, each part is considered as a sample</span>\nclass<span class=\"token punctuation\">(</span>t2<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>We use bar plot to show the composition at the Genus level.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># calculate taxa abundance, that is, the frequency</span>\nt2<span class=\"token operator\">$</span>cal_abund<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># transform and plot</span>\nt3 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> t2<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span>\nt3<span class=\"token operator\">$</span>plot_bar<span class=\"token punctuation\">(</span>bar_type <span class=\"token operator\">=</span> <span class=\"token string\">\"part\"</span><span class=\"token punctuation\">,</span> legend_text_italic <span class=\"token operator\">=</span> T<span class=\"token punctuation\">,</span> ylab_title <span class=\"token operator\">=</span> <span class=\"token string\">\"Frequency (%)\"</span><span class=\"token punctuation\">,</span> xtext_type_hor <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>We also try to use pie chart to show the compositions at the Phylum level</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t3 <span class=\"token operator\">&lt;-</span> trans_abund<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> t2<span class=\"token punctuation\">,</span> taxrank <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">,</span> ntaxa <span class=\"token operator\">=</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\nt3<span class=\"token operator\">$</span>plot_pie<span class=\"token punctuation\">(</span>facet_nrow <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> use_colors <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span>RColorBrewer<span class=\"token operator\">::</span>brewer.pal<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Dark2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"grey50\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-9-trans_alpha-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-9-trans_alpha-classfont\"></a> <font color=#FF0000 >9. trans_alpha class</font></h1>\n<ul>\n<li>\n<p>Alpha diversity can be transformed and plotted using trans_alpha class. Creating trans_alpha object can return two data frame: alpha_data and alpha_stat.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1 <span class=\"token operator\">&lt;-</span> trans_alpha<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$alpha_stat</span>\nt1<span class=\"token operator\">$</span>alpha_stat<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Then, we test the differences among groups using the KW rank sum test and anova with multiple comparisons.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>cal_diff<span class=\"token punctuation\">(</span>method <span class=\"token operator\">=</span> <span class=\"token string\">\"KW\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_alpha_diff</span>\nt1<span class=\"token operator\">$</span>res_alpha_diff<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th>|Groups</th>\n<th>Measure</th>\n<th>Test method</th>\n<th>p.value</th>\n<th>Significance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1|T16 vs T18</td>\n<td>Observed</td>\n<td>KW</td>\n<td>2.601895e-03</td>\n<td>**</td>\n</tr>\n<tr>\n<td>2|T16 vs T20</td>\n<td>Observed</td>\n<td>KW</td>\n<td>3.011399e-08</td>\n<td>***</td>\n</tr>\n<tr>\n<td>3|T16 vs T21</td>\n<td>Observed</td>\n<td>KW</td>\n<td>2.174162e-04</td>\n<td>***</td>\n</tr>\n<tr>\n<td>4|T16 vs T17</td>\n<td>Observed</td>\n<td>KW</td>\n<td>1.234229e-03</td>\n<td>**</td>\n</tr>\n<tr>\n<td>5|T18 vs T20</td>\n<td>Observed</td>\n<td>KW</td>\n<td>7.319258e-08</td>\n<td>***</td>\n</tr>\n</tbody>\n</table>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>cal_diff<span class=\"token punctuation\">(</span>method <span class=\"token operator\">=</span> <span class=\"token string\">\"anova\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_alpha_diff</span>\nt1<span class=\"token operator\">$</span>res_alpha_diff<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n  <div style=\"overflow-x:auto;\">\n  <table>\n<table>\n<thead>\n<tr>\n<th>Observed</th>\n<th>Chao1</th>\n<th>ACE</th>\n<th>Shannon</th>\n<th>Simpson</th>\n<th>InvSimpson</th>\n<th>Fisher</th>\n<th>Coverage</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>T18</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>c</td>\n</tr>\n<tr>\n<td>T16</td>\n<td>b</td>\n<td>b</td>\n<td>b</td>\n<td>a</td>\n<td>a</td>\n<td>a</td>\n<td>b</td>\n<td>b</td>\n</tr>\n<tr>\n<td>T17</td>\n<td>c</td>\n<td>c</td>\n<td>c</td>\n<td>b</td>\n<td>a</td>\n<td>b</td>\n<td>c</td>\n<td>b</td>\n</tr>\n<tr>\n<td>T21</td>\n<td>d</td>\n<td>d</td>\n<td>d</td>\n<td>c</td>\n<td>a</td>\n<td>c</td>\n<td>d</td>\n<td>b</td>\n</tr>\n<tr>\n<td>T20</td>\n<td>e</td>\n<td>e</td>\n<td>e</td>\n<td>d</td>\n<td>b</td>\n<td>d</td>\n<td>e</td>\n<td>a</td>\n</tr>\n</tbody>\n</table>\n  </table>\n  </div>\n</li>\n<li>\n<p>Now, let us plot the mean and se of alpha diversity for each group, and add the duncan.test (agricolae package) result.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>plot_alpha<span class=\"token punctuation\">(</span>add_letter <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"Chao1\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>We can also use the boxplot to show the paired comparisons directly.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>plot_alpha<span class=\"token punctuation\">(</span>pair_compare <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"Chao1\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-10-trans_beta-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-10-trans_beta-classfont\"></a> <font color=#FF0000 >10. trans_beta class</font></h1>\n<ul>\n<li>\n<p>The distance matrix of beta diversity can be transformed and plotted using trans_beta class. The analysis referred to the beta diversity in this class mainly include ordination, group distance, clustering and manova. We first show the ordination using PCoA.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># we first create an object and select PCoA for ordination</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_beta<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"bray\"</span><span class=\"token punctuation\">,</span> ordination <span class=\"token operator\">=</span> <span class=\"token string\">\"PCoA\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1$res_ordination is the ordination result list</span>\nclass<span class=\"token punctuation\">(</span>t1<span class=\"token operator\">$</span>res_ordination<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># plot the PCoA result</span>\nt1<span class=\"token operator\">$</span>plot_ordination<span class=\"token punctuation\">(</span>plot_color <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> plot_shape <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> plot_group_ellipse <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Then we plot and compare the group distances.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># calculate and plot sample distances within groups</span>\nt1<span class=\"token operator\">$</span>cal_group_distance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_group_distance</span>\nt1<span class=\"token operator\">$</span>plot_group_distance<span class=\"token punctuation\">(</span>distance_pair_stat <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># calculate and plot sample distances between groups (报错：错误: Insufficient values in manual scale. 10 needed but only 8 provided.)</span>\nt1<span class=\"token operator\">$</span>cal_group_distance<span class=\"token punctuation\">(</span>within_group <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_group_distance<span class=\"token punctuation\">(</span>distance_pair_stat <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Clustering plot is also a frequently used method.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># use replace_name to set the label name, group parameter used to set the color (报错：找不到对象'dataset')</span>\nt1<span class=\"token operator\">$</span>plot_clustering<span class=\"token punctuation\">(</span>group <span class=\"token operator\">=</span> <span class=\"token string\">\"Indexs\"</span><span class=\"token punctuation\">,</span> replace_name <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Water-depth(m)\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Indexs\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>perMANOVA is often used in the differential test of distances among groups.</p>\n <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># manova for all groups</span>\nt1<span class=\"token operator\">$</span>cal_manova<span class=\"token punctuation\">(</span>cal_manova_all <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>res_manova<span class=\"token operator\">$</span>aov.tab<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th colspan=\"7\">ermutation: free</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>umber of permutations: 999</td>\n</tr>\n<tr>\n<td>erms added sequentially (first to last)</td>\n</tr>\n<tr>\n<td>Df</td>\n<td>SumsOfSqs</td>\n<td>MeanSqs</td>\n<td>F.Model</td>\n<td>R<sup>2</sup></td>\n<td>Pr(&gt;F)</td>\n</tr>\n<tr>\n<td>ite</td>\n<td>4</td>\n<td>15.669</td>\n<td>3.9173</td>\n<td>19.445</td>\n<td>0.48077</td>\n<td>0.001 ***</td>\n</tr>\n<tr>\n<td>esiduals</td>\n<td>84</td>\n<td>16.923</td>\n<td colspan=\"2\">0.2015</td>\n<td>0.51923</td>\n</tr>\n<tr>\n<td>otal</td>\n<td>88</td>\n<td colspan=\"3\">32.592</td>\n<td>1.00000</td>\n</tr>\n</tbody>\n</table>\n<p>&gt; Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># manova for each paired groups</span>\nt1<span class=\"token operator\">$</span>cal_manova<span class=\"token punctuation\">(</span>cal_manova_paired <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>res_manova<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th>Groups</th>\n<th>measure</th>\n<th>permutations</th>\n<th>R<sup>2</sup></th>\n<th>p.value</th>\n<th>Significance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>T16 vs T18</td>\n<td>bray</td>\n<td>999</td>\n<td>0.2748773</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>2</td>\n<td>T16 vs T20</td>\n<td>bray</td>\n<td>999</td>\n<td>0.4539103</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>3</td>\n<td>T16 vs T21</td>\n<td>bray</td>\n<td>999</td>\n<td>0.4102009</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>4</td>\n<td>T16 vs T17</td>\n<td>bray</td>\n<td>999</td>\n<td>0.2243404</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>5</td>\n<td>T18 vs T20</td>\n<td>bray</td>\n<td>999</td>\n<td>0.3736482</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>6</td>\n<td>T18 vs T21</td>\n<td>bray</td>\n<td>999</td>\n<td>0.3504104</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>7</td>\n<td>T18 vs T17</td>\n<td>bray</td>\n<td>999</td>\n<td>0.2147055</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>8</td>\n<td>T20 vs T21</td>\n<td>bray</td>\n<td>999</td>\n<td>0.3575765</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>9</td>\n<td>T20 vs T17</td>\n<td>bray</td>\n<td>999</td>\n<td>0.4589248</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>10</td>\n<td>T21 vs T17</td>\n<td>bray</td>\n<td>999</td>\n<td>0.4395176</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n</tbody>\n</table>\n <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"> <span class=\"token comment\"># manova for specified group set: here \"Group + Type\"</span>\nt1<span class=\"token operator\">$</span>cal_manova<span class=\"token punctuation\">(</span>cal_manova_set <span class=\"token operator\">=</span> <span class=\"token string\">\"Site+ Indexs\"</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>res_manova<span class=\"token operator\">$</span>aov.tab<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th colspan=\"7\">Permutation: free</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td colspan=\"7\">Number of permutations: 999</td>\n</tr>\n<tr>\n<td colspan=\"7\">Terms added sequentially (first to last)</td>\n</tr>\n<tr>\n<td>Df</td>\n<td>SumsOfSqs</td>\n<td>MeanSqs</td>\n<td>F.Model</td>\n<td>R<sup>2</sup></td>\n<td>Pr(F)</td>\n</tr>\n<tr>\n<td>Site</td>\n<td>4</td>\n<td>15.669</td>\n<td>4</td>\n<td>0</td>\n<td>0.48077</td>\n<td>1</td>\n</tr>\n<tr>\n<td>Indexs</td>\n<td>84</td>\n<td>16.923</td>\n<td>0</td>\n<td>0</td>\n<td>0.51923</td>\n<td>1</td>\n</tr>\n<tr>\n<td>Residuals</td>\n<td>0</td>\n<td>0.000</td>\n<td colspan=\"2\">Inf</td>\n<td colspan=\"2\">0.00000</td>\n</tr>\n<tr>\n<td>Total</td>\n<td>88</td>\n<td colspan=\"3\">32.592</td>\n<td colspan=\"2\">1.00000</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"font-colorff0000-11-trans_diff-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-11-trans_diff-classfont\"></a> <font color=#FF0000 >11. trans_diff class</font></h1>\n<ul>\n<li>\n<p>Differential abundance test is a very important part in the microbial community data analysis. It can be used to find the significant taxa in determining the community differences across groups. Currently, trans_diff class have three famous approaches to perform this analysis: metastat[11], LEfSe[12] and random forest. Metastat depends on the permutations and t-test and performs well on the sparse data. It is used for the comparisons between two groups.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># metastat analysis at Genus level</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_diff<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> method <span class=\"token operator\">=</span> <span class=\"token string\">\"metastat\"</span><span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> metastat_taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1$res_metastat is the result</span>\n<span class=\"token comment\"># t1$res_metastat_group_matrix is the group comparisons order for plotting</span>\n<span class=\"token comment\"># plot the first paired groups, choose_group = 1</span>\nt1<span class=\"token operator\">$</span>plot_metastat<span class=\"token punctuation\">(</span>use_number <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> qvalue <span class=\"token operator\">=</span> <span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> choose_group <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>LEfSe combines the non-parametric test and linear discriminant analysis. We implement this approach in this package instead of the python version.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1 <span class=\"token operator\">&lt;-</span> trans_diff<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> method <span class=\"token operator\">=</span> <span class=\"token string\">\"lefse\"</span><span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> alpha <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> lefse_subgroup <span class=\"token operator\">=</span> <span class=\"token keyword\">NULL</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1$res_lefse is the LEfSe result</span>\n<span class=\"token comment\"># t1$res_abund is the abundance information</span>\nt1<span class=\"token operator\">$</span>plot_lefse_bar<span class=\"token punctuation\">(</span>LDA_score <span class=\"token operator\">=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>We can also plot the abundance of taxa detected using LEfSe.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>plot_diff_abund<span class=\"token punctuation\">(</span>use_number <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>Then, we show the cladogram of the differential features in the taxonomic tree. There are too many taxa in this dataset. As an example, we only use the highest 200 abundant taxa in the tree and 50 differential features. We only show the full taxonomic label at Phylum level and use letters at other levels to reduce the text overlap.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># clade_label_level 5 represent phylum level in this analysis</span>\n<span class=\"token comment\"># require ggtree package</span>\nt1<span class=\"token operator\">$</span>plot_lefse_cladogram<span class=\"token punctuation\">(</span>use_taxa_num <span class=\"token operator\">=</span> <span class=\"token number\">200</span><span class=\"token punctuation\">,</span> use_feature_num <span class=\"token operator\">=</span> <span class=\"token number\">50</span><span class=\"token punctuation\">,</span> clade_label_level <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>There may be a problem related with the taxonomic labels in the plot. When the levels used are too many, the taxonomic labels may have too much overlap. However, if we only indicate the Phylum labels, the taxa in the legend with marked letters are too many. At this time, you can select the taxa that you want to show in the plot manually like the following operation.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># choose some taxa according to the positions in the previous picture; those taxa labels have minimum overlap</span>\nuse_labels <span class=\"token operator\">&lt;-</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"c__Deltaproteobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"c__Actinobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"o__Rhizobiales\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"p__Proteobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"p__Bacteroidetes\"</span><span class=\"token punctuation\">,</span> \n\t<span class=\"token string\">\"o__Micrococcales\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"p__Acidobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"p__Verrucomicrobia\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"p__Firmicutes\"</span><span class=\"token punctuation\">,</span> \n\t<span class=\"token string\">\"p__Chloroflexi\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"c__Acidobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"c__Gammaproteobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"c__Betaproteobacteria\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"c__KD4-96\"</span><span class=\"token punctuation\">,</span>\n\t<span class=\"token string\">\"c__Bacilli\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"o__Gemmatimonadales\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"f__Gemmatimonadaceae\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"o__Bacillales\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"o__Rhodobacterales\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># then use parameter select_show_labels to show</span>\nt1<span class=\"token operator\">$</span>plot_lefse_cladogram<span class=\"token punctuation\">(</span>use_taxa_num <span class=\"token operator\">=</span> <span class=\"token number\">200</span><span class=\"token punctuation\">,</span> use_feature_num <span class=\"token operator\">=</span> <span class=\"token number\">50</span><span class=\"token punctuation\">,</span> select_show_labels <span class=\"token operator\">=</span> use_labels<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Now we can see that more taxa names appear in the tree</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>If you are interested in taxonomic tree, you can also use metacoder package[13] to plot the taxonomic tree based on the selected taxa. We do not show the usage here.</p>\n</li>\n<li>\n<p>The third approach is rf, which depends on the random forest[14, 15] and the non-parametric test. The current method can calculate random forest by bootstrapping like the method in LEfSe and only use the significant features. MeanDecreaseGini is selected as the indicator value in the analysis.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># use Genus level for parameter rf_taxa_level, if you want to use all taxa, change to \"all\"</span>\n<span class=\"token comment\"># nresam = 1 and boots = 1 represent no bootstrapping and use all samples directly</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_diff<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> method <span class=\"token operator\">=</span> <span class=\"token string\">\"rf\"</span><span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> rf_taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1$res_rf is the result stored in the object</span>\n<span class=\"token comment\"># plot the result</span>\nt2 <span class=\"token operator\">&lt;-</span> t1<span class=\"token operator\">$</span>plot_diff_abund<span class=\"token punctuation\">(</span>use_number <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> only_abund_plot <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\ngridExtra<span class=\"token operator\">::</span>grid.arrange<span class=\"token punctuation\">(</span>t2<span class=\"token operator\">$</span>p1<span class=\"token punctuation\">,</span> t2<span class=\"token operator\">$</span>p2<span class=\"token punctuation\">,</span> ncol<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> nrow <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> widths <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># the middle asterisk represent the significances</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-12-trans_env-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-12-trans_env-classfont\"></a> <font color=#FF0000 >12. trans_env class</font></h1>\n<ul>\n<li>\n<p>分析环境因子对微生物群落结构和组装的影响：RDA 分析 (db-RDA 和 RDA).</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># add_data is used to add the environmental data</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_env<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">7</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># use bray-curtis distance to do dbrda</span>\nt1<span class=\"token operator\">$</span>cal_rda<span class=\"token punctuation\">(</span>use_dbrda <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> use_measure <span class=\"token operator\">=</span> <span class=\"token string\">\"bray\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># t1$res_rda is the result list stored in the object</span>\nt1<span class=\"token operator\">$</span>trans_rda<span class=\"token punctuation\">(</span>adjust_arrow_length <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> max_perc_env <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># t1$res_rda_trans is the transformed result for plotting</span>\nt1<span class=\"token operator\">$</span>plot_rda<span class=\"token punctuation\">(</span>plot_color <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># use Genus</span>\nt1<span class=\"token operator\">$</span>cal_rda<span class=\"token punctuation\">(</span>use_dbrda <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># As the main results of RDA are related with the projection and angles between different arrows,</span>\n<span class=\"token comment\"># we adjust the length of the arrow to show them clearly using several parameters.</span>\nt1<span class=\"token operator\">$</span>trans_rda<span class=\"token punctuation\">(</span>show_taxa <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> adjust_arrow_length <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> max_perc_env <span class=\"token operator\">=</span> <span class=\"token number\">1500</span><span class=\"token punctuation\">,</span> max_perc_tax <span class=\"token operator\">=</span> <span class=\"token number\">3000</span><span class=\"token punctuation\">,</span> min_perc_env <span class=\"token operator\">=</span> <span class=\"token number\">200</span><span class=\"token punctuation\">,</span> min_perc_tax <span class=\"token operator\">=</span> <span class=\"token number\">300</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># t1$res_rda_trans is the transformed result for plotting</span>\nt1<span class=\"token operator\">$</span>plot_rda<span class=\"token punctuation\">(</span>plot_color <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Mantel test 用于检测环境因子和距离矩阵之间是否具有显著的相关性。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>cal_mantel<span class=\"token punctuation\">(</span>use_measure <span class=\"token operator\">=</span> <span class=\"token string\">\"bray\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_mantel</span>\nt1<span class=\"token operator\">$</span>res_mantel<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n  <div style=\"overflow-x:auto;\">\n  <table>\n<table>\n<thead>\n<tr>\n<th>|variable_name</th>\n<th>cor_method</th>\n<th>corr_res</th>\n<th>p_res</th>\n<th>significance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1|<strong>TN</strong></td>\n<td>pearson</td>\n<td>0.5571885</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>2|<strong>TC</strong></td>\n<td>pearson</td>\n<td>0.5712239</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>3|<strong>TS</strong></td>\n<td>pearson</td>\n<td>0.2665453</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>4|<strong>TOC</strong></td>\n<td>pearson</td>\n<td>0.3540337</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>5|<strong>Salinity</strong></td>\n<td>pearson</td>\n<td>0.2782537</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>6|Temperature</td>\n<td>pearson</td>\n<td>0.5856050</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>7|<strong>Dissolved.oxygen</strong></td>\n<td>pearson</td>\n<td>0.4358422</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>8|Surface.chlorophyll.concentrations</td>\n<td>pearson</td>\n<td>0.2586823</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>9|pH</td>\n<td>pearson</td>\n<td>0.4498964</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>10</td>\n<td><strong>PAR</strong></td>\n<td>pearson</td>\n<td>0.1712861</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>11</td>\n<td>Density</td>\n<td>pearson</td>\n<td>0.5682679</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n<tr>\n<td>12</td>\n<td>Turbidity</td>\n<td>pearson</td>\n<td>0.2260436</td>\n<td>0.001</td>\n<td>***</td>\n</tr>\n</tbody>\n</table>\n  </table></div>\n</li>\n<li>\n<p>环境变量与分类群（taxa）的相关性对分析和推断影响群落结构的因素具有重要意义。在本例中，我们首先进行了差异丰度检验（differential abundance test）和随机森林分析（random forest），得到了重要的属（Genus）。然后利用这些分类单元进行相关性分析。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># first create trans_diff object</span>\nt2 <span class=\"token operator\">&lt;-</span> trans_diff<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> method <span class=\"token operator\">=</span> <span class=\"token string\">\"rf\"</span><span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> rf_taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"Genus\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># then create trans_env object</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_env<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">7</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># calculate correlation</span>\nt1<span class=\"token operator\">$</span>cal_cor<span class=\"token punctuation\">(</span>use_data <span class=\"token operator\">=</span> <span class=\"token string\">\"other\"</span><span class=\"token punctuation\">,</span> p_adjust_method <span class=\"token operator\">=</span> <span class=\"token string\">\"fdr\"</span><span class=\"token punctuation\">,</span> other_taxa <span class=\"token operator\">=</span> t2<span class=\"token operator\">$</span>res_rf<span class=\"token operator\">$</span>Taxa<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">60</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_cor </span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>使用 ggplot2 或 pheatmap 进行可视化</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># default ggplot2 method</span>\nt1<span class=\"token operator\">$</span>plot_corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># clustering heatmap; require pheatmap package</span>\nt1<span class=\"token operator\">$</span>plot_corr<span class=\"token punctuation\">(</span>pheatmap <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/7%E4%B8%AA%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%8E%E5%88%86%E7%B1%BB%E7%BE%A4ggplot2.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/7%E4%B8%AA%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%8E%E5%88%86%E7%B1%BB%E7%BE%A4ggplot2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"7个环境变量与分类群ggplot2\" /></p>\n<p><img src=\"#/images/lujia/7%E4%B8%AA%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%8E%E5%88%86%E7%B1%BB%E7%BE%A4%E7%9B%B8%E5%85%B3%E6%80%A7_pheatmap.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/7%E4%B8%AA%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%8E%E5%88%86%E7%B1%BB%E7%BE%A4%E7%9B%B8%E5%85%B3%E6%80%A7_pheatmap.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"7个环境变量与分类群相关性_pheatmap\" /></p>\n<ul>\n<li>\n<p>各组内的环境变量与分类群 taxa 之间的关系</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># calculate correlations for different groups using parameter by_group</span>\nt1<span class=\"token operator\">$</span>cal_cor<span class=\"token punctuation\">(</span>by_group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> use_data <span class=\"token operator\">=</span> <span class=\"token string\">\"other\"</span><span class=\"token punctuation\">,</span> p_adjust_method <span class=\"token operator\">=</span> <span class=\"token string\">\"fdr\"</span><span class=\"token punctuation\">,</span> other_taxa <span class=\"token operator\">=</span> t2<span class=\"token operator\">$</span>res_rf<span class=\"token operator\">$</span>Taxa<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">60</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_cor</span>\nt1<span class=\"token operator\">$</span>plot_corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/correlations_between_environmental_variables_and_60_taxa.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/correlations_between_environmental_variables_and_60_taxa.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"correlations_between_environmental_variables_and_60_taxa\" /></p>\n<ul>\n<li>\n<p>环境因子与 alpha - 多样性之间的关系</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1 <span class=\"token operator\">&lt;-</span> trans_env<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">7</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># use add_abund_table parameter to add the extra data table</span>\nt1<span class=\"token operator\">$</span>cal_cor<span class=\"token punctuation\">(</span>add_abund_table <span class=\"token operator\">=</span> meco_dataset<span class=\"token operator\">$</span>alpha_diversity<span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>plot_corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/relationship_between_7_environmental_factors_and_alpha_diversity.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/relationship_between_7_environmental_factors_and_alpha_diversity.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"relationship_between_7_environmental_factors_and_alpha_diversity\" /></p>\n<h1 id=\"font-colorff0000-13-trans_nullmodel-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-13-trans_nullmodel-classfont\"></a> <font color=#FF0000 >13. trans_nullmodel class</font></h1>\n<ul>\n<li>\n<p>近几十年来，系统发育分析和空模型（null model）的结合，通过增加系统发育维度（phylogeny dimension），更加有力地促进了生态位和中性（niche and neutral）对群落组装影响的推断 [16，17]。trans_nullmodel class 提供了一个封装，包括对系统发育信号、beta 平均成对系统发育距离（beta mean pairwise phylogenetic distance，betaMPD）、beta 平均最近分类单元距离（beta mean nearest taxon distance，betaMNTD）、beta 最近分类单元指数（beta nearest taxon index，betaNTI）、beta 净相关指数（beta net relatedness index，betaNRI）和基于 Bray-Curtis 的 Raup-Crick（Bray-Curtis-based Raup-Crick，RCbray）的计算。系统发育信号分析的方法基于 mantel 相关图（mantel correlogram）[18]，与其他方法相比，系统发育信号的变化是直观而清晰的。betaMNTD 和 betaMPD 的算法已经过优化，比 picante 包中的算法更快 [3]。RCbray 和 betaNTI（或 betaNRI）之间的组合可用于推断在特定假设下支配群落装配（community assembly）的每个生态过程（ecological process）的强度 [17]。这可以通过函数 cal_process () 来解析每个推断进程（ecological process）的百分比来实现。<font color=#2196F3 ><strong>我们首先检查系统发育信号：</strong></font></p>\n <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># generate trans_nullmodel object; use 10000 OTUs as example</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_nullmodel<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">,</span> taxa_number <span class=\"token operator\">=</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># use TOC as the test variable (__报错：Error in cor(as.vector(xdis), ydis, method = method, use = use) : </span>\n  cov<span class=\"token operator\">/</span>cor中有遗漏值__<span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>cal_mantel_corr<span class=\"token punctuation\">(</span>use_env <span class=\"token operator\">=</span> <span class=\"token string\">\"TOC\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># return t1$res_mantel_corr</span>\n<span class=\"token comment\"># plot the mantel correlogram(__报错：Error in names(x) &lt;- value : 'names'属性的长度[4]必需和矢量的长度[0]一样__)</span>\nt1<span class=\"token operator\">$</span>plot_mantel_corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>betaNRI（ses.betampd）用于显示 “basal” 系统发育转换（phylogenetic turnover）[18]。与 betaNTI 相比，它能捕获更多与深层系统发育（deep phylogeny）相关的转换信息（turnover information）。值得注意的是，经过几十年的发展，出现了许多空模型（null models）。在 trans-nullmodel class 中，我们随机化了物种的系统发育相关性。这种洗牌方法（shuffling approach）固定了观察到的物种 α- 多样性和 β- 多样性的水平，以探讨观察到的系统发育转换是否与空模型（物种间的系统发育关系是随机的）显著不同。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 运行500次null model</span>\nt1<span class=\"token operator\">$</span>cal_ses_betampd<span class=\"token punctuation\">(</span>runs<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span> abundance.weighted <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 返回t1$res_ses_betampd</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>可以使用 trans_beta class 中的 plot_group_distance function 绘制 betaNRI 图。结果表明 T20 和 T21 的平均 betaNRI 显著高于其它三者，表明 T20 和 T21 中的 basal phylogenetic turnover 是高的。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 将betaNRI矩阵加入到beta_diversity列表中</span>\nmeco_dataset<span class=\"token operator\">$</span>beta_diversity<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"betaNRI\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;-</span> t1<span class=\"token operator\">$</span>res_ses_betampd\n\n<span class=\"token comment\"># 使用measure \"betaNRI\"创建trans_beta class</span>\nt2 <span class=\"token operator\">&lt;-</span> trans_beta<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"betaNRI\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># transform the distance for each group</span>\nt2<span class=\"token operator\">$</span>cal_group_distance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 结果可视化</span>\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">&lt;-</span> t2<span class=\"token operator\">$</span>plot_group_distance<span class=\"token punctuation\">(</span>distance_pair_stat <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/betaNRI_all.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/betaNRI_all.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"betaNRI all\" /></p>\n<ul>\n<li>\n<p>若要单独的对每个组进行 null model analysis，例如每个组作为一个物种池（species pool），我们可以分别为每个组计算结果。 我们发现，当分别对每个组进行 betaNRI 分析时，CW 和 TW 间的 mean betaNRI 没有显著差异，且二者均显著高于 IW ，揭示了在将每个区域视为特定物种库的条件下，CW 和 TW 中变量选择的强度（strength of variable selection）可能相似。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 创建一个列表用于存放trans_nullmodel的结果</span>\nsesbeta_each <span class=\"token operator\">&lt;-</span> list<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ngroup_col <span class=\"token operator\">&lt;-</span> <span class=\"token string\">\"Site\"</span>\nall_groups <span class=\"token operator\">&lt;-</span> unique<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token operator\">$</span>sample_table<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> group_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 对每个组分别进行计算</span>\n<span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span>i <span class=\"token keyword\">in</span> all_groups<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token comment\"># like the above operation, but need provide 'group' and 'select_group'</span>\n\ttest <span class=\"token operator\">&lt;-</span> trans_nullmodel<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> group_col<span class=\"token punctuation\">,</span> select_group <span class=\"token operator\">=</span> i<span class=\"token punctuation\">,</span> taxa_number <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data<span class=\"token punctuation\">)</span>\n\ttest<span class=\"token operator\">$</span>cal_ses_betampd<span class=\"token punctuation\">(</span>runs <span class=\"token operator\">=</span> <span class=\"token number\">500</span><span class=\"token punctuation\">,</span> abundance.weighted <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\tsesbeta_each<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;-</span> test<span class=\"token operator\">$</span>res_ses_betampd\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># 合并结果并重塑（reshape），得到一个对称矩阵（symmetrical matrix）</span>\nlibrary<span class=\"token punctuation\">(</span>reshape2<span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">&lt;-</span> lapply<span class=\"token punctuation\">(</span>sesbeta_each<span class=\"token punctuation\">,</span> melt<span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> do.call<span class=\"token punctuation\">(</span>rbind<span class=\"token punctuation\">,</span> .<span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> reshape2<span class=\"token operator\">::</span>dcast<span class=\"token punctuation\">(</span>.<span class=\"token punctuation\">,</span> Var1<span class=\"token operator\">~</span>Var2<span class=\"token punctuation\">,</span> value.var <span class=\"token operator\">=</span> <span class=\"token string\">\"value\"</span><span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> `row.names<span class=\"token operator\">&lt;-</span>`<span class=\"token punctuation\">(</span>.<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token percent-operator operator\">%>%</span> .<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> drop <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># 如同上述操作</span>\nmeco_dataset<span class=\"token operator\">$</span>beta_diversity<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"betaNRI\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;-</span> test\nt2 <span class=\"token operator\">&lt;-</span> trans_beta<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"betaNRI\"</span><span class=\"token punctuation\">)</span>\nt2<span class=\"token operator\">$</span>cal_group_distance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">&lt;-</span> t2<span class=\"token operator\">$</span>plot_group_distance<span class=\"token punctuation\">(</span>distance_pair_stat <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<p><img src=\"#/images/lujia/betaNRI_individual.jpg\" class=\"lazyload placeholder\" data-srcset=\"#/images/lujia/betaNRI_individual.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"betaNRI individual\" /></p>\n<ul>\n<li>\n<p>BetaNTI (ses.betamntd) 可用于指示系统发育的末端转换（ phylogenetic terminal turnover） [17]</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 运行500次null model</span>\nt1<span class=\"token operator\">$</span>cal_ses_betamntd<span class=\"token punctuation\">(</span>runs<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span> abundance.weighted <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 返回t1$res_ses_betamntd</span>\n\n<span class=\"token comment\"># 将betaNTI矩阵加入到beta_diversity列表中</span>\nmeco_dataset<span class=\"token operator\">$</span>beta_diversity<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"betaNTI\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;-</span> t1<span class=\"token operator\">$</span>res_ses_betamntd\n\n<span class=\"token comment\"># 使用measure \"betaNRI\"创建trans_beta class</span>\nt2 <span class=\"token operator\">&lt;-</span> trans_beta<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> group <span class=\"token operator\">=</span> <span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> measure <span class=\"token operator\">=</span> <span class=\"token string\">\"betaNTI\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># transform the distance for each group</span>\nt2<span class=\"token operator\">$</span>cal_group_distance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 结果可视化</span>\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">&lt;-</span> t2<span class=\"token operator\">$</span>plot_group_distance<span class=\"token punctuation\">(</span>distance_pair_stat <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\ng1 <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_hline<span class=\"token punctuation\">(</span>yintercept <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>cal_rcbray () 功能用于计算 RCbray (Bray-Curtis-based Raup-Crick) ，以评估成分转换（compositional turnover）是否主要受漂移控制 [19]。我们应用空模型（null model）通过从每个物种池中随机采样个体来模拟物种分布，同时保留物种发生频率（species occurrence frequency）和样本物种丰富度（sample species richness）[18]。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># result stored in t1$res_rcbray</span>\nt1<span class=\"token operator\">$</span>cal_rcbray<span class=\"token punctuation\">(</span>runs <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_rcbray</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>作为一个例子，我们还计算了引用文献 [17，18] 中所示的在群落组装（community assembly）上推断过程（ inferred processes ）所占的比例。在此示例中，具有显着 betaNTI 值（|βNTI|&gt; 2）的成对比较部分是估计的选择（Selection）造成影响； βNTI&gt; 2 代表异构选择（heterogeneous ）； βNTI&lt;-2 表示同质选择（homogeneous ）。 RCbray 值表征了随机分配（randomization）下观察到的 Bray-Curtis 和 Bray-Curtis 期望值之间的偏差大小（magnitude of deviation）。 | RCbray | &gt; 0.95 被认为是显着的。 |βNTI| &lt; 2 和 RCbray &gt; +0.95 被视为受散播限制（Dispersal Limitation）与漂移（Drift）相结合的影响。 |βNTI| &lt; 2 和 RCbray &lt; -0.95 被视为均质分散（Homogenizing Dispersal）影响的估计值。 |βNTI| &lt; 2 和 | RCbray| &lt; 0.95 估算了漂移单独作用的影响。</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># use betaNTI and rcbray to evaluate processes</span>\nt1<span class=\"token operator\">$</span>cal_process<span class=\"token punctuation\">(</span>use_betamntd <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># return t1$res_process</span>\nt1<span class=\"token operator\">$</span>res_process<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>process</th>\n<th>percentage</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>variable selection</td>\n<td>0.4341164</td>\n</tr>\n<tr>\n<td>2</td>\n<td>homogeneous selection</td>\n<td>63.6874362</td>\n</tr>\n<tr>\n<td>3</td>\n<td>dispersal limitation</td>\n<td>0.0000000</td>\n</tr>\n<tr>\n<td>4</td>\n<td>homogeneous dispersal</td>\n<td>14.8365679</td>\n</tr>\n<tr>\n<td>5</td>\n<td>drift</td>\n<td>21.0418795</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-14-trans_network-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-14-trans_network-classfont\"></a> <font color=#FF0000 >14. trans_network class</font></h1>\n<h2 id=\"font-colorff9800-correlation-based-networkfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-correlation-based-networkfont\"></a> <font color=#FF9800 >correlation-based network</font></h2>\n<ul>\n<li>准备 R 包并进行计算相关性  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"WGCNA\"</span><span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>WGCNA<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 以下3选1</span>\n<span class=\"token comment\"># 1. Use R base cor.test, slow</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_network<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> cal_cor <span class=\"token operator\">=</span> <span class=\"token string\">\"base\"</span><span class=\"token punctuation\">,</span> taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"OTU\"</span><span class=\"token punctuation\">,</span> filter_thres <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span><span class=\"token punctuation\">,</span> cor_method <span class=\"token operator\">=</span> <span class=\"token string\">\"spearman\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_cor_p list; one table: correlation; another: p value</span>\n\n<span class=\"token comment\"># 2. SparCC method, require SpiecEasi package</span>\n<span class=\"token comment\"># SparCC is very slow, so consider filtering more species with low abundance</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_network<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> meco_dataset<span class=\"token punctuation\">,</span> cal_cor <span class=\"token operator\">=</span> <span class=\"token string\">\"SparCC\"</span><span class=\"token punctuation\">,</span> taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"OTU\"</span><span class=\"token punctuation\">,</span> filter_thres <span class=\"token operator\">=</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span> SparCC_simu_num <span class=\"token operator\">=</span> <span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 3. When the OTU number is large, use R WGCNA package to replace R base to calculate correlations</span>\n<span class=\"token comment\"># require WGCNA package</span>\nt1 <span class=\"token operator\">&lt;-</span> trans_network<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> dataset<span class=\"token punctuation\">,</span> cal_cor <span class=\"token operator\">=</span> <span class=\"token string\">\"WGCNA\"</span><span class=\"token punctuation\">,</span> taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"OTU\"</span><span class=\"token punctuation\">,</span> filter_thres <span class=\"token operator\">=</span> <span class=\"token number\">0.0001</span><span class=\"token punctuation\">,</span> cor_method <span class=\"token operator\">=</span> <span class=\"token string\">\"spearman\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h2 id=\"font-colorff9800-构建网络font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-构建网络font\"></a> <font color=#FF9800 >构建网络</font></h2>\n<ul>\n<li>\n<p>COR_optimization = TRUE represent using RMT theory to find the optimized correlation threshold instead of the COR_cut.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># construct network; require igraph package</span>\nt1<span class=\"token operator\">$</span>cal_network<span class=\"token punctuation\">(</span>p_thres <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> COR_optimization <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_network</span>\n\n<span class=\"token comment\"># (可选) use arbitrary coefficient threshold to contruct network</span>\nt1<span class=\"token operator\">$</span>cal_network<span class=\"token punctuation\">(</span>p_thres <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> COR_cut <span class=\"token operator\">=</span> <span class=\"token number\">0.73</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># save network</span>\n<span class=\"token comment\"># open the gexf file using Gephi(https://gephi.org/)</span>\n<span class=\"token comment\"># require rgexf package</span>\ninstall.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"rgexf\"</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token operator\">$</span>save_network<span class=\"token punctuation\">(</span>filepath <span class=\"token operator\">=</span> <span class=\"token string\">\"network.gexf\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Now, we show the node colors with the Phylum information and the edges colors with the positive and negative correlations. All the data used has been stored in the network.gexf file, including modules classifications, Phylum information and edges classifications.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># calculate network attributes</span>\nt1<span class=\"token operator\">$</span>cal_network_attr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_network_attr</span>\n\n<span class=\"token comment\"># classify the node; return t1$res_node_type</span>\nt1<span class=\"token operator\">$</span>cal_node_type<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_node_type</span>\n<span class=\"token comment\"># we retain the file for the following example in trans_func part</span>\nnetwork_node_type <span class=\"token operator\">&lt;-</span> t1<span class=\"token operator\">$</span>res_node_type\n\n<span class=\"token comment\"># plot node roles in terms of the within-module connectivity and among-module connectivity</span>\nt1<span class=\"token operator\">$</span>plot_taxa_roles<span class=\"token punctuation\">(</span>use_type <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># plot node roles with phylum information</span>\nt1<span class=\"token operator\">$</span>plot_taxa_roles<span class=\"token punctuation\">(</span>use_type <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Now, we show the eigengene analysis of modules. The eigengene of a module, i.e. the first principal component of PCA, represents the main variance of the abundance in the species of the module.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1<span class=\"token operator\">$</span>cal_eigen<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_eigen</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>出错了</strong>！Then we perform correlation heatmap to show the relationships between eigengenes and environmental factors.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># create trans_env object like the above operation</span>\nt2 <span class=\"token operator\">&lt;-</span> trans_env<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>dataset <span class=\"token operator\">=</span> dataset<span class=\"token punctuation\">,</span> add_data <span class=\"token operator\">=</span> env_data_16S<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token operator\">:</span><span class=\"token number\">11</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># calculate correlations</span>\nt2<span class=\"token operator\">$</span>cal_cor<span class=\"token punctuation\">(</span>add_abund_table <span class=\"token operator\">=</span> t1<span class=\"token operator\">$</span>res_eigen<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># plot the correlation heatmap</span>\nt2<span class=\"token operator\">$</span>plot_corr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>The function cal_sum_links() is used to sum the links (edge) number from one taxa to another or in the same taxa. The function plot_sum_links() is used to show the result from the function cal_sum_links(). This is very useful to fast see how many nodes are connected between different taxa or within one taxa. In terms of “Phylum” level in the tutorial, the function cal_sum_links() sum the linkages number from one Phylum to another Phylum or the linkages in the same Phylum. So the numbers along the outside of the circular plot represent how many edges or linkages are related with the Phylum. For example, in terms of Proteobacteria, there are roughly total 900 edges associated with the OTUs in Proteobacteria, in which roughly 200 edges connect both OTUs in Proteobacteria and roughly 150 edges connect the OTUs from Proteobacteria with the OTUs from Chloroflexi.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">devtools<span class=\"token operator\">::</span>install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"mattflor/chorddiag\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># calculate the links between or within taxonomic ranks (报错：Error in ecount(network) : 没有\"ecount\"这个函数)</span>\nt1<span class=\"token operator\">$</span>cal_sum_links<span class=\"token punctuation\">(</span>taxa_level <span class=\"token operator\">=</span> <span class=\"token string\">\"Phylum\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t1$res_sum_links_pos and t1$res_sum_links_neg</span>\n<span class=\"token comment\"># require chorddiag package</span>\nt1<span class=\"token operator\">$</span>plot_sum_links<span class=\"token punctuation\">(</span>plot_pos <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> plot_num <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-15-trans_func-classfont\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-15-trans_func-classfont\"></a> <font color=#FF0000 >15. trans_func class</font></h1>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># Identify microbial traits</span>\n<span class=\"token comment\"># create object of trans_func</span>\nt2 <span class=\"token operator\">&lt;-</span> trans_func<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># mapping the taxonomy to the database</span>\n<span class=\"token comment\"># the function can recognize prokaryotes or fungi automatically</span>\nt2<span class=\"token operator\">$</span>cal_spe_func<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t2$res_spe_func, 1 represent function exists, 0 represent no or cannot confirmed.</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>\n<p>The percentages of the OTUs having the same trait can reflect the functional redundancy of this function in the community or the module in the network.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># calculate the percentages of OTUs for each trait in each module of network</span>\n<span class=\"token comment\"># use_community = FALSE represent calculating module, not community, node_type_table provide the module information</span>\nt2<span class=\"token operator\">$</span>cal_spe_func_perc<span class=\"token punctuation\">(</span>use_community <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> node_type_table <span class=\"token operator\">=</span> network_node_type<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return t2$res_spe_func_perc</span>\n<span class=\"token comment\"># we only plot some important traits, so we use the default group list to filter and show the traits.</span>\nt2<span class=\"token operator\">$</span>plot_spe_func_perc<span class=\"token punctuation\">(</span>select_samples <span class=\"token operator\">=</span> paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"M\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># M represents module, ordered by the nodes number from high to low</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Tax4Fun requires a strict input file demand on the taxonomic information. To analyze the trimmed or changed OTU data in R with Tax4Fun, we provide a link to the Tax4Fun functional prediction.</p>\n  <pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">t1 <span class=\"token operator\">&lt;-</span> trans_func<span class=\"token operator\">$</span>new<span class=\"token punctuation\">(</span>meco_dataset<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># install Tax4Fun package and download SILVA123 ref data from  http://tax4fun.gobics.de/</span>\nwget https<span class=\"token operator\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>github.com<span class=\"token operator\">/</span>bwemheu<span class=\"token operator\">/</span>Tax4Fun2<span class=\"token operator\">/</span>releases<span class=\"token operator\">/</span>download<span class=\"token operator\">/</span><span class=\"token number\">1.1</span><span class=\"token number\">.5</span><span class=\"token operator\">/</span>Tax4Fun2_1.<span class=\"token number\">1.5</span>.tar.gz\ninstall.packages<span class=\"token punctuation\">(</span>pkgs <span class=\"token operator\">=</span> <span class=\"token string\">\"Tax4Fun2_1.1.5.tar.gz\"</span><span class=\"token punctuation\">,</span> repos <span class=\"token operator\">=</span> <span class=\"token keyword\">NULL</span><span class=\"token punctuation\">,</span> source <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># decompress SILVA123; provide path in folderReferenceData as you put</span>\nt1<span class=\"token operator\">$</span>cal_tax4fun<span class=\"token punctuation\">(</span>folderReferenceData <span class=\"token operator\">=</span> <span class=\"token string\">\"./SILVA123\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># return two files: t1$tax4fun_KO: KO file; t1$tax4fun_path: pathway file.</span>\n<span class=\"token comment\"># t1$tax4fun_KO$Tax4FunProfile[1:5, 1:2]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"font-colorff0000-16-知识点font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-16-知识点font\"></a> <font color=#FF0000 >16. 知识点</font></h1>\n<h2 id=\"font-colorff9800-确定性过程和随机过程font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff9800-确定性过程和随机过程font\"></a> <font color=#FF9800 >确定性过程和随机过程</font></h2>\n<ul>\n<li>\n<p>The term <font color=#2196F3 size=5><b>“deterministic process”</b></font> refers to two types of selective forces, namely, those that lead to either more (i.e. homogeneous selection) or less (i.e. heterogeneous selection) similar structures among communities due to homogeneous and heterogeneous environmental pressures, respectively (Zhou &amp; Ning, 2017).  <font color=#2196F3 size=5><b>确定性过程</b></font>包括两种选择力，即分别导致更加相似（即同质选择）或更少相似（即异质选择）的群落间的结构的同质和异质环境压力。</p>\n</li>\n<li>\n<p>The term<font color=#2196F3 size=5><b> “stochastic process” </b></font>refers to homogenizing dispersal, dispersal limitation (combined with drift) and pure drift, which can obscure the turnover among microbial communities due to high dispersal; low dispersal; and random changes in birth, death and reproduction, respectively (Zhou &amp; Ning, 2017). <font color=#2196F3 size=5><b>随机过程</b></font>是指均匀分散、分散限制（结合漂变）和纯漂变，它们可以通过高度分散、低分散和出生、死亡和繁殖的随机变化来掩盖 / 减弱微生物群落之间的更替。</p>\n</li>\n</ul>\n<p><img src=\"/images/lujia/nullmodel.png\" class=\"lazyload placeholder\" data-srcset=\"/images/lujia/nullmodel.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Community assembly processes by Stegen et al. https://www.nature.com/articles/ismej201393\" /></p>\n<ul>\n<li>An NTI of &gt;+2 indicates that the ASVs in a local community are more closely related than expected by chance, suggesting the role of selective pressures (e.g. environmental conditions) in phylogenetic clustering. An NTI of &lt;−2 represents phylogenetic overdispersion, indicating two possible biotic interactions: competition and facilitation. In contrast, a mean NTI across multiple communities that is significantly greater or less than zero indicates phylogenetic clustering or overdispersion, respectively (Zhou &amp; Ning, 2017). NTI &gt;2 表明，在一个地方群落中，ASVs 的亲缘关系比预期的更为密切，表明选择压力（如环境条件）在系统发育聚类中的作用。NTI &lt;-2 表示系统发育过度分散，表明两种可能的生物相互作用：竞争和促进。相反，多个群落间的平均 NTI 显著大于或小于零，分别表明系统发育聚类或过度分散（Zhou 和 Ning，2017）。</li>\n<li>βNTI&gt;+2 or &lt;−2 signified heterogeneous selection or homogeneous selection, respectively. βNTI&gt;+2 or &lt;−2 分别指示异质选择和同质选择。</li>\n</ul>\n<h1 id=\"font-colorff0000-17-参考font\"><a class=\"markdownIt-Anchor\" href=\"#font-colorff0000-17-参考font\"></a> <font color=#FF0000 >17. 参考</font></h1>\n<ul>\n<li><a href=\"https://chiliubio.github.io/microeco/\">https://chiliubio.github.io/microeco/</a></li>\n<li>Zhou, J., &amp; Ning, D. (2017). Stochastic community assembly: Does it matter in microbial ecology? Microbiology and Molecular Biology Reviews, 81(4), e00002–17. <a href=\"https://doi.org/10.1128/MMBR.00002%E2%80%9017\">https://doi.org/10.1128/MMBR.00002‐17</a></li>\n<li><a href=\"http://www.360doc.com/content/20/1223/07/71874948_952966442.shtml\">http://www.360doc.com/content/20/1223/07/71874948_952966442.shtml</a></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"扩增子","path":"api/tags/扩增子.json"}]},{"title":"宏基因组分析流程及代码","slug":"宏基因组分析流程及代码","date":"2021-01-19T07:24:28.000Z","updated":"2022-01-08T02:16:28.443Z","comments":true,"path":"api/articles/宏基因组分析流程及代码.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>本文阐述宏基因组物种分类、组装、bining、基因预测及注释……</p>\n<span id=\"more\"></span>\n<h1 id=\"a-软件列表及安装\"><a class=\"markdownIt-Anchor\" href=\"#a-软件列表及安装\"></a> A、软件列表及安装</h1>\n<h2 id=\"a1-分类相关\"><a class=\"markdownIt-Anchor\" href=\"#a1-分类相关\"></a> A.1 分类相关</h2>\n<h3 id=\"a11-metaphlan-30\"><a class=\"markdownIt-Anchor\" href=\"#a11-metaphlan-30\"></a> A.1.1 metaphlan 3.0</h3>\n<p>MetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequencing data.</p>\n<h4 id=\"a-安装主文件\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n metaphlan <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.7</span> metaphlan\n$ conda activate metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"b-安装数据库\"><a class=\"markdownIt-Anchor\" href=\"#b-安装数据库\"></a> b. 安装数据库</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metaphlan --install<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-安装依赖包\"><a class=\"markdownIt-Anchor\" href=\"#c-安装依赖包\"></a> c. 安装依赖包</h4>\n<ul>\n<li>hclust<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> -c bioconda hclust2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>R, vegan, ape <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> r-base r-vegan r-ape<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>rbiom<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ R\n$ install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"rbiom\"</span><span class=\"token punctuation\">)</span>\n$ quit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h3 id=\"a12-gtdbtk\"><a class=\"markdownIt-Anchor\" href=\"#a12-gtdbtk\"></a> A.1.2 <a href=\"https://ecogenomics.github.io/GTDBTk/\">gtdbtk</a></h3>\n<h4 id=\"a-hardware-requirements\"><a class=\"markdownIt-Anchor\" href=\"#a-hardware-requirements\"></a> a. Hardware requirements</h4>\n<table>\n<thead>\n<tr>\n<th>Domain</th>\n<th>Memory</th>\n<th>Storage</th>\n<th>Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Archaea</td>\n<td>~8 GB</td>\n<td>~27 GB</td>\n<td>~1 hour / 1,000 genomes @ 64 CPUs</td>\n</tr>\n<tr>\n<td>Bacteria</td>\n<td>~150 GB</td>\n<td>~27 GB</td>\n<td>~1 hour / 1,000 genomes @ 64 CPUs</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"b-install-gtdb-tk-with-conda\"><a class=\"markdownIt-Anchor\" href=\"#b-install-gtdb-tk-with-conda\"></a> b. Install GTDB-Tk with conda</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n gtdbtk -c conda-forge -c bioconda gtdbtk<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-gtdb-tk-reference-data\"><a class=\"markdownIt-Anchor\" href=\"#c-gtdb-tk-reference-data\"></a> c. GTDB-Tk reference data</h4>\n<ul>\n<li><strong>Note that different versions of the GTDB release data may not run on all versions of GTDB-Tk, below are all supported versions:</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>GTDB Release</th>\n<th>Minimum version</th>\n<th>Maximum version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>R95</td>\n<td>1.3.0</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>R89</td>\n<td>0.3.0</td>\n<td>0.1.2</td>\n</tr>\n<tr>\n<td>R86.2</td>\n<td>0.2.1</td>\n<td>0.2.2</td>\n</tr>\n<tr>\n<td>R86</td>\n<td>0.1.0</td>\n<td>0.1.6</td>\n</tr>\n<tr>\n<td>R83</td>\n<td>0.0.6</td>\n<td>0.0.7</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Download the reference data</li>\n</ul>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/auxillary_files/gtdbtk_r95_data.tar.gz\n  \n$ <span class=\"token function\">tar</span> xvzf gtdbtk_r95_data.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p><strong>注意</strong>：GTDB-Tk requires an environment variable named GTDBTK_DATA_PATH to be set to the directory containing the unarchived GTDB-Tk reference data.</p>\n<ul>\n<li>You can automatically alias GTDBTK_DATA_PATH whenever the environment is activated by editing {gtdbtk environment path}/etc/conda/activate.d/gtdbtk.sh, e.g.:</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># Determine the GTDB-Tk environment path</span>\n$ conda activate gtdbtk\n$ <span class=\"token function\">which</span> gtdbtk\n<span class=\"token comment\"># /miniconda3/envs/gtdbtk-1.3.0/bin/gtdbtk</span>\n\n<span class=\"token comment\"># Edit the activate file</span>\n$ <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"export GTDBTK_DATA_PATH=/path/to/release/package/\"</span> <span class=\"token operator\">></span> /miniconda3/envs/gtdbtk-1.3.0/etc/conda/activate.d/gtdbtk.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"a13-kraken2\"><a class=\"markdownIt-Anchor\" href=\"#a13-kraken2\"></a> A.1.3 <a href=\"https://github.com/DerrickWood/kraken2\">Kraken2</a></h3>\n<h4 id=\"a-hardware-requirements-2\"><a class=\"markdownIt-Anchor\" href=\"#a-hardware-requirements-2\"></a> a. Hardware requirements</h4>\n<ul>\n<li>Disk space: Construction of a Kraken 2 standard database requires approximately 100 GB of disk space. A test on 01 Jan 2018 of the default installation showed 42 GB of disk space was used to store the genomic library files, 26 GB was used to store the taxonomy information from NCBI, and 29 GB was used to store the Kraken 2 compact hash table.</li>\n<li>Memory: To run efficiently, Kraken 2 requires enough free memory to hold the database (primarily the hash table) in RAM. While this can be accomplished with a ramdisk, Kraken 2 will by default load the database into process-local RAM; the --memory-mapping switch to kraken2 will avoid doing so. The default database size is 29 GB (as of Jan. 2018), and you will need slightly more than that in RAM if you want to build the default database.</li>\n</ul>\n<h4 id=\"b-install-kraken2-with-conda\"><a class=\"markdownIt-Anchor\" href=\"#b-install-kraken2-with-conda\"></a> b. Install Kraken2 with conda</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n kraken2 kraken2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-build-the-database\"><a class=\"markdownIt-Anchor\" href=\"#c-build-the-database\"></a> c. Build the database</h4>\n<ul>\n<li>下载数据库。找到一个存储空间比较大的目录并进入，运行如下命令，这里下载的数据库包括 archaea，bacteria，plasmid，viral，fungi，protozoa，UniVec 和 UniVec_Core：<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> <span class=\"token function\">bash</span> -c <span class=\"token string\">'for i in archaea bacteria plasmid viral fungi protozoa UniVec UniVec_Core; do kraken2-build --download-library $i --threads 24 --db db_name; done'</span> <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>下载分类信息<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> kraken2-build --download-taxonomy --threads <span class=\"token number\">24</span> --db db_name <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>建立索引<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> kraken2-build --build --threads <span class=\"token number\">24</span> --db db_name <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"d-序列分类\"><a class=\"markdownIt-Anchor\" href=\"#d-序列分类\"></a> d. 序列分类</h4>\n</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">kraken2 --paired --threads <span class=\"token number\">24</span> --unclassified-out unclassified<span class=\"token comment\">#.fq --classified-out classified#.fq --output outfile --confidence 0.5 --memory-mapping --use-names --report reportname --report-zero-counts --db $DBNAME reads1 read2</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"a2-组装-bining-质量评估\"><a class=\"markdownIt-Anchor\" href=\"#a2-组装-bining-质量评估\"></a> A.2 组装、Bining、质量评估</h2>\n<h3 id=\"a21-metawrap\"><a class=\"markdownIt-Anchor\" href=\"#a21-metawrap\"></a> A.2.1 metawrap</h3>\n<p>MetaWRAP is a pipeline for genome-resolved metagenomic data analysis.</p>\n<h4 id=\"a-安装主文件-2\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件-2\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n metawrap <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">2.7</span> metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"b-安装其他分析工具到metawrap环境中\"><a class=\"markdownIt-Anchor\" href=\"#b-安装其他分析工具到metawrap环境中\"></a> b. 安装其他分析工具到 metawrap 环境中</h4>\n<ul>\n<li><strong>cd-hit</strong></li>\n<li><strong>coverm</strong> DNA read coverage and relative abundance calculator focused on metagenomics applications</li>\n<li><strong>bamm</strong> Metagenomics-focused BAM file manipulation</li>\n<li><strong>unitem</strong> Ensemble binning strategies for combining the output of multiple binning methods</li>\n<li><strong>humann2</strong> The HMP Unified Metabolic Analysis Network 2</li>\n<li><strong><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">graphlan</a></strong></li>\n<li><strong><a href=\"https://pypi.org/project/export2graphlan/\">export2graphlan</a></strong></li>\n<li><strong><a href=\"https://data.ace.uq.edu.au/public/CheckM_databases/\">checkm database</a></strong></li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activeta metawrap\n$ conda <span class=\"token function\">install</span> cd-hit coverm bamm unitem humann2 graphlan export2graphlan\n\n<span class=\"token comment\"># 找到一个合适的目录并cd进入以便存储checkm数据库</span>\n$ <span class=\"token function\">wget</span> https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz\n$ <span class=\"token function\">tar</span> zxvf checkm_data_2015_01_16.tar.gz\n$ checkm data setRoot\n<span class=\"token comment\"># 随后输入数据库所在的full path</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"a3-非冗余基因功能注释\"><a class=\"markdownIt-Anchor\" href=\"#a3-非冗余基因功能注释\"></a> A.3 非冗余基因功能注释</h2>\n<h3 id=\"a31-eggnog-mapper\"><a class=\"markdownIt-Anchor\" href=\"#a31-eggnog-mapper\"></a> A.3.1 eggNOG-mapper</h3>\n<p>功能注释，uniref, eggNOG, KEGG, GO; CAZy; VFDB; CARD; TCDB; PHI。</p>\n<h3 id=\"a32-enrichm\"><a class=\"markdownIt-Anchor\" href=\"#a32-enrichm\"></a> A.3.2 EnrichM</h3>\n<p><a href=\"https://github.com/geronimp/enrichM\">EnrichM</a> is a set of comparative genomics tools for large sets of metagenome assembled genomes (MAGs). The current functionality includes:</p>\n<ul>\n<li>A basic annotation pipeline for MAGs.</li>\n<li>A pipeline to determine the metabolic pathways that are encoded by MAGs, using KEGG modules as a reference (although custom pathways can be specified)</li>\n<li>A pipeline to identify genes or metabolic pathways that are enriched within and between user-defined groups of genomes (groups can be genomes that are related functionally, phylogenetically, recovered from different environments, etc).</li>\n<li>To construct metabolic networks from annotated population genomes.</li>\n<li>Construct random forest machine learning models from the functional composition of either MAGs, metagenomes or transcriptomes.</li>\n<li>Apply these random forest machine learning models to classify new MAGs metagenomes.</li>\n</ul>\n<h4 id=\"a-安装主文件-3\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件-3\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n enrichm <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3</span>\n$ conda <span class=\"token function\">install</span> enrichm<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"b-安装数据库-2\"><a class=\"markdownIt-Anchor\" href=\"#b-安装数据库-2\"></a> b. 安装数据库</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 约5.7 G</span>\n$ enrichm data<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><strong>报错</strong> ：</p>\n<blockquote>\n<p>Traceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py&quot;, line 114, in do<br />\nversion_remote = urllib.request.urlopen(self.ftp + self.VERSION).readline().strip().decode(&quot;utf-8&quot;)<br />\nAttributeError: module 'urllib' has no attribute 'request'</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/bin/enrichm&quot;, line 342, in &lt;module&gt;<br />\nrun.run_enrichm(args, sys.argv)<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/run.py&quot;, line 288, in run_enrichm<br />\n<a href=\"http://d.do\">d.do</a>(args.uninstall, args.dry)<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py&quot;, line 117, in do<br />\n&quot;Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a>&quot;)<br />\nException: Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a></p>\n</blockquote>\n<p><strong>解决方案：将 data.py 中的 'import urllib' 替换为 'import urllib.request'</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> /home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-sepcifying-the-location-of-the-enrichm-database\"><a class=\"markdownIt-Anchor\" href=\"#c-sepcifying-the-location-of-the-enrichm-database\"></a> c. Sepcifying the location of the EnrichM database</h4>\n<p>If you would like to store the EnrichM database outside of your home directory, move you need to tell EnrichM where to look. To do this, export a BASH variable named &quot;ENRICHM_DB&quot;:</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">ENRICHM_DB</span><span class=\"token operator\">=</span>/path/to/database/ <span class=\"token operator\">>></span>~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注意</strong> ：/path/to/database/ 根据实际情况而定！<br />\n<strong>报错</strong>：</p>\n<blockquote>\n<p>$ enrichm<br />\nTraceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/bin/enrichm&quot;, line 38, in &lt;module&gt;<br />\nfrom enrichm.run import Run<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/run.py&quot;, line 24, in &lt;module&gt;<br />\nfrom enrichm.network_analyzer import NetworkAnalyser<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/network_analyzer.py&quot;, line 22, in &lt;module&gt;<br />\nfrom enrichm.network_builder import NetworkBuilder<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/network_builder.py&quot;, line 24, in &lt;module&gt;<br />\nfrom enrichm.databases import Databases<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/databases.py&quot;, line 28, in &lt;module&gt;<br />\nclass Databases:<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/databases.py&quot;, line 36, in Databases<br />\nPICKLE_VERSION = open(os.path.join(CUR_DATABASE_DIR, 'VERSION')).readline().strip()<br />\nFileNotFoundError: [Errno 2] No such file or directory: '/new_data/hualin/db/enrichm_database_v10/26-11-2018/VERSION'</p>\n</blockquote>\n<p><strong>Solve</strong>: 将下载的数据库文件全部复制一份到 “<strong>26-11-2018</strong>” 目录中，否则后续运行 annotaton 时会提示找不到数据库文件。</p>\n<h1 id=\"b-数据分析\"><a class=\"markdownIt-Anchor\" href=\"#b-数据分析\"></a> B、数据分析</h1>\n<h2 id=\"b1-使用metaphlan从reads中获取物种分类信息\"><a class=\"markdownIt-Anchor\" href=\"#b1-使用metaphlan从reads中获取物种分类信息\"></a> B.1 使用 metaphlan 从 Reads 中获取物种分类信息</h2>\n<h3 id=\"step-1-激活环境\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-对paired-end-reads进行注释\"><a class=\"markdownIt-Anchor\" href=\"#step-2-对paired-end-reads进行注释\"></a> Step 2. 对 paired-end Reads 进行注释</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metaphlan Reads1,Reads2 --input_type fastq --bowtie2out Str1.bowtie2.bz2 --nproc <span class=\"token number\">10</span> -o Str1_profiled.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Reads1 和 Reads2 分别代表双端测序得到的正向和反向数据；--input_type 指定文件格式，我们拿到的下机数据一般为 fastq 格式；--bowtie2out 参数将会保存运行产生的中间文件以便后续重新运行程序时作为输入文件；--nproc 指定使用的线程数量；-o 指定输出文件名。</p>\n<h3 id=\"step-3-汇总所有的结果文件\"><a class=\"markdownIt-Anchor\" href=\"#step-3-汇总所有的结果文件\"></a> Step 3. 汇总所有的结果文件</h3>\n<p>对所有的文件均运行 Step 2 ，产生了多个输出文件（*_profiled.txt），可以将它们汇总到一个文件中（merged_abundance_table.txt），便于后续对多个样品进行相互比较。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ merge_metaphlan_tables.py *_profiled.txt <span class=\"token operator\">></span> merged_abundance_table.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-4-从合并的文件中提取种水平的分类\"><a class=\"markdownIt-Anchor\" href=\"#step-4-从合并的文件中提取种水平的分类\"></a> Step 4. 从合并的文件中提取种水平的分类</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">grep</span> -E <span class=\"token string\">\"s__|clade\"</span> merged_abundance_table.txt <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> <span class=\"token string\">'s/^.*s__//g'</span> <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -f1,3-8 <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> -e <span class=\"token string\">'s/clade_name/body_site/g'</span> <span class=\"token operator\">></span> merged_abundance_table_species.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-5-绘制样本间种水平的热图\"><a class=\"markdownIt-Anchor\" href=\"#step-5-绘制样本间种水平的热图\"></a> Step 5. 绘制样本间种水平的热图</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ hclust2.py -i merged_abundance_table_species.txt -o abundance_heatmap_species.png --ftop <span class=\"token number\">50</span> --f_dist_f braycurtis --s_dist_f braycurtis --cell_aspect_ratio <span class=\"token number\">0.5</span> -l --flabel_size <span class=\"token number\">10</span> --slabel_size <span class=\"token number\">10</span> --max_flabel_len <span class=\"token number\">100</span> --max_slabel_len <span class=\"token number\">100</span> --minv <span class=\"token number\">0.1</span> --dpi <span class=\"token number\">300</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-6-计算样本间的unifrac距离\"><a class=\"markdownIt-Anchor\" href=\"#step-6-计算样本间的unifrac距离\"></a> Step 6. 计算样本间的 unifrac 距离</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 下载依赖的tree文件和脚本,与要分析的文件放于同一目录下</span>\n$ <span class=\"token function\">wget</span> https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/mpa_v30_CHOCOPhlAn_201901_species_tree.nwk\n$ <span class=\"token function\">wget</span> https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/calculate_unifrac.R\n\n<span class=\"token comment\"># 开始计算距离</span>\n$ Rscript plot_unifrac.R merged_abundance_table.txt mpa_v30_CHOCOPhlAn_201901_species_tree.nwk unifrac_merged_abundance_table.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"step-7-绘制cladogram图\"><a class=\"markdownIt-Anchor\" href=\"#step-7-绘制cladogram图\"></a> Step 7. 绘制 cladogram 图</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 激活依赖软件所在的环境</span>\n$ conda activate metawrap\n\n<span class=\"token comment\"># 生成绘图所需的文件</span>\n$ <span class=\"token function\">tail</span> -n +2 merged_abundance_table.txt <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -f1,3- <span class=\"token operator\">></span> merged_abundance_table_reformatted.txt\n\n$ export2graphlan.py --skip_rows <span class=\"token number\">1</span> -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant <span class=\"token number\">100</span> --abundance_threshold <span class=\"token number\">1</span> --least_biomarkers <span class=\"token number\">10</span> --annotations <span class=\"token number\">5,6</span> --external_annotations <span class=\"token number\">7</span> --min_clade_size <span class=\"token number\">1</span>\n\n<span class=\"token comment\"># 绘图</span>\n$ graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml\n\n$ graphlan.py --dpi <span class=\"token number\">300</span> merged_abundance.xml merged_abundance.pdf --external_legends<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"b2-使用metawrap对reads进行组装\"><a class=\"markdownIt-Anchor\" href=\"#b2-使用metawrap对reads进行组装\"></a> B.2 使用 metawrap 对 Reads 进行组装</h2>\n<h3 id=\"step-1-激活环境-2\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境-2\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metawrap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-组装\"><a class=\"markdownIt-Anchor\" href=\"#step-2-组装\"></a> Step 2. 组装</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap assembly -1 Reads1 -2 Reads2 -o Assemble1 -m <span class=\"token number\">300</span> -t <span class=\"token number\">15</span> --metaspades<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP assembly [options] -1 reads_1.fastq -2 reads_2.fastq -o output_dir\n<ul>\n<li>Options:\n<ul>\n<li>\n<p>-1 STR          forward fastq reads</p>\n</li>\n<li>\n<p>-2 STR          reverse fastq reads</p>\n</li>\n<li>\n<p>-o STR          output directory</p>\n</li>\n<li>\n<p>-m INT          memory in GB (default=24)</p>\n</li>\n<li>\n<p>-t INT          number of threads (defualt=1)</p>\n</li>\n<li>\n<p>-l INT\t\tminimum length of assembled contigs (default=1000)</p>\n</li>\n<li>\n<p>--megahit\tassemble with megahit (default)</p>\n</li>\n<li>\n<p>--metaspades\tassemble with metaspades instead of megahit (better results but slower and higher memory requirement)</p>\n</li>\n</ul>\n</li>\n</ul>\n</details>\n<p>Reads1 和 Reads2 分别代表双端测序得到的正向和反向数据；-o 指定输出目录，-m 指定最大可用内存大小，超过设定值后程序会自动退出，建议设大一点，我 10G 的数据大概需要 180G 内存；-t 指定线程数；--metaspades 表示用 metaspades 进行组装，特别慢，但是组装结果相对好一些。</p>\n<h2 id=\"b3-使用metawrap对contigs进行bining\"><a class=\"markdownIt-Anchor\" href=\"#b3-使用metawrap对contigs进行bining\"></a> B.3 使用 metawrap 对 Contigs 进行 Bining</h2>\n<h3 id=\"step-1-激活环境-3\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境-3\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metawrap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-bining\"><a class=\"markdownIt-Anchor\" href=\"#step-2-bining\"></a> Step 2. Bining</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap binning -o Str1.INITIAL_BINNING -t <span class=\"token number\">20</span> -m <span class=\"token number\">200</span> --universal --run-checkm -a <span class=\"token operator\">&lt;</span>path of contigs<span class=\"token operator\">></span> --metabat2 --maxbin2 --concoct 解压的Reads1 解压的Reads2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP binning [options] -a assembly.fa -o output_dir readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n<ul>\n<li>\n<p>Note1: Make sure to provide all your separately replicate read files, not the joined file.</p>\n</li>\n<li>\n<p>Note2: You may provide single end or interleaved reads as well with the use of the correct option</p>\n</li>\n<li>\n<p>Note3: If the output already has the .bam alignments files from previous runs, the module will skip re-aligning the reads</p>\n</li>\n<li>\n<p>Options:</p>\n<ul>\n<li>-a STR          metagenomic assembly file</li>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads (default=1)</li>\n<li>-m INT\t\tamount of RAM available (default=4)</li>\n<li>-l INT\t\tminimum contig length to bin (default=1000bp). Note: metaBAT will default to 1500bp minimum</li>\n<li>--metabat2      bin contigs with metaBAT2</li>\n<li>--metabat1\tbin contigs with the original metaBAT</li>\n<li>--maxbin2\tbin contigs with MaxBin2</li>\n<li>--concoct\tbin contigs with CONCOCT</li>\n<li>--universal\tuse universal marker genes instead of bacterial markers in MaxBin2 (improves Archaea binning)</li>\n<li>--run-checkm\timmediately run CheckM on the bin results (requires 40GB+ of memory)</li>\n<li>--single-end\tnon-paired reads mode (provide *.fastq files)</li>\n<li>--interleaved\tthe input read files contain interleaved paired-end reads</li>\n</ul>\n</li>\n</ul>\n</details>\n**注意避坑：** 这里的Reads1和Reads2需要提供解压缩后的Reads文件，不但要解压缩，还需要重命名，即后缀名必须为“\\_clean\\_1.fastq” 和 “\\_clean\\_2.fastq”，否则软件无法运行。-o指定输出目录；-t指定线程数；-m指定最大内存限制；--run-checkm表明即时检查Bining的质量；--metabat2 --maxbin2 --concoct 指定同时采用这三个分箱工具进行Bining；--universal指定MaxBin2采用universal marker 基因代替 bacterial markers  (improves Archaea binning)。\n<h3 id=\"step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"><a class=\"markdownIt-Anchor\" href=\"#step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"></a> Step 3. 整合三种方法的 bins (metabat2, maxbin2, concoct) 结果</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap bin_refinement -o F01_BIN_REFINEMENT<span class=\"token punctuation\">(</span>输出目录<span class=\"token punctuation\">)</span> -t <span class=\"token number\">20</span> -A str1.INITIAL_BINNING/metabat2_bins/ -B str1.INITIAL_BINNING/maxbin2_bins/ -C str1.INITIAL_BINNING/concoct_bins/ -c <span class=\"token number\">70</span> -x <span class=\"token number\">5</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP bin_refinement [options] -o output_dir -A bin_folderA [-B bin_folderB -C bin_folderC]\n<ul>\n<li>\n<p>Note: the contig names in different bin folders must be consistant (must come from the same assembly).</p>\n</li>\n<li>\n<p>Options:</p>\n<ul>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads (default=1)</li>\n<li>-m INT\t\tmemory available (default=40)</li>\n<li>-c INT          完整度 minimum % completion of bins [should be&gt;50%] (default=70)</li>\n<li>-x INT          污染度 maximum % contamination of bins that is acceptable (default=10)</li>\n<li>-A STR\t\tfolder with metagenomic bins (files must have .fa or .fasta extension)</li>\n<li>-B STR\t\tanother folder with metagenomic bins</li>\n<li>-C STR\t\tanother folder with metagenomic bins</li>\n<li>--skip-refinement\tdont use binning_refiner to come up with refined bins based on combinations of binner outputs</li>\n<li>--skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>--skip-consolidation\tchoose the best version of each bin from all bin refinement iteration</li>\n<li>--keep-ambiguous\tfor contigs that end up in more than one bin, keep them in all bins (default: keeps them only in the best bin)</li>\n<li>--remove-ambiguous\tfor contigs that end up in more than one bin, remove them in all bins (default: keeps them only in the best bin)</li>\n<li>--quick\t\t\tadds --reduced_tree option to checkm, reducing runtime, especially with low memory</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-4-blobology可视化bin\"><a class=\"markdownIt-Anchor\" href=\"#step-4-blobology可视化bin\"></a> Step 4. Blobology 可视化 bin</h3>\n<p><strong>一个坑：</strong> metawrap 安装的 blast 为 2.6 版本，只能用 Version 4 的 nt 库。而最新的 nt 库为 Version 5，v4 已经不再维护了。因此需要更新 metawrap 安装环境中的 blast 至 2.8.0 及以上版本，这里无法通过‘conda updata blast’实现更新，而是需要下载新版本的 blast 可执行程序，覆盖 metawrap 环境中的 blast 程度们。 如果你采用的是默认版本的 blast 和 V5 的 nt 库，会得到报错：“BLAST Database error: Error: Not a valid version 4 database”.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap blobology -a Result/Assemble/F01/final_assembly.fasta -t <span class=\"token number\">20</span> -o F01.BLOBOLOGY --bins F01_BIN_REFINEMENT/metawrap_70_5_bins reads/F01_clean_1.fastq reads/F01_clean_2.fastq<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP blobology [options] -a assembly.fasta -o output_dir readsA_1.fastq readsA_2.fastq [readsB_1.fastq readsB_2.fastq ... ]\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-a STR\t\tassembly fasta file</li>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads</li>\n<li>--subsamble \tINT\tNumber of contigs to run blobology on. Subsampling is randomized. (default=ALL)</li>\n<li>--bins\t\tSTR\tFolder containing bins. Contig names must match those of the assembly file. (default=None)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-5-bins-定量\"><a class=\"markdownIt-Anchor\" href=\"#step-5-bins-定量\"></a> Step 5. Bins 定量</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap quant_bins -b F01_BIN_REFINEMENT/metawrap_70_5_bins -t <span class=\"token number\">8</span> -o F01.QUANT_BINS -a Result/Assemble/F01/final_assembly.fasta reads/F01_clean_1.fastq reads/F01_clean_2.fastq<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP quant_bins [options] -b bins_folder -o output_dir -a assembly.fa readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-b STR          folder containing draft genomes (bins) in fasta format</li>\n<li>-o STR          output directory</li>\n<li>-a STR\t\tfasta file with entire metagenomic assembly (strongly recommended!)</li>\n<li>-t INT\t\tnumber of threads</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-6-重组装\"><a class=\"markdownIt-Anchor\" href=\"#step-6-重组装\"></a> Step 6. 重组装</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">metawrap reassemble_bins -o F01.BIN_REASSEMBLY -1 reads/F01_clean_1.fastq -2 reads/F01_clean_2.fastq -t <span class=\"token number\">20</span> -m <span class=\"token number\">400</span> -c <span class=\"token number\">70</span> -x <span class=\"token number\">10</span> -b F01_BIN_REFINEMENT/metawrap_70_5_bins<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP reassemble_bins [options] -o output_dir -b bin_folder -1 reads_1.fastq -2 reads_2.fastq\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-b STR\t\tfolder with metagenomic bins</li>\n<li>-o STR\t\toutput directory</li>\n<li>-1 STR          forward reads to use for reassembly</li>\n<li>-2 STR          reverse reads to use for reassembly</li>\n<li>-t INT\t\tnumber of threads (default=1)</li>\n<li>-m INT\t\tmemory in GB (default=40)</li>\n<li>-c INT\t\tminimum desired bin completion % (default=70)</li>\n<li>-x INT\t\tmaximum desired bin contamination % (default=10)</li>\n<li>-l INT\t\tminimum contig length to be included in reassembly (default=500)</li>\n<li>--strict-cut-off\tmaximum allowed SNPs for strict read mapping (default=2)</li>\n<li>--permissive-cut-off\tmaximum allowed SNPs for permissive read mapping (default=5)</li>\n<li>--skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>--parallel\t\trun spades reassembly in parallel, but only using 1 thread per bin</li>\n</ul>\n</li>\n</ul>\n</details>\n<h2 id=\"b4-mags注释\"><a class=\"markdownIt-Anchor\" href=\"#b4-mags注释\"></a> B.4 MAGs 注释</h2>\n<h3 id=\"b41-gtdb-tk-进行物种分类和注释构建系统发育树\"><a class=\"markdownIt-Anchor\" href=\"#b41-gtdb-tk-进行物种分类和注释构建系统发育树\"></a> B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate gtdbtk<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"classify_wfclassify-workflow-包括了step-1-3\"><a class=\"markdownIt-Anchor\" href=\"#classify_wfclassify-workflow-包括了step-1-3\"></a> classify_wf——Classify workflow (包括了 Step 1-3)</h4>\n<p>The classify workflow consists of three steps: identify, align, and classify.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk classify_wf --genome_dir metawrap_70_5_bins/ --out_dir classify_wf_output -x .fa --prefix F --cpus <span class=\"token number\">6</span> -r --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk classify_wf (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [-x EXTENSION] [--min_perc_aa MIN_PERC_AA] [--prefix PREFIX] [--cpus CPUS]\n                          [--pplacer_cpus PPLACER_CPUS] [--force] [--scratch_dir SCRATCH_DIR] [-r] [--min_af MIN_AF] [--debug] [-h]\n<ul>\n<li>\n<p>mutually exclusive required arguments:</p>\n<ul>\n<li>--genome_dir GENOME_DIR<br />\ndirectory containing genome files in FASTA format</li>\n<li>--batchfile BATCHFILE<br />\npath to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</li>\n</ul>\n</li>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br />\nextension of files to process, gz = gzipped (default: fna)</li>\n<li>--min_perc_aa MIN_PERC_AA<br />\nexclude genomes that do not have at least this percentage of AA in the MSA (inclusive bound) (default: 10)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--pplacer_cpus PPLACER_CPUS<br />\nuse pplacer_cpus during placement (default: cpus)</li>\n<li>--force               continue processing if an error occurs on a single genome (default: False)</li>\n<li>--scratch_dir SCRATCH_DIR<br />\nReduce pplacer memory usage by writing to disk (slower).</li>\n<li>-r, --recalculate_red<br />\nrecalculate RED values based on the reference tree and all added user genomes (default: False)</li>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-1-identify在基因组中寻找marker-genes\"><a class=\"markdownIt-Anchor\" href=\"#step-1-identify在基因组中寻找marker-genes\"></a> Step 1: identify—— 在基因组中寻找 marker genes</h4>\n<p>Translation table 选择：use table 11 unless the coding density using table 4 is 5% higher than when using table 11 and the coding density under table 4 is &gt;70%.  GTDB-Tk 不会区分 tables 4 和 tables 5. 若用户清楚使用哪一个 table，可以通过 --batchfile 指定。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk identify --genome_dir metawrap_70_5_bins/ --out_dir identify_output --cpus <span class=\"token number\">6</span> --prefix F --debug -x .fa --write_single_copy_genes<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"step-2-align\"><a class=\"markdownIt-Anchor\" href=\"#step-2-align\"></a> Step 2: align</h4>\n<p>Create a multiple sequence alignment based on the AR122/BAC120 marker set.<br />\nTime 3m50.019s</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk align --identify_dir identify_output/ --out_dir align_output --cpus <span class=\"token number\">3</span> --prefix F --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"step-3-classify\"><a class=\"markdownIt-Anchor\" href=\"#step-3-classify\"></a> Step 3: classify</h4>\n<p>Determine taxonomic classification of genomes.<br />\nTime 118m9.386s</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk classify --genome_dir metawrap_70_5_bins/ --align_dir align_output/ --out_dir classify_output --cpus <span class=\"token number\">3</span> --prefix F --debug -x .fa -r<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注意</strong>：如果内存较小，则加上 “--scratch_dir” 参数。</p>\n<hr />\n<h4 id=\"step-4-export_msa-这一步不运行\"><a class=\"markdownIt-Anchor\" href=\"#step-4-export_msa-这一步不运行\"></a> Step 4: export_msa (这一步不运行)</h4>\n<p>The export_msa will export the untrimmed archaeal or bacterial MSA used in the reference data.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌 0m1.503s</span>\n$ <span class=\"token function\">time</span> gtdbtk export_msa --domain arc --output msa_arc.faa --debug\n\n<span class=\"token comment\"># 细菌 0m16.679s</span>\n$ <span class=\"token function\">time</span> gtdbtk export_msa --domain bac --output msa_bac.faa --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"step-5-trim_msa-这一步不运行\"><a class=\"markdownIt-Anchor\" href=\"#step-5-trim_msa-这一步不运行\"></a> Step 5: trim_msa (这一步不运行)</h4>\n<p>The trim_msa command will trim a MSA given a user-specified mask file, or the archaeal/bacterial mask present in the reference data.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌 0m10.675s</span>\n$ <span class=\"token function\">time</span> gtdbtk trim_msa --untrimmed_msa msa_arc.faa --output msa_arc_trim.faa --reference_mask arc --debug\n\n<span class=\"token comment\"># 细菌 3m28.793s</span>\n$ <span class=\"token function\">time</span> gtdbtk trim_msa --untrimmed_msa msa_bac.faa --output msa_bac_trim.faa --reference_mask bac --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"step-6-infer\"><a class=\"markdownIt-Anchor\" href=\"#step-6-infer\"></a> Step 6: infer</h4>\n<p>Infer tree from multiple sequence alignment.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#古菌 44m54.884s</span>\n$ <span class=\"token function\">time</span> gtdbtk infer --msa_file align_output/F.ar122.msa.fasta --out_dir infer_out_arc_F --prefix F --cpus <span class=\"token number\">12</span> --debug\n\n<span class=\"token comment\">#细菌</span>\n$ <span class=\"token function\">time</span> gtdbtk infer --msa_file align_output/F.bac120.msa.fasta --out_dir infer_out_bac_F --prefix F --cpus <span class=\"token number\">12</span> --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk infer --msa_file MSA_FILE --out_dir OUT_DIR [--prot_model {JTT,WAG,LG}] [--no_support] [--gamma] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--msa_file MSA_FILE   multiple sequence alignment in FASTA format</li>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--prot_model {JTT,WAG,LG}<br />\nprotein substitution model for tree inference (default: WAG)</li>\n<li>--no_support          do not compute local support values using the Shimodaira-Hasegawa test (default: False)</li>\n<li>--gamma               rescale branch lengths to optimize the Gamma20 likelihood (default: False)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-7-decorate\"><a class=\"markdownIt-Anchor\" href=\"#step-7-decorate\"></a> Step 7: decorate</h4>\n<p>Decorate a tree with the GTDB-Tk taxonomy.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌</span>\n$ <span class=\"token function\">time</span> gtdbtk decorate --input_tree infer_out_arc_F/F.unrooted.tree --output_tree F.decorate_unrooted_arc.tree --gtdbtk_classification_file classify_output/classify/F.ar122.summary.tsv --debug\n\n<span class=\"token comment\"># 细菌</span>\n$ <span class=\"token function\">time</span> gtdbtk decorate --input_tree infer_out_bac_F/F.unrooted.tree --output_tree F.decorate_unrooted_brc.tree --gtdbtk_classification_file classify_output/classify/F.bac120.summary.tsv --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk decorate --input_tree INPUT_TREE --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE] [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE]\n                       [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br />\npath to the unrooted tree in Newick format</li>\n<li>--output_tree OUTPUT_TREE<br />\npath to output the tree</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br />\nfile with GTDB-Tk classifications produced by the  <code>classify</code>  command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br />\nfile indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-8-root\"><a class=\"markdownIt-Anchor\" href=\"#step-8-root\"></a> Step 8: root</h4>\n<p>Root a tree using an outgroup.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk root --input_tree input.tree --outgroup_taxon p__Nanoarchaeota --output_tree output.tree --gtdbtk_classification_file <span class=\"token operator\">&lt;</span>file with GTDB-Tk classifications produced by the classify command<span class=\"token operator\">></span> --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk root --input_tree INPUT_TREE --outgroup_taxon OUTGROUP_TAXON --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE]\n                   [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE] [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br />\npath to the unrooted tree in Newick format</li>\n<li>--outgroup_taxon OUTGROUP_TAXON<br />\ntaxon to use as outgroup (e.g., p__Patescibacteria or p__Altarchaeota)</li>\n<li>--output_tree OUTPUT_TREE<br />\npath to output the tree</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br />\nfile with GTDB-Tk classifications produced by the  <code>classify</code>  command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br />\nfile indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<hr />\n<h4 id=\"step-9-ani_rep计算ani值\"><a class=\"markdownIt-Anchor\" href=\"#step-9-ani_rep计算ani值\"></a> Step 9: ani_rep—— 计算 ANI 值</h4>\n<p>Compute the ANI of input genomes to all GTDB-Tk representative genomes.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk ani_rep --genome_dir metawrap_70_5_bins/ --out_dir ani_rep/ --cpus <span class=\"token number\">6</span> -x .fa --prefix F --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ gtdbtk de_novo_wf --genome_dir metawrap_70_5_bins&#x2F; --out_dir de_novo_wf --extension .fa --bacteria --outgroup_taxon p__Patescibacteria --prefix F --cpus 6 --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk ani_rep (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [--no_mash] [--mash_k MASH_K] [--mash_s MASH_S] [--mash_d MASH_D] [--mash_v MASH_V]\n                      [--mash_db MASH_DB] [--min_af MIN_AF] [-x EXTENSION] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n<ul>\n<li>\n<p>mutually exclusive required arguments:</p>\n<ul>\n<li>\n<p>--genome_dir GENOME_DIR<br />\ndirectory containing genome files in FASTA format</p>\n</li>\n<li>\n<p>--batchfile BATCHFILE<br />\npath to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</p>\n</li>\n<li>\n<p>- required named arguments:</p>\n</li>\n<li>\n<p>--out_dir OUT_DIR     directory to output files</p>\n</li>\n</ul>\n</li>\n<li>\n<p>optional Mash arguments:</p>\n<ul>\n<li>--no_mash             skip pre-filtering of genomes using Mash (default: False)</li>\n<li>--mash_k MASH_K       k-mer size [1-32] (default: 16)</li>\n<li>--mash_s MASH_S       maximum number of non-redundant hashes (default: 5000)</li>\n<li>--mash_d MASH_D       maximum distance to keep [0-1] (default: 0.1)</li>\n<li>--mash_v MASH_V       maximum p-value to keep [0-1] (default: 1.0)</li>\n<li>--mash_db MASH_DB     path to save/read (if exists) the Mash reference sketch database (.msh)</li>\n</ul>\n</li>\n<li>\n<p>optional FastANI arguments:</p>\n<ul>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br />\nextension of files to process, gz = gzipped (default: fna)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n </details>\n<h3 id=\"b42-enrichm-注释\"><a class=\"markdownIt-Anchor\" href=\"#b42-enrichm-注释\"></a> B.4.2 EnrichM 注释</h3>\n<h4 id=\"step-1-annotate\"><a class=\"markdownIt-Anchor\" href=\"#step-1-annotate\"></a> Step 1. annotate</h4>\n<p>基因组注释管道，可以使用 dbCAN 将基因组与 KO, PFAM, TIGRFAM 和 CAZY 数据库进行比对。结果将为每个基因组产生一个.gff 文件，并生成每个注释类型的频率矩阵（frequency matrix），其中行是注释 IDs，列是基因组。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm annotate --genome_directory metawrap_70_5_bins --output EnrichM_annotate --force --ko --ko_hmm --pfam --tigrfam --clusters --orthologs --cazy --ec --threads <span class=\"token number\">30</span> --parallel <span class=\"token number\">8</span> --suffix .fa --count_domains --chunk_number <span class=\"token number\">8</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options (Use one):</p>\n<ul>\n<li>--genome_files GENOME_FILES [GENOME_FILES ...]<br />\nSpace separated list of genomes to annotate</li>\n<li>--genome_directory GENOME_DIRECTORY<br />\nDirectory containing genomes to annotate</li>\n<li>--protein_files PROTEIN_FILES [PROTEIN_FILES ...]<br />\nSpace separated list of .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n<li>--protein_directory PROTEIN_DIRECTORY<br />\nDirectory containing .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n</ul>\n</li>\n<li>\n<p>Annotations options:</p>\n<ul>\n<li>--ko                  Annotate with KO ids</li>\n<li>--ko_hmm              Annotate with KO ids</li>\n<li>--pfam                Annotate with Pfam HMMs</li>\n<li>--tigrfam             Annotate with TIGRFAM HMMs</li>\n<li>--clusters            Annotate with cluster ids</li>\n<li>--orthologs           Annotate with ortholog ids</li>\n<li>--cazy                Annotate with dbCAN HMMs</li>\n<li>--ec                  Annotate with EC ids</li>\n</ul>\n</li>\n<li>\n<p>Cutoff options:</p>\n<ul>\n<li>--cut_ga              For PFAM and TIGRfam searches: use profiles GA gathering cutoffs to set all thresholding</li>\n<li>--cut_nc              For PFAM and TIGRfam searches: use profiles NC noise cutoffs to set all thresholding</li>\n<li>--cut_tc              For PFAM and TIGRfam searches: use profiles TC trusted cutoffs to set all thresholding</li>\n<li>--cut_ko              For KO HMM annotation searches: use cutoffs defined by KEGG to maximise F-score.</li>\n<li>--evalue EVALUE       Use this evalue cutoff to filter false positives (default: 1e-05)</li>\n<li>--bit BIT             Use this bit score cutoff to filter false positives (default: 0)</li>\n<li>--id ID               Use this percent identity cutoff to filter false positives (default: 0.3)</li>\n<li>--aln_query ALN_QUERY<br />\nThis fraction of the query must align to the reference (default: 0.7)</li>\n<li>--aln_reference ALN_REFERENCE<br />\nThis fraction of the reference must align to the query (default: 0.7)</li>\n<li>--c C                 When clustering, use matches above this fraction of aligned (covered) query and target residues (default: 0.7)</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--threads THREADS     Use this number of threads when annotating with BLAST and HMMsearch (default: 1)</li>\n<li>--parallel PARALLEL   Run this number of jobs in parallel when annotating with HMMsearch (default: 5)</li>\n<li>--inflation INFLATION<br />\nInflation factor to use when calling clusters in ortholog (default = 5.0)</li>\n<li>--suffix SUFFIX       Treat files ending with this suffix within the --genome_directory as genomes (default: .fna for --genome_directory and .faa for )</li>\n<li>--light               Don't store metadata for genome files (can't use enrichM compare downstream, default=False)</li>\n<li>--count_domains       Fill the frequency matrix with the total number of times an annotation was detected (for example, when one domain more than once within a protein), rather than the count of proteins with with that annotation</li>\n<li>--chunk_number CHUNK_NUMBER<br />\nSplit loading of genomes into this many chunks (default = 4)</li>\n<li>--chunk_max CHUNK_MAX<br />\nMaximum number of genomes to load per chunk (default = 2500)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-2-classify\"><a class=\"markdownIt-Anchor\" href=\"#step-2-classify\"></a> Step 2. classify</h4>\n<p>Determine what pathways a genome encodes. Classify quickly reads in KO annotations in the form of a matrix (KO IDs as rows, genomes as columns) and determines which KEGG modules are complete. Annotation matrices can be generated using the annotate function.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm classify --output EnrichM_classify/ko_hmm_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_hmm_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ko_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n<span class=\"token comment\"># 以下6个命令可不必运行</span>\n$ enrichm classify --output EnrichM_classify/cazy_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cazy_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/cluster_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cluster_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ec_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ec_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ortholog_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ortholog_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/pfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/pfam_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/tigrfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/tigrfam_frequency_table.tsv --cutoff <span class=\"token number\">0</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--genome_and_annotation_matrix GENOME_AND_ANNOTATION_MATRIX<br />\nPath to file containing a genome annotation matrix</li>\n<li>--custom_modules CUSTOM_MODULES<br />\nTab separated file containing module name, definition as the columns</li>\n<li>--module_rules_json MODULE_RULES_JSON<br />\njson file specifying rules to interpret the annotation and guide module annotation</li>\n<li>--gff_files GFF_FILES<br />\nGFF files for the genomes being classified.</li>\n</ul>\n</li>\n<li>\n<p>Cutoff options:</p>\n<ul>\n<li>--cutoff CUTOFF       Output only modules with greater than this percent of the requied KO groups (default = print all modules)</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--aggregate           Calculate the abundance of each pathway within each genome/sample (column)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-3-enrichment\"><a class=\"markdownIt-Anchor\" href=\"#step-3-enrichment\"></a> Step 3. enrichment</h4>\n<p>Enrichment will read in KO or PFAM annotations in the form of a matrix (IDs as rows, genomes as columns) and a metadata file that separates genomes into groups to compare, and will run some basic stats to determine the enrichment of modules or pfam clans between and within the groups.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm enrichment --output EnrichM_enrichment/ --metadata genome.list --annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --force<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>- Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--annotate_output ANNOTATE_OUTPUT<br />\nOutput directory provided by enrichm annotate</li>\n<li>--metadata METADATA   Metadata file with two columns, the first with the genome name, the second with the groupings to compare.</li>\n<li>--annotation_matrix ANNOTATION_MATRIX<br />\nAnnotation matrix to compare.</li>\n<li>--gff_files GFF_FILES [GFF_FILES ...]<br />\nGff files for genomes to compare.</li>\n<li>--abundance 基因组丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata grouping abundance samples.</li>\n<li>--transcriptome TRANSCRIPTOME  基因组丰度矩阵</li>\n<li>--transcriptome_metadata TRANSCRIPTOME_METADATA<br />\nMetadata grouping abundance samples.</li>\n</ul>\n</li>\n<li>\n<p>Genome Taxonomy DataBase (GTDB) options:</p>\n<ul>\n<li>--batchfile BATCHFILE<br />\nmetadata file to compare with.</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--pval_cutoff PVAL_CUTOFF<br />\nOnly output results with a p-value below a this cutoff (default=0.05).</li>\n<li>--proportions_cutoff PROPORTIONS_CUTOFF<br />\nProportion enrichment cutoff.</li>\n<li>--threshold THRESHOLD<br />\nThe threshold to control for in false discovery rate of familywise error rate.</li>\n<li>--multi_test_correction MULTI_TEST_CORRECTION<br />\nThe form of mutiple test correction to use. Uses the statsmodel module and consequently has all of its options.<br />\nDefault: Benjamini-Hochberg FDR (fdr_bh)<br />\nOptions: Bonferroni (b)<br />\nSidak (s)<br />\nHolm (h)<br />\nHolm-Sidak (hs)<br />\nSimes-Hochberg (sh)<br />\nHommel (ho)<br />\nFDR Benjamini-Yekutieli (fdr_by)<br />\nFDR 2-stage Benjamini-Hochberg (fdr_tsbh)<br />\nFDR 2-stage Benjamini-Krieger-Yekutieli (fdr_tsbky)<br />\nFDR adaptive Gavrilov-Benjamini-Sarkar (fdr_gbs))</li>\n<li>--processes PROCESSES  采用多少个进程进行富集分析</li>\n<li>--allow_negative_values  允许输入的矩阵中有负值</li>\n<li>--ko                    Compare KO ids (annotated with DIAMOND)</li>\n<li>--ko_hmm          Compare KO ids (annotated with HMMs)</li>\n<li>--pfam                Compare Pfam ids</li>\n<li>--tigrfam             Compare TIGRFAM ids</li>\n<li>--cluster              Compare cluster ids</li>\n<li>--ortholog            Compare ortholog ids</li>\n<li>--cazy                 Compare dbCAN ids</li>\n<li>--ec                     Compare EC ids</li>\n<li>--range RANGE         Base pair range to search for synteny within. Default = 2500.</li>\n<li>--subblock_size SUBBLOCK_SIZE<br />\nNumber of genes clustered in a row to be reported. Default = 2.</li>\n<li>--operon_mismatch_cutoff OPERON_MISMATCH_CUTOFF<br />\nNumber of allowed mismatches when searching for operons across genomes. Defaul</li>\n<li>--operon_match_score_cutoff OPERON_MATCH_SCORE_CUTOFF<br />\nScore cutoff for operon matches</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-4-pathway\"><a class=\"markdownIt-Anchor\" href=\"#step-4-pathway\"></a> Step 4. pathway</h4>\n<p>Pathway reads in a KO matrix and generates a Cytoscape-readable metabolic network and metadata file. Only reactions that are possible given the KOs present in the input matrix are shown, and the modules and reactions that are included in the output can be customized（<strong>报错</strong>）.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm pathway --matrix EnrichM_annotate/ko_frequency_table.tsv --genome_metadata genome.list --output EnrichM_pathway --abundance EnrichM_enrichment/F01_vs_F02_ivg_results.cdf.tsv --abundance_metadata genome.list --force<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--matrix KO 矩阵。必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--tpm_values TPM_VALUES<br />\nDetectM 产生的 TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--metabolome METABOLOME<br />\nMetabolome CID matrix.</li>\n</ul>\n</li>\n<li>\n<p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br />\nLevel of verbosity (1 - 5 - default = 4) 5 = Very verbose, 1 = Silent</li>\n</ul>\n</li>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li>\n<p>Pathway options:</p>\n<ul>\n<li>--limit LIMIT [LIMIT ...]<br />\nUSE ONLY these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--filter FILTER [FILTER ...]<br />\nDo not use these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--enrichment_output ENRICHMENT_OUTPUT<br />\nSupply an enrichment output to integrate the results into the output network.</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-5-explore\"><a class=\"markdownIt-Anchor\" href=\"#step-5-explore\"></a> Step 5. explore</h4>\n<p>Explore is similar to pathway, but rather than generating a specified pathway it will start from a given query compound ID, and explore the possible reactions that use that compound given the enzymes present in the input KO matrix.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--matrix MATRIX       KO 矩阵。必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare..</li>\n<li>--tpm_values TPM_VALUES<br />\nDetectM 产生的 TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare..</li>\n<li>--metabolome METABOLOME<br />\nMetabolome CID matrix.</li>\n</ul>\n</li>\n<li>\n<p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br />\nLevel of verbosity (1 - 5 - default = 4) 5 = Very verbose, 1 = Silent</li>\n</ul>\n</li>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li>\n<p>Query options:</p>\n<ul>\n<li>--queries QUERIES     A file containing the KEGG ids of the compounds from which to start in the metabolic network</li>\n<li>--depth DEPTH         Number of steps to take into the metabolic network</li>\n</ul>\n</li>\n</ul>\n</details>\n<h1 id=\"c-metagenome-functional-profiling\"><a class=\"markdownIt-Anchor\" href=\"#c-metagenome-functional-profiling\"></a> C Metagenome functional profiling</h1>\n<ul>\n<li>从宏基因组组装的 contigs 中预测基因 ——prodigal -p meta 模式</li>\n<li>Metagenome-assembled genes which were not included in the MAGs were subjected to taxonomic classification using <a href=\"https://github.com/bioinformatics-centre/kaiju\">Kaiju</a></li>\n<li>eggNOG-mapper 比对<a href=\"https://doi.org/10.1093/nar/gkv1248\"> eggnog</a> 数据库</li>\n<li>HMMER 比对<a href=\"https://doi.org/10.1093/nar/gky995\"> Pfam</a></li>\n<li><a href=\"https://www.kegg.jp/blastkoala/\">GhostKOALA </a>和<a href=\"https://www.genome.jp/tools/kofamkoala/\"> KofamKOALA (v1.0.0)</a> 比对<a href=\"https://doi.org/10.1093/nar/28.1.27\"> KEGG</a></li>\n<li>BLASTP 比对<a href=\"https://doi.org/10.1093/nar/gkv1103\"> TCDB</a></li>\n<li><a href=\"http://bcb.unl.edu/dbCAN2/\">dbCAN2 (v2.0.1)</a> 比对<a href=\"https://doi.org/10.1093/nar/gkn663\"> CAZy</a></li>\n<li>BLASTP 比对<a href=\"https://www.ebi.ac.uk/merops/submit_searches.shtml\"> MEROPS </a></li>\n<li><a href=\"https://github.com/Arkadiy-Garber/FeGenie\">FeGenie</a> 检测 Iron-related genes</li>\n<li>Fe-containing domains were characterized using <a href=\"https://doi.org/10.1073/pnas.0605798103\">Superfamily (v1.75)</a>.</li>\n<li>砷呼吸和抗性基因挖掘<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search\"> https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search</a>，模型下载 https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource</li>\n</ul>\n<h1 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料：</h1>\n<ul>\n<li><a href=\"https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-3.0\">MetaPhlAn 3.0 tutorial</a></li>\n<li><a href=\"https://zouhua.top/archives/9d8099c8.html\">MetaPhlAn 3.0: 宏基因组物种组成分析软件</a></li>\n<li><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">GraPhlAn Tutorial</a></li>\n<li></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"宏基因组","path":"api/tags/宏基因组.json"}]},{"title":"PGCGAP中文说明","slug":"PGCGAP中文说明","date":"2019-04-28T07:22:33.000Z","updated":"2022-01-08T02:16:28.409Z","comments":true,"path":"api/articles/PGCGAP中文说明.json","excerpt":null,"keywords":null,"cover":null,"content":"<p><strong>为了方便广大中文用户学习 PGCGAP 的使用，特意书写该中文文档，但中文文档更新较慢，强烈建议大家阅读英文文档！</strong></p>\n<span id=\"more\"></span>\n<p><a href=\"https://liaochenlanruo.github.io/pgcgap\">English Readme</a> | <a href=\"https://liaochenlanruo.github.io/2019/04/28/PGCGAP%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E/\">中文说明</a></p>\n<h2 id=\"简介\"><a class=\"markdownIt-Anchor\" href=\"#简介\"></a> 简介</h2>\n<p>PGCGAP 是用于原核生物基因组学和比较基因组学分析管道，目前该管道包含 12 个模块，可以接受 Illumina 双端 reads、Oxford reads 或 PacBio reads 作为输入，可以完成基因组组装、基因预测和注释，并可以进行比较基因组学分析，包括构建单拷贝核心蛋白进化树以及单拷贝核心基因 SNPs 进化树，泛基因组分析与进化树构建，全基因组平均核苷酸一致性（ANI）计算，同源蛋白家族聚类及进化树构建，COG 注释，SNPs 和 INDELs calling，抗生素抗性基因 / 毒力因子预测，Multi-FASTA 进化树构建，组装后基因组短序列过滤与统计信息呈现（genome size，GC content……）。</p>\n<h2 id=\"安装\"><a class=\"markdownIt-Anchor\" href=\"#安装\"></a> 安装</h2>\n<p>PGCGAP 可以安装于 Windows 子系统 Linux（WSL）、Linux x64 系统以及 macOS 中。</p>\n<p><strong>Step1：通过<a href=\"https://bioconda.github.io/user/install.html#install-conda\"> Bioconda</a> 安装 PGCGAP</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> create -n pgcgap <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.7</span>\n\n<span class=\"token variable\">$conda</span> activate pgcgap\n\n<span class=\"token variable\">$conda</span> <span class=\"token function\">install</span> pgcgap\n\n<span class=\"token variable\">$conda</span> deactivate\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>声明：用conda安装时一直在“Solving environment”怎么办？</strong>随着加入conda的软件越来越多，使其索引库变的庞大，因此安装新的软件时需要逐一验证软件间的兼容性，会耗费大量时间。严重的时候会无法完成软件的安装，这个时候坐以待毙是不行的。下面介绍两种办法解决此问题：<br/></p>\n<ul>\n<li>\n<p>Method 1: 使用 mamba (非常快) 替代 conda。前提是已经用 conda 创建好了 pgcgap 的虚拟环境：</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> activate pgcgap\n<span class=\"token variable\">$conda</span> <span class=\"token function\">install</span> mamba -c conda-forge\n<span class=\"token variable\">$mamba</span> <span class=\"token function\">install</span> pgcgap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>Method 2: 使用本人提供的 pgcgap<a href=\"https://github.com/liaochenlanruo/pgcgap/blob/master/conda/pgcgap_latest_env.ym\"> 配置文件</a>来创建环境并安装 PGCGAP：</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># download pgcgap_latest_env.yml</span>\n<span class=\"token variable\">$wget</span> https://github.com/liaochenlanruo/pgcgap/blob/master/conda/pgcgap_latest_env.yml\n\t\n<span class=\"token comment\"># create a conda environment named as pgcgap and install the latest version of PGCGAP</span>\n<span class=\"token variable\">$conda</span> <span class=\"token function\">env</span> create -f pgcgap_latest_env.yml<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<br/>\n<p><strong>Step2：配置 COG 数据库</strong> (初次安装 PGCGAP 后需要执行此步骤)</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> activate pgcgap\n\n<span class=\"token variable\">$pgcgap</span> --setup-COGdb\n\n<span class=\"token variable\">$conda</span> deactivate<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>Step3: 升级 PGCGAP (升级版本时运行)</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> activate pgcgap\n<span class=\"token variable\">$conda</span> update pgcgap\n<span class=\"token comment\"># v1.0.28以后可通过如下命令升级</span>\n<span class=\"token variable\">$pgcgap</span> --check-update<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>此外，用户也可以通过容器 (docker) 安装 PGCGAP</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$docker</span> pull quay.io/biocontainers/pgcgap:<span class=\"token operator\">&lt;</span>tag<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注：</strong> 前提是用户电脑中安装了<a href=\"https://www.docker.com/\"> Docker</a>，Docker 可以跨平台使用。可用的 tag 可<a href=\"https://quay.io/repository/biocontainers/pgcgap?tab=tags\">在此</a>查询，建议安装最新版。</p>\n<h2 id=\"依赖包\"><a class=\"markdownIt-Anchor\" href=\"#依赖包\"></a> 依赖包</h2>\n<ul>\n<li><a href=\"https://github.com/tseemann/abricate\">Abricate</a></li>\n<li><a href=\"http://www.bcgsc.ca/platform/bioinfo/software/abyss/\">ABySS</a></li>\n<li><a href=\"http://canu.readthedocs.org/\">Canu</a></li>\n<li><a href=\"http://weizhongli-lab.org/cd-hit/\">CD-HIT</a></li>\n<li><a href=\"https://www.gnu.org/software/coreutils/\">Coreutils</a></li>\n<li><a href=\"https://github.com/bbuchfink/diamond\">Diamond</a></li>\n<li><a href=\"https://github.com/ParBLiSS/FastANI\">FastANI</a></li>\n<li><a href=\"http://www.atgc-montpellier.fr/fastme/binaries.php\">Fastme</a></li>\n<li><a href=\"https://github.com/OpenGene/fastp\">Fastp</a></li>\n<li><a href=\"http://www.microbesonline.org/fasttree\">FastTree</a></li>\n<li><a href=\"https://github.com/sanger-pathogens/gubbins\">Gubbins</a> &gt;=2.3.4</li>\n<li><a href=\"https://github.com/samtools/htslib\">Htslib</a></li>\n<li><a href=\"http://www.iqtree.org/\">IQ-TREE</a></li>\n<li><a href=\"https://mafft.cbrc.jp/alignment/software/\">Mafft</a></li>\n<li><a href=\"https://github.com/marbl/Mash\">Mash</a></li>\n<li><a href=\"https://github.com/soedinglab/mmseqs2\">Mmseqs2</a></li>\n<li><a href=\"https://www.ebi.ac.uk/Tools/msa/muscle/\">Muscle</a></li>\n<li><a href=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download\">NCBI-blast+</a></li>\n<li><a href=\"https://github.com/davidemms/OrthoFinder\">OrthoFinder</a></li>\n<li><a href=\"https://openjdk.java.net/\">OpenJDK8</a></li>\n<li><a href=\"http://www.bork.embl.de/pal2nal/\">PAL2NAL v14</a></li>\n<li><a href=\"http://trimal.cgenomics.org\">trimAL</a></li>\n<li><a href=\"http://www.perl.org/get.html\">Perl</a> &amp; the modules\n<ul>\n<li><a href=\"http://metacpan.org/pod/BioPerl\">perl-bioperl</a></li>\n<li><a href=\"http://metacpan.org/pod/Data::Dumper\">perl-data-dumper</a></li>\n<li><a href=\"http://metacpan.org/pod/File::Tee\">perl-file-tee</a></li>\n<li><a href=\"http://metacpan.org/pod/Getopt::Long\">perl-getopt-long</a></li>\n<li><a href=\"http://search.cpan.org/~marekr/Pod-Usage-1.69/\">perl-pod-usage</a></li>\n<li><a href=\"https://metacpan.org/pod/release/DLUX/Parallel-ForkManager-0.7.5/ForkManager.pm\">perl-parallel-forkmanager</a></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/tseemann/prokka\">Prokka</a></li>\n<li><a href=\"https://www.python.org/\">Python</a> &amp; the modules\n<ul>\n<li><a href=\"https://biopython.org/\">biopython</a></li>\n<li><a href=\"https://matplotlib.org/\">matplotlib</a></li>\n<li><a href=\"http://www.numpy.org/\">numpy</a></li>\n<li><a href=\"http://pandas.pydata.org/\">pandas</a></li>\n<li><a href=\"http://seaborn.pydata.org/\">seaborn</a></li>\n</ul>\n</li>\n<li><a href=\"https://www.r-project.org/\">R</a> &amp; the packages\n<ul>\n<li><a href=\"https://cran.r-project.org/web/packages/corrplot/index.html\">corrplot</a></li>\n<li><a href=\"https://cran.r-project.org/web/packages/ggplot2/\">ggplot2</a></li>\n<li><a href=\"https://cran.r-project.org/web/packages/gplots/\">gplots</a></li>\n<li><a href=\"https://cran.r-project.org/web/packages/pheatmap/index.html\">pheatmap</a></li>\n<li><a href=\"https://cran.r-project.org/web/packages/plotrix/\">plotrix</a></li>\n</ul>\n</li>\n<li><a href=\"https://sanger-pathogens.github.io/Roary/\">Roary</a></li>\n<li><a href=\"https://github.com/najoshi/sickle\">Sickle-trim</a></li>\n<li><a href=\"https://github.com/tseemann/snippy\">Snippy</a></li>\n<li><a href=\"https://github.com/sanger-pathogens/snp-sites\">Snp-sites</a></li>\n<li><a href=\"https://github.com/rrwick/Unicycler\">unicycler</a></li>\n<li><a href=\"https://www.gnu.org/software/wget/\">wget</a></li>\n</ul>\n<h2 id=\"pgcgap用法\"><a class=\"markdownIt-Anchor\" href=\"#pgcgap用法\"></a> PGCGAP 用法</h2>\n<ul>\n<li>\n<p><strong>显示帮助信息：</strong></p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --help<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>管道用法：</strong></p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> <span class=\"token punctuation\">[</span>modules<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">[</span>options<span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>展示各模块的参数：</strong></p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> <span class=\"token punctuation\">[</span>Assemble<span class=\"token operator\">|</span>Annotate<span class=\"token operator\">|</span>ANI<span class=\"token operator\">|</span>AntiRes<span class=\"token operator\">|</span>CoreTree<span class=\"token operator\">|</span>MASH<span class=\"token operator\">|</span>OrthoF<span class=\"token operator\">|</span>Pan<span class=\"token operator\">|</span>pCOG<span class=\"token operator\">|</span>VAR<span class=\"token operator\">|</span>STREE<span class=\"token operator\">|</span>ACC<span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>展示各模块的运行示例：</strong>（这货是我用的最多的）</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> Examples<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>配置 COG 数据库：</strong> (初次安装 PGCGAP 后需要配置 COG 数据库)</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --setup-COGdb<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>功能模块：</strong></p>\n<ul>\n<li>\n<p><strong>[--All]</strong>                          运行 Assemble, Annotate, CoreTree, Pan, OrthoF, ANI, MASH 和 pCOG 模块</p>\n</li>\n<li>\n<p><strong>[--Assemble]</strong>                     基因组组装</p>\n</li>\n<li>\n<p><strong>[--Annotate]</strong>                     基因预测及注释</p>\n</li>\n<li>\n<p><strong>[--CoreTree]</strong>                     构建单拷贝核心蛋白进化树与核心 SNPs 进化树</p>\n</li>\n<li>\n<p><strong>[--Pan]</strong>                          泛基因组分析并构建单拷贝核心蛋白进化树</p>\n</li>\n<li>\n<p><strong>[--OrthoF]</strong>                       同源蛋白家族聚类及单拷贝直系同源蛋白进化树构建</p>\n</li>\n<li>\n<p><strong>[--ANI]</strong>                          计算平均核苷酸一致性 (ANI)</p>\n</li>\n<li>\n<p><strong>[--MASH]</strong>                         通过 MinHash 估算基因组 / 宏基因组相似性</p>\n</li>\n<li>\n<p><strong>[--pCOG]</strong>                         COG 注释</p>\n</li>\n<li>\n<p><strong>[--VAR]</strong>                          变异检测并构建核心基因组进化树</p>\n</li>\n<li>\n<p><strong>[--AntiRes]</strong>                      从基因组 (contigs/scaffolds) 中预测抗生素抗性基因或毒力基因</p>\n</li>\n<li>\n<p><strong>[--STREE]</strong>                        基于 Multi-FASTA 序列 (所有序列在一个文件中) 构建系统发育树</p>\n</li>\n<li>\n<p><strong>[--ACC]</strong>                          一些实用的附加程序 (目前只开发了 &quot;Assess&quot; 用于对基因组中的短序列进行过滤，并评估过滤前后的基因组状态)</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>全局参数（请参照英文版，参数有所改变，中文版暂时没有时间修改）：</strong></p>\n<ul>\n<li>\n<p><strong>[--strain_num (INT)]</strong>             [Required by &quot;--All&quot;, &quot;--CoreTree&quot;, &quot;--Pan&quot;, &quot;--VAR&quot; and &quot;--COG&quot;] 用于分析的菌株数目，不包含参考基因组</p>\n</li>\n<li>\n<p><strong>[--ReadsPath (PATH)]</strong>             [Required by &quot;--All&quot;, &quot;--Assemble&quot; and &quot;--VAR&quot;] 所有菌株测序 reads 所在的目录路径  Default ./Reads/Illumina)</p>\n</li>\n<li>\n<p><strong>[--scafPath (PATH)]</strong>              [Required by &quot;--All&quot;, &quot;--Assess&quot;, &quot;--Annotate&quot; and &quot;--MASH&quot;] contigs/scaffolds 的存放路径 (Default &quot;Results/Assembles/Scaf/Illumina&quot;)</p>\n</li>\n<li>\n<p><strong>[--AAsPath (PATH)]</strong>               [Required by &quot;--All&quot;, &quot;--CoreTree&quot;, &quot;--OrthoF&quot; and &quot;--pCOG&quot;] 所有菌株的氨基酸序列文件的存放路径 (Default &quot;./Results/Annotations/AAs&quot;)</p>\n</li>\n<li>\n<p><strong>[--reads1 (STRING)]</strong>              [Required by &quot;--All&quot;, &quot;--Assemble&quot; and &quot;--VAR&quot;] reads 1 的后缀名 (例如 reads 1 的名字为 &quot;YBT-1520_L1_I050.R1.clean.fastq.gz&quot;，&quot;YBT-1520&quot; 是菌株名，则后缀名为 &quot;.R1.clean.fastq.gz&quot;)</p>\n</li>\n<li>\n<p><strong>[--reads2 (STRING)]</strong>              [Required by &quot;--All&quot;, &quot;--Assemble&quot; and &quot;--VAR&quot;] reads 2 的后缀名</p>\n</li>\n<li>\n<p><strong>[--Scaf_suffix (STRING)]</strong>         [Required by &quot;--All&quot;, &quot;--Assess&quot;, &quot;--Annotate&quot; &quot;MASH&quot; and &quot;--ANI&quot;] contigs/scaffolds 的后缀名 (Default -8.fa)</p>\n</li>\n<li>\n<p><strong>[--filter_length (INT)]</strong>          [Required by &quot;--All&quot;, &quot;--Assemble&quot; and &quot;--Assess&quot;]&gt; Sequences shorter than the 'filter_length' will be deleted from the assembled genomes. ( Default 200 )</p>\n</li>\n<li>\n<p><strong>[--codon (INT)]</strong>                  [Required by &quot;--All&quot;, &quot;--Annotate&quot;, &quot;--CoreTree&quot; and &quot;--Pan&quot;] 翻译密码子表 (Default 11)</p>\n<ul>\n<li>1                             Universal code</li>\n<li>2                             Vertebrate mitochondrial code</li>\n<li>3                             Yeast mitochondrial code</li>\n<li>4                             Mold, Protozoan, and Coelenterate Mitochondrial code and Mycoplasma/Spiroplasma code</li>\n<li>5                             Invertebrate mitochondrial</li>\n<li>6                             Ciliate, Dasycladacean and Hexamita nuclear code</li>\n<li>9                             Echinoderm and Flatworm mitochondrial code</li>\n<li>10                            Euplotid nuclear code</li>\n<li>11                            Bacterial, archaeal and plant plastid code ( Default )</li>\n<li>12                            Alternative yeast nuclear code</li>\n<li>13                            Ascidian mitochondrial code</li>\n<li>14                            Alternative flatworm mitochondrial code</li>\n<li>15                            Blepharisma nuclear code</li>\n<li>16                            Chlorophycean mitochondrial code</li>\n<li>21                            Trematode mitochondrial code</li>\n<li>22                            Scenedesmus obliquus mitochondrial code</li>\n<li>23                            Thraustochytrium mitochondrial code</li>\n</ul>\n</li>\n<li>\n<p><strong>[--suffix_len (INT)]</strong>             [Required by &quot;--All&quot;, &quot;--Assemble&quot; and &quot;--VAR&quot;] <strong>(强烈建议设置此项)</strong> reads 后缀的长度。例如 &quot;YBT-1520_L1_I050.R1.clean.fastq.gz&quot; 的 --suffix_len 为 26 (&quot;YBT-1520&quot; 为菌株名) (Default 0)</p>\n</li>\n<li>\n<p><strong>[--logs (STRING)]</strong>                Log 文件的名字 (Default Logs.txt)</p>\n</li>\n<li>\n<p><strong>[--threads (INT)]</strong>                运行程序时调用的线程数目 (Default 4)<br />\n<br/></p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>各模块的局部参数：</strong></p>\n<ul>\n<li>\n<p><strong>--Assemble</strong></p>\n<ul>\n<li>\n<p><strong>[--platform (STRING)]</strong>        [Required] 测序平台，可以选择 “illumina”, “pacbio” 和 “oxford” (Default illumina)</p>\n</li>\n<li>\n<p><strong>[--assembler (STRING)]</strong>       [Required] 用于 illumina 数据组装的软件，可选 &quot;abyss&quot;, &quot;spades&quot; 或 &quot;auto&quot; ( Default abyss )</p>\n</li>\n<li>\n<p><strong>[--kmmer (INT)]</strong>              [Required] Illumina 数据组装时采用的 k-mer 大小 (Default 81)</p>\n</li>\n<li>\n<p><strong>[--genomeSize (FLOAT)]</strong>       [Required] 预估的基因组大小，如 3.7m、2.8g，组装 PacBio data 和 Oxford data 时需要设置此项 (Default Unset)</p>\n</li>\n<li>\n<p><strong>[--short1 (STRING)]</strong>           [Required] FASTQ file of first short reads in each pair. Needed by hybrid assembly ( Default Unset )</p>\n</li>\n<li>\n<p><strong>[--short2 (STRING)]</strong>           [Required] FASTQ file of second short reads in each pair. Needed by hybrid assembly ( Default Unset )</p>\n</li>\n<li>\n<p><strong>[--long (STRING)]</strong>             [Required] FASTQ or FASTA file of long reads. Needed by hybrid assembly ( Default Unset )</p>\n</li>\n<li>\n<p><strong>[--hout (STRING)]</strong>             [Required] Output directory for hybrid assembly ( Default ../../Results/Assembles/Hybrid )</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--Annotate</strong></p>\n<ul>\n<li>\n<p><strong>[--genus (STRING)]</strong>           菌株的属名 (Default &quot;NA&quot;)</p>\n</li>\n<li>\n<p><strong>[--species (STRING)]</strong>         菌株的种名 (Default &quot;NA&quot;)<br />\n<br/></p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--CoreTree</strong></p>\n<ul>\n<li>\n<p><strong>[--CDsPath (PATH)]</strong>           [Required] 包含所有菌株核苷酸序列文件的路径，如果设置为 &quot;NO&quot;，将不会构建核心 SNPs 进化树 ( Default &quot;./Results/Annotations/CDs&quot; )</p>\n</li>\n<li>\n<p><strong>[-c (FLOAT)]</strong>                 序列一致性 (identity) 阈值 ( Default 0.5)</p>\n</li>\n<li>\n<p><strong>[-n (INT)]</strong>                   Word_length,  -n 2 for thresholds 0.4-0.5, -n 3 for thresholds 0.5-0.6, -n 4 for thresholds 0.6-0.7, -n 5 for thresholds 0.7-1.0 ( Default 2 )</p>\n</li>\n<li>\n<p><strong>[-G (INT)]</strong>                   Use global (set to 1) or local (set to 0) sequence identity, ( Default 0 )</p>\n</li>\n<li>\n<p><strong>[-t (INT)]</strong>                   Tolerance for redundance ( Default 0 )</p>\n</li>\n<li>\n<p><strong>[-aL (FLOAT)]</strong>                Alignment coverage for the longer sequence. If set to 0.9, the alignment must covers 90% of the sequence ( Default 0.5 )</p>\n</li>\n<li>\n<p><strong>[-aS (FLOAT)]</strong>                Alignment coverage for the shorter sequence. If set to 0.9, the alignment must covers 90% of the sequence ( Default 0.7 )</p>\n</li>\n<li>\n<p><strong>[-g (INT)]</strong>                   If set to 0, a sequence is clustered to the first cluster that meet the threshold (fast cluster). If set to 1, the program will cluster it into the most similar cluster that meet the threshold (accurate but slow mode, Default 1)</p>\n</li>\n<li>\n<p><strong>[-d (INT)]</strong>                   length of description in .clstr file. if set to 0, it takes the fasta defline and stops at first space ( Default 0 )<br />\n<br/></p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--Pan</strong></p>\n<ul>\n<li>\n<p><strong>[--GffPath (PATH)]</strong>           [Required] 存放所有菌株 GFF3 格式文件的路径 ( Default &quot;./Results/Annotations/GFF&quot; )</p>\n</li>\n<li>\n<p><strong>[--identi (INT)]</strong>                  Minimum percentage identity for blastp ( Default 95 )<br />\n<br/></p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--OrthoF</strong></p>\n<ul>\n<li><strong>[--Sprogram (STRING)]</strong>        序列对比程序，Options: blast, mmseqs, blast_gz, diamond (Default blast)<br />\n<br/></li>\n</ul>\n</li>\n<li>\n<p><strong>--ANI</strong></p>\n<ul>\n<li>\n<p><strong>[--queryL (FILE)]</strong>            [Required] The file containing paths to query genomes, one per line ( Default scaf.list )</p>\n</li>\n<li>\n<p><strong>[--refL (FILE)]</strong>              [Required] The file containing paths to reference genomes, one per line. ( Default scaf.list )</p>\n</li>\n<li>\n<p><strong>[--ANIO (FILE)]</strong>              The name of output file ( Default &quot;Results/ANI/ANIs&quot; )</p>\n</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p><strong>--VAR</strong></p>\n<ul>\n<li>\n<p><strong>[--refgbk (FILE)]</strong>            [Required] The full path and name of reference genome in GENBANK format ( recommended ), fasta format is also OK. For example: &quot;/mnt/g/test/ref.gbk&quot;</p>\n</li>\n<li>\n<p><strong>[--qualtype (STRING)]</strong>        [Required] Type of quality values (solexa (CASAVA &lt; 1.3), illumina (CASAVA 1.3 to 1.7), sanger (which is CASAVA &gt;= 1.8)). ( Default sanger )</p>\n</li>\n<li>\n<p><strong>[--qual (INT)]</strong>               Threshold for trimming based on average quality in a window. ( Default 20 )</p>\n</li>\n<li>\n<p><strong>[--length (INT)]</strong>             Threshold to keep a read based on length after trimming. ( Default 20 )</p>\n</li>\n<li>\n<p><strong>[--mincov (INT)]</strong>             The minimum number of reads covering a site to be considered ( Default 10 )</p>\n</li>\n<li>\n<p><strong>[--minfrac (FLOAT)]</strong>          The minimum proportion of those reads which must differ from the reference ( Default 0.9 )</p>\n</li>\n<li>\n<p><strong>[--minqual (INT)]</strong>            The minimum VCF variant call &quot;quality&quot; ( Default 100 )</p>\n</li>\n<li>\n<p><strong>[--ram (INT)]</strong>                Try and keep RAM under this many GB ( Default 8 )</p>\n</li>\n<li>\n<p><strong>[--tree_builder (STRING)]</strong>    Application to use for tree building [raxml|fasttree|hybrid] ( Default fasttree)</p>\n</li>\n<li>\n<p><strong>[--iterations (INT)]</strong>         Maximum No. of iterations for gubbins ( Default 5 )<br />\n<br/></p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--AntiRes</strong></p>\n<ul>\n<li>\n<p><strong>[--db (STRING)]</strong>              [Required] 用于分析的数据库，options: <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/24145532\">argannot</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/27789705\">card</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5343136/\">ecoh</a>, ecoli_vf, <a href=\"https://www.biorxiv.org/content/10.1101/550707v1\">ncbi</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/24777092\">plasmidfinder</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/22782487\">resfinder</a> and <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/26578559\">vfdb</a>. ( Default ncbi )</p>\n</li>\n<li>\n<p><strong>[--identity (INT)]</strong>           [Required] Minimum %identity to keep the result, should be a number between 1 to 100. ( Default 75 )</p>\n</li>\n<li>\n<p><strong>[--coverage (INT)]</strong>           [Required] Minimum %coverage to keep the result, should be a number between 0 to 100. ( Default 50 )</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--STREE</strong></p>\n<ul>\n<li>\n<p><strong>[--seqfile (STRING)]</strong>        [Required] Path of the sequence file for analysis.</p>\n</li>\n<li>\n<p><strong>[--seqtype (INT)]</strong>           [Required] Type Of Sequence (p, d, c for Protein, DNA, Codons, respectively). ( Default p )</p>\n</li>\n<li>\n<p><strong>[--bsnum (INT)]</strong>             [Required] Times for bootstrap. ( Default 1000 )</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>--ACC</strong></p>\n<ul>\n<li><strong>[--Assess (STRING)]</strong>         Filter short sequences in the genome and assess the status of the genome (详细参数通过 &quot;pgcgap ACC&quot; 查看)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>依赖软件安装目录</strong></p>\n<p>Not needed if they were in the environment variables path. Users can check with the &quot;--check-external-programs&quot; option for the essential programs.<br />\n<br/></p>\n</li>\n<li>\n<p><strong>[--abricate-bin (PATH)]</strong>          Path to abyss binary file. Default tries if abyss is in PATH;</p>\n</li>\n<li>\n<p><strong>[--abyss-bin (PATH)]</strong>             Path to abyss binary file. Default tries if abyss is in PATH;</p>\n</li>\n<li>\n<p><strong>[--canu-bin (PATH)]</strong>              Path to canu binary file. Default tries if canu is in PATH;</p>\n</li>\n<li>\n<p><strong>[--cd-hit-bin (PATH)]</strong>            Path to cd-hit binary file. Default tries if cd-hit is in PATH;</p>\n</li>\n<li>\n<p><strong>[--fastANI-bin (PATH)]</strong>           Path to the fastANI binary file. Default tries if fastANI is in PATH;</p>\n</li>\n<li>\n<p><strong>[--Gblocks-bin (PATH)]</strong>           Path to the Gblocks binary file. Default tries if Gblocks is in PATH;</p>\n</li>\n<li>\n<p><strong>[--gubbins-bin (PATH)]</strong>           Path to the run_gubbins.py binary file. Default tries if run_gubbins.py is in PATH;</p>\n</li>\n<li>\n<p><strong>[--iqtree-bin (PATH)]</strong>            Path to the iqtree binary file. Default tries if iqtree is in PATH;</p>\n</li>\n<li>\n<p><strong>[--mafft-bin (PATH)]</strong>             Path to mafft binary file. Default tries if mafft is in PATH;</p>\n</li>\n<li>\n<p><strong>[--mash-bin (PATH)]</strong>              Path to the mash binary file. Default tries if mash is in PATH.</p>\n</li>\n<li>\n<p><strong>[--modeltest-ng-bin (PATH)]</strong>      Path to the modeltest-ng binary file. Default tries if modeltest-ng is in PATH.</p>\n</li>\n<li>\n<p><strong>[--muscle-bin (PATH)]</strong>            Path to the muscle binary file. Default tries if muscle is in PATH.</p>\n</li>\n<li>\n<p><strong>[--orthofinder-bin (PATH)]</strong>       Path to the orthofinder binary file. Default tries if orthofinder is in PATH;</p>\n</li>\n<li>\n<p><strong>[--pal2nal-bin (PATH)]</strong>           Path to the <a href=\"http://pal2nal.pl\">pal2nal.pl</a> binary file. Default tries if <a href=\"http://pal2nal.pl\">pal2nal.pl</a> is in PATH;</p>\n</li>\n<li>\n<p><strong>[--prodigal-bin (PATH)]</strong>          Path to prodigal binary file. Default tries if prodigal is in PATH;</p>\n</li>\n<li>\n<p><strong>[--prokka-bin (PATH)]</strong>            Path to prokka binary file. Default tries if prokka is in PATH;</p>\n</li>\n<li>\n<p><strong>[--raxml-ng-bin (PATH)]</strong>          Path to the raxml-ng binary file. Default tries if raxml-ng is in PATH;</p>\n</li>\n<li>\n<p><strong>[--roary-bin (PATH)]</strong>             Path to the roary binary file. Default tries if roary is in PATH;</p>\n</li>\n<li>\n<p><strong>[--sickle-bin (PATH)]</strong>            Path to the sickle-trim binary file. Default tries if sickle is in PATH.</p>\n</li>\n<li>\n<p><strong>[--snippy-bin (PATH)]</strong>            Path to the snippy binary file. Default tries if snippy is in PATH;</p>\n</li>\n<li>\n<p><strong>[--snp-sites-bin (PATH)]</strong>         Path to the snp-sites binary file. Default tries if snp-sites is in PATH;</p>\n</li>\n<li>\n<p><strong>[--unicycler-bin (PATH)]</strong>         Path to the unicycler binary file. Default tries if unicycler is in PATH;</p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p><strong>配置 COG 数据库</strong></p>\n<ul>\n<li><strong>[--setup-COGdb]</strong>                  首次安装 PGCGAP 后需要执行此步<br />\n<br/></li>\n</ul>\n</li>\n<li>\n<p>检查依赖软件包是否安装 (<strong>强烈建议在安装完 PGCGAP 之后运行此步</strong>):</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --check-external-programs<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<br/>\n<h2 id=\"示例\"><a class=\"markdownIt-Anchor\" href=\"#示例\"></a> 示例</h2>\n<ul>\n<li>\n<p><strong>Example 1:</strong> 执行所有模块，以 <em>Escherichia coli</em> 的 6 个 Illumina 双端 reads 为数据集。</p>\n<p><strong>注</strong>：为了提高灵活性，&quot;VAR&quot; 模块需要额外添加。<br/></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --All --platform illumina --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --suffix_len <span class=\"token number\">11</span> --kmmer <span class=\"token number\">81</span> --genus Escherichia --species “Escherichia coli” --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --VAR --refgbk /mnt/h/PGCGAP_Examples/Reads/MG1655.gbff --qualtype sanger<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 2:</strong> 基因组组装。</p>\n<ul>\n<li>\n<p><strong>Illumina 双端 reads 组装</strong></p>\n<p>该数据集中，reads 的命名格式为 “strain_1.fastq.gz” 和 “strain_2.fastq.gz”。 后缀名为 “_1.fastq.gz”，其长度为 11，因此 &quot;--suffix_len&quot; 设置为 11。</p>\n</li>\n</ul>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --Assemble --platform illumina --assembler abyss --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --kmmer <span class=\"token number\">81</span> --threads <span class=\"token number\">4</span> --suffix_len <span class=\"token number\">11</span>\n\t \n<span class=\"token variable\">$pgcgap</span> --Assemble --platform illumina --assembler spades --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --threads <span class=\"token number\">4</span> --suffix_len <span class=\"token number\">11</span>\n\t \n<span class=\"token variable\">$pgcgap</span> --Assemble --platform illumina --assembler auto --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --kmmer <span class=\"token number\">81</span> --threads <span class=\"token number\">4</span> --suffix_len <span class=\"token number\">11</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>\n<p><strong>Oxford reads 组装</strong></p>\n<p>Oxford nanopore 测序仅产生一个 reads 文件，因此只需要设置 &quot;--reads1&quot; 参数，其值为 &quot;.fasta&quot;。 “--genomeSize” 是预估的基因组大小，用户可以到 NCBI 数据库中查看同物种基因组的大小作为参考，此处设置为 &quot;4.8m&quot;。Reads 文件的后缀名为 &quot;.fasta&quot;，其长度为 6，因此将 &quot;--suffix_len&quot; 设置为 6。</p>\n</li>\n</ul>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --Assemble --platform oxford --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/Oxford --reads1 .fasta --genomeSize <span class=\"token number\">4</span>.8m --threads <span class=\"token number\">4</span> --suffix_len <span class=\"token number\">6</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li><strong>PacBio reads 组装</strong></li>\n</ul>\n<p>PacBio 同样只产生一个文件 &quot;pacbio.fastq&quot;，参数设置与 Oxford 类似。此处，文件的后缀名为 &quot;.fastq&quot;，其长度为 6，因此 &quot;--suffix_len&quot; 设置为 6。</p>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --Assemble --platform pacbio --filter_length <span class=\"token number\">200</span> --ReadsPath Reads/PacBio --reads1 .fastq --genomeSize <span class=\"token number\">4</span>.8m --threads <span class=\"token number\">4</span> --suffix_len <span class=\"token number\">6</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 3:</strong> 基因预测及注释。</p>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --Annotate --scafPath Results/Assembles/Scaf/Illumina --Scaf_suffix -8.fa --genus Escherichia --species “Escherichia coli” --codon <span class=\"token number\">11</span> --threads <span class=\"token number\">4</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 4:</strong> 构建单拷贝核心蛋白进化树与核心 SNPs 进化树。</p>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with FastTree (Quick without best fit model testing)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath Results/Annotations/CDs --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --fasttree\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath Results/Annotations/CDs --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --bsnum <span class=\"token number\">500</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath Results/Annotations/CDs --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --fastboot <span class=\"token number\">1000</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 5:</strong> 仅构建单拷贝核心蛋白进化树。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with FastTree (Quick without best fit model testing)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath NO --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --fasttree\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath NO --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --bsnum <span class=\"token number\">500</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --CoreTree --CDsPath NO --AAsPath Results/Annotations/AAs --codon <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --fastboot <span class=\"token number\">1000</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 6:</strong> 进行泛基因组分析并构建单拷贝核心蛋白进化树。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with FastTree (Quick without best fit model testing)</span>\n<span class=\"token variable\">$pgcgap</span> --Pan --codon <span class=\"token number\">11</span> --identi <span class=\"token number\">95</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --GffPath Results/Annotations/GFF --PanTree --fasttree\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --Pan --codon <span class=\"token number\">11</span> --identi <span class=\"token number\">95</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --GffPath Results/Annotations/GFF --PanTree --bsnum <span class=\"token number\">500</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --Pan --codon <span class=\"token number\">11</span> --identi <span class=\"token number\">95</span> --strain_num <span class=\"token number\">6</span> --threads <span class=\"token number\">4</span> --GffPath Results/Annotations/GFF --PanTree --fastboot <span class=\"token number\">1000</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 7:</strong> 同源蛋白家族聚类分析并构建进化树。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with FastTree (Quick without best fit model testing)</span>\n<span class=\"token variable\">$pgcgap</span> --OrthoF --threads <span class=\"token number\">4</span> --AAsPath Results/Annotations/AAs --fasttree\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --OrthoF --threads <span class=\"token number\">4</span> --AAsPath Results/Annotations/AAs --bsnum <span class=\"token number\">500</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --OrthoF --threads <span class=\"token number\">4</span> --AAsPath Results/Annotations/AAs --fastboot <span class=\"token number\">1000</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 8:</strong> 计算两两基因组之间的平均核苷酸一致性 (ANI)。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --ANI --threads <span class=\"token number\">4</span> --queryL scaf.list --refL scaf.list --ANIO Results/ANI/ANIs --Scaf_suffix .fa<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 9:</strong> 通过 MinHash 计算基因组及宏基因组的相似性。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --MASH --scafPath <span class=\"token operator\">&lt;</span><span class=\"token environment constant\">PATH</span><span class=\"token operator\">></span> --Scaf_suffix <span class=\"token operator\">&lt;</span>STRING<span class=\"token operator\">></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 10:</strong> 对所有基因组进行 COG 注释。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --pCOG --threads <span class=\"token number\">4</span> --strain_num <span class=\"token number\">6</span> --AAsPath Results/Annotations/AAs<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 11:</strong> 变异 (SNPs, Indels) 检测与注释，并构建基于参考基因组的 SNPs 进化树。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --VAR --threads <span class=\"token number\">4</span> --refgbk /mnt/h/PGCGAP_Examples/Reads/MG1655.gbff --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --suffix_len <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --qualtype sanger --bsnum <span class=\"token number\">500</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --VAR --threads <span class=\"token number\">4</span> --refgbk /mnt/h/PGCGAP_Examples/Reads/MG1655.gbff --ReadsPath Reads/Illumina --reads1 _1.fastq.gz --reads2 _2.fastq.gz --suffix_len <span class=\"token number\">11</span> --strain_num <span class=\"token number\">6</span> --qualtype sanger --fastboot <span class=\"token number\">1000</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 12:</strong> 从基因组中寻找抗生素抗性基因或毒力基因。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --AntiRes --scafPath Results/Assembles/Scaf/Illumina --Scaf_suffix -8.fa --threads <span class=\"token number\">6</span> --db ncbi --identity <span class=\"token number\">75</span> --coverage <span class=\"token number\">50</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 13:</strong> Filter short sequences in the genome and assess the status of the genome</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$pgcgap</span> --ACC --Assess --scafPath Results/Assembles/Scaf/Illumina --Scaf_suffix -8.fa --filter_length <span class=\"token number\">200</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p><strong>Example 14:</strong> Construct a phylogenetic tree based on multiple sequences in one file</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">   <span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Very slow with best fit model testing, traditional bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --STREE --seqfile proteins.fas --seqtype p --bsnum <span class=\"token number\">500</span> --threads <span class=\"token number\">4</span>\n\n<span class=\"token comment\"># Construct phylogenetic tree with IQ-TREE (Slow with best fit model testing, ultrafast bootstrap)</span>\n<span class=\"token variable\">$pgcgap</span> --STREE --seqfile proteins.fas --seqtype p --fastboot <span class=\"token number\">1000</span> --threads <span class=\"token number\">4</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h2 id=\"准备输入文件\"><a class=\"markdownIt-Anchor\" href=\"#准备输入文件\"></a> 准备输入文件</h2>\n<h3 id=\"工作目录\"><a class=\"markdownIt-Anchor\" href=\"#工作目录\"></a> 工作目录</h3>\n<ul>\n<li>PGCGAP 的运行目录。</li>\n</ul>\n<h3 id=\"assemble\"><a class=\"markdownIt-Anchor\" href=\"#assemble\"></a> Assemble</h3>\n<ul>\n<li>将所有双端 reads、或 PacBio reads 或 Oxford nanopore reads 存于某个目录下 (Default: ./Reads/Illumina/)。</li>\n</ul>\n<h3 id=\"annotate\"><a class=\"markdownIt-Anchor\" href=\"#annotate\"></a> Annotate</h3>\n<ul>\n<li>基因组文件 (完整或不完整) 存放于某个目录下 (Default: Results/Assembles/Scaf/Illumina)。</li>\n</ul>\n<h3 id=\"ani\"><a class=\"markdownIt-Anchor\" href=\"#ani\"></a> ANI</h3>\n<ul>\n<li>QUERY_LIST 和 REFERENCE_LIST 文件，每个文件中含有需要计算的基因组的绝对路径，每个基因组一行 (default: 工作目录下的 &quot;scaf.list&quot;)。若先运行了 “--Assemble” 模块，该文件会自动生成。</li>\n</ul>\n<h3 id=\"coretree\"><a class=\"markdownIt-Anchor\" href=\"#coretree\"></a> CoreTree</h3>\n<ul>\n<li>将所有菌株的氨基酸文件 (后缀名必须为 “.faa”) 和核苷酸文件 (需以 “.ffn” 为后缀) 分别存放于两个目录中 (default: “./Results/Annotations/AAs/” 和 “./Results/Annotations/CDs/”)。“.faa” 和 “.ffn” 文件需要有相同的前缀名字，且 protein IDs 和 gene IDs 需以菌株名开头。建议用 “Prokka” 软件获取输入文件，若已经运行了 “--Annotate” 模块，则该模块的输入文件会自动生产。若 “--CDsPath” 设置为 “NO”，则不需要提供核苷酸文件，但也不会生产核心 SNPs 进化树。</li>\n</ul>\n<h3 id=\"mash\"><a class=\"markdownIt-Anchor\" href=\"#mash\"></a> MASH</h3>\n<ul>\n<li>基因组文件 (完整或不完整) 存放于某个目录下 (Default: Results/Assembles/Scaf/Illumina)。</li>\n</ul>\n<h3 id=\"orthof\"><a class=\"markdownIt-Anchor\" href=\"#orthof\"></a> OrthoF</h3>\n<ul>\n<li>所有菌株的 fasta 格式氨基酸文件 (每个菌株一个文件) 存放于一个目录中 (default: “./Results/Annotations/AAs/”)。 若先运行了 “--Annotate” 模块，该文件会自动生成。</li>\n</ul>\n<h3 id=\"pan\"><a class=\"markdownIt-Anchor\" href=\"#pan\"></a> Pan</h3>\n<ul>\n<li>包含所有菌株 GFF3 文件 (With “.gff” as the suffix) 的目录路径 (default: ./Results/Annotations/GFF/);</li>\n<li>若先运行了 “--Annotate” 模块，上述文件会自动生成。</li>\n</ul>\n<h3 id=\"pcog\"><a class=\"markdownIt-Anchor\" href=\"#pcog\"></a> pCOG</h3>\n<ul>\n<li>存放所有菌株的 fasta 格式氨基酸序列文件 (With “.faa” as the suffix) 的目录路径 (default: ./Results/Annotations/AAs/)。 若先运行了 “--Annotate” 模块，该文件会自动生成。</li>\n</ul>\n<h3 id=\"var\"><a class=\"markdownIt-Anchor\" href=\"#var\"></a> VAR</h3>\n<ul>\n<li>包含所有菌株的 Pair-end reads 的目录路径 (default: ./Reads/Over/under the working directory)。</li>\n<li>fasta 格式或 GenBank 格式的参考基因组的绝对路径 (<strong>必需提供</strong>)。</li>\n</ul>\n<h3 id=\"antires\"><a class=\"markdownIt-Anchor\" href=\"#antires\"></a> AntiRes</h3>\n<ul>\n<li>存放基因组 (complete or draft) 的目录 (Default: Results/Assembles/Scaf/Illumina under the working directory).</li>\n</ul>\n<h3 id=\"stree\"><a class=\"markdownIt-Anchor\" href=\"#stree\"></a> STREE</h3>\n<ul>\n<li>Multiple-FASTA sequences in a file, can be Protein, DNA and Codons.</li>\n</ul>\n<h2 id=\"输出文件解读\"><a class=\"markdownIt-Anchor\" href=\"#输出文件解读\"></a> 输出文件解读</h2>\n<h3 id=\"assemble-2\"><a class=\"markdownIt-Anchor\" href=\"#assemble-2\"></a> Assemble</h3>\n<ul>\n<li>\n<p><strong>Results/Assembles/Illumina/</strong><br/><br />\nDirectories contain Illumina assembly files and information of each strain.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/PacBio/</strong><br/><br />\nDirectories contain PacBio assembly files and information of each strain.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/Oxford/</strong><br/><br />\nDirectories contain ONT assembly files and information of each strain.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/Hybrid/</strong><br/><br />\nDirectory contains hybrid assembly files of the short reads and long reads of the same strain.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/Scaf/Illumina</strong><br/><br />\nDirectory contains Illumina contigs/scaffolds of all strains. &quot;*.filtered.fas&quot; is the genome after excluding short sequences. &quot;*.prefilter.stats&quot; describes the stats of the genome before filtering, and &quot;*.filtered.stats&quot; describes the stats of the genome after filtering.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/Scaf/Oxford</strong><br/><br />\nDirectory contains Oxford nanopore contigs/scaffolds of all strains.</p>\n</li>\n<li>\n<p><strong>Results/Assembles/Scaf/PacBio</strong><br/><br />\nDirectory contains PacBio contigs/scaffolds of all strains.</p>\n</li>\n</ul>\n<h3 id=\"annotate-2\"><a class=\"markdownIt-Anchor\" href=\"#annotate-2\"></a> Annotate</h3>\n<ul>\n<li>\n<p><strong>Results/Annotations/*_annotation</strong><br/><br />\ndirectories contain <a href=\"https://github.com/tseemann/prokka?_blank\">annotation files</a> of each strain.</p>\n</li>\n<li>\n<p><strong>Results/Annotations/AAs</strong><br/><br />\nDirectory contain amino acids sequences of all strains.</p>\n</li>\n<li>\n<p><strong>Results/Annotations/CDs</strong><br/><br />\nDirectory contain nucleotide sequences of all strains.</p>\n</li>\n<li>\n<p><strong>Results/Annotations/GFF</strong><br/><br />\nDirectory contain the master annotation of all strains in GFF3 format.</p>\n</li>\n</ul>\n<h3 id=\"ani-2\"><a class=\"markdownIt-Anchor\" href=\"#ani-2\"></a> ANI</h3>\n<ul>\n<li>\n<p><strong>Results/ANI/ANIs</strong><br/><br />\nThe file contains comparation information of genome pairs. The document is composed of five columns, each of which represents query genome, reference genome, ANI value, count of bidirectional fragment mappings, total query fragments.</p>\n</li>\n<li>\n<p><strong>Results/ANI/ANIs.matrix</strong><br/><br />\nfile with identity values arranged in a <a href=\"https://www.mothur.org/wiki/Phylip-formatted_distance_matrix?_blank\">phylip-formatted lower triangular matrix</a>.</p>\n</li>\n<li>\n<p><strong>Results/ANI/ANIs.heatmap</strong><br/><br />\nAn ANI matrix of all strains.</p>\n</li>\n<li>\n<p><strong>Results/ANI/ANI_matrix.pdf</strong><br/><br />\nThe heatmap plot of &quot;ANIs.heatmap&quot;.</p>\n</li>\n</ul>\n<h3 id=\"mash-2\"><a class=\"markdownIt-Anchor\" href=\"#mash-2\"></a> MASH</h3>\n<ul>\n<li>\n<p><strong>Results/MASH/MASH</strong><br/><br />\nThe pairwise distance between pair genomes, each column represents Reference-ID, Query-ID, Mash-distance, P-value, and Matching-hashes, respectively.</p>\n</li>\n<li>\n<p><strong>Results/MASH/MASH2</strong><br/><br />\nThe pairwise similarity between pair genomes, each column represents Reference-ID, Query-ID, similarity, P-value, and Matching-hashes, respectively.</p>\n</li>\n<li>\n<p><strong>Results/MASH/MASH.heatmap</strong><br/><br />\nA similarity matrix of all genomes.</p>\n</li>\n<li>\n<p><strong>Results/MASH/MASH_matrix.pdf</strong><br/><br />\nA heat map plot of &quot;MASH.heatmap&quot;.</p>\n</li>\n</ul>\n<h3 id=\"coretree-2\"><a class=\"markdownIt-Anchor\" href=\"#coretree-2\"></a> CoreTree</h3>\n<ul>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.protein.fasta</strong><br/><br />\nConcatenated and aligned sequences file of single-copy core proteins.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.protein.nwk</strong><br/><br />\nThe phylogenetic tree file of single-copy core proteins for all strains constructed by FastTree.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.protein.fasta.gb.treefile</strong><br/><br />\nThe phylogenetic tree file of single-copy core proteins for all strains constructed by IQ-TREE.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/faa2ffn/ALL.core.nucl.fasta</strong><br/><br />\nConcatenated and aligned sequences file of single-copy core genes.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.snp.fasta</strong><br/><br />\nCore SNPs of single-copy core genes in fasta format.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.snp.nwk</strong><br/><br />\nThe phylogenetic tree file of SNPs of single-copy core genes for all strains constructed by FastTree.</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/ALL.core.snp.fasta.gb.treefile</strong><br/><br />\nThe phylogenetic tree file of SNPs of single-copy core genes for all strains constructed by IQ-TREE</p>\n</li>\n<li>\n<p><strong>Results/CoreTrees/&quot;Other_files&quot;</strong><br/><br />\nIntermediate directories and files.</p>\n</li>\n</ul>\n<h3 id=\"orthof-2\"><a class=\"markdownIt-Anchor\" href=\"#orthof-2\"></a> OrthoF</h3>\n<ul>\n<li>\n<p><strong>Results/OrthoFinder/Results_orthoF</strong><br/><br />\nSame as <a href=\"https://github.com/davidemms/OrthoFinder?_blank\">OrthoFinder</a> outputs.</p>\n</li>\n<li>\n<p><strong>Results/OrthoFinder/Results_orthoF/Single_Copy_Orthologue_Tree/</strong><br/><br />\nDirectory contains Phylogenetic tree files based on Single Copy Orthologue sequences.<br/></p>\n</li>\n<li>\n<p><strong>Results/OrthoFinder/Results_orthoF/Single_Copy_Orthologue_Tree/Single.Copy.Orthologue.nwk</strong><br/><br />\nPhylogenetic tree constructed by FastTree.<br/></p>\n</li>\n<li>\n<p><strong>Results/OrthoFinder/Results_orthoF/Single_Copy_Orthologue_Tree/Single.Copy.Orthologue.fasta.gb.treefile</strong><br/><br />\nPhylogenetic tree constructed by IQ-TREE.<br/></p>\n</li>\n</ul>\n<h3 id=\"pan-2\"><a class=\"markdownIt-Anchor\" href=\"#pan-2\"></a> Pan</h3>\n<ul>\n<li>\n<p><strong>Results/PanGenome/Pangenome_Pie.pdf</strong><br/><br />\nA 3D pie chart and a fan chart of the breakdown of genes and the number of isolates they are present in.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/pangenome_frequency.pdf</strong><br/><br />\nA graph with the frequency of genes versus the number of genomes.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/Pangenome_matrix.pdf</strong><br/><br />\nA figure showing the tree compared to a matrix with the presence and absence of core and accessory genes.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/Core/Roary.core.protein.fasta</strong><br/><br />\nAlignments of single-copy core proteins called by roary software.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/Core/Roary.core.protein.nwk</strong><br/><br />\nA phylogenetic tree of Roary.core.protein.fasta constructed by FastTree.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/Core/Roary.core.protein.fasta.gb.treefile</strong><br/><br />\nA phylogenetic tree of Roary.core.protein.fasta constructed by IQ-TREE.</p>\n</li>\n<li>\n<p><strong>Results/PanGenome/Other_files</strong><br/><br />\nsee <a href=\"https://sanger-pathogens.github.io/Roary/?_blank\">roary</a> outputs.</p>\n</li>\n</ul>\n<h3 id=\"pcog-2\"><a class=\"markdownIt-Anchor\" href=\"#pcog-2\"></a> pCOG</h3>\n<ul>\n<li>\n<p><strong>*.COG.xml, *.2gi.table, *.2id.table, *.2Sid.table</strong><br/><br />\nIntermediate files.</p>\n</li>\n<li>\n<p><strong>*.2Scog.table</strong><br/><br />\nThe super COG table of each strain.</p>\n</li>\n<li>\n<p><strong>*.2Scog.table.pdf</strong><br/><br />\nA plot of super COG table in pdf format.</p>\n</li>\n<li>\n<p><strong>All_flags_relative_abundances.table</strong><br />\nA table containing the relative abundance of each flag for all strains.</p>\n</li>\n</ul>\n<h3 id=\"var-2\"><a class=\"markdownIt-Anchor\" href=\"#var-2\"></a> VAR</h3>\n<ul>\n<li>\n<p><strong>Results/Variants/directory-named-in-strains</strong><br/><br />\ndirectories containing substitutions (snps) and insertions/deletions (indels) of each strain. See <a href=\"https://github.com/tseemann/snippy?_blank\">Snippy</a> outputs for detail.</p>\n</li>\n<li>\n<p><strong>Results/Variants/Core</strong><br/><br />\nThe directory containing SNP phylogeny files.</p>\n<ul>\n<li><strong>core.aln</strong> : A core SNP alignment includes only SNP sites.</li>\n<li><strong>core.full.aln</strong> : A whole genome SNP alignment (includes invariant sites).</li>\n<li><strong>core.*.treefile</strong> : Phylogenetic tree of the core SNP alignment based on the best-fit model of evolution selected using IQ-TREE (ignoring possible recombination).</li>\n<li><strong>gubbins.core.full.node_labelled.final_tree.tre</strong> : Phylogenetic tree of the whole genome SNP alignment constructed with <strong>gubbins</strong> (get rid of recombination).</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"antires-2\"><a class=\"markdownIt-Anchor\" href=\"#antires-2\"></a> AntiRes</h3>\n<ul>\n<li><strong>Results/AntiRes/*.tab</strong> : Screening results of each strain.</li>\n<li><strong>Results/AntiRes/summary.txt</strong> : A matrix of gene presence/absence for all strains.</li>\n</ul>\n<h3 id=\"stree-2\"><a class=\"markdownIt-Anchor\" href=\"#stree-2\"></a> STREE</h3>\n<ul>\n<li><strong>Results/STREE/*.aln</strong> : Aligned sequences.</li>\n<li><strong>Results/STREE/*.aln.gb</strong> : Conserved blocks of the sequences.</li>\n<li><strong>Results/STREE/*.aln.gb.treefile</strong> : The final phylogenetic tree.</li>\n</ul>\n<h2 id=\"使用许可\"><a class=\"markdownIt-Anchor\" href=\"#使用许可\"></a> 使用许可</h2>\n<p>PGCGAP 不可商用，其它情况可使用免费 (licensed under GPLv3)。</p>\n<h2 id=\"反馈与提问\"><a class=\"markdownIt-Anchor\" href=\"#反馈与提问\"></a> 反馈与提问</h2>\n<p>若有问题，可在 <a href=\"https://github.com/liaochenlanruo/pgcgap/issues?_blank\">issues page</a> 提出或通过邮件咨询 <a href=\"mailto:liaochenlanruo@webmail.hzau.edu.cn\">liaochenlanruo@webmail.hzau.edu.cn</a>。</p>\n<h2 id=\"引用\"><a class=\"markdownIt-Anchor\" href=\"#引用\"></a> 引用</h2>\n<ul>\n<li>\n<p>If you use this software please cite: Liu H, Xin B, Zheng J, Zhong H, Yu Y, Peng D, Sun M. Build a bioinformatics analysis platform and apply it to routine analysis of microbial genomics and comparative genomics. <em>Protocol exchange</em>, 2020. DOI: <a href=\"https://doi.org/10.21203/rs.2.21224/v5\">10.21203/rs.2.21224/v5</a></p>\n</li>\n<li>\n<p>If you use &quot;--Assemble&quot;, please also cite one or two of <a href=\"https://github.com/OpenGene/fastp\">Fastp</a>, <a href=\"https://doi.org/10.1101/gr.214346.116\">ABySS</a>, <a href=\"http://link.springer.com/chapter/10.1007%2F978-3-642-37195-0_13\">SPAdes</a>, <a href=\"https://doi.org/10.1101/gr.215087.116\">Canu</a>, or <a href=\"https://doi.org/10.1371/journal.pcbi.1005595\">Unicycler</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--Annotate&quot;, please also cite <a href=\"https://www.pixiv.net/member_illust.php?mode=medium&amp;illust_id=24642063\">Prokka</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--CoreTree&quot;, please also cite <a href=\"https://doi.org/10.1093/bioinformatics/btl158\">CD-HIT</a>, <a href=\"https://doi.org/10.1093/nar/gkf436\">MAFFT</a>, <a href=\"https://doi.org/10.1093/nar/gkl315\">PAL2NAL</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btp348\">trimAL</a>, <a href=\"https://doi.org/10.1371/journal.pone.0009490\">FastTree</a> or <a href=\"https://doi.org/10.1093/molbev/msaa015\">IQ-TREE</a>, and <a href=\"https://dx.doi.org/10.1099%2Fmgen.0.000056\">SNP-sites</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--Pan&quot;, please also cite <a href=\"https://dx.doi.org/10.1093%2Fbioinformatics%2Fbtv421\">Roary</a>, <a href=\"https://doi.org/10.1093/nar/gkf436\">MAFFT</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btp348\">trimAL</a>, <a href=\"https://doi.org/10.1371/journal.pone.0009490\">FastTree</a> or <a href=\"https://doi.org/10.1093/molbev/msaa015\">IQ-TREE</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--OrthoF&quot;, please also cite <a href=\"https://dx.doi.org/10.1186%2Fs13059-019-1832-y\">OrthoFinder</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btp348\">trimAL</a>, <a href=\"https://doi.org/10.1371/journal.pone.0009490\">FastTree</a> or <a href=\"https://doi.org/10.1093/molbev/msaa015\">IQ-TREE</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--ANI&quot;, please also cite <a href=\"https://dx.doi.org/10.1038%2Fs41467-018-07641-9\">fastANI</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--MASH&quot;, please also cite <a href=\"https://dx.doi.org/10.1186%2Fs13059-016-0997-x\">Mash</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--VAR&quot;, please also cite <a href=\"https://github.com/najoshi/sickle\">Sickle</a>, <a href=\"https://github.com/tseemann/snippy\">Snippy</a>, <a href=\"https://dx.doi.org/10.1093%2Fnar%2Fgku1196\">Gubbins</a>,  <a href=\"https://doi.org/10.1093/molbev/msaa015\">IQ-TREE</a>, and <a href=\"https://dx.doi.org/10.4161%2Ffly.19695\">SnpEff</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--AntiRes&quot;, please also cite <a href=\"https://github.com/tseemann/abricate\">Abricate</a> and the corresponding database you used: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6811410\">NCBI AMRFinderPlus</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/27789705\">CARD</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/22782487\">Resfinder</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/24145532\">ARG-ANNOT</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/26578559\">VFDB</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/24777092\">PlasmidFinder</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5343136/\">EcOH</a>, or <a href=\"https://academic.oup.com/nar/article/48/D1/D561/5624973\">MEGARES 2.00</a>.</p>\n</li>\n<li>\n<p>If you use &quot;--STREE&quot;, please also cite <a href=\"http://europepmc.org/abstract/MED/30976793\">Muscle</a> , <a href=\"https://doi.org/10.1093/bioinformatics/btp348\">trimAL</a>, and <a href=\"https://doi.org/10.1093/molbev/msaa015\">IQ-TREE</a>.</p>\n</li>\n</ul>\n<h2 id=\"常见问题\"><a class=\"markdownIt-Anchor\" href=\"#常见问题\"></a> 常见问题</h2>\n<h3 id=\"q1-var-founction-ran-failed-to-get-annotated-vcfs-and-core-results\"><a class=\"markdownIt-Anchor\" href=\"#q1-var-founction-ran-failed-to-get-annotated-vcfs-and-core-results\"></a> Q1 VAR founction ran failed to get annotated VCFs and Core results</h3>\n<p>Check the log file named in &quot;strain_name.log&quot; under Results/Variants/&lt;strain_name&gt;/ directory. If you find a sentence like &quot;WARNING: All frames are zero! This seems rather odd, please check that 'frame' information in your 'genes' file is accurate.&quot; This is an snpEff error. Users can install JDK8 to solve this problem.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> <span class=\"token function\">install</span> java-jdk<span class=\"token operator\">=</span><span class=\"token number\">8.0</span>.112<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Click <a href=\"https://github.com/tseemann/snippy/issues/259?_blank\">here</a> for more solutions.</p>\n<h3 id=\"q2-could-not-determine-version-of-minced-please-install-version-2-or-higher\"><a class=\"markdownIt-Anchor\" href=\"#q2-could-not-determine-version-of-minced-please-install-version-2-or-higher\"></a> Q2 Could not determine version of minced please install version 2 or higher</h3>\n<p>When running prokka of Assemble founction, this error could happened, the error message shows as following:</p>\n<pre class=\"line-numbers language-text\" data-language=\"text\"><code class=\"language-text\">Error: A JNI error has occurred, please check your installation and try again\nException in thread \"main\" java.lang.UnsupportedClassVersionError: minced has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n[01:09:40] Could not determine version of minced - please install version 2.0 or higher<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Users can downgrade the minced to version 0.3 to solve this problem.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token variable\">$conda</span> <span class=\"token function\">install</span> <span class=\"token assign-left variable\">minced</span><span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Click <a href=\"https://github.com/bioconda/bioconda-recipes/pull/15407?_blank\">here</a> for detail informations.</p>\n<h3 id=\"q3-dyld-library-not-loaded-rpathlibcrypto100dylib\"><a class=\"markdownIt-Anchor\" href=\"#q3-dyld-library-not-loaded-rpathlibcrypto100dylib\"></a> Q3 dyld: Library not loaded: @rpath/libcrypto.1.0.0.dylib</h3>\n<p>This error may happen when running function &quot;VAR&quot; on macOS. It is an error of openssl. Users can solve this problem as following:</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#Firstly, install brew if have not installed before</span>\n<span class=\"token variable\">$ruby</span> -e <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install<span class=\"token variable\">)</span></span>\"</span>\n\n<span class=\"token comment\">#Install openssl with brew</span>\n<span class=\"token variable\">$brew</span> <span class=\"token function\">install</span> openssl\n\n<span class=\"token comment\">#Create the soft link for libraries</span>\n<span class=\"token variable\">$ln</span> -s /usr/local/opt/openssl/lib/libcrypto.1.0.0.dylib /usr/local/lib/\n\n<span class=\"token variable\">$ln</span> -s /usr/local/opt/openssl/lib/libssl.1.0.0.dylib /usr/local/lib/<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Click <a href=\"https://gist.github.com/aklap/e885721ef15c8668ed0a1dd64d2ea1a7\">here</a> for more informations</p>\n<h3 id=\"q4-use-of-uninitialized-value-in-require-at-encodepm-line-61\"><a class=\"markdownIt-Anchor\" href=\"#q4-use-of-uninitialized-value-in-require-at-encodepm-line-61\"></a> Q4 Use of uninitialized value in require at <a href=\"http://Encode.pm\">Encode.pm</a> line 61</h3>\n<p>This warning may happen when running function &quot;Pan&quot;. It is a warning of Roary software.<br />\nThe content of line 61 is &quot;require Encode::ConfigLocal;&quot;. Users can ignore the warning.<br />\nClick <a href=\"https://github.com/sanger-pathogens/Roary/issues/323\">here</a> for details.</p>\n<h2 id=\"updates\"><a class=\"markdownIt-Anchor\" href=\"#updates\"></a> Updates</h2>\n<ul>\n<li>\n<p>V1.0.3</p>\n<ul>\n<li>Updated ANI fuction.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.4</p>\n<ul>\n<li>Add parallel for function &quot;COG&quot;.</li>\n<li>Optimized drawing of ANI heat map.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.5</p>\n<ul>\n<li>Bug repair for input of gubbins.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.6</p>\n<ul>\n<li>Modified CoreTree to split protein and SNPs tree constructing.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.7</p>\n<ul>\n<li>Split Assemble and Annotate into two functions.</li>\n<li>Added third generation genome assembly function.</li>\n<li>Changed the default parameters of the CoreTree function (aS 0.8 to 0.7 and aL 0.8 to 0.5).</li>\n<li>Changed the name of function &quot;COG&quot; to &quot;pCOG&quot;.</li>\n<li>Fixed the sorting bug for ANI heat map.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.8</p>\n<ul>\n<li>Add the &quot;MASH&quot; function to compute genome distance and similarity using MinHash.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.9</p>\n<ul>\n<li>The function of constructing a single-copy core protein phylogenetic tree was added to &quot;Pan&quot;.</li>\n<li>Fixed a bug of plot_3Dpie.R, Optimized image display, and a fan chart has been added.</li>\n<li>Fixed a bug for ploting the ANI matrix.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.10</p>\n<ul>\n<li>Add the &quot;AntiRes&quot; function to screening of contigs for antimicrobial and virulence genes.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.11</p>\n<ul>\n<li>Users now can choose &quot;abyss&quot; or &quot;spades&quot; for illumina reads aseembly.</li>\n<li>New support for hybrid assembly of paired-end short reads and long reads.</li>\n<li>Add the selecting of best-fit model of evolution for DNA and protein alignments before constructing a phylogenetic tree.</li>\n<li>Optimized display of help information. Users can check parameters for each modulewith command &quot;pgcgap [Assemble|Annotate|ANI|AntiRes|CoreTree|MASH|OrthoF|Pan|pCOG|VAR]&quot;, and can look up the examples of each module with command &quot;pgcgap Examples&quot;.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.12</p>\n<ul>\n<li>Added automatic mode for illumina genome assembly. First, PGCGAP calls &quot;ABySS&quot; for genome assembly. When the assembled N50 is less than 50,000, it automatically calls &quot;SPAdes&quot; to try multiple parameters for assembly.</li>\n<li>Added ability to filter short sequences of assembled genomes.</li>\n<li>Added function of genome assembly status assessment.</li>\n<li>Modified the drawing script of ANI and MASH modules so that it can automatically adjust the font size according to the number of samples.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.13</p>\n<ul>\n<li>Fixed the &quot;running error&quot; bug of function &quot;Assess&quot; in module &quot;ACC&quot;.</li>\n<li>Added module &quot;STREE&quot; for constructing a phylogenetic tree based on multiple sequences in one file.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.14</p>\n<ul>\n<li>The relative_abundances of flags among strains will not be called while the strain number is less than two.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.15</p>\n<ul>\n<li>When the number of threads set by the user exceeds the number of threads owned by the system, PGCGAP will automatically adjust the number of threads to avoid program crash.</li>\n<li>Add FASTQ preprocessor before Illunima genome assembly: adapter trimming, polyG tail trimming of Illumina NextSeq/NovaSeq reads, quality filtering (Q value filtering, N base filtering, sliding window filtering), length filtering.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.16</p>\n<ul>\n<li>Reduced the number of Racon polishing rounds for better speed performance when peforming genome assembly.</li>\n<li>Force overwriting existing output folder when running &quot;Annotate&quot; analysis to avoid program crash.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.17</p>\n<ul>\n<li>Fixed a bug that the program can not go back to the working directory after genome annotation.</li>\n<li>Added scripts to check if there were single-copy core proteins found while running module &quot;CoreTree&quot;.</li>\n<li>Modified the help message.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.18</p>\n<ul>\n<li>Updated the downloading link of COG database.</li>\n<li>Users can choose the number of threads used for running module &quot;STREE&quot;.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.19</p>\n<ul>\n<li>Can resume from break-point when downloading the COG database.</li>\n<li>Fixed a bug that failed to create multi-level directories.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.20</p>\n<ul>\n<li>Fixed a little bug (path error) of module &quot;VAR&quot;.</li>\n<li>Fixed a little bug of module &quot;CoreTree&quot; to avoid the interference of special characters in sequence ID to the program.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.21</p>\n<ul>\n<li>Change the default search program &quot;blast&quot; to &quot;diamond&quot; of module &quot;OrthoF&quot;.</li>\n<li>Fixed a bug of module &quot;pCOG&quot; to output the right figure.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.22</p>\n<ul>\n<li>The drawing function of module &quot;ANI&quot; and module &quot;MASH&quot; has been enhanced, including automatic adjustment of font size and legend according to the size of the picture.</li>\n<li>Fixed a bug of module &quot;ANI&quot;, that is no heatmap will be drawn when there is &quot;NA&quot; in the ANI matrix in the previous versions.</li>\n<li>When the ANI value or genome similarity is greater than 95%, an asterisk (*) will be drawn in the corresponding cell of the heatmap.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.23</p>\n<ul>\n<li>The &quot;--Assess&quot; function of module &quot;ACC&quot; was enhanced to (1) generate a summary file containing the status of all genomes (before and after the short sequence filtering), (2) auto move the low-quality genomes (that is genomes with N50 length less than 50 k) to a directory, and others to another directory.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.24</p>\n<ul>\n<li>Fixed a little bug of module &quot;Pan&quot; to avoid the interference of special characters (&gt;) in sequence ID to the program.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.25</p>\n<ul>\n<li>Gblocks was used to eliminate poorly aligned positions and divergent regions of an alignment of DNA or protein sequences in module &quot;CoreTree&quot; and &quot;Pan&quot;.</li>\n<li>The parameter &quot;--identi&quot; was added into module &quot;Pan&quot; to allow users to set the minimum percentage identity for blastp.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.26</p>\n<ul>\n<li>Adjusted the font size with the variation of genome number and the string length of the genome name when plotting the heat map of module &quot;ANI&quot; and &quot;MASH&quot;.</li>\n<li>Two heat map are provided, one of which with a star (means the similarity of the two genomes is larger than 95%) and another without a star, when performing the &quot;ANI&quot; and &quot;MASH&quot; analysis.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.27</p>\n<ul>\n<li>The Amino Acid files are no longer needed when performing the Pan-genome analysis with module Pan.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.28</p>\n<ul>\n<li>Users can check and install the latest version of PGCGAP by the command &quot;pgcgap --check-update&quot;.</li>\n<li>Update module Assemble to allow polish after the assembly of PacBio and ONT data.</li>\n<li>Update module pCOG to adjust the latest database of <a href=\"https://ftp.ncbi.nih.gov/pub/COG/COG2020/data/COG\">COG 2020</a>.</li>\n<li>Optimized the drawing and color scheme of the module pCOG.</li>\n<li>Fixed the parameter &quot;CoreTree&quot; in the module Pan to avoid program termination caused by the &quot;&gt;&quot; in non-sequence lines.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.29</p>\n<ul>\n<li>Function added to module OrthoF: Phylogenetic tree can be constructed automatically with the Single Copy Orthologue Sequences called by module OrthoF.</li>\n<li>Fixed the &quot;permission denied&quot; error when moving directories on the WSL platform.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.30</p>\n</li>\n<li>\n<p>Replace Gblocks with trimAL to trim MSA (module CoreTree, Pan, STREE, and OrthoF).</p>\n</li>\n<li>\n<p>Replaced Modeltest-ng and Raxml-ng with IQ-TREE (module CoreTree, Pan OrthoF, and VAR).</p>\n</li>\n<li>\n<p>Added the option of using FastTree to build phylogenetic tree (module CoreTree, Pan, and OrthoF).</p>\n</li>\n<li>\n<p>V1.0.31</p>\n<ul>\n<li>The default replicates for bootstrap testing was set to 500.</li>\n<li>Add the method for phylogenetic tree constructing with ultrafast bootstrap of IQ-TREE.</li>\n<li>Prevent the log from being written to the tree file generated by FastTree.</li>\n</ul>\n</li>\n<li>\n<p>V1.0.32</p>\n<ul>\n<li>A more colorful version, try &quot;pgcgap Examples&quot; to have a look.</li>\n<li>Updated module AntiRes: the parameter --db had been modified to add choices of &quot;all&quot; and &quot;megares&quot;.</li>\n<li>A little optimization of module VAR.</li>\n<li>Replaced conda with mamba to update PGCGAP more quickly.</li>\n</ul>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"比较基因组学","path":"api/tags/比较基因组学.json"}]}]}