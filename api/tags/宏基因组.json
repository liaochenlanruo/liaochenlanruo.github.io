{"name":"宏基因组","postlist":[{"title":"利用NCycDB数据库从宏基因组中预测氮循环基因","slug":"利用NCycDB数据库从宏基因组中预测氮循环基因","date":"2021-11-25T03:19:20.000Z","updated":"2022-01-08T02:16:28.433Z","comments":true,"path":"api/articles/利用NCycDB数据库从宏基因组中预测氮循环基因.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>氮（N）循环是地球生态系统中重要的生物地球化学途径的集合，在生态学和环境研究中得到了广泛的关注。目前，<ruby>鸟枪法宏基因组测序<rt>Shotgun metagenome sequencing</rt></ruby>已被广泛应用于探索负责 N 循环过程的基因家族。NCycDB 是一个手动管理的综合数据库，用于从鸟枪法宏基因组测序数据中快速准确地分析 N 循环基因（亚）家族。 NCycDB 总共包含 68 个基因（亚）家族，涵盖 8 个 N 循环过程，分别具有 95% 和 100% 一致性阈值的 84 759 和 219 146 个代表性序列。数据库中还包含了 1958 个<ruby>同源直系同源组<rt>Homologous orthology groups</rt></ruby>的序列，以避免由于 “小数据库” 问题导致的假阳性分配。</p>\n<h1 id=\"数据库及脚本\"><a class=\"markdownIt-Anchor\" href=\"#数据库及脚本\"></a> 数据库及脚本</h1>\n<h2 id=\"下载\"><a class=\"markdownIt-Anchor\" href=\"#下载\"></a> 下载</h2>\n<ul>\n<li>\n<p>通过 Git</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/liaochenlanruo/NCyc.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>通过 wget</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/liaochenlanruo/NCyc/archive/refs/heads/master.zip<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h2 id=\"配置\"><a class=\"markdownIt-Anchor\" href=\"#配置\"></a> 配置</h2>\n<ul>\n<li>通过 <code>Git</code>  下载的不需要解压，通过 <code>Wget</code>  下载的需要先解压。</li>\n<li>修改 <code>NCycProfilter.PL</code>  文件的第 8-13 行中 4 个依赖软件的安装路径。</li>\n<li>将 <code>data</code>  目录下的 <code>NCyc_100_2019Jul.7z</code>  解压，将解压得到的 <code>NCyc_100_2019Jul</code>  重命名为 <code>NCyc_100.faa</code>  并移动至 <code>data</code>  目录下。</li>\n</ul>\n<h2 id=\"依赖\"><a class=\"markdownIt-Anchor\" href=\"#依赖\"></a> 依赖</h2>\n<ul>\n<li>Blast</li>\n<li>diamond</li>\n<li>usearch</li>\n<li>Perl</li>\n</ul>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<ul>\n<li>\n<p>序列文件<br />\n宏基因组测序得到的 Reads 文件、组装后的序列文件以及通过基因预测后得到的氨基酸序列文件均可。序列文件可以是压缩的，也可以是解压的。</p>\n</li>\n<li>\n<p>基因组 - 序列数对应文件<br />\n提供一份文本文档，共包含两列，第一列为 <code>样本名称</code>  (即序列文件的名字，不带文件后缀名)，第二列为 <code>样本包含的序列数量</code> 。</p>\n</li>\n</ul>\n<h1 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl NCycProfiler.PL -d ./ -m diamond -f faa -s prot -si SI.txt -o Ncycle.out.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<div class=\"note info\">\n<p>参数解析：</p>\n</div>\n<p>-d 指定工作目录，即序列文件所在目录。<br />\n-m 指定用哪个软件进行序列比对，可选 <code>diamond</code> ， <code>blast</code> ， <code>usearch</code> 。<br />\n-f 指定序列文件的后缀名，不需要带 <code>.</code> 。<br />\n-s 指定序列类型，氨基酸为 <code>prot</code> ，核苷酸为 <code>nucl</code> 。<br />\n-si 基因组 - 序列数对应文件<br />\n - rs 随机取样大小，如果不指定，将取包含序列最少的样本的序列数<br />\n - o 指定输出的文件名称</p>\n<h1 id=\"结果解析\"><a class=\"markdownIt-Anchor\" href=\"#结果解析\"></a> 结果解析</h1>\n<p>得到的结果文件是一个表格，第一行为随机取样大小。第一列为参与 N 循环的基因名，其他列为各样本含有的对应基因的数量。</p>\n<h1 id=\"可视化\"><a class=\"markdownIt-Anchor\" href=\"#可视化\"></a> 可视化</h1>\n<p>可参考本站另一篇文章<a href=\"https://www.liaochenlanruo.fun/post/b68c.html\"> R 语言绘制气泡图 Bubb_Plot</a> 进行数据可视化。</p>\n<ul>\n<li>不带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 做主图</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 修改细节 — 图注，点大小，点shape</span>\nbubble_style <span class=\"token operator\">&lt;-</span> bubble <span class=\"token operator\">+</span> theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    labs<span class=\"token punctuation\">(</span>\n        x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span>\n        y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">,</span>\n        color<span class=\"token operator\">=</span><span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 颜色图注名</span>\n        size<span class=\"token operator\">=</span><span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>    <span class=\"token comment\"># 大小图注名</span>\n    scale_size<span class=\"token punctuation\">(</span>range <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>  <span class=\"token comment\">#等比修改圆圈大小</span>\n    theme<span class=\"token punctuation\">(</span>plot.title<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"Arial\"</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span>\n                                  color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span>face<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>\n                                  hjust<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>lineheight<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n          plot.subtitle <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nbubble_style<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>依据下表获得基因的 <code>Pathways</code>  和 <code>Annotation</code> ，随后依据 <code>Pathways</code>  进行分组并绘图。</p>\n<table>\n<thead>\n<tr>\n<th>Pathways</th>\n<th>Gene (sub) families</th>\n<th>Annotation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"9\">Nitrification</td>\n<td>amoA_A</td>\n<td>Ammonia monooxygenase subunit A (archaea)</td>\n</tr>\n<tr>\n<td>amoB_A</td>\n<td>Ammonia monooxygenase subunit B (archaea)</td>\n</tr>\n<tr>\n<td>amoC_A</td>\n<td>Ammonia monooxygenase subunit C (archaea)</td>\n</tr>\n<tr>\n<td>amoA_B</td>\n<td>Ammonia monooxygenase subunit A (bacteria)</td>\n</tr>\n<tr>\n<td>amoB_B</td>\n<td>Ammonia monooxygenase subunit B (bacteria)</td>\n</tr>\n<tr>\n<td>amoC_B</td>\n<td>Ammonia monooxygenase subunit C (bacteria)</td>\n</tr>\n<tr>\n<td>hao</td>\n<td>Hydroxylamine dehydrogenase</td>\n</tr>\n<tr>\n<td>nxrA</td>\n<td>Nitrite oxidoreductase, alpha subunit</td>\n</tr>\n<tr>\n<td>nxrB</td>\n<td>Nitrite oxidoreductase, beta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"16\">Denitrification</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>nirK</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>nirS</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>norB</td>\n<td>Nitric oxide reductase subunit B</td>\n</tr>\n<tr>\n<td>norC</td>\n<td>Nitric oxide reductase subunit C</td>\n</tr>\n<tr>\n<td>nosZ</td>\n<td>Nitrous-oxide reductase</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"6\">Assimilatory nitrate reduction</td>\n<td>nasA</td>\n<td>Assimilatory nitrate reductase catalytic subunit</td>\n</tr>\n<tr>\n<td>nasB</td>\n<td>Assimilatory nitrate reductase electron transfer subunit</td>\n</tr>\n<tr>\n<td>nirA</td>\n<td>Ferredoxin-nitrite reductase</td>\n</tr>\n<tr>\n<td>NR</td>\n<td>Nitrate reductase (NAD(P)H)</td>\n</tr>\n<tr>\n<td>narB</td>\n<td>Assimilatory nitrate reductase</td>\n</tr>\n<tr>\n<td>narC</td>\n<td>Cytochrome b-561</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Dissimilatory nitrate reduction</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td>nirB</td>\n<td>Nitrite reductase (NADH) large subunit</td>\n</tr>\n<tr>\n<td>nirD</td>\n<td>Nitrite reductase (NADH) small subunit</td>\n</tr>\n<tr>\n<td>nrfA</td>\n<td>Nitrite reductase (cytochrome c-552)</td>\n</tr>\n<tr>\n<td>nrfB</td>\n<td>Cytochrome c-type protein NrfB</td>\n</tr>\n<tr>\n<td>nrfC</td>\n<td>Protein NrfC</td>\n</tr>\n<tr>\n<td>nrfD</td>\n<td>Protein NrfD</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Nitrogen fixation</td>\n<td>anfG</td>\n<td>Nitrogenase delta subunit</td>\n</tr>\n<tr>\n<td>nifD</td>\n<td>Nitrogenase molybdenum-iron protein alpha chain</td>\n</tr>\n<tr>\n<td>nifH</td>\n<td>Nitrogenase iron protein NifH</td>\n</tr>\n<tr>\n<td>nifK</td>\n<td>Nitrogenase molybdenum-iron protein beta chain</td>\n</tr>\n<tr>\n<td>nifW</td>\n<td>Nitrogenase-stabilizing/protective protein</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Anammox</td>\n<td>hzo</td>\n<td>Hydrazine oxidoreductase</td>\n</tr>\n<tr>\n<td>hzsA</td>\n<td>Hydrazine synthase subunit A</td>\n</tr>\n<tr>\n<td>hzsB</td>\n<td>Hydrazine synthase subunit B</td>\n</tr>\n<tr>\n<td>hzsC</td>\n<td>Hydrazine synthase subunit C</td>\n</tr>\n<tr>\n<td>hdh</td>\n<td>Hydrazine dehydrogenase</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Organic degradation and synthesis</td>\n<td>ureA</td>\n<td>Urease subunit gamma</td>\n</tr>\n<tr>\n<td>ureB</td>\n<td>Urease subunit beta</td>\n</tr>\n<tr>\n<td>ureC</td>\n<td>Urease subunit alpha</td>\n</tr>\n<tr>\n<td>nao</td>\n<td>Nitroalkane oxidase</td>\n</tr>\n<tr>\n<td>nmo</td>\n<td>Nitronate monooxygenase</td>\n</tr>\n<tr>\n<td>gdh_K00260</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gdh_K00261</td>\n<td>Glutamate dehydrogenase (NAD(P)+)</td>\n</tr>\n<tr>\n<td>gdh_K00262</td>\n<td>Glutamate dehydrogenase (NADP+)</td>\n</tr>\n<tr>\n<td>gdh_K15371</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gs_K00264</td>\n<td>Glutamate synthase (NADPH/NADH)</td>\n</tr>\n<tr>\n<td>gs_K00265</td>\n<td>Glutamate synthase (NADPH/NADH) large chain</td>\n</tr>\n<tr>\n<td>gs_K00266</td>\n<td>Glutamate synthase (NADPH/NADH) small chain</td>\n</tr>\n<tr>\n<td>gs_K00284</td>\n<td>Glutamate synthase (ferredoxin)</td>\n</tr>\n<tr>\n<td>glsA</td>\n<td>Glutaminase</td>\n</tr>\n<tr>\n<td>glnA</td>\n<td>Glutamine synthetase</td>\n</tr>\n<tr>\n<td>asnB</td>\n<td>Asparagine synthase (glutamine-hydrolysing)</td>\n</tr>\n<tr>\n<td>ansB</td>\n<td>Glutamin-(asparagin-)ase</td>\n</tr>\n<tr>\n<td rowspan=\"4\">Others</td>\n<td>hcp</td>\n<td>Hydroxylamine reductase</td>\n</tr>\n<tr>\n<td>pmoA</td>\n<td>Particulate methane monooxygenase subunit A</td>\n</tr>\n<tr>\n<td>pmoB</td>\n<td>Particulate methane monooxygenase subunit B</td>\n</tr>\n<tr>\n<td>pmoC</td>\n<td>Particulate methane monooxygenase subunit C</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Annotation\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Pathways\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"black\"</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis.text.y <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.grid <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> panel.border <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.spacing <span class=\"token operator\">=</span> unit<span class=\"token punctuation\">(</span><span class=\"token number\">.1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"lines\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>plot.margin<span class=\"token operator\">=</span>unit<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cm\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> facet_grid<span class=\"token punctuation\">(</span>Pathways <span class=\"token operator\">~</span> .<span class=\"token punctuation\">,</span> drop<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span>space<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span> switch <span class=\"token operator\">=</span> <span class=\"token string\">\"y\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>strip.background <span class=\"token operator\">=</span> element_rect<span class=\"token punctuation\">(</span>fill <span class=\"token operator\">=</span> <span class=\"token string\">\"grey95\"</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"white\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text.y.left <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle<span class=\"token operator\">=</span><span class=\"token number\">360</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://doi.org/10.1093/bioinformatics/bty741\">NCycDB: a curated integrative database for fast and accurate metagenomic profiling of nitrogen cycling genes</a></li>\n<li><a href=\"https://github.com/qichao1984/NCyc\">GitHub</a></li>\n</ul>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “18ea” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"宏基因组","path":"api/tags/宏基因组.json"}]},{"title":"宏基因组分析流程及代码","slug":"宏基因组分析流程及代码","date":"2021-01-19T07:24:28.000Z","updated":"2022-01-08T02:16:28.443Z","comments":true,"path":"api/articles/宏基因组分析流程及代码.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>本文阐述宏基因组物种分类、组装、bining、基因预测及注释……</p>\n<span id=\"more\"></span>\n<h1 id=\"a-软件列表及安装\"><a class=\"markdownIt-Anchor\" href=\"#a-软件列表及安装\"></a> A、软件列表及安装</h1>\n<h2 id=\"a1-分类相关\"><a class=\"markdownIt-Anchor\" href=\"#a1-分类相关\"></a> A.1 分类相关</h2>\n<h3 id=\"a11-metaphlan-30\"><a class=\"markdownIt-Anchor\" href=\"#a11-metaphlan-30\"></a> A.1.1 metaphlan 3.0</h3>\n<p>MetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequencing data.</p>\n<h4 id=\"a-安装主文件\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n metaphlan <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.7</span> metaphlan\n$ conda activate metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"b-安装数据库\"><a class=\"markdownIt-Anchor\" href=\"#b-安装数据库\"></a> b. 安装数据库</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metaphlan --install<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-安装依赖包\"><a class=\"markdownIt-Anchor\" href=\"#c-安装依赖包\"></a> c. 安装依赖包</h4>\n<ul>\n<li>hclust<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> -c bioconda hclust2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>R, vegan, ape <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda <span class=\"token function\">install</span> r-base r-vegan r-ape<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>rbiom<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ R\n$ install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"rbiom\"</span><span class=\"token punctuation\">)</span>\n$ quit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h3 id=\"a12-gtdbtk\"><a class=\"markdownIt-Anchor\" href=\"#a12-gtdbtk\"></a> A.1.2 <a href=\"https://ecogenomics.github.io/GTDBTk/\">gtdbtk</a></h3>\n<h4 id=\"a-hardware-requirements\"><a class=\"markdownIt-Anchor\" href=\"#a-hardware-requirements\"></a> a. Hardware requirements</h4>\n<table>\n<thead>\n<tr>\n<th>Domain</th>\n<th>Memory</th>\n<th>Storage</th>\n<th>Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Archaea</td>\n<td>~8 GB</td>\n<td>~27 GB</td>\n<td>~1 hour / 1,000 genomes @ 64 CPUs</td>\n</tr>\n<tr>\n<td>Bacteria</td>\n<td>~150 GB</td>\n<td>~27 GB</td>\n<td>~1 hour / 1,000 genomes @ 64 CPUs</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"b-install-gtdb-tk-with-conda\"><a class=\"markdownIt-Anchor\" href=\"#b-install-gtdb-tk-with-conda\"></a> b. Install GTDB-Tk with conda</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n gtdbtk -c conda-forge -c bioconda gtdbtk<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-gtdb-tk-reference-data\"><a class=\"markdownIt-Anchor\" href=\"#c-gtdb-tk-reference-data\"></a> c. GTDB-Tk reference data</h4>\n<ul>\n<li><strong>Note that different versions of the GTDB release data may not run on all versions of GTDB-Tk, below are all supported versions:</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>GTDB Release</th>\n<th>Minimum version</th>\n<th>Maximum version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>R95</td>\n<td>1.3.0</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>R89</td>\n<td>0.3.0</td>\n<td>0.1.2</td>\n</tr>\n<tr>\n<td>R86.2</td>\n<td>0.2.1</td>\n<td>0.2.2</td>\n</tr>\n<tr>\n<td>R86</td>\n<td>0.1.0</td>\n<td>0.1.6</td>\n</tr>\n<tr>\n<td>R83</td>\n<td>0.0.6</td>\n<td>0.0.7</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Download the reference data</li>\n</ul>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/auxillary_files/gtdbtk_r95_data.tar.gz\n  \n$ <span class=\"token function\">tar</span> xvzf gtdbtk_r95_data.tar.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p><strong>注意</strong>：GTDB-Tk requires an environment variable named GTDBTK_DATA_PATH to be set to the directory containing the unarchived GTDB-Tk reference data.</p>\n<ul>\n<li>You can automatically alias GTDBTK_DATA_PATH whenever the environment is activated by editing {gtdbtk environment path}/etc/conda/activate.d/gtdbtk.sh, e.g.:</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># Determine the GTDB-Tk environment path</span>\n$ conda activate gtdbtk\n$ <span class=\"token function\">which</span> gtdbtk\n<span class=\"token comment\"># /miniconda3/envs/gtdbtk-1.3.0/bin/gtdbtk</span>\n\n<span class=\"token comment\"># Edit the activate file</span>\n$ <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"export GTDBTK_DATA_PATH=/path/to/release/package/\"</span> <span class=\"token operator\">></span> /miniconda3/envs/gtdbtk-1.3.0/etc/conda/activate.d/gtdbtk.sh<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"a13-kraken2\"><a class=\"markdownIt-Anchor\" href=\"#a13-kraken2\"></a> A.1.3 <a href=\"https://github.com/DerrickWood/kraken2\">Kraken2</a></h3>\n<h4 id=\"a-hardware-requirements-2\"><a class=\"markdownIt-Anchor\" href=\"#a-hardware-requirements-2\"></a> a. Hardware requirements</h4>\n<ul>\n<li>Disk space: Construction of a Kraken 2 standard database requires approximately 100 GB of disk space. A test on 01 Jan 2018 of the default installation showed 42 GB of disk space was used to store the genomic library files, 26 GB was used to store the taxonomy information from NCBI, and 29 GB was used to store the Kraken 2 compact hash table.</li>\n<li>Memory: To run efficiently, Kraken 2 requires enough free memory to hold the database (primarily the hash table) in RAM. While this can be accomplished with a ramdisk, Kraken 2 will by default load the database into process-local RAM; the --memory-mapping switch to kraken2 will avoid doing so. The default database size is 29 GB (as of Jan. 2018), and you will need slightly more than that in RAM if you want to build the default database.</li>\n</ul>\n<h4 id=\"b-install-kraken2-with-conda\"><a class=\"markdownIt-Anchor\" href=\"#b-install-kraken2-with-conda\"></a> b. Install Kraken2 with conda</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n kraken2 kraken2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-build-the-database\"><a class=\"markdownIt-Anchor\" href=\"#c-build-the-database\"></a> c. Build the database</h4>\n<ul>\n<li>下载数据库。找到一个存储空间比较大的目录并进入，运行如下命令，这里下载的数据库包括 archaea，bacteria，plasmid，viral，fungi，protozoa，UniVec 和 UniVec_Core：<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> <span class=\"token function\">bash</span> -c <span class=\"token string\">'for i in archaea bacteria plasmid viral fungi protozoa UniVec UniVec_Core; do kraken2-build --download-library $i --threads 24 --db db_name; done'</span> <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>下载分类信息<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> kraken2-build --download-taxonomy --threads <span class=\"token number\">24</span> --db db_name <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>建立索引<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">nohup</span> kraken2-build --build --threads <span class=\"token number\">24</span> --db db_name <span class=\"token operator\">&amp;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"d-序列分类\"><a class=\"markdownIt-Anchor\" href=\"#d-序列分类\"></a> d. 序列分类</h4>\n</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">kraken2 --paired --threads <span class=\"token number\">24</span> --unclassified-out unclassified<span class=\"token comment\">#.fq --classified-out classified#.fq --output outfile --confidence 0.5 --memory-mapping --use-names --report reportname --report-zero-counts --db $DBNAME reads1 read2</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"a2-组装-bining-质量评估\"><a class=\"markdownIt-Anchor\" href=\"#a2-组装-bining-质量评估\"></a> A.2 组装、Bining、质量评估</h2>\n<h3 id=\"a21-metawrap\"><a class=\"markdownIt-Anchor\" href=\"#a21-metawrap\"></a> A.2.1 metawrap</h3>\n<p>MetaWRAP is a pipeline for genome-resolved metagenomic data analysis.</p>\n<h4 id=\"a-安装主文件-2\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件-2\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n metawrap <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">2.7</span> metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"b-安装其他分析工具到metawrap环境中\"><a class=\"markdownIt-Anchor\" href=\"#b-安装其他分析工具到metawrap环境中\"></a> b. 安装其他分析工具到 metawrap 环境中</h4>\n<ul>\n<li><strong>cd-hit</strong></li>\n<li><strong>coverm</strong> DNA read coverage and relative abundance calculator focused on metagenomics applications</li>\n<li><strong>bamm</strong> Metagenomics-focused BAM file manipulation</li>\n<li><strong>unitem</strong> Ensemble binning strategies for combining the output of multiple binning methods</li>\n<li><strong>humann2</strong> The HMP Unified Metabolic Analysis Network 2</li>\n<li><strong><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">graphlan</a></strong></li>\n<li><strong><a href=\"https://pypi.org/project/export2graphlan/\">export2graphlan</a></strong></li>\n<li><strong><a href=\"https://data.ace.uq.edu.au/public/CheckM_databases/\">checkm database</a></strong></li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activeta metawrap\n$ conda <span class=\"token function\">install</span> cd-hit coverm bamm unitem humann2 graphlan export2graphlan\n\n<span class=\"token comment\"># 找到一个合适的目录并cd进入以便存储checkm数据库</span>\n$ <span class=\"token function\">wget</span> https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz\n$ <span class=\"token function\">tar</span> zxvf checkm_data_2015_01_16.tar.gz\n$ checkm data setRoot\n<span class=\"token comment\"># 随后输入数据库所在的full path</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"a3-非冗余基因功能注释\"><a class=\"markdownIt-Anchor\" href=\"#a3-非冗余基因功能注释\"></a> A.3 非冗余基因功能注释</h2>\n<h3 id=\"a31-eggnog-mapper\"><a class=\"markdownIt-Anchor\" href=\"#a31-eggnog-mapper\"></a> A.3.1 eggNOG-mapper</h3>\n<p>功能注释，uniref, eggNOG, KEGG, GO; CAZy; VFDB; CARD; TCDB; PHI。</p>\n<h3 id=\"a32-enrichm\"><a class=\"markdownIt-Anchor\" href=\"#a32-enrichm\"></a> A.3.2 EnrichM</h3>\n<p><a href=\"https://github.com/geronimp/enrichM\">EnrichM</a> is a set of comparative genomics tools for large sets of metagenome assembled genomes (MAGs). The current functionality includes:</p>\n<ul>\n<li>A basic annotation pipeline for MAGs.</li>\n<li>A pipeline to determine the metabolic pathways that are encoded by MAGs, using KEGG modules as a reference (although custom pathways can be specified)</li>\n<li>A pipeline to identify genes or metabolic pathways that are enriched within and between user-defined groups of genomes (groups can be genomes that are related functionally, phylogenetically, recovered from different environments, etc).</li>\n<li>To construct metabolic networks from annotated population genomes.</li>\n<li>Construct random forest machine learning models from the functional composition of either MAGs, metagenomes or transcriptomes.</li>\n<li>Apply these random forest machine learning models to classify new MAGs metagenomes.</li>\n</ul>\n<h4 id=\"a-安装主文件-3\"><a class=\"markdownIt-Anchor\" href=\"#a-安装主文件-3\"></a> a. 安装主文件</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda create -n enrichm <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3</span>\n$ conda <span class=\"token function\">install</span> enrichm<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"b-安装数据库-2\"><a class=\"markdownIt-Anchor\" href=\"#b-安装数据库-2\"></a> b. 安装数据库</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 约5.7 G</span>\n$ enrichm data<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p><strong>报错</strong> ：</p>\n<blockquote>\n<p>Traceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py&quot;, line 114, in do<br />\nversion_remote = urllib.request.urlopen(self.ftp + self.VERSION).readline().strip().decode(&quot;utf-8&quot;)<br />\nAttributeError: module 'urllib' has no attribute 'request'</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/bin/enrichm&quot;, line 342, in &lt;module&gt;<br />\nrun.run_enrichm(args, sys.argv)<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/run.py&quot;, line 288, in run_enrichm<br />\n<a href=\"http://d.do\">d.do</a>(args.uninstall, args.dry)<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py&quot;, line 117, in do<br />\n&quot;Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a>&quot;)<br />\nException: Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a></p>\n</blockquote>\n<p><strong>解决方案：将 data.py 中的 'import urllib' 替换为 'import urllib.request'</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> /home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"c-sepcifying-the-location-of-the-enrichm-database\"><a class=\"markdownIt-Anchor\" href=\"#c-sepcifying-the-location-of-the-enrichm-database\"></a> c. Sepcifying the location of the EnrichM database</h4>\n<p>If you would like to store the EnrichM database outside of your home directory, move you need to tell EnrichM where to look. To do this, export a BASH variable named &quot;ENRICHM_DB&quot;:</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">ENRICHM_DB</span><span class=\"token operator\">=</span>/path/to/database/ <span class=\"token operator\">>></span>~/.bashrc<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注意</strong> ：/path/to/database/ 根据实际情况而定！<br />\n<strong>报错</strong>：</p>\n<blockquote>\n<p>$ enrichm<br />\nTraceback (most recent call last):<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/bin/enrichm&quot;, line 38, in &lt;module&gt;<br />\nfrom enrichm.run import Run<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/run.py&quot;, line 24, in &lt;module&gt;<br />\nfrom enrichm.network_analyzer import NetworkAnalyser<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/network_analyzer.py&quot;, line 22, in &lt;module&gt;<br />\nfrom enrichm.network_builder import NetworkBuilder<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/network_builder.py&quot;, line 24, in &lt;module&gt;<br />\nfrom enrichm.databases import Databases<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/databases.py&quot;, line 28, in &lt;module&gt;<br />\nclass Databases:<br />\nFile &quot;/home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/databases.py&quot;, line 36, in Databases<br />\nPICKLE_VERSION = open(os.path.join(CUR_DATABASE_DIR, 'VERSION')).readline().strip()<br />\nFileNotFoundError: [Errno 2] No such file or directory: '/new_data/hualin/db/enrichm_database_v10/26-11-2018/VERSION'</p>\n</blockquote>\n<p><strong>Solve</strong>: 将下载的数据库文件全部复制一份到 “<strong>26-11-2018</strong>” 目录中，否则后续运行 annotaton 时会提示找不到数据库文件。</p>\n<h1 id=\"b-数据分析\"><a class=\"markdownIt-Anchor\" href=\"#b-数据分析\"></a> B、数据分析</h1>\n<h2 id=\"b1-使用metaphlan从reads中获取物种分类信息\"><a class=\"markdownIt-Anchor\" href=\"#b1-使用metaphlan从reads中获取物种分类信息\"></a> B.1 使用 metaphlan 从 Reads 中获取物种分类信息</h2>\n<h3 id=\"step-1-激活环境\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metaphlan<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-对paired-end-reads进行注释\"><a class=\"markdownIt-Anchor\" href=\"#step-2-对paired-end-reads进行注释\"></a> Step 2. 对 paired-end Reads 进行注释</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metaphlan Reads1,Reads2 --input_type fastq --bowtie2out Str1.bowtie2.bz2 --nproc <span class=\"token number\">10</span> -o Str1_profiled.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>Reads1 和 Reads2 分别代表双端测序得到的正向和反向数据；--input_type 指定文件格式，我们拿到的下机数据一般为 fastq 格式；--bowtie2out 参数将会保存运行产生的中间文件以便后续重新运行程序时作为输入文件；--nproc 指定使用的线程数量；-o 指定输出文件名。</p>\n<h3 id=\"step-3-汇总所有的结果文件\"><a class=\"markdownIt-Anchor\" href=\"#step-3-汇总所有的结果文件\"></a> Step 3. 汇总所有的结果文件</h3>\n<p>对所有的文件均运行 Step 2 ，产生了多个输出文件（*_profiled.txt），可以将它们汇总到一个文件中（merged_abundance_table.txt），便于后续对多个样品进行相互比较。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ merge_metaphlan_tables.py *_profiled.txt <span class=\"token operator\">></span> merged_abundance_table.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-4-从合并的文件中提取种水平的分类\"><a class=\"markdownIt-Anchor\" href=\"#step-4-从合并的文件中提取种水平的分类\"></a> Step 4. 从合并的文件中提取种水平的分类</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">grep</span> -E <span class=\"token string\">\"s__|clade\"</span> merged_abundance_table.txt <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> <span class=\"token string\">'s/^.*s__//g'</span> <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -f1,3-8 <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> -e <span class=\"token string\">'s/clade_name/body_site/g'</span> <span class=\"token operator\">></span> merged_abundance_table_species.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-5-绘制样本间种水平的热图\"><a class=\"markdownIt-Anchor\" href=\"#step-5-绘制样本间种水平的热图\"></a> Step 5. 绘制样本间种水平的热图</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ hclust2.py -i merged_abundance_table_species.txt -o abundance_heatmap_species.png --ftop <span class=\"token number\">50</span> --f_dist_f braycurtis --s_dist_f braycurtis --cell_aspect_ratio <span class=\"token number\">0.5</span> -l --flabel_size <span class=\"token number\">10</span> --slabel_size <span class=\"token number\">10</span> --max_flabel_len <span class=\"token number\">100</span> --max_slabel_len <span class=\"token number\">100</span> --minv <span class=\"token number\">0.1</span> --dpi <span class=\"token number\">300</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-6-计算样本间的unifrac距离\"><a class=\"markdownIt-Anchor\" href=\"#step-6-计算样本间的unifrac距离\"></a> Step 6. 计算样本间的 unifrac 距离</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 下载依赖的tree文件和脚本,与要分析的文件放于同一目录下</span>\n$ <span class=\"token function\">wget</span> https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/mpa_v30_CHOCOPhlAn_201901_species_tree.nwk\n$ <span class=\"token function\">wget</span> https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/calculate_unifrac.R\n\n<span class=\"token comment\"># 开始计算距离</span>\n$ Rscript plot_unifrac.R merged_abundance_table.txt mpa_v30_CHOCOPhlAn_201901_species_tree.nwk unifrac_merged_abundance_table.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"step-7-绘制cladogram图\"><a class=\"markdownIt-Anchor\" href=\"#step-7-绘制cladogram图\"></a> Step 7. 绘制 cladogram 图</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 激活依赖软件所在的环境</span>\n$ conda activate metawrap\n\n<span class=\"token comment\"># 生成绘图所需的文件</span>\n$ <span class=\"token function\">tail</span> -n +2 merged_abundance_table.txt <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -f1,3- <span class=\"token operator\">></span> merged_abundance_table_reformatted.txt\n\n$ export2graphlan.py --skip_rows <span class=\"token number\">1</span> -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant <span class=\"token number\">100</span> --abundance_threshold <span class=\"token number\">1</span> --least_biomarkers <span class=\"token number\">10</span> --annotations <span class=\"token number\">5,6</span> --external_annotations <span class=\"token number\">7</span> --min_clade_size <span class=\"token number\">1</span>\n\n<span class=\"token comment\"># 绘图</span>\n$ graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml\n\n$ graphlan.py --dpi <span class=\"token number\">300</span> merged_abundance.xml merged_abundance.pdf --external_legends<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"b2-使用metawrap对reads进行组装\"><a class=\"markdownIt-Anchor\" href=\"#b2-使用metawrap对reads进行组装\"></a> B.2 使用 metawrap 对 Reads 进行组装</h2>\n<h3 id=\"step-1-激活环境-2\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境-2\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metawrap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-组装\"><a class=\"markdownIt-Anchor\" href=\"#step-2-组装\"></a> Step 2. 组装</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap assembly -1 Reads1 -2 Reads2 -o Assemble1 -m <span class=\"token number\">300</span> -t <span class=\"token number\">15</span> --metaspades<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP assembly [options] -1 reads_1.fastq -2 reads_2.fastq -o output_dir\n<ul>\n<li>Options:\n<ul>\n<li>\n<p>-1 STR          forward fastq reads</p>\n</li>\n<li>\n<p>-2 STR          reverse fastq reads</p>\n</li>\n<li>\n<p>-o STR          output directory</p>\n</li>\n<li>\n<p>-m INT          memory in GB (default=24)</p>\n</li>\n<li>\n<p>-t INT          number of threads (defualt=1)</p>\n</li>\n<li>\n<p>-l INT\t\tminimum length of assembled contigs (default=1000)</p>\n</li>\n<li>\n<p>--megahit\tassemble with megahit (default)</p>\n</li>\n<li>\n<p>--metaspades\tassemble with metaspades instead of megahit (better results but slower and higher memory requirement)</p>\n</li>\n</ul>\n</li>\n</ul>\n</details>\n<p>Reads1 和 Reads2 分别代表双端测序得到的正向和反向数据；-o 指定输出目录，-m 指定最大可用内存大小，超过设定值后程序会自动退出，建议设大一点，我 10G 的数据大概需要 180G 内存；-t 指定线程数；--metaspades 表示用 metaspades 进行组装，特别慢，但是组装结果相对好一些。</p>\n<h2 id=\"b3-使用metawrap对contigs进行bining\"><a class=\"markdownIt-Anchor\" href=\"#b3-使用metawrap对contigs进行bining\"></a> B.3 使用 metawrap 对 Contigs 进行 Bining</h2>\n<h3 id=\"step-1-激活环境-3\"><a class=\"markdownIt-Anchor\" href=\"#step-1-激活环境-3\"></a> Step 1. 激活环境</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate metawrap<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"step-2-bining\"><a class=\"markdownIt-Anchor\" href=\"#step-2-bining\"></a> Step 2. Bining</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap binning -o Str1.INITIAL_BINNING -t <span class=\"token number\">20</span> -m <span class=\"token number\">200</span> --universal --run-checkm -a <span class=\"token operator\">&lt;</span>path of contigs<span class=\"token operator\">></span> --metabat2 --maxbin2 --concoct 解压的Reads1 解压的Reads2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP binning [options] -a assembly.fa -o output_dir readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n<ul>\n<li>\n<p>Note1: Make sure to provide all your separately replicate read files, not the joined file.</p>\n</li>\n<li>\n<p>Note2: You may provide single end or interleaved reads as well with the use of the correct option</p>\n</li>\n<li>\n<p>Note3: If the output already has the .bam alignments files from previous runs, the module will skip re-aligning the reads</p>\n</li>\n<li>\n<p>Options:</p>\n<ul>\n<li>-a STR          metagenomic assembly file</li>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads (default=1)</li>\n<li>-m INT\t\tamount of RAM available (default=4)</li>\n<li>-l INT\t\tminimum contig length to bin (default=1000bp). Note: metaBAT will default to 1500bp minimum</li>\n<li>--metabat2      bin contigs with metaBAT2</li>\n<li>--metabat1\tbin contigs with the original metaBAT</li>\n<li>--maxbin2\tbin contigs with MaxBin2</li>\n<li>--concoct\tbin contigs with CONCOCT</li>\n<li>--universal\tuse universal marker genes instead of bacterial markers in MaxBin2 (improves Archaea binning)</li>\n<li>--run-checkm\timmediately run CheckM on the bin results (requires 40GB+ of memory)</li>\n<li>--single-end\tnon-paired reads mode (provide *.fastq files)</li>\n<li>--interleaved\tthe input read files contain interleaved paired-end reads</li>\n</ul>\n</li>\n</ul>\n</details>\n**注意避坑：** 这里的Reads1和Reads2需要提供解压缩后的Reads文件，不但要解压缩，还需要重命名，即后缀名必须为“\\_clean\\_1.fastq” 和 “\\_clean\\_2.fastq”，否则软件无法运行。-o指定输出目录；-t指定线程数；-m指定最大内存限制；--run-checkm表明即时检查Bining的质量；--metabat2 --maxbin2 --concoct 指定同时采用这三个分箱工具进行Bining；--universal指定MaxBin2采用universal marker 基因代替 bacterial markers  (improves Archaea binning)。\n<h3 id=\"step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"><a class=\"markdownIt-Anchor\" href=\"#step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"></a> Step 3. 整合三种方法的 bins (metabat2, maxbin2, concoct) 结果</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap bin_refinement -o F01_BIN_REFINEMENT<span class=\"token punctuation\">(</span>输出目录<span class=\"token punctuation\">)</span> -t <span class=\"token number\">20</span> -A str1.INITIAL_BINNING/metabat2_bins/ -B str1.INITIAL_BINNING/maxbin2_bins/ -C str1.INITIAL_BINNING/concoct_bins/ -c <span class=\"token number\">70</span> -x <span class=\"token number\">5</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP bin_refinement [options] -o output_dir -A bin_folderA [-B bin_folderB -C bin_folderC]\n<ul>\n<li>\n<p>Note: the contig names in different bin folders must be consistant (must come from the same assembly).</p>\n</li>\n<li>\n<p>Options:</p>\n<ul>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads (default=1)</li>\n<li>-m INT\t\tmemory available (default=40)</li>\n<li>-c INT          完整度 minimum % completion of bins [should be&gt;50%] (default=70)</li>\n<li>-x INT          污染度 maximum % contamination of bins that is acceptable (default=10)</li>\n<li>-A STR\t\tfolder with metagenomic bins (files must have .fa or .fasta extension)</li>\n<li>-B STR\t\tanother folder with metagenomic bins</li>\n<li>-C STR\t\tanother folder with metagenomic bins</li>\n<li>--skip-refinement\tdont use binning_refiner to come up with refined bins based on combinations of binner outputs</li>\n<li>--skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>--skip-consolidation\tchoose the best version of each bin from all bin refinement iteration</li>\n<li>--keep-ambiguous\tfor contigs that end up in more than one bin, keep them in all bins (default: keeps them only in the best bin)</li>\n<li>--remove-ambiguous\tfor contigs that end up in more than one bin, remove them in all bins (default: keeps them only in the best bin)</li>\n<li>--quick\t\t\tadds --reduced_tree option to checkm, reducing runtime, especially with low memory</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-4-blobology可视化bin\"><a class=\"markdownIt-Anchor\" href=\"#step-4-blobology可视化bin\"></a> Step 4. Blobology 可视化 bin</h3>\n<p><strong>一个坑：</strong> metawrap 安装的 blast 为 2.6 版本，只能用 Version 4 的 nt 库。而最新的 nt 库为 Version 5，v4 已经不再维护了。因此需要更新 metawrap 安装环境中的 blast 至 2.8.0 及以上版本，这里无法通过‘conda updata blast’实现更新，而是需要下载新版本的 blast 可执行程序，覆盖 metawrap 环境中的 blast 程度们。 如果你采用的是默认版本的 blast 和 V5 的 nt 库，会得到报错：“BLAST Database error: Error: Not a valid version 4 database”.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap blobology -a Result/Assemble/F01/final_assembly.fasta -t <span class=\"token number\">20</span> -o F01.BLOBOLOGY --bins F01_BIN_REFINEMENT/metawrap_70_5_bins reads/F01_clean_1.fastq reads/F01_clean_2.fastq<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP blobology [options] -a assembly.fasta -o output_dir readsA_1.fastq readsA_2.fastq [readsB_1.fastq readsB_2.fastq ... ]\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-a STR\t\tassembly fasta file</li>\n<li>-o STR          output directory</li>\n<li>-t INT          number of threads</li>\n<li>--subsamble \tINT\tNumber of contigs to run blobology on. Subsampling is randomized. (default=ALL)</li>\n<li>--bins\t\tSTR\tFolder containing bins. Contig names must match those of the assembly file. (default=None)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-5-bins-定量\"><a class=\"markdownIt-Anchor\" href=\"#step-5-bins-定量\"></a> Step 5. Bins 定量</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ metawrap quant_bins -b F01_BIN_REFINEMENT/metawrap_70_5_bins -t <span class=\"token number\">8</span> -o F01.QUANT_BINS -a Result/Assemble/F01/final_assembly.fasta reads/F01_clean_1.fastq reads/F01_clean_2.fastq<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP quant_bins [options] -b bins_folder -o output_dir -a assembly.fa readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-b STR          folder containing draft genomes (bins) in fasta format</li>\n<li>-o STR          output directory</li>\n<li>-a STR\t\tfasta file with entire metagenomic assembly (strongly recommended!)</li>\n<li>-t INT\t\tnumber of threads</li>\n</ul>\n</li>\n</ul>\n</details>\n<h3 id=\"step-6-重组装\"><a class=\"markdownIt-Anchor\" href=\"#step-6-重组装\"></a> Step 6. 重组装</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">metawrap reassemble_bins -o F01.BIN_REASSEMBLY -1 reads/F01_clean_1.fastq -2 reads/F01_clean_2.fastq -t <span class=\"token number\">20</span> -m <span class=\"token number\">400</span> -c <span class=\"token number\">70</span> -x <span class=\"token number\">10</span> -b F01_BIN_REFINEMENT/metawrap_70_5_bins<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP reassemble_bins [options] -o output_dir -b bin_folder -1 reads_1.fastq -2 reads_2.fastq\n<ul>\n<li>\n<p>Options:</p>\n<ul>\n<li>-b STR\t\tfolder with metagenomic bins</li>\n<li>-o STR\t\toutput directory</li>\n<li>-1 STR          forward reads to use for reassembly</li>\n<li>-2 STR          reverse reads to use for reassembly</li>\n<li>-t INT\t\tnumber of threads (default=1)</li>\n<li>-m INT\t\tmemory in GB (default=40)</li>\n<li>-c INT\t\tminimum desired bin completion % (default=70)</li>\n<li>-x INT\t\tmaximum desired bin contamination % (default=10)</li>\n<li>-l INT\t\tminimum contig length to be included in reassembly (default=500)</li>\n<li>--strict-cut-off\tmaximum allowed SNPs for strict read mapping (default=2)</li>\n<li>--permissive-cut-off\tmaximum allowed SNPs for permissive read mapping (default=5)</li>\n<li>--skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>--parallel\t\trun spades reassembly in parallel, but only using 1 thread per bin</li>\n</ul>\n</li>\n</ul>\n</details>\n<h2 id=\"b4-mags注释\"><a class=\"markdownIt-Anchor\" href=\"#b4-mags注释\"></a> B.4 MAGs 注释</h2>\n<h3 id=\"b41-gtdb-tk-进行物种分类和注释构建系统发育树\"><a class=\"markdownIt-Anchor\" href=\"#b41-gtdb-tk-进行物种分类和注释构建系统发育树\"></a> B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ conda activate gtdbtk<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"classify_wfclassify-workflow-包括了step-1-3\"><a class=\"markdownIt-Anchor\" href=\"#classify_wfclassify-workflow-包括了step-1-3\"></a> classify_wf——Classify workflow (包括了 Step 1-3)</h4>\n<p>The classify workflow consists of three steps: identify, align, and classify.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk classify_wf --genome_dir metawrap_70_5_bins/ --out_dir classify_wf_output -x .fa --prefix F --cpus <span class=\"token number\">6</span> -r --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk classify_wf (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [-x EXTENSION] [--min_perc_aa MIN_PERC_AA] [--prefix PREFIX] [--cpus CPUS]\n                          [--pplacer_cpus PPLACER_CPUS] [--force] [--scratch_dir SCRATCH_DIR] [-r] [--min_af MIN_AF] [--debug] [-h]\n<ul>\n<li>\n<p>mutually exclusive required arguments:</p>\n<ul>\n<li>--genome_dir GENOME_DIR<br />\ndirectory containing genome files in FASTA format</li>\n<li>--batchfile BATCHFILE<br />\npath to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</li>\n</ul>\n</li>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br />\nextension of files to process, gz = gzipped (default: fna)</li>\n<li>--min_perc_aa MIN_PERC_AA<br />\nexclude genomes that do not have at least this percentage of AA in the MSA (inclusive bound) (default: 10)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--pplacer_cpus PPLACER_CPUS<br />\nuse pplacer_cpus during placement (default: cpus)</li>\n<li>--force               continue processing if an error occurs on a single genome (default: False)</li>\n<li>--scratch_dir SCRATCH_DIR<br />\nReduce pplacer memory usage by writing to disk (slower).</li>\n<li>-r, --recalculate_red<br />\nrecalculate RED values based on the reference tree and all added user genomes (default: False)</li>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-1-identify在基因组中寻找marker-genes\"><a class=\"markdownIt-Anchor\" href=\"#step-1-identify在基因组中寻找marker-genes\"></a> Step 1: identify—— 在基因组中寻找 marker genes</h4>\n<p>Translation table 选择：use table 11 unless the coding density using table 4 is 5% higher than when using table 11 and the coding density under table 4 is &gt;70%.  GTDB-Tk 不会区分 tables 4 和 tables 5. 若用户清楚使用哪一个 table，可以通过 --batchfile 指定。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk identify --genome_dir metawrap_70_5_bins/ --out_dir identify_output --cpus <span class=\"token number\">6</span> --prefix F --debug -x .fa --write_single_copy_genes<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"step-2-align\"><a class=\"markdownIt-Anchor\" href=\"#step-2-align\"></a> Step 2: align</h4>\n<p>Create a multiple sequence alignment based on the AR122/BAC120 marker set.<br />\nTime 3m50.019s</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk align --identify_dir identify_output/ --out_dir align_output --cpus <span class=\"token number\">3</span> --prefix F --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h4 id=\"step-3-classify\"><a class=\"markdownIt-Anchor\" href=\"#step-3-classify\"></a> Step 3: classify</h4>\n<p>Determine taxonomic classification of genomes.<br />\nTime 118m9.386s</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk classify --genome_dir metawrap_70_5_bins/ --align_dir align_output/ --out_dir classify_output --cpus <span class=\"token number\">3</span> --prefix F --debug -x .fa -r<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>注意</strong>：如果内存较小，则加上 “--scratch_dir” 参数。</p>\n<hr />\n<h4 id=\"step-4-export_msa-这一步不运行\"><a class=\"markdownIt-Anchor\" href=\"#step-4-export_msa-这一步不运行\"></a> Step 4: export_msa (这一步不运行)</h4>\n<p>The export_msa will export the untrimmed archaeal or bacterial MSA used in the reference data.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌 0m1.503s</span>\n$ <span class=\"token function\">time</span> gtdbtk export_msa --domain arc --output msa_arc.faa --debug\n\n<span class=\"token comment\"># 细菌 0m16.679s</span>\n$ <span class=\"token function\">time</span> gtdbtk export_msa --domain bac --output msa_bac.faa --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"step-5-trim_msa-这一步不运行\"><a class=\"markdownIt-Anchor\" href=\"#step-5-trim_msa-这一步不运行\"></a> Step 5: trim_msa (这一步不运行)</h4>\n<p>The trim_msa command will trim a MSA given a user-specified mask file, or the archaeal/bacterial mask present in the reference data.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌 0m10.675s</span>\n$ <span class=\"token function\">time</span> gtdbtk trim_msa --untrimmed_msa msa_arc.faa --output msa_arc_trim.faa --reference_mask arc --debug\n\n<span class=\"token comment\"># 细菌 3m28.793s</span>\n$ <span class=\"token function\">time</span> gtdbtk trim_msa --untrimmed_msa msa_bac.faa --output msa_bac_trim.faa --reference_mask bac --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"step-6-infer\"><a class=\"markdownIt-Anchor\" href=\"#step-6-infer\"></a> Step 6: infer</h4>\n<p>Infer tree from multiple sequence alignment.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\">#古菌 44m54.884s</span>\n$ <span class=\"token function\">time</span> gtdbtk infer --msa_file align_output/F.ar122.msa.fasta --out_dir infer_out_arc_F --prefix F --cpus <span class=\"token number\">12</span> --debug\n\n<span class=\"token comment\">#细菌</span>\n$ <span class=\"token function\">time</span> gtdbtk infer --msa_file align_output/F.bac120.msa.fasta --out_dir infer_out_bac_F --prefix F --cpus <span class=\"token number\">12</span> --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk infer --msa_file MSA_FILE --out_dir OUT_DIR [--prot_model {JTT,WAG,LG}] [--no_support] [--gamma] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--msa_file MSA_FILE   multiple sequence alignment in FASTA format</li>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--prot_model {JTT,WAG,LG}<br />\nprotein substitution model for tree inference (default: WAG)</li>\n<li>--no_support          do not compute local support values using the Shimodaira-Hasegawa test (default: False)</li>\n<li>--gamma               rescale branch lengths to optimize the Gamma20 likelihood (default: False)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-7-decorate\"><a class=\"markdownIt-Anchor\" href=\"#step-7-decorate\"></a> Step 7: decorate</h4>\n<p>Decorate a tree with the GTDB-Tk taxonomy.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 古菌</span>\n$ <span class=\"token function\">time</span> gtdbtk decorate --input_tree infer_out_arc_F/F.unrooted.tree --output_tree F.decorate_unrooted_arc.tree --gtdbtk_classification_file classify_output/classify/F.ar122.summary.tsv --debug\n\n<span class=\"token comment\"># 细菌</span>\n$ <span class=\"token function\">time</span> gtdbtk decorate --input_tree infer_out_bac_F/F.unrooted.tree --output_tree F.decorate_unrooted_brc.tree --gtdbtk_classification_file classify_output/classify/F.bac120.summary.tsv --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk decorate --input_tree INPUT_TREE --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE] [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE]\n                       [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br />\npath to the unrooted tree in Newick format</li>\n<li>--output_tree OUTPUT_TREE<br />\npath to output the tree</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br />\nfile with GTDB-Tk classifications produced by the  <code>classify</code>  command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br />\nfile indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-8-root\"><a class=\"markdownIt-Anchor\" href=\"#step-8-root\"></a> Step 8: root</h4>\n<p>Root a tree using an outgroup.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk root --input_tree input.tree --outgroup_taxon p__Nanoarchaeota --output_tree output.tree --gtdbtk_classification_file <span class=\"token operator\">&lt;</span>file with GTDB-Tk classifications produced by the classify command<span class=\"token operator\">></span> --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk root --input_tree INPUT_TREE --outgroup_taxon OUTGROUP_TAXON --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE]\n                   [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE] [--debug] [-h]\n<ul>\n<li>\n<p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br />\npath to the unrooted tree in Newick format</li>\n<li>--outgroup_taxon OUTGROUP_TAXON<br />\ntaxon to use as outgroup (e.g., p__Patescibacteria or p__Altarchaeota)</li>\n<li>--output_tree OUTPUT_TREE<br />\npath to output the tree</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br />\nfile with GTDB-Tk classifications produced by the  <code>classify</code>  command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br />\nfile indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n</details>\n<hr />\n<h4 id=\"step-9-ani_rep计算ani值\"><a class=\"markdownIt-Anchor\" href=\"#step-9-ani_rep计算ani值\"></a> Step 9: ani_rep—— 计算 ANI 值</h4>\n<p>Compute the ANI of input genomes to all GTDB-Tk representative genomes.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">time</span> gtdbtk ani_rep --genome_dir metawrap_70_5_bins/ --out_dir ani_rep/ --cpus <span class=\"token number\">6</span> -x .fa --prefix F --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">$ gtdbtk de_novo_wf --genome_dir metawrap_70_5_bins&#x2F; --out_dir de_novo_wf --extension .fa --bacteria --outgroup_taxon p__Patescibacteria --prefix F --cpus 6 --debug<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk ani_rep (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [--no_mash] [--mash_k MASH_K] [--mash_s MASH_S] [--mash_d MASH_D] [--mash_v MASH_V]\n                      [--mash_db MASH_DB] [--min_af MIN_AF] [-x EXTENSION] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n<ul>\n<li>\n<p>mutually exclusive required arguments:</p>\n<ul>\n<li>\n<p>--genome_dir GENOME_DIR<br />\ndirectory containing genome files in FASTA format</p>\n</li>\n<li>\n<p>--batchfile BATCHFILE<br />\npath to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</p>\n</li>\n<li>\n<p>- required named arguments:</p>\n</li>\n<li>\n<p>--out_dir OUT_DIR     directory to output files</p>\n</li>\n</ul>\n</li>\n<li>\n<p>optional Mash arguments:</p>\n<ul>\n<li>--no_mash             skip pre-filtering of genomes using Mash (default: False)</li>\n<li>--mash_k MASH_K       k-mer size [1-32] (default: 16)</li>\n<li>--mash_s MASH_S       maximum number of non-redundant hashes (default: 5000)</li>\n<li>--mash_d MASH_D       maximum distance to keep [0-1] (default: 0.1)</li>\n<li>--mash_v MASH_V       maximum p-value to keep [0-1] (default: 1.0)</li>\n<li>--mash_db MASH_DB     path to save/read (if exists) the Mash reference sketch database (.msh)</li>\n</ul>\n</li>\n<li>\n<p>optional FastANI arguments:</p>\n<ul>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n</ul>\n</li>\n<li>\n<p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br />\nextension of files to process, gz = gzipped (default: fna)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</li>\n</ul>\n</li>\n</ul>\n </details>\n<h3 id=\"b42-enrichm-注释\"><a class=\"markdownIt-Anchor\" href=\"#b42-enrichm-注释\"></a> B.4.2 EnrichM 注释</h3>\n<h4 id=\"step-1-annotate\"><a class=\"markdownIt-Anchor\" href=\"#step-1-annotate\"></a> Step 1. annotate</h4>\n<p>基因组注释管道，可以使用 dbCAN 将基因组与 KO, PFAM, TIGRFAM 和 CAZY 数据库进行比对。结果将为每个基因组产生一个.gff 文件，并生成每个注释类型的频率矩阵（frequency matrix），其中行是注释 IDs，列是基因组。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm annotate --genome_directory metawrap_70_5_bins --output EnrichM_annotate --force --ko --ko_hmm --pfam --tigrfam --clusters --orthologs --cazy --ec --threads <span class=\"token number\">30</span> --parallel <span class=\"token number\">8</span> --suffix .fa --count_domains --chunk_number <span class=\"token number\">8</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options (Use one):</p>\n<ul>\n<li>--genome_files GENOME_FILES [GENOME_FILES ...]<br />\nSpace separated list of genomes to annotate</li>\n<li>--genome_directory GENOME_DIRECTORY<br />\nDirectory containing genomes to annotate</li>\n<li>--protein_files PROTEIN_FILES [PROTEIN_FILES ...]<br />\nSpace separated list of .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n<li>--protein_directory PROTEIN_DIRECTORY<br />\nDirectory containing .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n</ul>\n</li>\n<li>\n<p>Annotations options:</p>\n<ul>\n<li>--ko                  Annotate with KO ids</li>\n<li>--ko_hmm              Annotate with KO ids</li>\n<li>--pfam                Annotate with Pfam HMMs</li>\n<li>--tigrfam             Annotate with TIGRFAM HMMs</li>\n<li>--clusters            Annotate with cluster ids</li>\n<li>--orthologs           Annotate with ortholog ids</li>\n<li>--cazy                Annotate with dbCAN HMMs</li>\n<li>--ec                  Annotate with EC ids</li>\n</ul>\n</li>\n<li>\n<p>Cutoff options:</p>\n<ul>\n<li>--cut_ga              For PFAM and TIGRfam searches: use profiles GA gathering cutoffs to set all thresholding</li>\n<li>--cut_nc              For PFAM and TIGRfam searches: use profiles NC noise cutoffs to set all thresholding</li>\n<li>--cut_tc              For PFAM and TIGRfam searches: use profiles TC trusted cutoffs to set all thresholding</li>\n<li>--cut_ko              For KO HMM annotation searches: use cutoffs defined by KEGG to maximise F-score.</li>\n<li>--evalue EVALUE       Use this evalue cutoff to filter false positives (default: 1e-05)</li>\n<li>--bit BIT             Use this bit score cutoff to filter false positives (default: 0)</li>\n<li>--id ID               Use this percent identity cutoff to filter false positives (default: 0.3)</li>\n<li>--aln_query ALN_QUERY<br />\nThis fraction of the query must align to the reference (default: 0.7)</li>\n<li>--aln_reference ALN_REFERENCE<br />\nThis fraction of the reference must align to the query (default: 0.7)</li>\n<li>--c C                 When clustering, use matches above this fraction of aligned (covered) query and target residues (default: 0.7)</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--threads THREADS     Use this number of threads when annotating with BLAST and HMMsearch (default: 1)</li>\n<li>--parallel PARALLEL   Run this number of jobs in parallel when annotating with HMMsearch (default: 5)</li>\n<li>--inflation INFLATION<br />\nInflation factor to use when calling clusters in ortholog (default = 5.0)</li>\n<li>--suffix SUFFIX       Treat files ending with this suffix within the --genome_directory as genomes (default: .fna for --genome_directory and .faa for )</li>\n<li>--light               Don't store metadata for genome files (can't use enrichM compare downstream, default=False)</li>\n<li>--count_domains       Fill the frequency matrix with the total number of times an annotation was detected (for example, when one domain more than once within a protein), rather than the count of proteins with with that annotation</li>\n<li>--chunk_number CHUNK_NUMBER<br />\nSplit loading of genomes into this many chunks (default = 4)</li>\n<li>--chunk_max CHUNK_MAX<br />\nMaximum number of genomes to load per chunk (default = 2500)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-2-classify\"><a class=\"markdownIt-Anchor\" href=\"#step-2-classify\"></a> Step 2. classify</h4>\n<p>Determine what pathways a genome encodes. Classify quickly reads in KO annotations in the form of a matrix (KO IDs as rows, genomes as columns) and determines which KEGG modules are complete. Annotation matrices can be generated using the annotate function.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm classify --output EnrichM_classify/ko_hmm_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_hmm_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ko_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n<span class=\"token comment\"># 以下6个命令可不必运行</span>\n$ enrichm classify --output EnrichM_classify/cazy_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cazy_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/cluster_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cluster_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ec_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ec_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/ortholog_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ortholog_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/pfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/pfam_frequency_table.tsv --cutoff <span class=\"token number\">0</span>\n\n$ enrichm classify --output EnrichM_classify/tigrfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/tigrfam_frequency_table.tsv --cutoff <span class=\"token number\">0</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--genome_and_annotation_matrix GENOME_AND_ANNOTATION_MATRIX<br />\nPath to file containing a genome annotation matrix</li>\n<li>--custom_modules CUSTOM_MODULES<br />\nTab separated file containing module name, definition as the columns</li>\n<li>--module_rules_json MODULE_RULES_JSON<br />\njson file specifying rules to interpret the annotation and guide module annotation</li>\n<li>--gff_files GFF_FILES<br />\nGFF files for the genomes being classified.</li>\n</ul>\n</li>\n<li>\n<p>Cutoff options:</p>\n<ul>\n<li>--cutoff CUTOFF       Output only modules with greater than this percent of the requied KO groups (default = print all modules)</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--aggregate           Calculate the abundance of each pathway within each genome/sample (column)</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-3-enrichment\"><a class=\"markdownIt-Anchor\" href=\"#step-3-enrichment\"></a> Step 3. enrichment</h4>\n<p>Enrichment will read in KO or PFAM annotations in the form of a matrix (IDs as rows, genomes as columns) and a metadata file that separates genomes into groups to compare, and will run some basic stats to determine the enrichment of modules or pfam clans between and within the groups.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm enrichment --output EnrichM_enrichment/ --metadata genome.list --annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --force<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>- Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--annotate_output ANNOTATE_OUTPUT<br />\nOutput directory provided by enrichm annotate</li>\n<li>--metadata METADATA   Metadata file with two columns, the first with the genome name, the second with the groupings to compare.</li>\n<li>--annotation_matrix ANNOTATION_MATRIX<br />\nAnnotation matrix to compare.</li>\n<li>--gff_files GFF_FILES [GFF_FILES ...]<br />\nGff files for genomes to compare.</li>\n<li>--abundance 基因组丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata grouping abundance samples.</li>\n<li>--transcriptome TRANSCRIPTOME  基因组丰度矩阵</li>\n<li>--transcriptome_metadata TRANSCRIPTOME_METADATA<br />\nMetadata grouping abundance samples.</li>\n</ul>\n</li>\n<li>\n<p>Genome Taxonomy DataBase (GTDB) options:</p>\n<ul>\n<li>--batchfile BATCHFILE<br />\nmetadata file to compare with.</li>\n</ul>\n</li>\n<li>\n<p>Runtime options:</p>\n<ul>\n<li>--pval_cutoff PVAL_CUTOFF<br />\nOnly output results with a p-value below a this cutoff (default=0.05).</li>\n<li>--proportions_cutoff PROPORTIONS_CUTOFF<br />\nProportion enrichment cutoff.</li>\n<li>--threshold THRESHOLD<br />\nThe threshold to control for in false discovery rate of familywise error rate.</li>\n<li>--multi_test_correction MULTI_TEST_CORRECTION<br />\nThe form of mutiple test correction to use. Uses the statsmodel module and consequently has all of its options.<br />\nDefault: Benjamini-Hochberg FDR (fdr_bh)<br />\nOptions: Bonferroni (b)<br />\nSidak (s)<br />\nHolm (h)<br />\nHolm-Sidak (hs)<br />\nSimes-Hochberg (sh)<br />\nHommel (ho)<br />\nFDR Benjamini-Yekutieli (fdr_by)<br />\nFDR 2-stage Benjamini-Hochberg (fdr_tsbh)<br />\nFDR 2-stage Benjamini-Krieger-Yekutieli (fdr_tsbky)<br />\nFDR adaptive Gavrilov-Benjamini-Sarkar (fdr_gbs))</li>\n<li>--processes PROCESSES  采用多少个进程进行富集分析</li>\n<li>--allow_negative_values  允许输入的矩阵中有负值</li>\n<li>--ko                    Compare KO ids (annotated with DIAMOND)</li>\n<li>--ko_hmm          Compare KO ids (annotated with HMMs)</li>\n<li>--pfam                Compare Pfam ids</li>\n<li>--tigrfam             Compare TIGRFAM ids</li>\n<li>--cluster              Compare cluster ids</li>\n<li>--ortholog            Compare ortholog ids</li>\n<li>--cazy                 Compare dbCAN ids</li>\n<li>--ec                     Compare EC ids</li>\n<li>--range RANGE         Base pair range to search for synteny within. Default = 2500.</li>\n<li>--subblock_size SUBBLOCK_SIZE<br />\nNumber of genes clustered in a row to be reported. Default = 2.</li>\n<li>--operon_mismatch_cutoff OPERON_MISMATCH_CUTOFF<br />\nNumber of allowed mismatches when searching for operons across genomes. Defaul</li>\n<li>--operon_match_score_cutoff OPERON_MATCH_SCORE_CUTOFF<br />\nScore cutoff for operon matches</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-4-pathway\"><a class=\"markdownIt-Anchor\" href=\"#step-4-pathway\"></a> Step 4. pathway</h4>\n<p>Pathway reads in a KO matrix and generates a Cytoscape-readable metabolic network and metadata file. Only reactions that are possible given the KOs present in the input matrix are shown, and the modules and reactions that are included in the output can be customized（<strong>报错</strong>）.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ enrichm pathway --matrix EnrichM_annotate/ko_frequency_table.tsv --genome_metadata genome.list --output EnrichM_pathway --abundance EnrichM_enrichment/F01_vs_F02_ivg_results.cdf.tsv --abundance_metadata genome.list --force<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--matrix KO 矩阵。必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--tpm_values TPM_VALUES<br />\nDetectM 产生的 TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--metabolome METABOLOME<br />\nMetabolome CID matrix.</li>\n</ul>\n</li>\n<li>\n<p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br />\nLevel of verbosity (1 - 5 - default = 4) 5 = Very verbose, 1 = Silent</li>\n</ul>\n</li>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li>\n<p>Pathway options:</p>\n<ul>\n<li>--limit LIMIT [LIMIT ...]<br />\nUSE ONLY these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--filter FILTER [FILTER ...]<br />\nDo not use these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--enrichment_output ENRICHMENT_OUTPUT<br />\nSupply an enrichment output to integrate the results into the output network.</li>\n</ul>\n</li>\n</ul>\n</details>\n<h4 id=\"step-5-explore\"><a class=\"markdownIt-Anchor\" href=\"#step-5-explore\"></a> Step 5. explore</h4>\n<p>Explore is similar to pathway, but rather than generating a specified pathway it will start from a given query compound ID, and explore the possible reactions that use that compound given the enzymes present in the input KO matrix.</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<details>\n<summary>点击此处查看参数</summary>\n<ul>\n<li>\n<p>Input options:</p>\n<ul>\n<li>--matrix MATRIX       KO 矩阵。必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare..</li>\n<li>--tpm_values TPM_VALUES<br />\nDetectM 产生的 TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br />\nMetadata 文件包含两列，第一列为基因组名字，第二列 with the groupings to compare..</li>\n<li>--metabolome METABOLOME<br />\nMetabolome CID matrix.</li>\n</ul>\n</li>\n<li>\n<p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br />\nLevel of verbosity (1 - 5 - default = 4) 5 = Very verbose, 1 = Silent</li>\n</ul>\n</li>\n<li>\n<p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li>\n<p>Query options:</p>\n<ul>\n<li>--queries QUERIES     A file containing the KEGG ids of the compounds from which to start in the metabolic network</li>\n<li>--depth DEPTH         Number of steps to take into the metabolic network</li>\n</ul>\n</li>\n</ul>\n</details>\n<h1 id=\"c-metagenome-functional-profiling\"><a class=\"markdownIt-Anchor\" href=\"#c-metagenome-functional-profiling\"></a> C Metagenome functional profiling</h1>\n<ul>\n<li>从宏基因组组装的 contigs 中预测基因 ——prodigal -p meta 模式</li>\n<li>Metagenome-assembled genes which were not included in the MAGs were subjected to taxonomic classification using <a href=\"https://github.com/bioinformatics-centre/kaiju\">Kaiju</a></li>\n<li>eggNOG-mapper 比对<a href=\"https://doi.org/10.1093/nar/gkv1248\"> eggnog</a> 数据库</li>\n<li>HMMER 比对<a href=\"https://doi.org/10.1093/nar/gky995\"> Pfam</a></li>\n<li><a href=\"https://www.kegg.jp/blastkoala/\">GhostKOALA </a>和<a href=\"https://www.genome.jp/tools/kofamkoala/\"> KofamKOALA (v1.0.0)</a> 比对<a href=\"https://doi.org/10.1093/nar/28.1.27\"> KEGG</a></li>\n<li>BLASTP 比对<a href=\"https://doi.org/10.1093/nar/gkv1103\"> TCDB</a></li>\n<li><a href=\"http://bcb.unl.edu/dbCAN2/\">dbCAN2 (v2.0.1)</a> 比对<a href=\"https://doi.org/10.1093/nar/gkn663\"> CAZy</a></li>\n<li>BLASTP 比对<a href=\"https://www.ebi.ac.uk/merops/submit_searches.shtml\"> MEROPS </a></li>\n<li><a href=\"https://github.com/Arkadiy-Garber/FeGenie\">FeGenie</a> 检测 Iron-related genes</li>\n<li>Fe-containing domains were characterized using <a href=\"https://doi.org/10.1073/pnas.0605798103\">Superfamily (v1.75)</a>.</li>\n<li>砷呼吸和抗性基因挖掘<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search\"> https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search</a>，模型下载 https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource</li>\n</ul>\n<h1 id=\"参考资料\"><a class=\"markdownIt-Anchor\" href=\"#参考资料\"></a> 参考资料：</h1>\n<ul>\n<li><a href=\"https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-3.0\">MetaPhlAn 3.0 tutorial</a></li>\n<li><a href=\"https://zouhua.top/archives/9d8099c8.html\">MetaPhlAn 3.0: 宏基因组物种组成分析软件</a></li>\n<li><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">GraPhlAn Tutorial</a></li>\n<li></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"宏基因组","path":"api/tags/宏基因组.json"}]}]}