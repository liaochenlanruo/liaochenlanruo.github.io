{"name":"SY179","postlist":[{"title":"CAZy碳水化合物活性酶预测","slug":"CAZy碳水化合物活性酶预测","date":"2021-09-30T01:18:19.000Z","updated":"2022-01-08T02:16:28.396Z","comments":true,"path":"api/articles/CAZy碳水化合物活性酶预测.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg","content":"<h1 id=\"cazy数据库简介\"><a class=\"markdownIt-Anchor\" href=\"#cazy数据库简介\"></a> CAZy 数据库简介</h1>\n<p><a href=\"http://www.cazy.org/Home.html\">CAZy</a> 全称为 Carbohydrate-Active enZYmes Database，碳水化合物酶相关的专业数据库，内容包括能催化碳水化合物降解、修饰、以及生物合成的相关酶系家族。其包含五个主要分类：糖苷水解酶（Glycoside Hydrolases, GHs）、糖基转移酶（GlycosylTransferases, GTs）、多糖裂解酶（Polysaccharide Lyases, PLs）、糖酯酶（Carbohydrate Esterases, CEs）和氧化还原酶（Auxiliary Activities, AAs）。此外，还包含与碳水化合物结合结构域（Carbohydrate-Binding Modules， CBMs）。五大分类和一个结构域下，都分别建立了多个 Family。</p>\n<ul>\n<li>\n<p><a href=\"http://www.cazy.org/Glycoside-Hydrolases.html\">GHs</a>：糖苷键的水解和 / 或重排</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/GlycosylTransferases.html\">GTs</a>：糖苷键的形成</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Polysaccharide-Lyases.html\">PLs</a>：糖苷键的非水解裂解</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Carbohydrate-Esterases.html\">CEs</a>：水解碳水化合物的酯类</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Auxiliary-Activities.html\">AAs</a>：与 CAZymes 协同作用的氧化还原酶</p>\n</li>\n<li>\n<p><a href=\"http://www.cazy.org/Carbohydrate-Binding-Modules.html\">CBMs</a>：与碳水化合物结合</p>\n</li>\n</ul>\n<h1 id=\"cazy数据库的准备\"><a class=\"markdownIt-Anchor\" href=\"#cazy数据库的准备\"></a> CAZy 数据库的准备</h1>\n<p>在进行预测之前需要准备数据库，CAZy 貌似没有提供 FASTA 格式的序列数据库，而仅提供了序列的 Assenssion number，需要我们自己从 NCBI 数据库中下载序列。下载方法参照我之前的文章《<a href=\"https://liaochenlanruo.github.io/post/e7e9.html\">根据 assession number 批量从 NCB 下载数据</a>》，在文章中提供了下载 CAZy 序列的方法和脚本，此处不再赘述。</p>\n<p>在上一篇文章结尾获得的 “All.sequences.fas” 文件包含了所有的 CAZy 数据库序列，在正式预测之前需要完成数据库的格式化。后面我们将通过 Diamond 软件从基因组中预测 CAZy 蛋白，因此采用 Diamond 格式化数据库。</p>\n<ul>\n<li>\n<p>序列预处理</p>\n<p>不知道什么原因，下载的序列存在两个问题，其一，下一条序列的 ID 连接着上一条序列的末尾，没有断行；其二，序列中存在着一段网页代码。因此，需要分两步进行修正。</p>\n<ul>\n<li>\n<p>解决断行问题</p>\n<p>撰写脚本 “add_linebreak.pl”，内容如下：</p>\n  <pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span><span class=\"token operator\">=</span><span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"All.sequences.fas\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.fas\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\">$_\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将脚本与 &quot;All.sequences.fas&quot; 放在同一目录下，在终端或者命令行中运行如下命令，得到 “CAZy.fas”。</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl add_linebreak.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>删除无关内容</p>\n<p>用 EmEditor 软件打开 CAZy.fas，Ctrl+F 调出查找功能，搜索 “www.” 可以看到如下内容，手动将其删除，并保存文件。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"数据库中需要手动删除的网页信息\" /></p>\n</li>\n</ul>\n</li>\n<li>\n<p>构建 Diamond 数据库</p>\n</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond makedb --in CAZy.fas -d CAZy<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"开始序列比对\"><a class=\"markdownIt-Anchor\" href=\"#开始序列比对\"></a> 开始序列比对</h1>\n<p>当然，我们选择用 Perl 进行批量比对</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有后缀为“.faa”的文件，可以自己更改</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".CAZy.diamond\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token comment\"># -p表示线程数，在笔记本上用6个即可</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"diamond blastp -d CAZy -q $_ -e 1e-5 -f 6 -o $out -k 1 --sensitive -p 30 --query-cover 50\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “run_diamond_CAZy.pl”，将其和序列文件放在同一目录下，并在终端中输入如下命令，完成分析，得到 “*.CAZy.diamond”：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_diamond_CAZy.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"比对结果过滤\"><a class=\"markdownIt-Anchor\" href=\"#比对结果过滤\"></a> 比对结果过滤</h1>\n<p>在比对过程中我们控制了 evalue 和 query coverage，但是没有控制 identity。但是很多时候，需要设定一个 identity 的阈值，低于阈值的比对将会被删除，该步骤可以将比对结果拷贝到 Excel 中根据 identity 排序，手动删除阈值以下的行，然而我选择用 Perl 批处理。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@cazy</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.CAZy.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@cazy</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).CAZy.diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".CAZy.diamond.filtered\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">>=</span> <span class=\"token number\">40</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “filter_cazy_diamond.pl”，将其和上一步产生的文件放在同一目录下，并在终端中输入如下命令，完成过滤，保留 identity &gt;= 40% 的行，得到 “*.CAZy.diamond.filtered”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl filter_cazy_diamond.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"你以为完了还得mapping\"><a class=\"markdownIt-Anchor\" href=\"#你以为完了还得mapping\"></a> 你以为完了？还得 mapping！</h1>\n<p>得到的结果如下图所示，第二列的 Hits 是 NCBI 的 Assession number，我们根本只知道这是什么 CAZy 家族，因此需要 mapping！</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Diamond比对结果\" /></p>\n<p>回头找到我们下载的<a href=\"http://www.cazy.org/IMG/cazy_data/cazy_data.zip\"> cazy_data.txt</a>，里面保存的是 CAZy 家族与 Assession number 的对应关系。比较闲的兄弟可以用查找 - 复制 - 粘贴的方法将 “*.CAZy.diamond.filtered” 中的 Assession number 替换为 CAZy 家族。我为比较忙的兄弟准备了下面的代码，批处理。不过我输出的是一个矩阵。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%cazy</span><span class=\"token punctuation\">;</span>\n\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"cazy_data.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@filtered</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.CAZy.diamond.filtered\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@filtered</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).CAZy.diamond.filtered/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sample</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$samples</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@line</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cazy</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$line</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@ids</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@ids</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$ids[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “<a href=\"http://assession2cazy.pl\">assession2cazy.pl</a>“，将其和”cazy_data.txt“，及上一步产生的文件 “*.CAZy.diamond.filtered” 放在同一目录下，并在终端中输入如下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl assession2cazy.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>得到一个矩阵 “CAZy.Matrix.txt”，内容如下，行为 CAZy 家族，列为基因组 / 样本名。拿到本文件后，可以做热图看 CAZy 家族在各样本中的分布情况，然而这个热图将会比鞋帮子脸还要长，可读性不高，因此我选择将这些 family 合并为大类，生成一个新的矩阵。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Mapping后的矩阵\" /></p>\n<p>二话不说，上代码。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 30, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%category</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$count</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"CAZy.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$count</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\tchomp<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$count</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+?)\\d+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$cate</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$category</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cate</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$i</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$cate</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+=</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IN<span class=\"token punctuation\">;</span>\n\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">CAZy.Category.Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@category</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%category</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@category</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$category</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$category</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$category[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “<a href=\"http://cazyfamily2categories.pl\">cazyfamily2categories.pl</a>”，将其和上一步产生的文件 “CAZy.Matrix.txt” 放在同一目录下，并在终端中输入如下命令，得到文件 “CAZy.Category.Matrix.txt”。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl cazyfamily2categories.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_4.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/9052_4.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"CAZy.Category.Matrix.txt内容概览\" /></p>\n<p>接下来是要做柱状图还是 heatmap，就随便了。</p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “9052” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"CAZy","path":"api/tags/CAZy.json"},{"name":"SY179","path":"api/tags/SY179.json"}]},{"title":"R语言绘制分组条形图","slug":"R语言绘制分组条形图","date":"2021-11-26T06:37:02.000Z","updated":"2022-01-08T02:16:28.413Z","comments":true,"path":"api/articles/R语言绘制分组条形图.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/36cc_1.jpg","content":"<p>当我们要对一个多行多列的数据进行可视化的时候，分组条形图是一种不错的选择。</p>\n<h1 id=\"输入文件样式\"><a class=\"markdownIt-Anchor\" href=\"#输入文件样式\"></a> 输入文件样式</h1>\n<p>本例中数据内容如下图所示，将其保存在名为 <code>CAZy.Category.Matrix.txt</code>  的文件中。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/36cc_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/36cc_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"CAZy.Category.Matrix.txt\" /></p>\n<h1 id=\"绘图代码\"><a class=\"markdownIt-Anchor\" href=\"#绘图代码\"></a> 绘图代码</h1>\n<p>在 Rstudio 中运行如下代码，细节可根据具体情况修改</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">library<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\nwindowsFonts<span class=\"token punctuation\">(</span>Arial<span class=\"token operator\">=</span>windowsFont<span class=\"token punctuation\">(</span><span class=\"token string\">\"Arial\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#加载Windows字体</span>\nsetwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#设定工作目录</span>\ncazy <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"CAZy.Category.Matrix.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\ncazy_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>cazy<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>cazy_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Cazy\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\nggplot<span class=\"token punctuation\">(</span>cazy_melt<span class=\"token punctuation\">,</span>aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span>y <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n     geom_bar<span class=\"token punctuation\">(</span>stat <span class=\"token operator\">=</span> <span class=\"token string\">'identity'</span><span class=\"token punctuation\">,</span> <span class=\"token comment\">#identity是直接引用数据集中变量的值（表示不要计数，而是直接使用数据本身作为频数。）</span>\n              aes<span class=\"token punctuation\">(</span>fill <span class=\"token operator\">=</span> Cazy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              position <span class=\"token operator\">=</span> position_dodge<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span><span class=\"token comment\">#使柱子并排放置</span>\n     theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> \n     theme<span class=\"token punctuation\">(</span>text<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"Arial\"</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span>face <span class=\"token operator\">=</span> <span class=\"token string\">\"plain\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token comment\">#设置文字的字体字号</span>\n           axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token comment\"># 设置X轴文字大小</span>\n      scale_fill_manual<span class=\"token punctuation\">(</span>values<span class=\"token operator\">=</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 设置填充颜色</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/36cc_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/36cc_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"分组条形图\" /></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://blog.csdn.net/weixin_45387324/article/details/109398216\">R 语言 ggplot2 分组条形图</a></li>\n<li><a href=\"https://www.jianshu.com/p/e443edd76daa\">geom_bar () 函数绘制条形图</a></li>\n</ul>\n","raw":null,"categories":[{"name":"可视化","path":"api/categories/可视化.json"}],"tags":[{"name":"SY179","path":"api/tags/SY179.json"},{"name":"R语言","path":"api/tags/R语言.json"},{"name":"绘图","path":"api/tags/绘图.json"}]},{"title":"Swissprot数据库的本地化与序列比对并与其他数据库快速mapping","slug":"Swissprot数据库的本地化与序列比对","date":"2021-09-28T08:13:44.000Z","updated":"2022-01-08T02:16:28.416Z","comments":true,"path":"api/articles/Swissprot数据库的本地化与序列比对.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg","content":"<h1 id=\"数据库下载与构建\"><a class=\"markdownIt-Anchor\" href=\"#数据库下载与构建\"></a> 数据库下载与构建</h1>\n<h2 id=\"下载\"><a class=\"markdownIt-Anchor\" href=\"#下载\"></a> 下载</h2>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h2 id=\"构建\"><a class=\"markdownIt-Anchor\" href=\"#构建\"></a> 构建</h2>\n<ul>\n<li>\n<p>解压缩</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gunzip -d uniprot_sprot.fasta.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>构建 blast + 数据库</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">makeblastdb -in uniprot_sprot.fasta -dbtype prot -out uniprot_sprot -parse_seqids<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>构建 DIAMOND 数据库</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond makedb --in uniprot_sprot.fasta -d uniprot_sprot_diamond<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"比对\"><a class=\"markdownIt-Anchor\" href=\"#比对\"></a> 比对</h1>\n<ul>\n<li>\n<p>blastp 蛋白比对</p>\n <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">blastp -query F01.faa -out F01.swissprot -db /new_data/hualin/db/uniprot_sprot -outfmt <span class=\"token number\">6</span> -num_threads <span class=\"token number\">30</span> -evalue 1e-5<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>diamond 蛋白比对</p>\n<ul>\n<li>\n<p>单个基因组对比</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">diamond blastp -d /new_data/hualin/db/uniprot_sprot_diamond -q F01.faa -e 1e-5 -f <span class=\"token number\">6</span> -o F01.diamond -k <span class=\"token number\">1</span> --sensitive -p <span class=\"token number\">30</span> --query-cover <span class=\"token number\">50</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>多个个基因组对比</p>\n<p>不会 shell 没办法，写 Perl 脚本 (run_diamond.pl) 来完成。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n   <span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n   <span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n   <span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有后缀为“.faa”的文件，可以自己更改</span>\n   <span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".diamond\"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># 将/new_data/hualin/db/uniprot_sprot_diamond换成自己的数据库路径; -p表示线程数，在笔记本上用6个即可</span>\n    system<span class=\"token punctuation\">(</span><span class=\"token string\">\"diamond blastp -d /new_data/hualin/db/uniprot_sprot_diamond -q $_ -e 1e-5 -f 6 -o $out -k 1 --sensitive -p 30 --query-cover 50\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n   <span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将上述代码复制到文件中，命名为 “run_diamond.pl”，将其和序列文件放在同一目录下，并在终端中输入如下命令，完成分析：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_diamond.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"将比对结果mapping至其他数据库\"><a class=\"markdownIt-Anchor\" href=\"#将比对结果mapping至其他数据库\"></a> 将比对结果 mapping 至其他数据库</h1>\n<ul>\n<li>\n<p>打开网址<a href=\"https://www.uniprot.org/uploadlists/\"> https://www.uniprot.org/uploadlists/</a>, 上传比对上的 swissprot ID，可以将比对结果转换为诸如 KEGG 等其他数据库的 ID。个人感觉不是很好用。</p>\n</li>\n<li>\n<p>我们可以把 mapping 文件下载下来，自己写脚本来提取信息，虽然麻烦些，但得到的更多。</p>\n<ul>\n<li>\n<p>下载 mapping 文件</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/idmapping_selected.tab.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>解压缩</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">gunzip -d idmapping_selected.tab.gz<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>写脚本提取对应信息</p>\n<p>Diamond 比对的结果文件内容如下，第一列是自己的氨基酸序列 ID，第二列是 SwissProt 数据库中序列的 ID，而我们真正需要的是第二列中两个竖线中间的内容，在稍后的脚本中将通过正则表达式把它给揪出来。</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">F01_00001\tsp|Q73G44|MDH_WOLPM\t47.2\t72\t38\t0\t10\t81\t243\t314\t9.55e-16\t72.8\n   F01_00003\tsp|D9PU00|TFRA_METTM\t41.3\t569\t301\t7\t7\t574\t4\t540\t4.89e-131\t397\n   F01_00004\tsp|P9WN88|FRDB_MYCTO\t32.7\t208\t118\t6\t19\t215\t23\t219\t3.84e-28\t110\n   F01_00005\tsp|Q021N6|SUCC_SOLUE\t62.8\t384\t141\t2\t1\t383\t1\t383\t1.45e-155\t446<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<p>开始写脚本，保存为 “run_mapping.pl”。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%maps</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@diaout</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有的diamond比对后的输出文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@diaout</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\|(.+)\\|.+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"idmapping_selected.tab\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@diaout2</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.diamond\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 读取所有的diamond比对后的输出文件</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@diaout2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+).diamond/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".mapped\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"qseqid\\tsseqid\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tUniProtKB-AC\tUniProtKB-ID\tGeneID (EntrezGene)\tRefSeq\tGI\tPDB\tGO\tUniRef100\tUniRef90\tUniRef50\tUniParc\tPIR\tNCBI-taxon\tMIM\tUniGene\tPubMed\tEMBL\tEMBL-CDS\tEnsembl\tEnsembl_TRS\tEnsembl_PRO\tAdditional PubMed\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\|(.+)\\|.+/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$maps</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将脚本与 diamond 比对的结果文件以及下载的 mapping 文件放在同一目录下，在终端里输入如下命令即可得到 mapping 后的结果：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_mapping.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"go-注释\"><a class=\"markdownIt-Anchor\" href=\"#go-注释\"></a> GO 注释</h1>\n<ul>\n<li>\n<p>从 map 后的文件中提取基因 ID 和 GO number，各列以制表符分隔，没有 GO 注释的只输出 gene ID。</p>\n<p>准备脚本，命名为 “get_GO.pl”，与上一步生成的 “*.mapped” 文件放在同一目录下。</p>\n  <pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 28, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@mapped</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.mapped\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@mapped</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).mapped/</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".GO\"</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\; /</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@terms</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\; /</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 18代表文件的第19列</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@terms</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\S+/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>在终端或者 Windows 命令行中运行如下命令，得到的 “*.GO” 为输出文件。</p>\n  <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_GO.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>GO 注释与可视化</p>\n</li>\n</ul>\n<p>访问网页<a href=\"https://wego.genomics.cn/\"> WEGO 2.0</a>，在网页中间位置是数据传输接口，将刚刚得到的所有结果文件拖拽上传，<strong>File format</strong> 选择<u>Native Format</u>，如果自己的数据是模式物种，可以在<strong> Reference</strong> 中选择对应的物种，点击<strong> Submit</strong> 即可。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"在WEGO 2.0网页提交数据\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"WEGO 2.0分析结果一览表\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/e922-3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"WEGO 2.0分析结果柱状图\" /></p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “e922” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"}]},{"title":"使用EffectiveT3预测微生物中的III型分泌系统效应蛋白","slug":"使用EffectiveT3预测微生物中的III型分泌系统效应蛋白","date":"2021-10-13T02:01:56.000Z","updated":"2022-01-08T02:16:28.430Z","comments":true,"path":"api/articles/使用EffectiveT3预测微生物中的III型分泌系统效应蛋白.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg","content":"<p>III 型分泌系统 (Type III secretion system，T3SS) 主要是革兰氏阴性菌的分泌蛋白分泌到细胞外的运输途径，T3SS 效应蛋白 (Type III secretion system Effector protein) 与革兰氏阴性致病菌致病机理有关。</p>\n<p>通常用软件<a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\"> EffectiveT3</a> 预测 T3SS，通过其内部特定的计算模型对每条氨基酸序列进行评分，分值越高，可信度越高，选出评分高于阈值的序列，认为这些序列为 III 型分泌系统效应蛋白。</p>\n<p>EffectiveT3 的更新版本加强了 Effective 中 N 端信号肽的识别。对于更新，开发者收集了新的训练数据集，将来自 T3SEdb 的 504 个经过验证的分泌蛋白与其原始的训练数据结合在一起。新模型同样基于朴素贝叶斯分类器（Naive Bayesian Classifier），只是用了更多数据进行训练。在执行遗漏交叉验证测试（leave-one-taxon-out test ）时，其精度为 0.87，与其之前的报告相当。</p>\n<p>新模型现已嵌入到 Effective 中，也可供下载。在新模型中，朴素贝叶斯分类器对 “secreted” 类的默认最小分数为 0.9999。该默认值在网页上称为 “selective”，而 0.95 称为 “sensitive”。阈值也可以自由选择。</p>\n<h1 id=\"软件\"><a class=\"markdownIt-Anchor\" href=\"#软件\"></a> 软件</h1>\n<ul>\n<li>\n<p>主程序</p>\n<ul>\n<li><a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\">EffectiveT3</a></li>\n</ul>\n</li>\n<li>\n<p>依赖</p>\n<ul>\n<li>openjdk &gt;=6</li>\n</ul>\n</li>\n<li>\n<p>安装</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 使用conda安装时依赖Pyton 2.7，3.5，3.6，需要首先创建相应版本的Python环境（自行创建）</span>\nconda <span class=\"token function\">install</span> effectivet3<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p>数据库（modules）配置</p>\n<p><font color=\"#FF0000\">记录一个深坑</font>：程序默认在 module 的路径前加了一个 &quot;./module&quot; 路径，因此，虽然程序安装的过程中自动下载了 modules，然而我们并没有办法调用它们，只能重新下载。用户每次运行软件前需要在当前目录下创建了 module 目录，并下载 modules，然后将其存到 module 目录中。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">mkdir</span> -p module\n\n<span class=\"token function\">curl</span> -o TTSS_STD-2.0.2.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_2.0.2_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_ANIMAL-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_ANIMAL/TTSS_ANIMAL_1.0.1_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_PLANT-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_PLANT/TTSS_PLANT_1.0.1_src_all.jar\n\n<span class=\"token function\">curl</span> -o TTSS_STD-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_1.0.1_src_all.jar\n\n<span class=\"token function\">mv</span> -f TTSS_STD-2.0.2.jar TTSS_ANIMAL-1.0.1.jar TTSS_PLANT-1.0.1.jar TTSS_STD-1.0.1.jar module<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n<h1 id=\"输入数据\"><a class=\"markdownIt-Anchor\" href=\"#输入数据\"></a> 输入数据</h1>\n<p>包含蛋白序列的 FASTA 格式文件</p>\n<h1 id=\"运行软件\"><a class=\"markdownIt-Anchor\" href=\"#运行软件\"></a> 运行软件</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">effectivet3 -f F02_bin.1.faa -m TTSS_TTSS_STD-2.0.2.jar -t selective -o F02_bin.1.out -q<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>-f: 输入文件</li>\n<li>-m: 模型，可选 &quot;TTSS_ANIMAL-1.0.1.jar&quot;，&quot;TTSS_PLANT-1.0.1.jar&quot;，&quot;TTSS_STD-1.0.1.jar&quot; 和 “TTSS_STD-2.0.2.jar”，建议用 “TTSS_STD-2.0.2.jar”</li>\n<li>-t: 模式，&quot;sensitive&quot; and &quot;selective&quot; 二选一，建议使用 &quot;selective&quot;</li>\n<li>-o: 输出文件</li>\n<li>-q: 启动命令行模式</li>\n</ul>\n<h1 id=\"输出文件解读\"><a class=\"markdownIt-Anchor\" href=\"#输出文件解读\"></a> 输出文件解读</h1>\n<ul>\n<li>\n<p>English: The table of results displays all query proteins sorted by prediction score. Effector classification (true/false) according to the applied threshold is shown in the last column.</p>\n</li>\n<li>\n<p>简体中文：结果包含了输入文件中所有的查询序列 IDs，根据得分进行排序。一共包含 4 列，第一列为序列 ID，第二列为序列描述，第三列为预测得分，第四列描述该序列是否为效应因子。各列间以英文的分号（;）分隔。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_0.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"F01_bin.1.out\" /></p>\n</li>\n</ul>\n<h1 id=\"批处理与结果整合\"><a class=\"markdownIt-Anchor\" href=\"#批处理与结果整合\"></a> 批处理与结果整合</h1>\n<p><strong>脚本名</strong>：run_effectiveT3.pl</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Oct 13, 2021</span>\n\n<span class=\"token comment\"># Download modules</span>\n<span class=\"token comment\"># 记录一个深坑，程序默认在module的路径前加了一个\"./module\"路径，因此，虽然程序安装的过程中自动下载了modules，然而我们并没有办法调用它们，只能重新下载。</span>\n<span class=\"token comment\"># 以下代码在当前目录下创建了module目录，并下载modules，然后将其存到module目录中。</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mkdir -p module\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_STD-2.0.2.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_2.0.2_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_ANIMAL-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_ANIMAL/TTSS_ANIMAL_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_PLANT-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_PLANT/TTSS_PLANT_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"curl -o TTSS_STD-1.0.1.jar https://depot.galaxyproject.org/software/TTSS_STD/TTSS_STD_1.0.1_src_all.jar\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv -f TTSS_STD-2.0.2.jar TTSS_ANIMAL-1.0.1.jar TTSS_PLANT-1.0.1.jar TTSS_STD-1.0.1.jar module\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\"># Predict one by one</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".T3\"</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"effectivet3 -f $_ -m TTSS_STD-2.0.2.jar -t selective -o $out -q\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token comment\"># information aggregation</span>\n<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">%strain</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">$line_num</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nopen T3<span class=\"token punctuation\">,</span> <span class=\"token string\">\">T3SS.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> T3 <span class=\"token string\">\"Strain\\tId\\tDescription\\tScore\\tis secreted\\tProtein sequences\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@t3</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.T3\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$t3</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">@t3</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$t3</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).T3/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$faa</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".faa\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$strain</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%temp</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token comment\"># Save ID and Sequence to %temp</span>\n\topen FAA<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$faa\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;FAA></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;FAA></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$seq</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$temp</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose FAA<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$t3\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token regex\">/^#/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\;/</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">eq</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$line_num</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> T3 <span class=\"token string\">\"$str\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@lines</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$temp</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$str</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose T3<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$line_num</span> <span class=\"token operator\">></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\topen T3NUM<span class=\"token punctuation\">,</span> <span class=\"token string\">\">T3SS.num\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token string\">\"Strain\\tTotal sequences\\tT3S effective true\\tT3S effective false\\n\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span>sort keys <span class=\"token variable\">%strain</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> T3NUM <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>true<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span>false<span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose T3NUM<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mkdir -p T3SS_result\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv *.T3 T3SS.num T3SS.txt T3SS_result\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>用法</strong>：将脚本与含有氨基酸序列的 FASTA 格式文件（后缀名为 &quot;.faa&quot;，如果为其他，需要修改脚本第 19、21 和 31 行）放在同一目录下，在终端里运行如下命令（不需要事先配置数据库）：</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\">perl run_effectiveT3<span class=\"token operator\">.</span>pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><strong>报错</strong>：Use of uninitialized value $seq in substitution (s///) at run_effectiveT3.pl line 47, &lt;FAA&gt; chunk .</p>\n<p><strong>原因</strong>：氨基酸序列 ID/Header 那一行的注释信息中含有”&gt;“。该报错不影响结果的准确性，可以忽略。</p>\n<h1 id=\"结果解读\"><a class=\"markdownIt-Anchor\" href=\"#结果解读\"></a> 结果解读</h1>\n<ul>\n<li>\n<p>T3SS_result/strain_name.T3：（strain_name 代表输入文件的名称）effectiveT3 输出的原始结果，共 4 列，如前文所述。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"CXY008.T3\" /></p>\n</li>\n<li>\n<p>T3SS_result/T3SS.txt：包含了所有菌株的预测得到的效应因子，共 6 列，第一列为菌株名，中间的 4 列同上一个文件，最后一列为对应的氨基酸序列。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"T3SS.txt\" /></p>\n</li>\n<li>\n<p>T3SS_result/T3SS.sum：记录所有菌株中序列总数、效应因子序列数和非效应因子序列数。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/fb68_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"T3SS.sum\" /></p>\n</li>\n</ul>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “fb68” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://effectors.csb.univie.ac.at/method/effectivet3\">EffectiveDB</a></li>\n<li><a href=\"https://github.com/bioconda/bioconda-recipes/tree/master/recipes/effectivet3\">Bioconda</a></li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"T3SS","path":"api/tags/T3SS.json"},{"name":"WGS","path":"api/tags/WGS.json"}]},{"title":"利用NCycDB数据库从宏基因组中预测氮循环基因","slug":"利用NCycDB数据库从宏基因组中预测氮循环基因","date":"2021-11-25T03:19:20.000Z","updated":"2022-01-08T02:16:28.433Z","comments":true,"path":"api/articles/利用NCycDB数据库从宏基因组中预测氮循环基因.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>氮（N）循环是地球生态系统中重要的生物地球化学途径的集合，在生态学和环境研究中得到了广泛的关注。目前，<ruby>鸟枪法宏基因组测序<rt>Shotgun metagenome sequencing</rt></ruby>已被广泛应用于探索负责 N 循环过程的基因家族。NCycDB 是一个手动管理的综合数据库，用于从鸟枪法宏基因组测序数据中快速准确地分析 N 循环基因（亚）家族。 NCycDB 总共包含 68 个基因（亚）家族，涵盖 8 个 N 循环过程，分别具有 95% 和 100% 一致性阈值的 84 759 和 219 146 个代表性序列。数据库中还包含了 1958 个<ruby>同源直系同源组<rt>Homologous orthology groups</rt></ruby>的序列，以避免由于 “小数据库” 问题导致的假阳性分配。</p>\n<h1 id=\"数据库及脚本\"><a class=\"markdownIt-Anchor\" href=\"#数据库及脚本\"></a> 数据库及脚本</h1>\n<h2 id=\"下载\"><a class=\"markdownIt-Anchor\" href=\"#下载\"></a> 下载</h2>\n<ul>\n<li>\n<p>通过 Git</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/liaochenlanruo/NCyc.git<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>通过 wget</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://github.com/liaochenlanruo/NCyc/archive/refs/heads/master.zip<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n</ul>\n<h2 id=\"配置\"><a class=\"markdownIt-Anchor\" href=\"#配置\"></a> 配置</h2>\n<ul>\n<li>通过 <code>Git</code>  下载的不需要解压，通过 <code>Wget</code>  下载的需要先解压。</li>\n<li>修改 <code>NCycProfilter.PL</code>  文件的第 8-13 行中 4 个依赖软件的安装路径。</li>\n<li>将 <code>data</code>  目录下的 <code>NCyc_100_2019Jul.7z</code>  解压，将解压得到的 <code>NCyc_100_2019Jul</code>  重命名为 <code>NCyc_100.faa</code>  并移动至 <code>data</code>  目录下。</li>\n</ul>\n<h2 id=\"依赖\"><a class=\"markdownIt-Anchor\" href=\"#依赖\"></a> 依赖</h2>\n<ul>\n<li>Blast</li>\n<li>diamond</li>\n<li>usearch</li>\n<li>Perl</li>\n</ul>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<ul>\n<li>\n<p>序列文件<br />\n宏基因组测序得到的 Reads 文件、组装后的序列文件以及通过基因预测后得到的氨基酸序列文件均可。序列文件可以是压缩的，也可以是解压的。</p>\n</li>\n<li>\n<p>基因组 - 序列数对应文件<br />\n提供一份文本文档，共包含两列，第一列为 <code>样本名称</code>  (即序列文件的名字，不带文件后缀名)，第二列为 <code>样本包含的序列数量</code> 。</p>\n</li>\n</ul>\n<h1 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl NCycProfiler.PL -d ./ -m diamond -f faa -s prot -si SI.txt -o Ncycle.out.txt<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<div class=\"note info\">\n<p>参数解析：</p>\n</div>\n<p>-d 指定工作目录，即序列文件所在目录。<br />\n-m 指定用哪个软件进行序列比对，可选 <code>diamond</code> ， <code>blast</code> ， <code>usearch</code> 。<br />\n-f 指定序列文件的后缀名，不需要带 <code>.</code> 。<br />\n-s 指定序列类型，氨基酸为 <code>prot</code> ，核苷酸为 <code>nucl</code> 。<br />\n-si 基因组 - 序列数对应文件<br />\n - rs 随机取样大小，如果不指定，将取包含序列最少的样本的序列数<br />\n - o 指定输出的文件名称</p>\n<h1 id=\"结果解析\"><a class=\"markdownIt-Anchor\" href=\"#结果解析\"></a> 结果解析</h1>\n<p>得到的结果文件是一个表格，第一行为随机取样大小。第一列为参与 N 循环的基因名，其他列为各样本含有的对应基因的数量。</p>\n<h1 id=\"可视化\"><a class=\"markdownIt-Anchor\" href=\"#可视化\"></a> 可视化</h1>\n<p>可参考本站另一篇文章<a href=\"https://www.liaochenlanruo.fun/post/b68c.html\"> R 语言绘制气泡图 Bubb_Plot</a> 进行数据可视化。</p>\n<ul>\n<li>不带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 做主图</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 修改细节 — 图注，点大小，点shape</span>\nbubble_style <span class=\"token operator\">&lt;-</span> bubble <span class=\"token operator\">+</span> theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    labs<span class=\"token punctuation\">(</span>\n        x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span>\n        y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">,</span>\n        color<span class=\"token operator\">=</span><span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 颜色图注名</span>\n        size<span class=\"token operator\">=</span><span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>    <span class=\"token comment\"># 大小图注名</span>\n    scale_size<span class=\"token punctuation\">(</span>range <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> breaks <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>  <span class=\"token comment\">#等比修改圆圈大小</span>\n    theme<span class=\"token punctuation\">(</span>plot.title<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"Arial\"</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span>\n                                  color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span>face<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>\n                                  hjust<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span>lineheight<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n          plot.subtitle <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nbubble_style<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>依据下表获得基因的 <code>Pathways</code>  和 <code>Annotation</code> ，随后依据 <code>Pathways</code>  进行分组并绘图。</p>\n<table>\n<thead>\n<tr>\n<th>Pathways</th>\n<th>Gene (sub) families</th>\n<th>Annotation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td rowspan=\"9\">Nitrification</td>\n<td>amoA_A</td>\n<td>Ammonia monooxygenase subunit A (archaea)</td>\n</tr>\n<tr>\n<td>amoB_A</td>\n<td>Ammonia monooxygenase subunit B (archaea)</td>\n</tr>\n<tr>\n<td>amoC_A</td>\n<td>Ammonia monooxygenase subunit C (archaea)</td>\n</tr>\n<tr>\n<td>amoA_B</td>\n<td>Ammonia monooxygenase subunit A (bacteria)</td>\n</tr>\n<tr>\n<td>amoB_B</td>\n<td>Ammonia monooxygenase subunit B (bacteria)</td>\n</tr>\n<tr>\n<td>amoC_B</td>\n<td>Ammonia monooxygenase subunit C (bacteria)</td>\n</tr>\n<tr>\n<td>hao</td>\n<td>Hydroxylamine dehydrogenase</td>\n</tr>\n<tr>\n<td>nxrA</td>\n<td>Nitrite oxidoreductase, alpha subunit</td>\n</tr>\n<tr>\n<td>nxrB</td>\n<td>Nitrite oxidoreductase, beta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"16\">Denitrification</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>nirK</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>nirS</td>\n<td>Nitrite reductase (NO-forming)</td>\n</tr>\n<tr>\n<td>norB</td>\n<td>Nitric oxide reductase subunit B</td>\n</tr>\n<tr>\n<td>norC</td>\n<td>Nitric oxide reductase subunit C</td>\n</tr>\n<tr>\n<td>nosZ</td>\n<td>Nitrous-oxide reductase</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td rowspan=\"6\">Assimilatory nitrate reduction</td>\n<td>nasA</td>\n<td>Assimilatory nitrate reductase catalytic subunit</td>\n</tr>\n<tr>\n<td>nasB</td>\n<td>Assimilatory nitrate reductase electron transfer subunit</td>\n</tr>\n<tr>\n<td>nirA</td>\n<td>Ferredoxin-nitrite reductase</td>\n</tr>\n<tr>\n<td>NR</td>\n<td>Nitrate reductase (NAD(P)H)</td>\n</tr>\n<tr>\n<td>narB</td>\n<td>Assimilatory nitrate reductase</td>\n</tr>\n<tr>\n<td>narC</td>\n<td>Cytochrome b-561</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Dissimilatory nitrate reduction</td>\n<td>napA</td>\n<td>Periplasmic nitrate reductase NapA</td>\n</tr>\n<tr>\n<td>napB</td>\n<td>Cytochrome c-type protein NapB</td>\n</tr>\n<tr>\n<td>napC</td>\n<td>Cytochrome c-type protein NapC</td>\n</tr>\n<tr>\n<td>narG</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narH</td>\n<td>Nitrate reductase</td>\n</tr>\n<tr>\n<td>narJ</td>\n<td>Nitrate reductase molybdenum cofactor assembly chaperone</td>\n</tr>\n<tr>\n<td>narI</td>\n<td>Nitrate reductase gamma subunit</td>\n</tr>\n<tr>\n<td>narZ</td>\n<td>Nitrate reductase 2, alpha subunit</td>\n</tr>\n<tr>\n<td>narY</td>\n<td>Nitrate reductase 2, beta subunit</td>\n</tr>\n<tr>\n<td>narV</td>\n<td>Nitrate reductase 2, gamma subunit</td>\n</tr>\n<tr>\n<td>narW</td>\n<td>Nitrate reductase 2, delta subunit</td>\n</tr>\n<tr>\n<td>nirB</td>\n<td>Nitrite reductase (NADH) large subunit</td>\n</tr>\n<tr>\n<td>nirD</td>\n<td>Nitrite reductase (NADH) small subunit</td>\n</tr>\n<tr>\n<td>nrfA</td>\n<td>Nitrite reductase (cytochrome c-552)</td>\n</tr>\n<tr>\n<td>nrfB</td>\n<td>Cytochrome c-type protein NrfB</td>\n</tr>\n<tr>\n<td>nrfC</td>\n<td>Protein NrfC</td>\n</tr>\n<tr>\n<td>nrfD</td>\n<td>Protein NrfD</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Nitrogen fixation</td>\n<td>anfG</td>\n<td>Nitrogenase delta subunit</td>\n</tr>\n<tr>\n<td>nifD</td>\n<td>Nitrogenase molybdenum-iron protein alpha chain</td>\n</tr>\n<tr>\n<td>nifH</td>\n<td>Nitrogenase iron protein NifH</td>\n</tr>\n<tr>\n<td>nifK</td>\n<td>Nitrogenase molybdenum-iron protein beta chain</td>\n</tr>\n<tr>\n<td>nifW</td>\n<td>Nitrogenase-stabilizing/protective protein</td>\n</tr>\n<tr>\n<td rowspan=\"5\">Anammox</td>\n<td>hzo</td>\n<td>Hydrazine oxidoreductase</td>\n</tr>\n<tr>\n<td>hzsA</td>\n<td>Hydrazine synthase subunit A</td>\n</tr>\n<tr>\n<td>hzsB</td>\n<td>Hydrazine synthase subunit B</td>\n</tr>\n<tr>\n<td>hzsC</td>\n<td>Hydrazine synthase subunit C</td>\n</tr>\n<tr>\n<td>hdh</td>\n<td>Hydrazine dehydrogenase</td>\n</tr>\n<tr>\n<td rowspan=\"17\">Organic degradation and synthesis</td>\n<td>ureA</td>\n<td>Urease subunit gamma</td>\n</tr>\n<tr>\n<td>ureB</td>\n<td>Urease subunit beta</td>\n</tr>\n<tr>\n<td>ureC</td>\n<td>Urease subunit alpha</td>\n</tr>\n<tr>\n<td>nao</td>\n<td>Nitroalkane oxidase</td>\n</tr>\n<tr>\n<td>nmo</td>\n<td>Nitronate monooxygenase</td>\n</tr>\n<tr>\n<td>gdh_K00260</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gdh_K00261</td>\n<td>Glutamate dehydrogenase (NAD(P)+)</td>\n</tr>\n<tr>\n<td>gdh_K00262</td>\n<td>Glutamate dehydrogenase (NADP+)</td>\n</tr>\n<tr>\n<td>gdh_K15371</td>\n<td>Glutamate dehydrogenase</td>\n</tr>\n<tr>\n<td>gs_K00264</td>\n<td>Glutamate synthase (NADPH/NADH)</td>\n</tr>\n<tr>\n<td>gs_K00265</td>\n<td>Glutamate synthase (NADPH/NADH) large chain</td>\n</tr>\n<tr>\n<td>gs_K00266</td>\n<td>Glutamate synthase (NADPH/NADH) small chain</td>\n</tr>\n<tr>\n<td>gs_K00284</td>\n<td>Glutamate synthase (ferredoxin)</td>\n</tr>\n<tr>\n<td>glsA</td>\n<td>Glutaminase</td>\n</tr>\n<tr>\n<td>glnA</td>\n<td>Glutamine synthetase</td>\n</tr>\n<tr>\n<td>asnB</td>\n<td>Asparagine synthase (glutamine-hydrolysing)</td>\n</tr>\n<tr>\n<td>ansB</td>\n<td>Glutamin-(asparagin-)ase</td>\n</tr>\n<tr>\n<td rowspan=\"4\">Others</td>\n<td>hcp</td>\n<td>Hydroxylamine reductase</td>\n</tr>\n<tr>\n<td>pmoA</td>\n<td>Particulate methane monooxygenase subunit A</td>\n</tr>\n<tr>\n<td>pmoB</td>\n<td>Particulate methane monooxygenase subunit B</td>\n</tr>\n<tr>\n<td>pmoC</td>\n<td>Particulate methane monooxygenase subunit C</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>带分组</li>\n</ul>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/宏基因组数据/Result/NCyc\"</span><span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"Ncycle.out.txt\"</span><span class=\"token punctuation\">,</span>header <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>ggplot2<span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>reshape<span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span> melt<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nnames<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> c<span class=\"token punctuation\">(</span><span class=\"token string\">\"Genes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Annotation\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Pathways\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Samples\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Abundances\"</span><span class=\"token punctuation\">)</span>\ndata_melt <span class=\"token operator\">&lt;-</span>as.data.frame<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">)</span>\nbubble <span class=\"token operator\">&lt;-</span> ggplot<span class=\"token punctuation\">(</span>data_melt<span class=\"token punctuation\">[</span>which<span class=\"token punctuation\">(</span>data_melt<span class=\"token operator\">$</span>Abundances<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> Genes<span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> Abundances<span class=\"token punctuation\">,</span> color <span class=\"token operator\">=</span> Samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme_bw<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> labs<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> <span class=\"token string\">\"Sediment layers\"</span><span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> <span class=\"token string\">\"N cycling genes\"</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"black\"</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis.text.y <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>size <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.grid <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> panel.border <span class=\"token operator\">=</span> element_blank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>panel.spacing <span class=\"token operator\">=</span> unit<span class=\"token punctuation\">(</span><span class=\"token number\">.1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"lines\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> \n    theme<span class=\"token punctuation\">(</span>plot.margin<span class=\"token operator\">=</span>unit<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cm\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> facet_grid<span class=\"token punctuation\">(</span>Pathways <span class=\"token operator\">~</span> .<span class=\"token punctuation\">,</span> drop<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span>space<span class=\"token operator\">=</span><span class=\"token string\">\"free\"</span><span class=\"token punctuation\">,</span> switch <span class=\"token operator\">=</span> <span class=\"token string\">\"y\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n    theme<span class=\"token punctuation\">(</span>strip.background <span class=\"token operator\">=</span> element_rect<span class=\"token punctuation\">(</span>fill <span class=\"token operator\">=</span> <span class=\"token string\">\"grey95\"</span><span class=\"token punctuation\">,</span> colour <span class=\"token operator\">=</span> <span class=\"token string\">\"white\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text.y.left <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle<span class=\"token operator\">=</span><span class=\"token number\">360</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strip.text<span class=\"token operator\">=</span>element_text<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://doi.org/10.1093/bioinformatics/bty741\">NCycDB: a curated integrative database for fast and accurate metagenomic profiling of nitrogen cycling genes</a></li>\n<li><a href=\"https://github.com/qichao1984/NCyc\">GitHub</a></li>\n</ul>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “18ea” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"宏基因组","path":"api/tags/宏基因组.json"}]},{"title":"扩增子系之绘制物种分类堆叠图","slug":"扩增子系之绘制物种分类堆叠图","date":"2021-09-27T09:09:53.000Z","updated":"2022-01-08T02:16:28.448Z","comments":true,"path":"api/articles/扩增子系之绘制物种分类堆叠图.json","excerpt":null,"keywords":null,"cover":null,"content":"<p><strong>为何要手绘堆叠图？</strong><br />\nQIIME2 虽然可以生成堆叠图，然而图片只能在网页上查看，无法下载。此外，QIIME2 的图有几分丑，且不可个性化修改，因此，手绘最靠谱。手绘当然不是用手画，而是用手敲代码。</p>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<ul>\n<li>各级别的物种分布文件，可以直接从 QIIME2 生成的 taxa_barplot.qzv 文件提交至 <a href=\"https://view.qiime2.org\">https://view.qiime2.org</a> ，随后从网页左上角 “CSV” 按钮处导出各分类级别的丰度表，但是要删除风度表最后几列的元数据信息，只保留丰度信息，各列之间以逗号分隔，内容如下所示，该文件是 LEVEL-2（Phylum）水平的物种丰度分布：</li>\n</ul>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">index,Bacteria;Chloroflexi,Bacteria;Planctomycetota,Archaea;Nanoarchaeota,Bacteria;Patescibacteria,Bacteria;Proteobacteria,Bacteria;Actinobacteriota,Archaea;Aenigmarchaeota,Bacteria;Acidobacteriota,Archaea;Altiarchaeota,Bacteria;Firmicutes,Bacteria;Bdellovibrionota,Bacteria;Dependentiae,Bacteria;Spirochaetota,Bacteria;Margulisbacteria,Bacteria;Myxococcota,Archaea;Halobacterota,Archaea;Crenarchaeota,Bacteria;Latescibacterota,Bacteria;NB1-j,Bacteria;Desulfobacterota,Bacteria;Verrucomicrobiota,Archaea;Iainarchaeota,Bacteria;DTB120,Bacteria;Elusimicrobiota,Eukaryota;SAR,Archaea;Asgardarchaeota,Archaea;Euryarchaeota,Bacteria;CK-2C2-2,Bacteria;Sva0485,Archaea;Thermoplasmatota,Bacteria;Bacteroidota,Bacteria;Marinimicrobia (SAR406 clade),Bacteria;MBNT15,Bacteria;Nitrospinota,Bacteria;Zixibacteria,Bacteria;Nitrospirota,Archaea;Micrarchaeota,Bacteria;LCP-89,Bacteria;Armatimonadota,Bacteria;WOR-1,Bacteria;Gemmatimonadota,Bacteria;Fibrobacterota,Bacteria;Calditrichota,Bacteria;Sumerlaeota,Bacteria;Aerophobota,Bacteria;WS1,Bacteria;NKB15,Bacteria;SAR324 clade(Marine group B),Bacteria;Dadabacteria,Bacteria;BHI80-139,Bacteria;Desantisbacteria,Bacteria;Schekmanbacteria,Archaea;Hadarchaeota,Archaea;Hydrothermarchaeota,Bacteria;Caldatribacteriota,Bacteria;TA06,Bacteria;WS2,Eukaryota;Amorphea,Bacteria;Cyanobacteria,Bacteria;Hydrogenedentes,Bacteria;Cloacimonadota,Bacteria;WPS-2,Bacteria;Modulibacteria,Eukaryota;Archaeplastida,Bacteria;10bav-F6,Bacteria;Methylomirabilota,Bacteria;Deferrisomatota,Bacteria;Fusobacteriota,Bacteria;Fermentibacterota,Bacteria;Entotheonellaeota,Eukaryota;Discoba,Bacteria;Campylobacterota,Bacteria;PAUC34f,Bacteria;Poribacteria,Bacteria;AncK6,Bacteria;GN01,Bacteria;Acetothermia,Bacteria;FCPU426\nB01,383,1058,157,274,7755,1317,0,1025,0,39,22,16,0,0,71,0,6841,20,633,49,145,0,0,0,247,13,0,0,0,13,1012,0,0,53,0,137,0,0,39,0,271,7,17,4,0,0,0,7,471,0,0,0,0,0,3,0,0,69,3,53,0,0,0,0,0,46,0,0,0,0,0,0,0,0,0,0,0,0\nB02,225,507,98,27,3279,228,0,522,0,10,4,0,0,0,25,0,7995,8,336,6,54,0,0,0,9,4,0,0,0,0,259,0,12,65,0,29,0,0,0,0,163,0,16,0,0,0,0,22,106,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,71,0,0,0,0,0,0,0,0,0,0,0,0\nB03,196,360,246,38,2605,119,0,587,0,8,5,0,0,0,172,0,11619,16,370,11,0,3,0,0,13,0,0,0,0,0,206,5,0,83,8,67,0,0,0,0,130,0,5,0,0,0,0,27,136,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,120,0,0,0,0,0,0,0,0,0,0,0,0\nB04,437,922,636,61,4209,195,0,1051,0,9,5,6,0,0,274,0,14573,22,628,5,88,9,0,0,17,8,0,0,0,26,271,14,0,129,7,95,0,0,0,0,219,0,20,0,0,0,0,84,145,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,467,0,0,0,5,0,0,12,0,0,0,0,0\nB05,240,1159,187,26,2929,149,0,778,0,8,0,0,0,0,204,0,10918,26,473,0,20,0,0,7,10,8,0,0,0,0,193,9,0,209,0,96,0,0,2,0,244,3,19,0,0,0,0,131,125,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,532,0,0,0,12,0,0,0,0,0,0,0,0\nB06,211,2003,1380,168,2469,188,12,617,3,13,4,15,7,2,196,0,7802,16,383,47,94,0,0,22,7,43,25,0,0,84,223,33,0,244,5,112,0,0,0,0,204,8,28,8,0,0,0,69,105,0,5,0,0,8,0,0,0,0,0,0,0,0,0,0,0,639,0,0,0,9,0,0,0,0,0,0,0,0\nB07,231,2607,4129,694,2667,231,20,399,12,36,10,21,37,0,156,0,5611,47,453,76,93,112,0,16,21,187,53,0,0,267,196,73,0,106,0,74,0,0,0,24,169,8,37,6,6,0,5,82,118,0,7,0,0,0,0,0,0,4,0,0,0,0,0,0,0,399,0,0,0,8,0,0,0,0,0,0,0,0\nB08,228,2573,4942,604,2084,150,51,507,7,14,0,22,32,2,109,0,6026,28,269,58,156,94,0,31,7,193,21,0,0,264,220,11,4,212,0,67,4,0,0,65,113,3,26,0,0,0,0,81,108,0,0,5,0,0,0,0,0,0,0,13,0,0,0,0,0,468,0,0,0,21,0,0,7,0,0,0,0,0\nB09,606,3235,2950,1247,1922,696,52,487,16,21,20,84,12,0,107,0,1559,80,341,478,198,148,0,34,63,131,6,3,9,144,141,30,6,106,13,87,42,0,4,0,205,6,76,5,8,11,8,142,70,9,0,3,0,15,0,0,0,0,0,7,0,0,0,0,0,508,0,0,0,18,0,5,0,0,0,0,0,0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>样本元数据，描述各样本特征的文件，以制表符分隔各列，内容如下：</li>\n</ul>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">ID\tSamples\tLayer\tDepth\tLocation\tPosition\tSite\nB01\tB01\t0-1\t5\tRight\tDownstream\tB\nB02\tB02\t1-2\t5\tRight\tDownstream\tB\nB03\tB03\t2-3\t5\tRight\tDownstream\tB\nB04\tB04\t3-4\t5\tRight\tDownstream\tB\nB05\tB05\t4-5\t5\tRight\tDownstream\tB\nB06\tB06\t5-6\t10\tRight\tDownstream\tB\nB07\tB07\t6-7\t10\tRight\tDownstream\tB\nB08\tB08\t7-8\t10\tRight\tDownstream\tB\nB09\tB09\t8-9\t10\tRight\tDownstream\tB<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"代码\"><a class=\"markdownIt-Anchor\" href=\"#代码\"></a> 代码</h1>\n<p><strong>建议在 Rstudio 中运行。</strong></p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\"># 首先需要安装依赖包“amplicon”，如果没有安装“devtools”需要先安装，命令如下：</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">,</span> quietly<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">)</span>\n\nlibrary<span class=\"token punctuation\">(</span>devtools<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 安装依赖包“amplicon”，我对原作者的程序做了些许的优化，所以，可以从我的GitHub进行安装，命令如下：</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"amplicon\"</span><span class=\"token punctuation\">,</span> quietly<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"liaochenlanruo/amplicon\"</span><span class=\"token punctuation\">)</span>\nsuppressWarnings<span class=\"token punctuation\">(</span>suppressMessages<span class=\"token punctuation\">(</span>library<span class=\"token punctuation\">(</span>amplicon<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 设置工作目录，视自己的具体情况而定，工作目录中当包含输入文件：</span>\nsetwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"E:/Researches/Xiaqian/NGS/CleanData/ALL/细菌V6V8-1/Analysis_20210624/barplot\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 从文件读取元数据和物种注释</span>\nmetadata<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"sample-metadata.tsv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\ntaxonomy<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"taxonomy.tsv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># 绘制堆叠柱状图，颜色自定义。界水平物种组成表和元数据作为输入，分组列名为Group，显示前4个分类，其余归类为其他(Other)，按丰度排序。</span>\notutab1<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"level-1.csv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\notutab1<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otutab1<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#按照站位分组，通过“groupID”参数设置分组信息，这里我选择根据站位（Site）分组，用户当根据自己的实际情况来设置。</span>\n<span class=\"token punctuation\">(</span>ds<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab1<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nds2 <span class=\"token operator\">=</span> ds <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 出图</span>\nds2\n\n<span class=\"token comment\">#按照深度分组</span>\n<span class=\"token punctuation\">(</span>dd<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab1<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Depth\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ndd2 <span class=\"token operator\">=</span> dd <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ndd2\n\n<span class=\"token comment\"># 门水平物种组成表和元数据作为输入，分组列名为Group，显示前19个分类，按丰度排序</span>\notutab2<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"level-2.csv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\notutab2<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otutab2<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#按照站位分组</span>\n<span class=\"token punctuation\">(</span>ps<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab2<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nps2 <span class=\"token operator\">=</span> ps <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nps2\n\n<span class=\"token comment\">#按照深度分组</span>\n<span class=\"token punctuation\">(</span>pd<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab2<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Depth\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\npd2 <span class=\"token operator\">=</span> pd <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\npd2\n\n<span class=\"token comment\"># 纲水平物种组成表和元数据作为输入，分组列名为Group，显示前19个分类，按丰度排序</span>\notutab3<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"level-3.csv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">,</span> quote<span class=\"token operator\">=</span><span class=\"token string\">\"\\\"\"</span><span class=\"token punctuation\">)</span>\n\notutab3<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otutab3<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#按照站位分组</span>\n<span class=\"token punctuation\">(</span>cs<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab3<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ncs2 <span class=\"token operator\">=</span> cs <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ncs2\n\n<span class=\"token comment\">#按照深度分组</span>\n<span class=\"token punctuation\">(</span>cd<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab3<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Depth\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ncd2 <span class=\"token operator\">=</span> cd <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ncd2\n\n<span class=\"token comment\"># 属水平物种组成表和元数据作为输入，分组列名为Site，显示前19个分类，按丰度排序</span>\notutab6<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"level-6.csv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\notutab6<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otutab6<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#按照站位分组</span>\n<span class=\"token punctuation\">(</span>gs<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab6<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ngs2 <span class=\"token operator\">=</span> gs <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ngs2\n\n<span class=\"token comment\">#按照深度分组</span>\n<span class=\"token punctuation\">(</span>gd<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab6<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Depth\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ngd2 <span class=\"token operator\">=</span> gd <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ngd2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>最后的图可以在 Rstudio 中手动导出。</p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"><iframe src=\"//player.bilibili.com/player.html?aid=378319348&page=\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\"></iframe></div>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"可视化","path":"api/categories/可视化.json"}],"tags":[{"name":"SY179","path":"api/tags/SY179.json"},{"name":"R语言","path":"api/tags/R语言.json"},{"name":"扩增子","path":"api/tags/扩增子.json"}]},{"title":"扩增子可视化专题","slug":"扩增子可视化专题","date":"2021-09-15T03:23:28.000Z","updated":"2022-01-08T02:16:28.447Z","comments":true,"path":"api/articles/扩增子可视化专题.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>扩增子分析较常用的软件是 QIIME2，然而其生成的图并不美观，且无法下载，是不可能够达到发表要求的，因此需要我们通过其他方法将 QIIME2 生成的数据结果进行可视化。本文将记录相关的分析方法和示例。</p>\n<h1 id=\"准备数据\"><a class=\"markdownIt-Anchor\" href=\"#准备数据\"></a> 准备数据</h1>\n<ul>\n<li>特征表（Feature table），或者叫做 OTU 表，本教程中文件名为<strong> feature-table.tsv</strong>。该文件可由 QIIME2 生成，由 biome 格式转换而来。</li>\n</ul>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">\tF01\tF02\tF03\tF04\tF05\tF06\tH2_1\tH2_2\tH2_3\tH2_4\tH2_5\tH2_6\tI1_1\tI1_2\tI1_3\tI1_4\tI1_5\tI1_6\n3733c766539aba5e3e8f964a5ba39048\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t6.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n547715c94c5b0c7ba2049658f732397b\t0.0\t0.0\t0.0\t6.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n708c69ff1252447c0709333304cd9bed\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t5.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n344ee69a9e51ffac2811294d3f04833d\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t7.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\nd2e467b7867f49c25caaacdea5c7eb43\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t18.0\t0.0\t0.0\t0.0\t0.0\n4adc9b2b0866f620425d07d3ff7ca7e2\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t8.0\t0.0\t0.0\t0.0\t0.0\n0ffcdef70b9c1436126ba32d7a40d961\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t31.0\t0.0\t0.0\t0.0\n7170ce6c7520acc3c13189478aea54a8\t53.0\t0.0\t0.0\t0.0\t0.0\t0.0\t37.0\t25.0\t0.0\t0.0\t0.0\t0.0\t23.0\t21.0\t0.0\t0.0\t0.0\t0.0\nb624986630f3d33fbe0a21e66c46d1a5\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t9.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n78305c3f5955043aba7de952c78859c9\t0.0\t0.0\t22.0\t57.0\t73.0\t55.0\t0.0\t0.0\t0.0\t82.0\t73.0\t0.0\t0.0\t0.0\t43.0\t132.0\t82.0\t95.0\n60d9992b10f6dd4da4dc53826b7433f5\t0.0\t0.0\t0.0\t0.0\t45.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n33468988848349138af5cb1c23b550f2\t0.0\t2.0\t11.0\t12.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>样本元数据（Metadata），本教程中文件名为<strong> sample-metadata.tsv</strong>。该文件由分析者自己准备，用于描述各个样本的特征。</li>\n</ul>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">  ID\tSamples\tLayer\tDepth\tDepth2\tLocation\tPosition\tSite\nF01\tF01\t0-5\t5\t05 cmbsf\tTurn\tUpstream\tF\nF02\tF02\t5-9\t10\t10 cmbsf\tTurn\tUpstream\tF\nF03\tF03\t9-13\t15\t15 cmbsf\tTurn\tUpstream\tF\nF04\tF04\t13-17\t15\t15 cmbsf\tTurn\tUpstream\tF\nF05\tF05\t17-22\t20\t20 cmbsf\tTurn\tUpstream\tF\nF06\tF06\t22-26\t25\t25 cmbsf\tTurn\tUpstream\tF\nH2_1\tH2_1\t0-5\t5\t05 cmbsf\tLeft\tUpstream\tH2\nH2_2\tH2_2\t5-10\t10\t10 cmbsf\tLeft\tUpstream\tH2\nH2_3\tH2_3\t10-15\t15\t15 cmbsf\tLeft\tUpstream\tH2\nH2_4\tH2_4\t15-20\t20\t20 cmbsf\tLeft\tUpstream\tH2\nH2_5\tH2_5\t20-25\t25\t25 cmbsf\tLeft\tUpstream\tH2\nH2_6\tH2_6\t25-29\t30\t30 cmbsf\tLeft\tUpstream\tH2\nI1_1\tI1_1\t0-5\t5\t05 cmbsf\tLeft\tUpstream\tI1\nI1_2\tI1_2\t5-10\t10\t10 cmbsf\tLeft\tUpstream\tI1\nI1_3\tI1_3\t10-15\t15\t15 cmbsf\tLeft\tUpstream\tI1\nI1_4\tI1_4\t15-20\t20\t20 cmbsf\tLeft\tUpstream\tI1\nI1_5\tI1_5\t20-25\t25\t25 cmbsf\tLeft\tUpstream\tI1\nI1_6\tI1_6\t25-29\t30\t30 cmbsf\tLeft\tUpstream\tI1<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>分类信息，本教程中文件名为<strong> taxonomy.tsv</strong>。该文件可由 QIIME2 生成。</li>\n</ul>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">Feature ID\tTaxon\tConfidence\n9e24eb7a415db9a59586d17d0f49cbea\tArchaea;Asgardarchaeota;Lokiarchaeia\t0.9999999998216045\n2a1d71d9fca92f9b3fc8f3126db076d0\tBacteria;Proteobacteria;Gammaproteobacteria;Pseudomonadales;Pseudomonadaceae;Pseudomonas\t0.9881304182870394\n5d89868f1a1db1bc0b153eca96bbf7fd\tArchaea;Crenarchaeota;Nitrososphaeria;Nitrosopumilales;Nitrosopumilaceae\t0.9999999999859067\ncc957f2e853493d72875a6528ca83435\tArchaea;Crenarchaeota;Nitrososphaeria;Nitrosopumilales;Nitrosopumilaceae\t0.9999999999854506\n5179960239613d4c220e889075c6773e\tArchaea;Crenarchaeota;Nitrososphaeria;Nitrosopumilales;Nitrosopumilaceae;Candidatus Nitrosopumilus\t0.9558707678091154\nd62ab321b324b106e11961e79384f974\tBacteria;Methylomirabilota;Methylomirabilia;Methylomirabilales;Methylomirabilaceae;wb1-A12\t0.9999999975860316\n920aa9728ffb783cbc5721932cadda36\tBacteria;Aerophobota;Aerophobia;Aerophobales;uncultured bacterium\t0.9999939600150409\nb5edcefd9280528ee377cb70dea8a6a7\tArchaea;Asgardarchaeota;Lokiarchaeia;uncultured archaeon\t0.99744406884555\n43b02d567fe419b94ad063081c7bba58\tBacteria;Planctomycetota;Brocadiae;Brocadiales;Scalinduaceae;Candidatus Scalindua;uncultured bacterium\t0.9999941829048367\n0f1be1121dd04bc63b5ec4be0efc09b8\tArchaea;Asgardarchaeota;Lokiarchaeia;uncultured archaeon\t0.7884239553020901\n430d9115ca79bad01227bcc9c7694cf1\tBacteria;Proteobacteria;Gammaproteobacteria;Xanthomonadales;Xanthomonadaceae;Thermomonas;uncultured bacterium\t0.7413321650122459\n0bf08973da329747d913d5c261f91944\tBacteria;Aerophobota;Aerophobia;Aerophobales\t1.0000000000000024<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>进化树，本教程中文件名为<strong> tree.nwk</strong>。该文件可由 QIIME2 生成，Newick 格式，是用代表序列构建的系统发育树。</li>\n</ul>\n<hr />\n<h1 id=\"alpha-diversity\"><a class=\"markdownIt-Anchor\" href=\"#alpha-diversity\"></a> Alpha diversity</h1>\n<h2 id=\"shannon-richness-simpson-chao1-ace-pielou-pd_whole_tree指数的计算与可视化\"><a class=\"markdownIt-Anchor\" href=\"#shannon-richness-simpson-chao1-ace-pielou-pd_whole_tree指数的计算与可视化\"></a> Shannon、Richness、Simpson、Chao1、ACE、Pielou、PD_whole_tree 指数的计算与可视化</h2>\n<h3 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h3>\n<ul>\n<li>feature-table.tsv</li>\n<li>sample-metadata.tsv</li>\n</ul>\n<h3 id=\"第一步计算多样性\"><a class=\"markdownIt-Anchor\" href=\"#第一步计算多样性\"></a> 第一步：计算多样性</h3>\n<p>将如下代码保存到文件”compute_alpha.R“中，并将程序与输入文件放在同一目录下。在终端中运行命令”Rscript compute_alpha.R“，得到输出文件”alpha.txt“。</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\">#!/usr/bin/env R</span>\n<span class=\"token comment\">#定义函数</span>\nlibrary<span class=\"token punctuation\">(</span>picante<span class=\"token punctuation\">)</span>       <span class=\"token comment\">#picante 包加载时默认同时加载 vegan</span>\n \nalpha <span class=\"token operator\">&lt;-</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> tree <span class=\"token operator\">=</span> <span class=\"token keyword\">NULL</span><span class=\"token punctuation\">,</span> base <span class=\"token operator\">=</span> exp<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n        est <span class=\"token operator\">&lt;-</span> estimateR<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        Richness <span class=\"token operator\">&lt;-</span> est<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">]</span>\n        Chao1 <span class=\"token operator\">&lt;-</span> est<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">]</span>\n        ACE <span class=\"token operator\">&lt;-</span> est<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">]</span>\n        Shannon <span class=\"token operator\">&lt;-</span> diversity<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">'shannon'</span><span class=\"token punctuation\">,</span> base <span class=\"token operator\">=</span> base<span class=\"token punctuation\">)</span>\n        Simpson <span class=\"token operator\">&lt;-</span> diversity<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">'simpson'</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\">#Gini-Simpson 指数</span>\n        Pielou <span class=\"token operator\">&lt;-</span> Shannon <span class=\"token operator\">/</span> log<span class=\"token punctuation\">(</span>Richness<span class=\"token punctuation\">,</span> base<span class=\"token punctuation\">)</span>\n        goods_coverage <span class=\"token operator\">&lt;-</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> rowSums<span class=\"token punctuation\">(</span>x <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> rowSums<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        result <span class=\"token operator\">&lt;-</span> data.frame<span class=\"token punctuation\">(</span>Richness<span class=\"token punctuation\">,</span> Shannon<span class=\"token punctuation\">,</span> Simpson<span class=\"token punctuation\">,</span> Pielou<span class=\"token punctuation\">,</span> Chao1<span class=\"token punctuation\">,</span> ACE<span class=\"token punctuation\">,</span> goods_coverage<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>is.null<span class=\"token punctuation\">(</span>tree<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n                PD_whole_tree <span class=\"token operator\">&lt;-</span> pd<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> tree<span class=\"token punctuation\">,</span> include.root <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n                names<span class=\"token punctuation\">(</span>PD_whole_tree<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;-</span> <span class=\"token string\">'PD_whole_tree'</span>\n                result <span class=\"token operator\">&lt;-</span> cbind<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">,</span> PD_whole_tree<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">&#125;</span>\n        result\n<span class=\"token punctuation\">&#125;</span>\n \n<span class=\"token comment\">#现在直接使用定义好的命令 alpha()，一步得到多种 Alpha 多样性指数</span>\n<span class=\"token comment\">#加载 OTU 丰度表和进化树文件</span>\notu <span class=\"token operator\">&lt;-</span> read.delim<span class=\"token punctuation\">(</span><span class=\"token string\">'feature-table.tsv'</span><span class=\"token punctuation\">,</span> row.names <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep <span class=\"token operator\">=</span> <span class=\"token string\">'\\t'</span><span class=\"token punctuation\">,</span> stringsAsFactors <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">,</span> check.names <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\notu <span class=\"token operator\">&lt;-</span> t<span class=\"token punctuation\">(</span>otu<span class=\"token punctuation\">)</span>\ntree <span class=\"token operator\">&lt;-</span> read.tree<span class=\"token punctuation\">(</span><span class=\"token string\">'tree.nwk'</span><span class=\"token punctuation\">)</span>\n \n<span class=\"token comment\">#不包含谱系多样性，无需指定进化树；Shannon 公式的 log 底数我们使用 2</span>\n<span class=\"token comment\">##alpha_all &lt;- alpha(otu, base = 2)</span>\n<span class=\"token comment\">#包含谱系多样性时，指定进化树文件；Shannon 公式的 log 底数我们使用 2</span>\nalpha_all <span class=\"token operator\">&lt;-</span> alpha<span class=\"token punctuation\">(</span>otu<span class=\"token punctuation\">,</span> tree<span class=\"token punctuation\">,</span> base <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n \n<span class=\"token comment\">#输出保存在本地</span>\nwrite.table<span class=\"token punctuation\">(</span>alpha_all<span class=\"token punctuation\">,</span> <span class=\"token string\">'alpha.txt'</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> quote <span class=\"token operator\">=</span> <span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"第二步制图\"><a class=\"markdownIt-Anchor\" href=\"#第二步制图\"></a> 第二步：制图</h3>\n<p>这一步需要在 Rstudio 中运行如下命令，在终端里直接运行会报错（莫名其妙），最终输出 7 个 PDF 图形文件。</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\"><span class=\"token comment\">#!/usr/bin/env R</span>\n<span class=\"token comment\"># 基于github安装包，需要devtools，检测是否存在，不存在则安装</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">,</span> quietly <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 加载github包安装工具</span>\nlibrary<span class=\"token punctuation\">(</span>devtools<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 检测amplicon包是否安装，没有从源码安装</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"amplicon\"</span><span class=\"token punctuation\">,</span> quietly <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"liaochenlanruo/amplicon\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 提示升级，选择3 None不升级；升级会容易出现报错</span>\n\n<span class=\"token comment\"># library加载包，suppress不显示消息和警告信息</span>\nsuppressWarnings<span class=\"token punctuation\">(</span>suppressMessages<span class=\"token punctuation\">(</span>library<span class=\"token punctuation\">(</span>amplicon<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 设置工作目录，根据实际情况设定</span>\nsetwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"用户自己的工作目录\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 读取元数据，参数指定包括标题行(TRUE)，列名为1列，制表符分隔，无注释行，不转换为因子类型</span>\nmetadata <span class=\"token operator\">=</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"sample-metadata.tsv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors <span class=\"token operator\">=</span> F<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 读取第一步中vegan计算的6种alpha多样性指数</span>\n<span class=\"token comment\">#alpha_div = read.table(\"alpha.txt\", header=T, row.names=1, sep=\"\\t\", comment.char=\"\")</span>\nalpha_div <span class=\"token operator\">&lt;-</span> read.delim<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha.txt\"</span><span class=\"token punctuation\">,</span> quote<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span><span class=\"token boolean\">FALSE</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 绘制各组香农指数分布，外层()可对保存的图形同时预览</span>\n<span class=\"token punctuation\">(</span>p1 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"Shannon\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">##物种丰富度 Richness 指数</span>\n<span class=\"token punctuation\">(</span>p2 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"Richness\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#Gini-Simpson 指数（我们平时常用的 Simpson 指数即为 Gini-Simpson 指数）</span>\n<span class=\"token punctuation\">(</span>p3 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"Simpson\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#Chao1 指数</span>\n<span class=\"token punctuation\">(</span>p4 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"Chao1\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#ACE 指数</span>\n<span class=\"token punctuation\">(</span>p5 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"ACE\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#Shannon 均匀度（Pielou 均匀度）</span>\n<span class=\"token punctuation\">(</span>p6 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"Pielou\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">##谱系多样性</span>\n<span class=\"token punctuation\">(</span>p7 <span class=\"token operator\">=</span> alpha_boxplot<span class=\"token punctuation\">(</span>alpha_div<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> <span class=\"token string\">\"PD_whole_tree\"</span><span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID <span class=\"token operator\">=</span> <span class=\"token string\">\"Depth2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># 保存图片，指定图片为pdf格式方便后期修改，图片宽89毫米，高75毫米</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_shannon.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p1<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_Richness.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p2<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_Simpson.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p3<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_Chao1.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p4<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_ACE.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p5<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_Pielou.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p6<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span>\nggsave<span class=\"token punctuation\">(</span>paste0<span class=\"token punctuation\">(</span><span class=\"token string\">\"alpha_boxplot_PD_whole_tree.pdf\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> p7<span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">89</span><span class=\"token punctuation\">,</span> height<span class=\"token operator\">=</span><span class=\"token number\">75</span><span class=\"token punctuation\">,</span> units<span class=\"token operator\">=</span><span class=\"token string\">\"mm\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"演示视频\"><a class=\"markdownIt-Anchor\" href=\"#演示视频\"></a> 演示视频</h3>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"><iframe src=\"//player.bilibili.com/player.html?aid=335536606&page=\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\"></iframe></div>\n<hr />\n<h2 id=\"物种多样性条形图的绘制\"><a class=\"markdownIt-Anchor\" href=\"#物种多样性条形图的绘制\"></a> 物种多样性条形图的绘制</h2>\n<h3 id=\"输入文件-2\"><a class=\"markdownIt-Anchor\" href=\"#输入文件-2\"></a> 输入文件</h3>\n<ul>\n<li>处理后的 Feature Table</li>\n</ul>\n<p>从 QIIME2 可视化网站上下载的各 level 的物种丰度表，此处以 level-2（Phylum 水平）为例，命名为 “level-2.csv”。该文件可以用 excel 或 WPS 打开，然后复制所有内容至一个新建的名字为 “level-2.txt” 的文本文档中，删除无关的行或列（如路径），只保留丰度数据，并保存。格式如下：</p>\n<pre class=\"line-numbers language-tex\" data-language=\"tex\"><code class=\"language-tex\">index\tspecies1\tspecies2\tspecies3\tspecies4\nSample1\t0\t8152\t11\t65\nSample2\t12\t97\t1097\t1315\n...\nSamplex\t15\t46\t2928\t1011<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>sample-metadata.tsv</li>\n<li>taxonomy.tsv</li>\n</ul>\n<h3 id=\"绘图\"><a class=\"markdownIt-Anchor\" href=\"#绘图\"></a> 绘图</h3>\n<p>以下代码在 Rstudio 中逐步输入运行</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"用户自己的路径\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">,</span> quietly<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install.packages<span class=\"token punctuation\">(</span><span class=\"token string\">\"devtools\"</span><span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span>devtools<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>requireNamespace<span class=\"token punctuation\">(</span><span class=\"token string\">\"amplicon\"</span><span class=\"token punctuation\">,</span> quietly<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    install_github<span class=\"token punctuation\">(</span><span class=\"token string\">\"microbiota/amplicon\"</span><span class=\"token punctuation\">)</span>\nsuppressWarnings<span class=\"token punctuation\">(</span>suppressMessages<span class=\"token punctuation\">(</span>library<span class=\"token punctuation\">(</span>amplicon<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 从文件读取元数据，特征表和物种注释</span>\nmetadata<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"sample-metadata.tsv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\ntaxonomy<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"taxonomy.tsv\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\notutab2<span class=\"token operator\">=</span>read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"level-2.txt\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span> row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> comment.char<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> stringsAsFactors<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#堆叠柱状图。以分组均值绘制，展示丰度最高的19个门，其余归类为其他(Other)</span>\n<span class=\"token comment\"># 门水平物种组成表和元数据作为输入，分组列名为Group，默认显示前19个分类，按丰度排序</span>\notutab2<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otutab2<span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">(</span>ps<span class=\"token operator\">=</span>tax_stackplot<span class=\"token punctuation\">(</span>otutab2<span class=\"token punctuation\">,</span> metadata<span class=\"token punctuation\">,</span> groupID<span class=\"token operator\">=</span><span class=\"token string\">\"Site\"</span><span class=\"token punctuation\">,</span> topN<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> style<span class=\"token operator\">=</span><span class=\"token string\">\"sample\"</span><span class=\"token punctuation\">,</span> sorted<span class=\"token operator\">=</span><span class=\"token string\">\"abundance\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nps2 <span class=\"token operator\">=</span> ps <span class=\"token operator\">+</span> scale_fill_manual<span class=\"token punctuation\">(</span>values <span class=\"token operator\">=</span> rev<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">(</span><span class=\"token string\">\"#1f77b4\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#aec7e8\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff7f0e\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ffbb78\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#2ca02c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#98df8a\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#d62728\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#ff9896\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9467bd\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c5b0d5\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#8c564b\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c49c94\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#e377c2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#f7b6d2\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#7f7f7f\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#c7c7c7\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#bcbd22\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#dbdb8d\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#17becf\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"#9edae5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> theme<span class=\"token punctuation\">(</span>axis.text.x <span class=\"token operator\">=</span> element_text<span class=\"token punctuation\">(</span>angle <span class=\"token operator\">=</span> <span class=\"token number\">90</span><span class=\"token punctuation\">,</span> hjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> vjust <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nps2<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"演示视频-2\"><a class=\"markdownIt-Anchor\" href=\"#演示视频-2\"></a> 演示视频</h3>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"><iframe src=\"//player.bilibili.com/player.html?aid=633107204&page=\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\"></iframe></div>\n<hr />\n<h1 id=\"beta多样性\"><a class=\"markdownIt-Anchor\" href=\"#beta多样性\"></a> Beta 多样性</h1>\n<h2 id=\"nmds分析及可视化\"><a class=\"markdownIt-Anchor\" href=\"#nmds分析及可视化\"></a> NMDS 分析及可视化</h2>\n<h3 id=\"输入文件-3\"><a class=\"markdownIt-Anchor\" href=\"#输入文件-3\"></a> 输入文件</h3>\n<ul>\n<li>feature-table.tsv</li>\n<li>sample-metadata.tsv</li>\n</ul>\n<h3 id=\"分析过程\"><a class=\"markdownIt-Anchor\" href=\"#分析过程\"></a> 分析过程</h3>\n<p>在 Rstudio 中运行如下代码：</p>\n<pre class=\"line-numbers language-r\" data-language=\"r\"><code class=\"language-r\">setwd<span class=\"token punctuation\">(</span><span class=\"token string\">\"用户的工作目录\"</span><span class=\"token punctuation\">)</span>\nlibrary<span class=\"token punctuation\">(</span><span class=\"token string\">\"vegan\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 读取数据，一份otu.table文件和一份分组信息文件</span>\notu <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"feature-table.tsv\"</span><span class=\"token punctuation\">,</span>row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span>sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span>check.names<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\ndesign <span class=\"token operator\">&lt;-</span> read.table<span class=\"token punctuation\">(</span><span class=\"token string\">\"sample-metadata.tsv\"</span><span class=\"token punctuation\">,</span>header<span class=\"token operator\">=</span>T<span class=\"token punctuation\">,</span>sep<span class=\"token operator\">=</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span>row.names<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>check.names<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 数据调整为列名是OTU，行名是样本名</span>\notu<span class=\"token operator\">=</span>t<span class=\"token punctuation\">(</span>otu<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 标准化，当然method有很多，可以通过?decostand查看其它method</span>\nvare.hel<span class=\"token operator\">&lt;-</span>decostand<span class=\"token punctuation\">(</span>otu<span class=\"token punctuation\">,</span>method<span class=\"token operator\">=</span><span class=\"token string\">\"hellinger\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 计算Bray-curtis距离矩阵</span>\nvare.dis <span class=\"token operator\">&lt;-</span> vegdist<span class=\"token punctuation\">(</span>vare.hel<span class=\"token punctuation\">,</span>method<span class=\"token operator\">=</span><span class=\"token string\">\"bray\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 使用NMDS的方法</span>\nvare.mds <span class=\"token operator\">&lt;-</span> metaMDS<span class=\"token punctuation\">(</span>vare.hel<span class=\"token punctuation\">,</span>distance <span class=\"token operator\">=</span> <span class=\"token string\">\"bray\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 首先提取前两轴坐标</span>\npoint <span class=\"token operator\">=</span> scores<span class=\"token punctuation\">(</span>vare.mds<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 将分组文件和得分文件合并</span>\nindex <span class=\"token operator\">=</span> merge<span class=\"token punctuation\">(</span>design<span class=\"token punctuation\">,</span> point<span class=\"token punctuation\">,</span>by<span class=\"token operator\">=</span><span class=\"token string\">\"row.names\"</span><span class=\"token punctuation\">,</span>all<span class=\"token operator\">=</span>F<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 查看Stress值</span>\n<span class=\"token comment\"># Stress值是反映模型合适程度的指标，NMDS会多次打乱数据计算Stress值，直到找到最合适的模型，也就是最低的Stress值；理想状况下，Stress值为0，一般Stress值低于0.1较为合理。</span>\nvare.mds\n\n<span class=\"token comment\"># Stress:     0.07498046 #记住这个数字，后面会打印在图中</span>\n\n<span class=\"token comment\"># 显着性检验；anosim本质是基于排名的算法，更加适合NMDS，这里基于元数据中的深度（Depth）计算</span>\nanosim.result<span class=\"token operator\">&lt;-</span>anosim<span class=\"token punctuation\">(</span>vare.dis<span class=\"token punctuation\">,</span> design<span class=\"token operator\">$</span>Depth<span class=\"token punctuation\">,</span>permutations <span class=\"token operator\">=</span><span class=\"token number\">999</span><span class=\"token punctuation\">)</span>\n\nsummary<span class=\"token punctuation\">(</span>anosim.result<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ANOSIM statistic R: 0.8036 #记住这个数字，后面会打印在图中</span>\n<span class=\"token comment\">#       Significance: 0.001 #记住这个数字，后面会打印在图中</span>\n\n<span class=\"token comment\"># tiff输出图形，适合大部分出版刊物，入门级别分辩率300,18*14的长宽；</span>\n<span class=\"token comment\">#tiff(file=\"beta_bray_NMDS.tiff\", res = 300, compression =\"none\", width=180,height=140,units= \"mm\")</span>\n\n<span class=\"token comment\"># 在这里我选择输出为PDF，后续可以进一步的编辑</span>\npdf<span class=\"token punctuation\">(</span>file<span class=\"token operator\">=</span><span class=\"token string\">\"beta_bray_NMDS.pdf\"</span><span class=\"token punctuation\">,</span> width<span class=\"token operator\">=</span><span class=\"token number\">180</span><span class=\"token punctuation\">,</span>height<span class=\"token operator\">=</span><span class=\"token number\">140</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#开始出图，代码如下：</span>\nlibrary<span class=\"token punctuation\">(</span><span class=\"token string\">\"ggplot2\"</span><span class=\"token punctuation\">)</span>\n\np <span class=\"token operator\">=</span> ggplot<span class=\"token punctuation\">(</span>index<span class=\"token punctuation\">,</span> aes<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>NMDS1<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>NMDS2<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span>as.factor<span class=\"token punctuation\">(</span>Depth<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n      geom_point<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span>\n     <span class=\"token comment\">#scale_colour_manual(values = c(\"red\",\"blue\", \"green\")) +#这行代码是用于自定义颜色的，有几个组就用几个颜色，少于3个组的话不支持自定义</span>\n     labs<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>paste<span class=\"token punctuation\">(</span><span class=\"token string\">\"NMDS1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>paste<span class=\"token punctuation\">(</span><span class=\"token string\">\"NMDS2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> title<span class=\"token operator\">=</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#置信区间当然要加上，有三种方式，线条类型也可以更改。将上面得到的三个指标在图中更换Stress，R，p。</span>\n\np<span class=\"token operator\">+</span>stat_ellipse<span class=\"token punctuation\">(</span>type <span class=\"token operator\">=</span> <span class=\"token string\">\"t\"</span><span class=\"token punctuation\">,</span> linetype <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> level <span class=\"token operator\">=</span> <span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span> show.legend <span class=\"token operator\">=</span> <span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    annotate<span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>x<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">2.5</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1.25</span><span class=\"token punctuation\">,</span>parse<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"'R: '*0.8036\"</span><span class=\"token punctuation\">,</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"serif\"</span><span class=\"token punctuation\">,</span>fontface<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>colour<span class=\"token operator\">=</span><span class=\"token string\">\"darkred\"</span><span class=\"token punctuation\">,</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    annotate<span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>x<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">2.5</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1.35</span><span class=\"token punctuation\">,</span>parse<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"'p: '*0.001\"</span><span class=\"token punctuation\">,</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"serif\"</span><span class=\"token punctuation\">,</span>fontface<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>colour<span class=\"token operator\">=</span><span class=\"token string\">\"darkred\"</span><span class=\"token punctuation\">,</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n    annotate<span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>x<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">2.5</span><span class=\"token punctuation\">,</span>y<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1.45</span><span class=\"token punctuation\">,</span>parse<span class=\"token operator\">=</span><span class=\"token boolean\">TRUE</span><span class=\"token punctuation\">,</span>size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"'Stress: '*0.075\"</span><span class=\"token punctuation\">,</span>family<span class=\"token operator\">=</span><span class=\"token string\">\"serif\"</span><span class=\"token punctuation\">,</span>fontface<span class=\"token operator\">=</span><span class=\"token string\">\"italic\"</span><span class=\"token punctuation\">,</span>colour<span class=\"token operator\">=</span><span class=\"token string\">\"darkred\"</span><span class=\"token punctuation\">,</span>hjust <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> geom_point<span class=\"token punctuation\">(</span>aes<span class=\"token punctuation\">(</span>x<span class=\"token operator\">=</span>NMDS1<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>NMDS2<span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span>Site<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span>\n\t<span class=\"token comment\">#scale_shape_manual(values = c(15, 19, 17))+#这行代码是用于自定义形状的，有几个组就用几个形状，少于3个组的话不支持自定义</span>\n    theme_classic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ndev.off<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h3 id=\"演示视频-3\"><a class=\"markdownIt-Anchor\" href=\"#演示视频-3\"></a> 演示视频</h3>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"><iframe src=\"//player.bilibili.com/player.html?aid=548008577&page=\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\"></iframe></div>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li><a href=\"https://github.com/YongxinLiu/MicrobiomeStatPlot\">https://github.com/YongxinLiu/MicrobiomeStatPlot</a></li>\n</ul>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"可视化","path":"api/categories/可视化.json"}],"tags":[{"name":"SY179","path":"api/tags/SY179.json"},{"name":"R语言","path":"api/tags/R语言.json"},{"name":"扩增子","path":"api/tags/扩增子.json"}]},{"title":"构建样本vs基因矩阵","slug":"构建样本vs基因矩阵","date":"2021-09-29T04:17:04.000Z","updated":"2022-01-08T02:16:28.453Z","comments":true,"path":"api/articles/构建样本vs基因矩阵.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg","content":"<p>承接上一篇文章<a href=\"https://liaochenlanruo.github.io/post/e922.html\"> Swissprot 数据库的本地化与序列比对</a>。</p>\n<h1 id=\"应用场景\"><a class=\"markdownIt-Anchor\" href=\"#应用场景\"></a> 应用场景</h1>\n<p>分别预测了多个样本 / 基因组中某些基因的存在与否即数量，需要将这些样本 / 基因组中的基因数量情况合并在一起构建矩阵，此时，手动是非常困难和无趣的。又该请出 Perl 神了。</p>\n<h1 id=\"输入文件\"><a class=\"markdownIt-Anchor\" href=\"#输入文件\"></a> 输入文件</h1>\n<p>在上一篇文章中，我们将多个宏基因组蛋白序列与 SwissProt 数据库做了比对，并根据比对到的 ID 与其他数据库做了 mapping，得到了多个输出文件，保存为 “sample.mapped”。其中 “sample” 可以是样本名，也可以是基因组名，它将出现在最后构建的矩阵中。这些文件既可作为本例的输入文件，其内容大概是下面酱紫的，各列以制表符分隔。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"输入文件长酱紫\" /></p>\n<h1 id=\"写脚本\"><a class=\"markdownIt-Anchor\" href=\"#写脚本\"></a> 写脚本</h1>\n<p>上图是其中一个文件的内容的一部分，接下来我们将提取第 19 列的 GO number 来构建矩阵。将以下代码保存到文件中，命名为 “get_matrix.pl”。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu hualin</span>\n<span class=\"token comment\"># Date: Sep 29, 2021</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@files</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.mapped\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@files</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+).mapped/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sample</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token variable\">$samples</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$1</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$_\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 忽略第一行，如果第一行不是标题行，请将该行注释掉</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/.+\\; /</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@terms</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\; /</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><span class=\"token comment\"># 18代表文件的第19列，若想提取其他列，可以自行修改该数字为“列号-1”，因为第一列代号为0</span>\n\t\t\t<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@terms</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$_</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">elsif</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=~</span><span class=\"token regex\">/\\S+/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$ids</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$sample</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">18</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Matrix.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@samples</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%samples</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@ids</span> <span class=\"token operator\">=</span> sort keys <span class=\"token variable\">%ids</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> join<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">@samples</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$i</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$i</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@ids</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$i</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">my</span> <span class=\"token variable\">$j</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token variable\">$j</span><span class=\"token operator\">&lt;</span><span class=\"token variable\">@samples</span> <span class=\"token punctuation\">;</span><span class=\"token variable\">$j</span><span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$samples</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$j</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$ids</span><span class=\"token punctuation\">[</span><span class=\"token variable\">$i</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t$hash&#123;$samples[$j]&#125;&#123;$ids[$i]&#125;\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\t0\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose OUT<span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h1 id=\"构建矩阵\"><a class=\"markdownIt-Anchor\" href=\"#构建矩阵\"></a> 构建矩阵</h1>\n<p>将脚本与输入文件放在同一目录下，在终端或 Windows 命令行中运行如下命令，得到的 “Matrix.txt” 即为输出文件。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl get_matrix.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/412a_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"输出文件长酱紫\" /></p>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “412a” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"SY179","path":"api/tags/SY179.json"},{"name":"perl","path":"api/tags/perl.json"},{"name":"编程","path":"api/tags/编程.json"}]},{"title":"SignalP+TMHMM预测微生物分泌蛋白","slug":"SignalP-TMHMM预测微生物分泌蛋白","date":"2021-10-14T01:09:45.000Z","updated":"2022-01-08T02:16:28.415Z","comments":true,"path":"api/articles/SignalP-TMHMM预测微生物分泌蛋白.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg","content":"<p>Subtitle: Predict Secretory Protein in microbes with SignalP and TMHMM</p>\n<p><ruby>分泌蛋白<rt>Secretory Protein</rt></ruby>是指在细胞内合成后，分泌到细胞外起作用的蛋白质。分泌蛋白的 N 端有一般由 15～30 个氨基酸组成的信号肽。信号肽是引导新合成的蛋白质向分泌通路转移的短（长度 5-30 个氨基酸）肽链。常指新合成多肽链中用于指导蛋白质的跨膜转移（定位）的 N - 末端的氨基酸序列（有时不一定在 N 端）。<u>使用<strong> SignalP</strong> 注释蛋白序列是否含有信号肽结构，使用<strong> TMHMM</strong> 注释蛋白序列是否含有跨膜结构，最终筛选出含有信号肽结构并且不含跨膜结构的蛋白为分泌蛋白</u>。</p>\n<h1 id=\"ruby软件-rtsoftwarertruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件-rtsoftwarertruby\"></a> <ruby>软件 <rt>Software</rt></ruby></h1>\n<ul>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\">SignalP V6.0</a></p>\n</li>\n<li>\n<p>SignalP 6.0 <ruby>预测来自古细菌、革兰氏阳性细菌、革兰氏阴性细菌和真核生物的蛋白质中存在的信号肽<rt>predicts signal peptides and the location of their cleavage sites in proteins from Archaea,  Gram-positive Bacteria,</rt></ruby><ruby>及其切割位点的位置。<rt> Gram-negative Bacteria and Eukarya.</rt></ruby><ruby>在细菌和古细菌中，SignalP 6.0 可以区分五种类型的信号肽：<rt>In Bacteria and Archaea, SignalP 6.0 can discriminate between five types of signal peptides:</rt></ruby></p>\n<ul>\n<li>\n<p>Sec/SPI：<ruby>由 Sec 转座转运，并由信号肽酶 I (Lep) 切割的 “标准” 分泌信号肽；<rt>&quot;Standard&quot; secretory signal peptides transported by Sec translocon and cleaved by Signal Peptidase I (Lep).</rt></ruby></p>\n</li>\n<li>\n<p>Sec/SPII：<ruby>由 Sec 转座子运输，并由信号肽酶 II (Lsp) 切割的脂蛋白信号肽；<rt>lipoprotein signal peptides transported by the Sec translocon and cleaved by Signal Peptidase II (Lsp).</rt></ruby></p>\n</li>\n<li>\n<p>Tat/SPI：<ruby>由 Tat 转座子转运，并由信号肽酶 I (Lep) 切割的 Tat 信号肽；<rt>Tat signal peptides transported by the Tat translocon and cleaved by Signal Peptidase I (Lep).</rt></ruby></p>\n</li>\n<li>\n<p>Tat/SPII：<ruby>由 Tat 转位子转运，并由信号肽酶 II (Lsp) 切割的 Tat 脂蛋白信号肽；<rt>Tat lipoprotein signal peptides transported by Tat translocon &amp; cleaved by Signal Peptidase II (Lsp).</rt></ruby></p>\n</li>\n<li>\n<p>Sec/SPIII：<ruby>由 Sec 转位子运输，并由信号肽酶 III (PilD/PibD) 切割的菌毛蛋白和菌毛蛋白样信号肽。<rt>Pilin &amp; pilin-like signal peptides transported by Sec translocon &amp; cleaved by Signal Peptidase III (PilD/PibD).</rt></ruby></p>\n</li>\n<li>\n<p><ruby>此外，SignalP 6.0 预测信号肽的区域。<rt>Additionally, SignalP 6.0 predicts the regions of signal peptides.</rt></ruby><ruby>根据类型，预测 n、h 和 c 区域以及其他显着特征的位置。<rt> Depending on the type, the positions of n-, h- and c-regions as well as of other distinctive features are predicted.</rt></ruby></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?TMHMM-2.0\">TMHMM V2.0c</a></p>\n<ul>\n<li>用于预测蛋白质中的跨膜螺旋。</li>\n</ul>\n</li>\n<li>\n<p>Python</p>\n</li>\n</ul>\n<p>SignalP 和 TMHMM 对于学术用户免费，但是需要填写相关信息和邮箱，以接收下载链接（4h 有效时间）。</p>\n<h1 id=\"ruby软件安装-rtinstallation-of-softwaresrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件安装-rtinstallation-of-softwaresrtruby\"></a> <ruby>软件安装 <rt>Installation of Softwares</rt></ruby></h1>\n<h2 id=\"安装signalp-60\"><a class=\"markdownIt-Anchor\" href=\"#安装signalp-60\"></a> 安装 SignalP 6.0</h2>\n<ul>\n<li>\n<p>下载</p>\n<p>访问<a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\"> SignalP V6.0</a> 网站，找到 “Download”，填写相关信息，获取下载链接，下载得到 “signalp-6.0.fast.tar.gz”。有两个模式可以选择 ——“slow_sequential” 和 “fast&quot;。前者 runs the full model sequentially, taking the same amount of RAM as  <code>fast</code>  but being 6 times slower；后者 uses a smaller model that approximates the performance of the full model, requiring a fraction of the resources and being significantly faste。本教程下载的是 fast 模式。</p>\n</li>\n<li>\n<p><ruby>安装 <rt>Installation</rt></ruby></p>\n<ul>\n<li>\n<p><ruby>安装依赖 <rt>Dependencies</rt></ruby></p>\n<ul>\n<li>\n<p>Python</p>\n</li>\n<li>\n<p>matplotlib&gt;3.3.2</p>\n</li>\n<li>\n<p>numpy&gt;1.19.2</p>\n</li>\n<li>\n<p>torch&gt;1.7.0</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> torch<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n</li>\n<li>\n<p>tqdm&gt;4.46.1</p>\n</li>\n</ul>\n</li>\n<li>\n<p>安装 SignalP 6.0</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 解压缩安装文件</span>\n<span class=\"token function\">tar</span> zxvf signalp-6.0.fast.tar.gz\n\n<span class=\"token comment\"># 进入解压后的软件目录，在终端运行</span>\npython setup.py <span class=\"token function\">install</span>\n\n<span class=\"token comment\"># 测试安装</span>\nsignalp6 --help<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装tmhmm-v20c\"><a class=\"markdownIt-Anchor\" href=\"#安装tmhmm-v20c\"></a> 安装 TMHMM V2.0c</h2>\n<ul>\n<li>\n<p>下载</p>\n<p>访问<a href=\"https://services.healthtech.dtu.dk/service.php?TMHMM-2.0\"> TMHMM V2.0c</a> 网站，找到 “Download”，填写相关信息，获取下载链接，下载得到 “tmhmm-2.0c.Linux.tar.gz”。</p>\n</li>\n<li>\n<p>安装</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 解压缩</span>\n<span class=\"token function\">tar</span> zxvf tmhmm-2.0c.Linux.tar.gz\n\n<span class=\"token comment\"># 进入解压后的目录</span>\n<span class=\"token builtin class-name\">cd</span> tmhmm-2.0c\n\n<span class=\"token comment\"># 获取当前路径，我的是“/home/liu/tools/tmhmm-2.0c/bin”</span>\n<span class=\"token builtin class-name\">pwd</span>\n\n<span class=\"token comment\"># 将该路径加入到系统的环境变量中，参考我之前的文章来（编辑~/.bashrc）https://liaochenlanruo.github.io/post/f6c9.html#%E6%B7%BB%E5%8A%A0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F</span>\n\n<span class=\"token comment\"># 修改bin目录下的tmhmm和tmhmmformat.pl的首行为“#!/usr/bin/perl”</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li>\n<p><font color=\"#FF0000\">运行错误</font></p>\n<p>运行软件时总报 <code>Segmentation fault (core dumped)</code>  错误，暂时无解。各位可以使用其<a href=\"http://www.cbs.dtu.dk/services/TMHMM/\">在线版</a>。</p>\n</li>\n</ul>\n<h1 id=\"ruby软件用法-rtusagertruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby软件用法-rtusagertruby\"></a> <ruby>软件用法 <rt>Usage</rt></ruby></h1>\n<h2 id=\"signalp-60\"><a class=\"markdownIt-Anchor\" href=\"#signalp-60\"></a> SignalP 6.0</h2>\n<h3 id=\"ruby预测-rtpredictionrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby预测-rtpredictionrtruby\"></a> <ruby>预测 <rt>Prediction</rt></ruby></h3>\n<p>A command takes the following form</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">signalp6 --fastafile /path/to/input.fasta --organism other --output_dir path/to/be/saved --format txt --mode fast<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>\n<p><code>fastafile</code>  <ruby>输入文件为 FASTA 格式的蛋白序列文件<rt>Specifies the fasta file with the sequences to be predicted.</rt></ruby>。</p>\n</li>\n<li>\n<p><code>organism</code>  is either  <code>other</code>  or  <code>Eukarya</code> . Specifying  <code>Eukarya</code>  triggers post-processing of the SP predictions to prevent spurious results (only predicts type Sec/SPI).</p>\n</li>\n<li>\n<p><code>format</code>  can take the values  <code>txt</code> ,  <code>png</code> ,  <code>eps</code> ,  <code>all</code> . It defines what output files are created for individual sequences.  <code>txt</code>  produces a tabular  <code>.gff</code>  file with the per-position predictions for each sequence.  <code>png</code> ,  <code>eps</code> ,  <code>all</code>  additionally produce probability plots in the requested format. For larger prediction jobs, plotting will slow down the processing speed significantly.</p>\n</li>\n<li>\n<p><code>mode</code>  is either  <code>fast</code> ,  <code>slow</code>  or  <code>slow-sequential</code> . Default is  <code>fast</code> , which uses a smaller model that approximates the performance of the full model, requiring a fraction of the resources and being significantly faster.  <code>slow</code>  runs the full model in parallel, which requires more than 14GB of RAM to be available.  <code>slow-sequential</code>  runs the full model sequentially, taking the same amount of RAM as  <code>fast</code>  but being 6 times slower. If the specified model is not installed, SignalP will abort with an error.</p>\n</li>\n</ul>\n<h3 id=\"ruby输出rt-outputsrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby输出rt-outputsrtruby\"></a> <ruby>输出<rt> Outputs</rt></ruby></h3>\n<ul>\n<li>\n<p>output_dir/output.gff3：仅包含含有信号肽的序列信息；</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_1.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"output.gff3\" /></p>\n</li>\n<li>\n<p>output_dir/prediction_results.txt：包含了输入文件中的所有序列（不重要）；</p>\n</li>\n<li>\n<p>output_dir/region_output.gff3：包含所有的信号肽区域信息。</p>\n<ul>\n<li>\n<p>n-region: The n-terminal region of the signal peptide. Reported for Sec/SPI, Sec/SPII, Tat/SPI and Tat/SPII. Labeled as N</p>\n</li>\n<li>\n<p>h-region: The center hydrophobic region of the signal peptide. Reported for Sec/SPI, Sec/SPII, Tat/SPI and Tat/SPII. Labeled as H</p>\n</li>\n<li>\n<p>c-region: The c-terminal region of the signal peptide, reported for Sec/SPI and Tat/SPI.</p>\n</li>\n<li>\n<p>Cysteine: The conserved cysteine in +1 of the cleavage site of Lipoproteins that is used for Lipidation. Labeled as c.</p>\n</li>\n<li>\n<p>Twin-arginine motif: The twin-arginine motif at the end of the n-region that is characteristic for Tat signal peptides. Labeled as R.</p>\n</li>\n<li>\n<p>Sec/SPIII: These signal peptides have no known region structure.</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"region_output.gff3\" /></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"批处理与结果优化\"><a class=\"markdownIt-Anchor\" href=\"#批处理与结果优化\"></a> 批处理与结果优化</h3>\n<p>脚本名：run_SignalP.pl</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: Oct 14, 2021</span>\n\n\nopen IDNOSEQ<span class=\"token punctuation\">,</span> <span class=\"token string\">\">IDNOSEQ.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@faa</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*.faa\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span>  <span class=\"token punctuation\">(</span><span class=\"token variable\">@faa</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$_</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(.+).faa/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".nodesc\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$sigseq</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".sigseq\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$outdir</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_signalp\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$out\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token regex\">/^(>\\S+)/</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$1</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token variable\">$_</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span> <span class=\"token operator\">=</span> idseq<span class=\"token punctuation\">(</span><span class=\"token variable\">$out</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"signalp6 --fastafile $out --organism other --output_dir $outdir --format txt --mode fast\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$gff</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$outdir</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/output.gff3\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span> <span class=\"token operator\">-z</span> <span class=\"token variable\">$gff</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\topen IN<span class=\"token punctuation\">,</span> <span class=\"token string\">\"$gff\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t\topen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$sigseq\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exists <span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t\t<span class=\"token keyword\">print</span> IDNOSEQ <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"\\t\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"$lines[0]\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">&#125;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t\tclose IN<span class=\"token punctuation\">;</span>\n\t\tclose OUT<span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"rm $out\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv $sigseq $outdir\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\nclose IDNOSEQ<span class=\"token punctuation\">;</span>\n\n\n<span class=\"token function\"><span class=\"token keyword\">sub</span> idseq</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token variable\">@_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>将 run_SignalP.pl 与后缀名为 “.faa” 的 FASTA 格式文件放在同一目录下，在终端中运行如下代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl run_SignalP.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"ruby结果解读rtoutput-interpretationrtruby\"><a class=\"markdownIt-Anchor\" href=\"#ruby结果解读rtoutput-interpretationrtruby\"></a> <ruby>结果解读<rt>Output interpretation</rt></ruby></h3>\n<p>* 代表输入文件的名字。</p>\n<ul>\n<li>\n<p>*_signalp/output.gff3：仅包含含有信号肽的序列信息；</p>\n</li>\n<li>\n<p>*_signalp/prediction_results.txt：包含了输入文件中的所有序列（不重要）；</p>\n</li>\n<li>\n<p>*_signalp/region_output.gff3：包含所有的信号肽区域信息；</p>\n</li>\n<li>\n<p><strong>*_signalp/*.sigseq</strong>：存储所有信号肽的氨基酸序列文件，可用作 TMHMM 的输入文件。</p>\n</li>\n</ul>\n<h2 id=\"tmhmm\"><a class=\"markdownIt-Anchor\" href=\"#tmhmm\"></a> TMHMM</h2>\n<h3 id=\"预测\"><a class=\"markdownIt-Anchor\" href=\"#预测\"></a> 预测</h3>\n<p>离线版总是报错，找不出原因，因此使用网页服务器进行，输入文件为上述生成的 “*_signalp/*.sigseq”，将其上传至网页版<a href=\"http://www.cbs.dtu.dk/services/TMHMM/\"> TMHMM</a>，提交任务，等待结果即可。</p>\n<h3 id=\"结果展示\"><a class=\"markdownIt-Anchor\" href=\"#结果展示\"></a> 结果展示</h3>\n<p>TMHMM 可以输出多种格式的结果文件，具体请参考其<a href=\"http://www.cbs.dtu.dk/services/TMHMM-2.0/TMHMM2.0.guide.html#output\">官方说明</a>。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.5.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_2.5.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"在TMHMM网站提交任务\" /></p>\n<ul>\n<li>\n<p><strong>Long output format</strong></p>\n<ul>\n<li>\n<p>Length： <ruby>蛋白序列的长度。<rt>The length of the protein sequence.</rt></ruby></p>\n</li>\n<li>\n<p>Number of predicted TMHs：<ruby>预测到的跨膜螺旋的数量。<rt>The number of predicted transmembrane helices.</rt></ruby></p>\n</li>\n<li>\n<p>Exp number of AAs in TMHs：<ruby>跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids intransmembrane helices. </rt></ruby> <ruby>如果此数字大于 18，则很可能是跨膜蛋白（或具有信号肽）。<rt>If this number is larger than 18 it is very likely to be a transmembrane protein (OR have a signal peptide).</rt></ruby></p>\n</li>\n<li>\n<p>Exp number, first 60 AAs：<ruby>在蛋白的前 60 个氨基酸中跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids in transmembrane helices in the first 60 amino acids of the protein.</rt></ruby><ruby>如果该数字超过几个，你应该被警告在 N 端预测的跨膜螺旋可能是一个信号肽。<rt>If it more than a few, you are warned that a predicted transmembrane helix in the N-term could be a signal peptide.</rt></ruby></p>\n</li>\n<li>\n<p>Total prob of N-in：<ruby>N 端在膜的细胞质一侧的总概率。<rt> The total probability that the N-term is on the cytoplasmic side of the membrane.</rt></ruby></p>\n</li>\n<li>\n<p>POSSIBLE N-term signal sequence：<ruby>当 “Exp number, first 60 AAs” 大于 10 时产生的警告。 <rt> A warning that is produced when &quot;Exp number, first 60 AAs&quot; is larger than 10.</rt></ruby></p>\n</li>\n</ul>\n</li>\n<li>\n<p>蛋白 F01_bin.1_00110 共计 436 个氨基酸，有 5 个跨膜螺旋结构。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_3.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_3.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"含有跨膜结构的蛋白\" /></p>\n</li>\n<li>\n<p>蛋白 F01_bin.1_00142 共计 557 个氨基酸，所有序列均在膜外，即该序列编码的是分泌蛋白。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_4.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_4.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"不含跨膜结构的蛋白\" /></p>\n</li>\n<li>\n<p><strong>Short output format</strong></p>\n<ul>\n<li>\n<p>&quot;len=&quot;： <ruby>蛋白序列的长度。 <rt>The length of the protein sequence.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;ExpAA=&quot;：<ruby>跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids intransmembrane helices.</rt></ruby><ruby>如果此数字大于 18，则很可能是跨膜蛋白（或具有信号肽）。<rt>If this number is larger than 18 it is very likely to be a transmembrane protein (OR have a signal peptide).</rt></ruby></p>\n</li>\n<li>\n<p>&quot;First60=&quot;：<ruby>在蛋白的前 60 个氨基酸中跨膜螺旋中氨基酸的预期数量。<rt>The expected number of amino acids in transmembrane helices in the first 60 amino acids of the protein.</rt></ruby><ruby>如果该数字超过几个，你应该被警告在 N 端预测的跨膜螺旋可能是一个信号肽。<rt>If it more than a few, you are warned that a predicted transmembrane helix in the N-term could be a signal peptide.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;PredHel=&quot;：<ruby>预测到的跨膜螺旋的数量。 <rt>The number of predicted transmembrane helices by N-best.</rt></ruby></p>\n</li>\n<li>\n<p>&quot;Topology=&quot;：<ruby>N-best 预测的拓扑结构。<rt>The topology predicted by N-best.</rt></ruby>拓扑是由跨膜螺旋的位置给出的，如果螺旋在内部，则由 “i” 分隔，如果螺旋在外部，则由 “o” 分隔。'i7-29o44-66i87-109o' 意味着它从膜内开始，在位置 7 到 29 有一个预测的 TMH，30-43 在膜外，然后是位置 44-66 的 TMH。</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_5.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/c886_5.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"Short output format\" /></p>\n</li>\n</ul>\n<h3 id=\"结果汇总\"><a class=\"markdownIt-Anchor\" href=\"#结果汇总\"></a> 结果汇总</h3>\n<p>通过网页版预测我们仅得到了一个列表文件（Short output format），该文件需要自己复制网页内容粘贴到新文件中，我将其命名为<b>*_TMHMM_SHORT.txt</b>，并将其存放在<b>*_signalp</b>目录中，该目录是由<strong> run_SignalP.pl</strong> 生成的。下面我将会统计各个基因组中信号肽蛋白的总数量、分泌蛋白数量和跨膜蛋白数量到文件<strong> Statistics.txt</strong> 中，并分别提取每个基因组的分泌蛋白序列到<b>*_signalp/*.secretory.faa</b>文件中，提取跨膜蛋白序列到<b>*_signalp/*.membrane.faa</b>文件中。该过程将通过<strong> tmhmm_parser.pl</strong> 完成。</p>\n<pre class=\"line-numbers language-perl\" data-language=\"perl\"><code class=\"language-perl\"><span class=\"token comment\">#!/usr/bin/perl</span>\n<span class=\"token keyword\">use</span> strict<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">use</span> warnings<span class=\"token punctuation\">;</span>\n<span class=\"token comment\"># Author: Liu Hualin</span>\n<span class=\"token comment\"># Date: Oct 15, 2021</span>\n\nopen OUT<span class=\"token punctuation\">,</span> <span class=\"token string\">\">Statistics.txt\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"Strain name\\tSignal peptide numbers\\tSecretory protein numbers\\tMembrane protein numbers\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">my</span> <span class=\"token variable\">@sig</span> <span class=\"token operator\">=</span> glob<span class=\"token punctuation\">(</span><span class=\"token string\">\"*_signalp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">foreach</span> <span class=\"token keyword\">my</span> <span class=\"token variable\">$sig</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">@sig</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token variable\">$sig</span><span class=\"token operator\">=~</span><span class=\"token regex\">/(.+)_signalp/</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$tmhmm</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sig</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/$str\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"_TMHMM_SHORT.txt\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$sig</span> <span class=\"token operator\">.</span> <span class=\"token string\">\"/$str\"</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".sigseq\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$secretory</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".secretory.faa\"</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$membrane</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$str</span> <span class=\"token operator\">.</span> <span class=\"token string\">\".membrane.faa\"</span><span class=\"token punctuation\">;</span>\n\topen SEC<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$secretory\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\topen MEM<span class=\"token punctuation\">,</span> <span class=\"token string\">\">$membrane\"</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$on</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span> <span class=\"token operator\">=</span> idseq<span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$tmhmm</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$_</span><span class=\"token operator\">=~</span><span class=\"token regex\">s/[\\r\\n]+//g</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">#\t\tprint $_ . \"\\n\";</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">@lines</span> <span class=\"token operator\">=</span> split <span class=\"token regex\">/\\t/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$lines</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">eq</span> <span class=\"token string\">\"Topology=o\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$out</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> SEC <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>\n\t\t\t<span class=\"token variable\">$on</span><span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">print</span> MEM <span class=\"token string\">\">$lines[0]\\n$hash&#123;$lines[0]&#125;\\n\"</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">&#125;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\tclose SEC<span class=\"token punctuation\">;</span>\n\tclose MEM<span class=\"token punctuation\">;</span>\n\tsystem<span class=\"token punctuation\">(</span><span class=\"token string\">\"mv $secretory $membrane $sig\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$total</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$out</span> <span class=\"token operator\">+</span> <span class=\"token variable\">$on</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">print</span> OUT <span class=\"token string\">\"$str\\t$total\\t$out\\t$on\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span>\n\nclose OUT<span class=\"token punctuation\">;</span>\n\n<span class=\"token function\"><span class=\"token keyword\">sub</span> idseq</span> <span class=\"token punctuation\">&#123;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$fasta</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token variable\">@_</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">my</span> <span class=\"token variable\">%hash</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">local</span> <span class=\"token variable\">$/</span> <span class=\"token operator\">=</span> <span class=\"token string\">\">\"</span><span class=\"token punctuation\">;</span>\n\topen IN<span class=\"token punctuation\">,</span> <span class=\"token variable\">$fasta</span> <span class=\"token operator\">||</span> <span class=\"token keyword\">die</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token filehandle symbol\">&lt;IN></span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n\t\tchomp<span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$header</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> split <span class=\"token punctuation\">(</span><span class=\"token regex\">/\\n/</span><span class=\"token punctuation\">,</span> <span class=\"token variable\">$_</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$header</span> <span class=\"token operator\">=~</span> <span class=\"token regex\">/(\\S+)/</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">my</span> <span class=\"token variable\">$id</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$1</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token variable\">$hash</span><span class=\"token punctuation\">&#123;</span><span class=\"token variable\">$id</span><span class=\"token punctuation\">&#125;</span> <span class=\"token operator\">=</span> <span class=\"token variable\">$seq</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">&#125;</span>\n\tclose IN<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">%hash</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><strong>运行方法</strong>：将<b>tmhmm_parser.pl</b>放在<b>*_signalp</b>的上一级目录下，<b>*_signalp</b>目录中必须包含<b>*_TMHMM_SHORT.txt</b>文件和<b>*.sigseq</b>文件。在终端运行如下代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">perl tmhmm_parser.pl<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h1 id=\"脚本获取\"><a class=\"markdownIt-Anchor\" href=\"#脚本获取\"></a> 脚本获取</h1>\n<p>关注公众号 “生信之巅”，聊天窗口回复 “c886” 获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n<h1 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h1>\n<ul>\n<li>\n<p><a href=\"https://services.healthtech.dtu.dk/service.php?SignalP-6.0\">SignalP V6.0</a></p>\n</li>\n<li>\n<p><a href=\"http://www.cbs.dtu.dk/services/TMHMM/\">TMHMM</a></p>\n</li>\n</ul>\n","raw":null,"categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"Functional genomics","path":"api/tags/Functional genomics.json"},{"name":"SY179","path":"api/tags/SY179.json"},{"name":"生信软件","path":"api/tags/生信软件.json"},{"name":"WGS","path":"api/tags/WGS.json"}]}]}