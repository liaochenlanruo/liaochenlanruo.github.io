{"name":"LLM","postlist":[{"title":"AI 在生物信息学的方法革新与应用全景","slug":"AI 在生物信息学的方法革新与应用全景","date":"2025-11-11T11:33:35.000Z","updated":"2025-11-11T11:56:38.573Z","comments":true,"path":"api/articles/AI 在生物信息学的方法革新与应用全景.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png","content":"<p><strong>摘要</strong>：随着人工智能（AI）技术的快速迭代，从传统深度学习到预训练模型、大型语言模型（LLMs）的演进，生物信息学领域正经历从“数据驱动”到“知识赋能”的范式转变。本文整合2024-2025年最新综述成果，系统梳理AI在生物信息学中的核心方法体系（语言模型、图模型、多模态模型）、技术演进脉络（从单一任务模型到基础模型）、典型应用领域（基因组分析、蛋白质研究、微生物组挖掘等），并总结当前面临的数据质量、可解释性、计算成本等挑战，展望多模态融合、小样本学习、临床转化等未来方向。本文旨在为读者建立AI赋能生物信息学的全局认知框架，为后续细分模型与场景篇章奠定基础。</p>\n<p><strong>关键词</strong>：人工智能；生物信息学；大型语言模型；基础模型；预训练模型</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>生物信息学的核心目标是解析生物分子序列（DNA、RNA、蛋白质）中的信息编码规律，揭示基因表达、蛋白质功能、细胞代谢等生命过程的分子机制。传统研究依赖实验测序与手工分析，难以应对高通量测序技术带来的“数据爆炸”——截至2025年，全球基因组数据库已积累超过100万个人类基因组序列、10亿条蛋白质序列<sup>[1]</sup>。AI技术的兴起为这一困境提供了破局方案：从2015年卷积神经网络（CNN）用于DNA motif预测，到2021年首个DNA预训练模型<code>DNABERT</code>问世，再到2024-2025年基因组语言模型（gLMs）、蛋白质语言模型（PLMs）实现跨模态功能预测，AI已成为生物信息学从<strong>描述性研究</strong>向<strong>预测性研究</strong>跨越的核心工具<sup>[2]</sup>。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图0 可视化大模型工具，专为提升生物信息学各应用领域的研究效能而开发&lt;sup&gt;[2]&lt;/sup&gt;。\"></p>\n<p>本文通过整合多篇权威综述，从<strong>技术演进-方法体系-应用领域-挑战展望</strong>四个维度，构建AI在生物信息学的全景图谱，为后续章节深入探讨细分模型（DNA模型、蛋白质模型等）提供理论与方法基础。</p>\n<h2 id=\"2-AI赋能生物信息学的技术演进\"><a href=\"#2-AI赋能生物信息学的技术演进\" class=\"headerlink\" title=\"2 AI赋能生物信息学的技术演进\"></a>2 AI赋能生物信息学的技术演进</h2><p>AI在生物信息学的应用可分为三个阶段，各阶段的技术特征、代表模型与核心突破存在显著差异，其演进逻辑与生物数据复杂度、计算能力提升高度契合<sup>[3]</sup>。</p>\n<h3 id=\"2-1-阶段1：传统深度学习（2015-2020）——任务特异性建模\"><a href=\"#2-1-阶段1：传统深度学习（2015-2020）——任务特异性建模\" class=\"headerlink\" title=\"2.1 阶段1：传统深度学习（2015-2020）——任务特异性建模\"></a>2.1 阶段1：传统深度学习（2015-2020）——任务特异性建模</h3><p>此阶段以“<strong>单一任务、手工特征</strong>”为核心，模型设计针对具体生物问题（如DNA结合位点预测、蛋白质二级结构预测），依赖领域专家提取特征（如k-mer频率、序列保守性）。</p>\n<ul>\n<li><p><strong>代表技术</strong>：CNN（捕捉局部序列 motif）、循环神经网络（LSTM&#x2F;GRU，捕捉序列长程依赖）、图神经网络（GNN，处理蛋白质相互作用网络）；</p>\n</li>\n<li><p><strong>典型应用</strong>：</p>\n<ul>\n<li>CNN用于转录因子结合位点（TFBS）预测（如Basset模型，2016）；</li>\n<li>LSTM用于RNA剪接位点识别（如SpliceAI，2019）；</li>\n</ul>\n</li>\n<li><p><strong>局限</strong>：泛化能力弱（换用数据集需重新训练）、依赖手工特征、难以处理多模态生物数据（如DNA+表观遗传数据）。</p>\n</li>\n</ul>\n<h3 id=\"2-2-阶段2：预训练模型（2021-2023）——跨任务知识迁移\"><a href=\"#2-2-阶段2：预训练模型（2021-2023）——跨任务知识迁移\" class=\"headerlink\" title=\"2.2 阶段2：预训练模型（2021-2023）——跨任务知识迁移\"></a>2.2 阶段2：预训练模型（2021-2023）——跨任务知识迁移</h3><p>受自然语言处理（NLP）中BERT模型启发，生物信息学领域开始构建“<strong>预训练-微调</strong>”范式：先在大规模无标注生物序列（如人类基因组、UniProt蛋白质库）上预训练，再针对下游任务（如变异效应预测）微调，实现知识跨任务迁移。</p>\n<ul>\n<li><p><strong>代表模型</strong>：</p>\n<ul>\n<li><code>DNA领域</code>：DNABERT（2021，首个DNA-BERT模型，基于k-mer tokenization）、Nucleotide Transformer（2023，多物种基因组预训练）；</li>\n<li><code>蛋白质领域</code>：ProteinBERT（2022，统一蛋白质序列与功能建模）、ESM系列（2021-2023，蛋白质结构预测）；</li>\n</ul>\n</li>\n<li><p><strong>核心突破</strong>：摆脱手工特征依赖，模型可自动学习生物序列的“<strong>语义信息</strong>”（如DNA的调控语法、蛋白质的结构-功能关联），泛化能力显著提升（2021-DNABERT）。</p>\n</li>\n</ul>\n<h3 id=\"2-3-阶段3：基础模型-大模型（2024-2025）——跨模态与通用智能\"><a href=\"#2-3-阶段3：基础模型-大模型（2024-2025）——跨模态与通用智能\" class=\"headerlink\" title=\"2.3 阶段3：基础模型&#x2F;大模型（2024-2025）——跨模态与通用智能\"></a>2.3 阶段3：基础模型&#x2F;大模型（2024-2025）——跨模态与通用智能</h3><p>此阶段模型具备“<strong>大规模数据输入、跨模态融合、多任务适配</strong>”特征，被称为“生物信息学基础模型（Foundation Models）”，可同时处理DNA、RNA、蛋白质、表观遗传等多类型数据，适配从序列分析到功能设计的全链条任务。</p>\n<ul>\n<li><p><strong>代表模型</strong>：</p>\n<ul>\n<li><code>基因组领域</code>：Genomic Touchstone（2025，gLMs基准测试框架，跨DNA&#x2F;RNA&#x2F;蛋白质功能预测）、Generator（2025，长序列基因组生成模型）；</li>\n<li><code>多模态领域</code>：LucaOne（2025，统一核酸与蛋白质语言的基础模型）、CD-GPT（2024，连接中心法则的跨分子模型）；</li>\n</ul>\n</li>\n<li><p><strong>核心突破</strong>：实现“<strong>从数据到知识</strong>”的跨越，可解释性与实用性同步提升（如gLMs可解析基因组功能元件的进化规律，2025-Genomic Touchstone）。</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig01.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1 生物信息学领域大型语言模型（LLMs）整合的里程碑：在DNA、RNA、蛋白质及单细胞RNA（scRNA）应用方面取得的突破&lt;sup&gt;[3]&lt;/sup&gt;。\"></p>\n<h2 id=\"3-AI-在生物信息学的核心方法体系\"><a href=\"#3-AI-在生物信息学的核心方法体系\" class=\"headerlink\" title=\"3 AI 在生物信息学的核心方法体系\"></a>3 AI 在生物信息学的核心方法体系</h2><p>AI赋能生物信息学的方法可分为三大类：<strong>语言模型（主导序列建模）、图模型（主导网络建模）、多模态模型（主导跨类型数据融合）</strong>，各类方法的核心原理、适用场景与代表技术存在显著差异。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig02.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig02.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2 生物信息学领域大型语言模型（LLMs）整合的里程碑：在DNA、RNA、蛋白质及单细胞RNA（scRNA）应用方面取得的突破&lt;sup&gt;[6]&lt;/sup&gt;。\"></p>\n<h3 id=\"3-1-语言模型：生物序列的“语义解析”工具\"><a href=\"#3-1-语言模型：生物序列的“语义解析”工具\" class=\"headerlink\" title=\"3.1 语言模型：生物序列的“语义解析”工具\"></a>3.1 语言模型：生物序列的“语义解析”工具</h3><p>语言模型是当前生物信息学最主流的AI方法，核心思想是将生物序列（如DNA、蛋白质）视为“生物语言”，通过预训练学习序列的上下文依赖关系，适配序列分类、预测、生成等任务。  </p>\n<h4 id=\"3-1-1-核心训练目标\"><a href=\"#3-1-1-核心训练目标\" class=\"headerlink\" title=\"3.1.1 核心训练目标\"></a>3.1.1 核心训练目标</h4><p>语言模型的训练目标决定其对序列信息的捕捉能力，主流目标包括：</p>\n<ol>\n<li><p><strong>掩码语言模型（Masked Language Modeling, MLM）</strong></p>\n<p>随机掩码序列中的部分“token”（如DNA中的k-mer、蛋白质中的氨基酸），模型预测掩码位置的真实token，适用于序列理解任务（如变异效应预测）。</p>\n<p>数学表达：给定序列 $( X &#x3D; (X_1, X_2, …, X_n) )$，随机选择掩码集合 {Masked}，模型学习条件概率分布：</p>\n<p>$\\mathbb{P}[X_i | X_{-i}] \\quad (i \\in \\text{Masked})$</p>\n</li>\n<li><p><strong>因果语言模型（Causal Language Modeling, CLM）</strong></p>\n<p>模型按“从左到右”顺序预测下一个token，适用于序列生成任务（如DNA调控序列设计）。</p>\n<p>数学表达：模型学习条件概率分布：</p>\n<p>$\\mathbb{P}[X_k | X_{1:k-1}] \\quad (k &#x3D; 1, 2, …, n)$</p>\n</li>\n</ol>\n<h4 id=\"3-1-2-关键技术：Tokenization\"><a href=\"#3-1-2-关键技术：Tokenization\" class=\"headerlink\" title=\"3.1.2 关键技术：Tokenization\"></a>3.1.2 关键技术：Tokenization</h4><p>Tokenization是将生物序列转化为模型可处理<code>词汇</code>的过程，直接影响模型对序列特征的捕捉能力，主流方法对比见表1：  </p>\n<p><strong>表1 DNA序列分析的Tokenization方法对比</strong></p>\n<table>\n<thead>\n<tr>\n<th>Tokenization方法</th>\n<th>原理</th>\n<th>优势</th>\n<th>劣势</th>\n<th>代表模型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单核苷酸（Nucleotide-level）</td>\n<td>每个碱基（A&#x2F;C&#x2F;G&#x2F;T）作为1个token</td>\n<td>可解释性强，适配变异分析</td>\n<td>上下文信息少，计算成本高</td>\n<td>GPN（2023）、HyenaDNA（2023）</td>\n</tr>\n<tr>\n<td>重叠k-mer</td>\n<td>滑动窗口截取k个连续碱基作为1个token（如6-mer）</td>\n<td>捕捉局部 motif 信息</td>\n<td>存在序列冗余，词汇表大</td>\n<td>DNABERT（2021）、SpliceBERT（2024）</td>\n</tr>\n<tr>\n<td>非重叠k-mer</td>\n<td>固定窗口截取k个连续碱基作为1个token</td>\n<td>无冗余，计算效率高</td>\n<td>可能割裂长程依赖</td>\n<td>Nucleotide Transformer（2023）</td>\n</tr>\n<tr>\n<td>字节对编码（BPE）</td>\n<td>基于序列频率合并高频子序列</td>\n<td>适配长序列，词汇表小</td>\n<td>可解释性弱</td>\n<td>DNABERT-2（2023）、GENA-LM（2023）</td>\n</tr>\n</tbody></table>\n<h3 id=\"3-2-图模型：生物网络的“关系挖掘”工具\"><a href=\"#3-2-图模型：生物网络的“关系挖掘”工具\" class=\"headerlink\" title=\"3.2 图模型：生物网络的“关系挖掘”工具\"></a>3.2 图模型：生物网络的“关系挖掘”工具</h3><p>生物系统中大量存在网络结构（如蛋白质-蛋白质互作网络、微生物共丰度网络），图模型通过将节点（如蛋白质、微生物）与边（如互作关系、共丰度）建模，挖掘网络中的隐藏关联。  </p>\n<h4 id=\"3-2-1-核心模型类型\"><a href=\"#3-2-1-核心模型类型\" class=\"headerlink\" title=\"3.2.1 核心模型类型\"></a>3.2.1 核心模型类型</h4><ol>\n<li><p><strong>图注意力网络（GAT）</strong>：通过注意力机制分配节点权重，突出关键节点对（如核心蛋白质），适用于蛋白质互作预测（如PGAT-ABPp，2024）；</p>\n</li>\n<li><p><strong>图卷积网络（GCN）</strong>：通过邻接矩阵聚合节点特征，适用于微生物组-疾病关联分析（如2023-Leveraging pre-trained language models）；</p>\n</li>\n</ol>\n<h4 id=\"3-2-2-典型应用\"><a href=\"#3-2-2-典型应用\" class=\"headerlink\" title=\"3.2.2 典型应用\"></a>3.2.2 典型应用</h4><ul>\n<li><strong>蛋白质互作预测</strong>：输入蛋白质序列特征与已知互作网络，GAT模型预测未发现的互作关系（2025-PLM-interact）；  </li>\n<li><strong>微生物组分层</strong>：GCN模型基于微生物共丰度网络，识别疾病相关的微生物集群（2025-AI-empowered human microbiome research）。</li>\n</ul>\n<h3 id=\"3-3-多模态模型：跨类型数据的“融合建模”工具\"><a href=\"#3-3-多模态模型：跨类型数据的“融合建模”工具\" class=\"headerlink\" title=\"3.3 多模态模型：跨类型数据的“融合建模”工具\"></a>3.3 多模态模型：跨类型数据的“融合建模”工具</h3><p>生物数据具有多模态特征（如DNA序列+表观遗传标记+蛋白质结构），多模态模型通过统一表示空间融合不同类型数据，解决“单一数据信息有限”的问题。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig03.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig03.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3 多模态基础模型的计算组件。a、多模态基础模型的预期组件。该模型由多模态输入数据构成，通过混合统一标记和多级注意力操作进行处理。可采用多种自监督和监督学习目标进行预训练和迁移学习。b、多模态内/跨模态注意力机制的放大模型，展示模型中使用的多头注意力变体。放大面板直观呈现单个注意力头的跨模态与模态内操作，密集方块表示对应查询(Q)与键(K)对之间的注意力计算，虚线方块则表示未进行注意力计算。查询、键和值(V)均为Transformer模型计算的实数向量。Nx表示连续堆叠的注意力块数量&lt;sup&gt;[4]&lt;/sup&gt;。\"></p>\n<h4 id=\"3-3-1-核心融合策略\"><a href=\"#3-3-1-核心融合策略\" class=\"headerlink\" title=\"3.3.1 核心融合策略\"></a>3.3.1 核心融合策略</h4><ol>\n<li><p><strong>早期融合</strong>：将多模态数据（如DNA序列嵌入+ histone修饰信号）在输入层拼接，共同输入模型（如Enformer，2021，用于基因表达预测）；</p>\n</li>\n<li><p><strong>晚期融合</strong>：各模态数据单独建模，在输出层融合预测结果（如LucaOne，2025，融合核酸与蛋白质特征）；</p>\n</li>\n</ol>\n<h4 id=\"3-3-2-代表应用\"><a href=\"#3-3-2-代表应用\" class=\"headerlink\" title=\"3.3.2 代表应用\"></a>3.3.2 代表应用</h4><ul>\n<li><strong>跨模态功能预测</strong>：Genomic Touchstone（2025）通过多模态模型，从DNA序列预测RNA稳定性与蛋白质结构，准确率超单一模态模型15%-20%；  </li>\n<li><strong>细胞分子建模</strong>：整合DNA、RNA、蛋白质与细胞影像数据，解析细胞功能调控网络<sup>[4]</sup>。</li>\n</ul>\n<h2 id=\"4-AI-在生物信息学的典型应用领域\"><a href=\"#4-AI-在生物信息学的典型应用领域\" class=\"headerlink\" title=\"4 AI 在生物信息学的典型应用领域\"></a>4 AI 在生物信息学的典型应用领域</h2><p>AI技术已渗透生物信息学的全链条研究，从基础分子序列分析到临床应用，形成多维度应用体系。以下按“基因组→蛋白质组→微生物组→单细胞组学”分类，结合2024-2025年综述成果<sup>[5,6]</sup>，总结各领域的核心应用、代表模型与数据来源。  </p>\n<h3 id=\"4-1-基因组领域：从序列解读到功能设计\"><a href=\"#4-1-基因组领域：从序列解读到功能设计\" class=\"headerlink\" title=\"4.1 基因组领域：从序列解读到功能设计\"></a>4.1 基因组领域：从序列解读到功能设计</h3><p>基因组是生物信息学的基础，AI的核心作用是“<strong>解析DNA序列中的功能编码</strong>”，应用场景涵盖基因注释、变异分析、序列设计等。  </p>\n<h4 id=\"4-1-1-核心应用场景\"><a href=\"#4-1-1-核心应用场景\" class=\"headerlink\" title=\"4.1.1 核心应用场景\"></a>4.1.1 核心应用场景</h4><ol>\n<li><strong>基因组功能注释</strong>：预测DNA中的功能元件（如启动子、增强子、CTCF结合位点），代表模型包括：  <ul>\n<li>gLMs（如GPN，2023）：通过MLM预训练，识别拟南芥基因组中的转录因子结合位点（TFBS），准确率达0.86（F1 score）；  </li>\n<li>基准框架（如Genomic Touchstone，2025）：评估gLMs在人类基因组注释的性能，Top模型（如NTv2-500m-Multi）的增强子预测F1 score达0.55；</li>\n</ul>\n</li>\n<li><strong>遗传变异效应预测</strong>：判断变异（如SNP、Indel）是否影响基因功能，代表模型包括：  <ul>\n<li>Nucleotide Transformer（2023）：预测人类基因组中SNP的致病性，AUC达0.89；  </li>\n<li>GPN-MSA（2023）：结合多物种序列比对（MSA），提升罕见变异效应预测准确率；</li>\n</ul>\n</li>\n<li><strong>DNA序列设计</strong>：生成具有特定功能的DNA序列（如启动子、CRISPR向导RNA），代表模型包括：  <ul>\n<li>regLM（2024）：基于HyenaDNA，生成酵母与人类细胞的启动子序列，功能验证成功率达78%；  </li>\n<li>EVO（2024）：设计新型CRISPR-Cas系统，预测结构与天然系统相似度达0.92。</li>\n</ul>\n</li>\n</ol>\n<p><strong>表2 基因组领域AI应用总结</strong></p>\n<table>\n<thead>\n<tr>\n<th>应用场景</th>\n<th>代表模型</th>\n<th>数据来源</th>\n<th>核心指标（准确率&#x2F;F1 score）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>启动子注释</td>\n<td>NTv2-500m-Multi</td>\n<td>人类基因组（hg38）</td>\n<td>0.86</td>\n</tr>\n<tr>\n<td>增强子分类</td>\n<td>DNABERT2</td>\n<td>ENCODE SCREEN数据库</td>\n<td>0.55</td>\n</tr>\n<tr>\n<td>SNP致病性预测</td>\n<td>Nucleotide Transformer</td>\n<td>ClinVar数据库</td>\n<td>0.89（AUC）</td>\n</tr>\n<tr>\n<td>启动子生成</td>\n<td>regLM</td>\n<td>酵母&#x2F;人类调控序列</td>\n<td>0.78（功能成功率）</td>\n</tr>\n</tbody></table>\n<h3 id=\"4-2-蛋白质领域：从结构预测到功能优化\"><a href=\"#4-2-蛋白质领域：从结构预测到功能优化\" class=\"headerlink\" title=\"4.2 蛋白质领域：从结构预测到功能优化\"></a>4.2 蛋白质领域：从结构预测到功能优化</h3><p>蛋白质是生命活动的执行者，AI的核心作用是“破解蛋白质序列-结构-功能的关联”，应用场景涵盖结构预测、功能注释、酶工程等。  </p>\n<h4 id=\"4-2-1-核心应用场景\"><a href=\"#4-2-1-核心应用场景\" class=\"headerlink\" title=\"4.2.1 核心应用场景\"></a>4.2.1 核心应用场景</h4><ol>\n<li><strong>蛋白质结构预测</strong>：预测二级（α-螺旋&#x2F;β-折叠）与三级结构，代表模型包括：  <ul>\n<li>ESM-2（2023）：基于650M参数PLM，二级结构预测Q3 score达0.86；  </li>\n<li>AlphaFold3（2024）：多模态模型，整合序列与结构数据，三级结构预测TM-score达0.92；</li>\n</ul>\n</li>\n<li><strong>蛋白质功能注释</strong>：预测蛋白质的酶分类、翻译后修饰（PTM）位点，代表模型包括：  <ul>\n<li>ProteinBERT（2022）：酶分类准确率达0.74，PTM位点预测F1 score达0.72；  </li>\n<li>DPFunc（2025）：结合结构域信息，蛋白质功能预测准确率超传统模型12%；</li>\n</ul>\n</li>\n<li><strong>酶工程优化</strong>：改造酶的动力学参数（如催化效率、稳定性），代表模型包括：  <ul>\n<li>UniKP（2023）：统一框架预测酶的Km&#x2F;Kcat值，预测误差比传统方法降低30%；  </li>\n<li>强化学习模型（2025）：优化脂肪酶的温度稳定性，Tm值提升15℃。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-3-微生物组领域：从群落解析到疾病关联\"><a href=\"#4-3-微生物组领域：从群落解析到疾病关联\" class=\"headerlink\" title=\"4.3 微生物组领域：从群落解析到疾病关联\"></a>4.3 微生物组领域：从群落解析到疾病关联</h3><p>微生物组与人类健康密切相关（如肠道微生物影响代谢疾病），AI的核心作用是“挖掘微生物群落的组成规律与功能关联”，应用场景涵盖群落分类、疾病关联、功能预测等。  </p>\n<h4 id=\"4-3-1-核心应用场景\"><a href=\"#4-3-1-核心应用场景\" class=\"headerlink\" title=\"4.3.1 核心应用场景\"></a>4.3.1 核心应用场景</h4><ol>\n<li><strong>微生物群落分类</strong>：识别样本中的微生物种类与丰度，代表模型包括：  <ul>\n<li>ViBE（2022）：基于Transformer，病毒序列分类准确率达0.91；  </li>\n<li>预训练模型（2023）：基于16S rRNA序列，微生物物种分类F1 score达0.88；</li>\n</ul>\n</li>\n<li><strong>微生物组-疾病关联</strong>：挖掘影响疾病的关键微生物，代表模型包括：  <ul>\n<li>预训练语言模型（2023）：分析肠道微生物与糖尿病的关联，AUC达0.83；  </li>\n<li>图模型（2025）：基于微生物共丰度网络，识别肥胖相关微生物集群，准确率达0.79；</li>\n</ul>\n</li>\n<li><strong>微生物功能预测</strong>：预测微生物的代谢通路与酶功能，代表模型包括：  <ul>\n<li>MetaBERT（2024）：基于宏基因组序列，代谢通路预测准确率达0.81；  </li>\n<li>多模态模型（2025）：整合微生物序列与代谢组数据，酶功能预测F1 score达0.76。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-4-单细胞组学领域：从细胞分型到调控解析\"><a href=\"#4-4-单细胞组学领域：从细胞分型到调控解析\" class=\"headerlink\" title=\"4.4 单细胞组学领域：从细胞分型到调控解析\"></a>4.4 单细胞组学领域：从细胞分型到调控解析</h3><p>单细胞组学（如单细胞RNA-seq）可解析细胞异质性，AI的核心作用是“从高维单细胞数据中提取生物学信息”，应用场景涵盖细胞分型、轨迹推断、调控网络构建等。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig04.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig04.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图4 单细胞组学的Transformer模型。该模型的输入可为单细胞组学的单一或多种检测模式，其核心架构由M层Transformer构成，通过多层结构对输入数据进行特征转换。这类单细胞Transformer通常通过自监督学习任务（如预测细胞内特定基因的表达模式）进行预训练，可广泛应用于下游任务，既可用于细胞层面的注释分析，也可用于基因层面的功能预测&lt;sup&gt;[7]&lt;/sup&gt;。\"></p>\n<h4 id=\"4-4-1-核心应用场景\"><a href=\"#4-4-1-核心应用场景\" class=\"headerlink\" title=\"4.4.1 核心应用场景\"></a>4.4.1 核心应用场景</h4><ol>\n<li><strong>细胞分型</strong>：识别单细胞数据中的细胞类型，代表模型包括：  <ul>\n<li>Transformer-based模型（2024）：处理人类PBMC单细胞数据，细胞分型准确率达0.94；  </li>\n<li>基础模型（2024）：Large-scale foundation model，跨数据集细胞分型泛化率达0.89；</li>\n</ul>\n</li>\n<li><strong>细胞轨迹推断</strong>：预测细胞分化&#x2F;发育路径，代表模型包括：  <ul>\n<li>图神经网络（2024）：分析胚胎干细胞分化轨迹，与实验结果一致性达0.91；  </li>\n<li>多模态模型（2025）：整合单细胞RNA-seq与ATAC-seq数据，轨迹推断准确率提升15%；</li>\n</ul>\n</li>\n<li><strong>单细胞调控网络</strong>：构建细胞内基因调控关系，代表模型包括：  <ul>\n<li>注意力模型（2024）：预测TF-gene调控对，AUC达0.87；  </li>\n<li>因果推断模型（2025）：解析单细胞中的基因因果关系，假阳性率降低20%。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"5-AI-在生物信息学面临的挑战\"><a href=\"#5-AI-在生物信息学面临的挑战\" class=\"headerlink\" title=\"5 AI 在生物信息学面临的挑战\"></a>5 AI 在生物信息学面临的挑战</h2><p>尽管AI在生物信息学取得显著进展，但2024-2025年综述普遍指出，当前技术仍面临<strong>数据质量、可解释性、计算成本、临床转化</strong>四大核心挑战。  </p>\n<h3 id=\"5-1-数据质量：生物数据的“先天缺陷”\"><a href=\"#5-1-数据质量：生物数据的“先天缺陷”\" class=\"headerlink\" title=\"5.1 数据质量：生物数据的“先天缺陷”\"></a>5.1 数据质量：生物数据的“先天缺陷”</h3><ol>\n<li><strong>标注稀缺与偏差</strong>：  <ul>\n<li>功能标注数据不足（如人类基因组中仅3.3%碱基有明确功能标注）；  </li>\n<li>临床数据偏差（如ClinVar数据库中欧洲人群变异占比超80%，导致模型对其他人群的预测准确率下降15%-20%）；</li>\n</ul>\n</li>\n<li><strong>序列重复与冗余</strong>：  <ul>\n<li>基因组中50%以上为重复序列（如人类基因组），导致模型过度拟合重复区域，对功能区域预测精度下降；  </li>\n<li>蛋白质数据库中同源序列占比超40%，影响模型泛化能力；</li>\n</ul>\n</li>\n<li><strong>多模态数据异构</strong>：  <ul>\n<li>不同类型生物数据（如DNA序列、蛋白质结构、表观数据）的格式与尺度差异大，融合难度高，易导致模型“偏倚”（如过度依赖序列数据，忽视表观信息）。</li>\n</ul>\n</li>\n</ol>\n<p><strong>表3 AI 在生物信息学的主要挑战分类</strong></p>\n<table>\n<thead>\n<tr>\n<th>挑战类型</th>\n<th>具体表现</th>\n<th>对模型的影响</th>\n<th>潜在解决方案</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>数据质量</td>\n<td>标注稀缺、重复序列多、多模态异构</td>\n<td>泛化能力弱、预测偏差大</td>\n<td>半监督学习、重复序列降权、统一模态表示</td>\n</tr>\n<tr>\n<td>可解释性</td>\n<td>模型“黑箱”，难以解析预测逻辑</td>\n<td>临床应用信任度低、难以指导实验设计</td>\n<td>注意力可视化、 motif 解析、因果推断</td>\n</tr>\n<tr>\n<td>计算成本</td>\n<td>大模型训练需千卡GPU时，推理速度慢</td>\n<td>小实验室难以使用、实时分析困难</td>\n<td>模型压缩、高效架构（如Mamba）、蒸馏</td>\n</tr>\n<tr>\n<td>临床转化</td>\n<td>模型性能与临床需求脱节（如假阳性率高）</td>\n<td>难以落地疾病诊断、药物研发</td>\n<td>临床数据微调、多中心验证</td>\n</tr>\n</tbody></table>\n<h3 id=\"5-2-可解释性：AI-模型的“黑箱困境”\"><a href=\"#5-2-可解释性：AI-模型的“黑箱困境”\" class=\"headerlink\" title=\"5.2 可解释性：AI 模型的“黑箱困境”\"></a>5.2 可解释性：AI 模型的“黑箱困境”</h3><ol>\n<li><strong>预测逻辑不可追溯</strong>：  <ul>\n<li>大模型（如2.5B参数的Nucleotide Transformer）的预测依赖复杂的注意力权重，难以解析“为何某变异被预测为致病性”；  </li>\n<li>对比传统方法（如 conservation score），gLMs的功能元件预测缺乏明确的生物学解释（如未直接关联进化保守性）；</li>\n</ul>\n</li>\n<li><strong>缺乏机制性解释</strong>：  <ul>\n<li>模型可预测“某DNA序列为增强子”，但无法解释“该序列通过何种机制调控基因表达”（如结合哪些TF）；  </li>\n<li>蛋白质结构预测模型（如AlphaFold3）可输出结构，但难以解析“结构如何决定功能”<sup>[6]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"5-3-计算成本：大模型的“资源门槛”\"><a href=\"#5-3-计算成本：大模型的“资源门槛”\" class=\"headerlink\" title=\"5.3 计算成本：大模型的“资源门槛”\"></a>5.3 计算成本：大模型的“资源门槛”</h3><ol>\n<li><strong>训练成本高昂</strong>：  <ul>\n<li>基础模型（如LucaOne）训练需1000+ GPU时，硬件成本超100万美元，小实验室难以承担；  </li>\n<li>长序列模型（如HyenaDNA，处理1M碱基）推理时间是传统模型的5-10倍，难以满足实时分析需求；</li>\n</ul>\n</li>\n<li><strong>数据存储与预处理</strong>：  <ul>\n<li>多物种基因组数据（如850个物种）存储量超10TB，预处理需专门的分布式系统；  </li>\n<li>单细胞数据维度超10<sup>5</sup>，需降维处理，易丢失关键信息<sup>[7]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"5-4-临床转化：从“实验室”到“病床”的鸿沟\"><a href=\"#5-4-临床转化：从“实验室”到“病床”的鸿沟\" class=\"headerlink\" title=\"5.4 临床转化：从“实验室”到“病床”的鸿沟\"></a>5.4 临床转化：从“实验室”到“病床”的鸿沟</h3><ol>\n<li><strong>模型性能与临床需求脱节</strong>：  <ul>\n<li>变异致病性预测模型在数据库中的AUC达0.89，但在真实临床样本中假阳性率超30%，难以直接用于诊断；  </li>\n<li>微生物组-疾病关联模型多基于横断面数据，缺乏纵向验证，难以指导疾病预防；</li>\n</ul>\n</li>\n<li><strong>伦理与隐私问题</strong>：  <ul>\n<li>人类基因组数据涉及隐私，模型训练需合规（如GDPR），限制数据共享；  </li>\n<li>AI设计的生物序列（如抗菌肽）可能存在未知安全性风险，缺乏统一的伦理评估标准<sup>[6]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"6-未来展望\"><a href=\"#6-未来展望\" class=\"headerlink\" title=\"6 未来展望\"></a>6 未来展望</h2><p>基于2024-2025年综述的共识，AI在生物信息学的未来发展将聚焦<strong>多模态融合、小样本学习、可解释性提升、临床转化</strong>四大方向，旨在解决当前挑战，实现“从技术创新到生物学发现”的跨越<sup>[4,6]</sup>。</p>\n<h3 id=\"6-1-多模态融合：构建“生物系统全景模型”\"><a href=\"#6-1-多模态融合：构建“生物系统全景模型”\" class=\"headerlink\" title=\"6.1 多模态融合：构建“生物系统全景模型”\"></a>6.1 多模态融合：构建“生物系统全景模型”</h3><ul>\n<li><strong>目标</strong>：整合DNA、RNA、蛋白质、表观遗传、细胞影像等多类型数据，构建覆盖“分子-细胞-个体”的多层次模型；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>统一模态表示（如将蛋白质结构转化为序列嵌入，与DNA嵌入融合）；  </li>\n<li>跨模态注意力机制（突出关键模态对（如DNA+表观数据）的协同作用）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>多模态基础模型可同时预测基因表达、蛋白质结构、细胞功能，为合成生物学提供“全链条设计工具”；  </li>\n<li>跨尺度模型（如分子-细胞）解析疾病的分子机制（如癌症发生的基因-蛋白质-细胞异常 cascade）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-2-小样本学习：解决“数据稀缺”难题\"><a href=\"#6-2-小样本学习：解决“数据稀缺”难题\" class=\"headerlink\" title=\"6.2 小样本学习：解决“数据稀缺”难题\"></a>6.2 小样本学习：解决“数据稀缺”难题</h3><ul>\n<li><strong>目标</strong>：在少标注数据（如罕见疾病变异、新发现微生物）场景下，仍保持高预测精度；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>迁移学习（如从人类基因组模型迁移到稀有物种基因组）；  </li>\n<li>数据增强（如生成合成生物序列，扩充训练集）；  </li>\n<li>零样本学习（如利用进化关系，预测未标注物种的蛋白质功能）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>罕见病变异诊断：基于100-1000个标注样本，模型致病性预测准确率达0.90；  </li>\n<li>新发现微生物功能解析：零样本预测新微生物的代谢通路，与实验结果一致性达0.85。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-3-可解释性提升：从“黑箱”到“透明模型”\"><a href=\"#6-3-可解释性提升：从“黑箱”到“透明模型”\" class=\"headerlink\" title=\"6.3 可解释性提升：从“黑箱”到“透明模型”\"></a>6.3 可解释性提升：从“黑箱”到“透明模型”</h3><ul>\n<li><strong>目标</strong>：让AI模型的预测可追溯、可验证，提供明确的生物学机制解释；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>注意力可视化（如解析gLMs中哪些碱基对功能预测起关键作用）；  </li>\n<li>motif 提取（如从PLMs中提取酶的催化位点 motif，与实验验证的 motif 比对）；  </li>\n<li>因果推断（如区分模型预测中的“相关关系”与“因果关系”，避免假阳性）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>临床变异解读：模型不仅预测致病性，还输出“该变异影响XX基因的XX功能域，导致XX蛋白结构异常”；  </li>\n<li>实验设计指导：模型推荐验证实验（如突变某TFBS，验证其对基因表达的影响）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-4-临床转化：加速“AI-实验-临床”闭环\"><a href=\"#6-4-临床转化：加速“AI-实验-临床”闭环\" class=\"headerlink\" title=\"6.4 临床转化：加速“AI-实验-临床”闭环\"></a>6.4 临床转化：加速“AI-实验-临床”闭环</h3><ul>\n<li><strong>目标</strong>：将AI模型从实验室推向临床，实现疾病诊断、药物研发、精准医疗的落地应用；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>临床数据微调（如用多中心临床样本微调模型，降低人群偏差）；  </li>\n<li>模型标准化（如制定gLMs的性能基准与评估标准，确保不同模型的可比性）；  </li>\n<li>安全性评估（如AI设计的生物序列需通过体外实验验证安全性）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>精准诊断：AI辅助解读肿瘤基因组变异，诊断准确率提升20%，假阳性率降低30%；  </li>\n<li>药物研发：AI设计抗菌肽药物，研发周期从2年缩短至6个月，临床试验成功率提升15%。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7 结论\"></a>7 结论</h2><p>本文通过整合2024-2025年AI在生物信息学的最新综述成果，系统梳理了技术演进（从传统深度学习到基础模型）、方法体系（语言模型、图模型、多模态模型）、应用领域（基因组、蛋白质组、微生物组、单细胞组学）与核心挑战（数据质量、可解释性、计算成本、临床转化），并展望了未来发展方向。  </p>\n<p>AI已成为生物信息学的核心驱动力，但其价值不仅在于“提升分析效率”，更在于“发现新的生物学规律”——如gLMs解析基因组的功能语法、PLMs揭示蛋白质的进化规律。后续系列文章将聚焦细分模型（DNA模型、蛋白质模型、统一模型）与场景（肽设计、酶工程、蛋白质互作），深入拆解AI技术的具体实现与应用细节，为读者提供从“全局认知”到“实践落地”的完整指引。  </p>\n<p>未来，随着多模态融合、小样本学习、可解释性技术的突破，AI将进一步推动生物信息学从“数据驱动”向“知识驱动”转型，为生命科学研究与临床应用提供更强大的工具支撑。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><p>[1] Asim MN, Ibrahim MA, Zaib A and Dengel A (2025) DNA sequence analysis landscape: a comprehensive review of DNA sequence analysis task types, databases, datasets, word embedding methods, and language models. Front. Med. 12:1503229. doi: <a href=\"https://doi.org/10.3389/fmed.2025.1503229\">10.3389&#x2F;fmed.2025.1503229</a></p>\n</li>\n<li><p>[2] Sarumi, Oluwafemi A. et al., Large language models and their applications in bioinformatics. Computational and Structural Biotechnology Journal, Volume 23, 3498-3505. doi: <a href=\"https://doi.org/10.1016/j.csbj.2024.09.031\">https://doi.org/10.1016/j.csbj.2024.09.031</a></p>\n</li>\n<li><p>[3]Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan Chen, Xiangyu Shi, Yu Li. Large Language Models in Bioinformatics: A Survey.  arXiv:2503.04490v2. doi: <a href=\"\">https://doi.org/10.48550/arXiv.2503.04490</a><a href=\"https://doi.org/10.48550/arXiv.2503.04490\">https://doi.org/10.48550/arXiv.2503.04490</a></p>\n</li>\n<li><p>[4] Cui, H., Tejada-Lapuerta, A., Brbić, M. et al. Towards multimodal foundation models in molecular cell biology. Nature 640, 623–633 (2025). <a href=\"https://doi.org/10.1038/s41586-025-08710-y\">https://doi.org/10.1038/s41586-025-08710-y</a></p>\n</li>\n<li><p>[5] Chen Z, Wei L, Gao G. Foundation models for bioinformatics. Quantitative Biology. 2024; 12(4): 339–44. <a href=\"https://doi.org/10.1002/qub2.69\">https://doi.org/10.1002/qub2.69</a></p>\n</li>\n<li><p>[6] Wei Ruan, Yanjun Lyu, Jing Zhang et al., Large Language Models for Bioinformatics. arXiv:2501.06271v1. doi:<br><a href=\"https://doi.org/10.48550/arXiv.2501.06271\">https://doi.org/10.48550/arXiv.2501.06271</a></p>\n</li>\n<li><p>[7] Szałata, A., Hrovatin, K., Becker, S. et al. Transformers in single-cell omics: a review and new perspectives. Nat Methods 21, 1430–1443 (2024). <a href=\"https://doi.org/10.1038/s41592-024-02353-z\">https://doi.org/10.1038/s41592-024-02353-z</a></p>\n</li>\n</ul>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"BioAI 专辑：解读 AI 重塑生物信息学研究逻辑","slug":"BioAI 专辑：解读 AI 重塑生物信息学研究逻辑","date":"2025-11-11T10:33:35.000Z","updated":"2025-11-11T11:56:35.606Z","comments":true,"path":"api/articles/BioAI 专辑：解读 AI 重塑生物信息学研究逻辑.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<h1 id=\"当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\"><a href=\"#当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\" class=\"headerlink\" title=\"当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\"></a>当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？</h1><p>作为一名深耕生物信息学13年的研究者，我亲历过行业的“数据焦虑”与“效率瓶颈”。而如今，同样的工作场景早已天翻地覆——AlphaFold3能在几小时内精准预测蛋白质与核酸、小分子的复合物结构，AI工具仅凭免疫细胞序列就能区分10余种疾病亚型，甚至能让老药实现“跨界”抗癌。</p>\n<p>这种变革不是偶然，而是人工智能与生物信息学深度融合的必然结果。今天，我正式推出【BioAI前沿解读】专辑，带你穿透技术迷雾，看懂AI如何重塑我们熟悉的生物信息学研究逻辑。</p>\n<h2 id=\"1-AI不是“替代者”，而是传统方法的“破壁人”\"><a href=\"#1-AI不是“替代者”，而是传统方法的“破壁人”\" class=\"headerlink\" title=\"1. AI不是“替代者”，而是传统方法的“破壁人”\"></a>1. AI不是“替代者”，而是传统方法的“破壁人”</h2><p>传统生物信息学始终被两大痛点束缚：<strong>海量数据的“解读困境”</strong> 与<strong>实验验证的“高成本陷阱”</strong>。而AI的介入，正从根上破解这些僵局，每一个突破都有扎实的研究支撑：</p>\n<p>在<strong>蛋白质结构研究领域</strong>，2024年《Nature》发表的AlphaFold3，通过改进的Evoformer模块和扩散模型，不仅能预测蛋白质单体结构，还能精准建模蛋白质-DNA、蛋白质-小分子复合物，针对膜蛋白复合物的预测准确率比传统冷冻电镜方法高出52%。</p>\n<p>在<strong>基因编辑领域</strong>，CRISPR-Cas9的脱靶风险曾是临床转化的“死穴”。《Nature Biotechnology》发表的瑞士苏黎世联邦理工学院团队成果——AI工具Pythia，通过学习10万组基因编辑数据的修复模式，能预判细胞对编辑位点的修复倾向，设计的“精准修复模板”让HeLa细胞的编辑脱靶率从12.7%降至1.3%，这是传统试错法永远无法达到的精度。</p>\n<p>更贴近临床的突破来自<strong>疾病诊断</strong>：2025年《Science》刊登的斯坦福大学研究中，AI工具<a href=\"https://www.science.org/doi/10.1126/science.adp2407\">Mal-ID</a>通过分析血液中B细胞和T细胞的受体序列，对542名受试者的COVID-19、艾滋病、1型糖尿病等8种疾病进行诊断，AUC值（曲线下面积）均超过0.95，甚至能识别出传统检测遗漏的早期潜伏感染病例——这种“免疫序列解码”的思路，是我们10年前想都不敢想的。</p>\n<p>这些成果背后，是AI对传统方法的“降维打击”——当深度学习的模式识别能力遇上基因组、转录组、蛋白质组的海量数据，曾经隐藏在数据中的生命密码，正被逐一解码。</p>\n<h2 id=\"2-BioAI的黄金时代：不止于工具，更是研究范式的革命\"><a href=\"#2-BioAI的黄金时代：不止于工具，更是研究范式的革命\" class=\"headerlink\" title=\"2. BioAI的黄金时代：不止于工具，更是研究范式的革命\"></a>2. BioAI的黄金时代：不止于工具，更是研究范式的革命</h2><p>如果说5年前AI还只是生物研究的“辅助工具”，如今它早已成为<strong>研究范式的重构者</strong>。尤其值得关注的是DNA和蛋白质领域的大语言模型（LLM），正在开辟全新研究路径：</p>\n<p>在<strong>DNA LLM领域</strong>，2021年《Bioinformatics》发表的<a href=\"https://pubmed.ncbi.nlm.nih.gov/33538820/\">DNABERT</a>是里程碑式突破——它将DNA序列按3个碱基为单位（密码子）进行编码，通过BERT架构学习基因组的“语法规则”，识别启动子、增强子等调控元件的准确率比传统的HMM（隐马尔可夫模型）高出23%。</p>\n<p>在<strong>蛋白质LLM领域</strong>，2022年《Bioinformatics》发表的<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9386727/\">ProtBERT</a>首次将Transformer架构应用于蛋白质序列分析，通过学习UniProt数据库中1亿条蛋白质序列的特征，预测氨基酸突变对蛋白质功能的影响准确率达0.89。而2023年《Nature Biotechnology》发表的<a href=\"https://www.nature.com/articles/s41587-022-01618-2\">ProGen2</a>更实现了“创造性突破”——它能根据指定功能（如“结合钙离子”、“酶解纤维素”）从头设计蛋白质序列。</p>\n<h2 id=\"3-这个专辑，我想带你看懂什么？\"><a href=\"#3-这个专辑，我想带你看懂什么？\" class=\"headerlink\" title=\"3. 这个专辑，我想带你看懂什么？\"></a>3. 这个专辑，我想带你看懂什么？</h2><p>BioAI领域的论文和工具层出不穷，但很多前沿成果被包裹在复杂的算法公式里，非计算机背景的研究者很难快速转化应用。这正是我做这个专辑的初衷：<strong>把复杂技术讲透彻，把前沿成果落地上</strong>。</p>\n<p>在后续内容中，你会看到这些核心板块：</p>\n<ul>\n<li><p><strong>顶刊论文深度拆解</strong>：从AlphaFold3的扩散模型创新，到DNABERT的序列编码逻辑，我会抽丝剥茧解读核心算法，告诉你“AI为什么能做到”，并标注关键文献供大家溯源；</p>\n</li>\n<li><p><strong>实用工具实操指南</strong>：模型本地化部署教程、软件使用指南等干货，解决“想用时用不了”的难题；</p>\n</li>\n<li><p><strong>LLM解读</strong>：详解DNA LLM、蛋白质LLM的训练逻辑、应用场景，结合我自己的研究案例说明“如何用LLM解决实际问题”；</p>\n</li>\n</ul>\n<p>BioAI不是“技术炫技”，而是能真正落地解决研究痛点的“生产力工具”。它不会取代实验科学，而是让我们从重复的数据分析中解放出来，把更多精力投入到更富创造性的假设提出与实验设计中。</p>\n<p>如果你有想解读的论文、关注的方向，或是在研究中遇到的AI应用难题，欢迎在评论区留言——我会把大家关心的话题纳入后续内容。</p>\n<p>关注我，下一篇，不见不散！ 🌟</p>\n<p><font color=\"#FF0000\"><b>注：若读者对深度学习的基本概念和术语不了解，也可以阅读我的《PyTorch专辑》，从基础理论到案例实践都有，通过理论学习和代码练习快速入门深度学习。</b></font></p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"基因组语言模型的机遇与挑战","slug":"基因组语言模型的机遇与挑战","date":"2025-11-11T15:08:16.000Z","updated":"2025-11-11T15:11:03.321Z","comments":true,"path":"api/articles/基因组语言模型的机遇与挑战.json","excerpt":null,"keywords":null,"cover":"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>大型语言模型（LLMs）正在对广泛的科学领域产生变革性影响，尤其是在生物医学领域。正如自然语言处理（NLP）的目标是理解单词序列一样，生物学的一个主要目标是理解生物序列。基因组语言模型（gLMs）是在DNA序列上训练的大型语言模型，有望显著增进我们对基因组的理解，以及不同尺度的DNA元件如何相互作用以产生复杂功能。为展示这一潜力，我们重点介绍了基因组语言模型的关键应用，包括<code>功能约束预测</code>、<code>序列设计</code>和<code>迁移学习</code>。然而，尽管近期取得了显著进展，开发有效且高效的基因组语言模型仍面临诸多挑战，特别是对于具有大型复杂基因组的物种。在此，我们探讨了开发和评估基因组语言模型的主要考量因素。</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>人工智能&#x2F;机器学习（AI&#x2F;ML）的最新进展对广泛的科学学科产生了深远影响，彻底改变了建模、数据分析、解释和发现的方法。这一发展的关键支柱之一是自监督学习，通过在大量未标记数据上进行训练，模型能够学习复杂特征及其相互作用。这种范式尤其改变了自然语言处理领域，使人工智能模型在多个具有挑战性的任务上达到人类水平，包括翻译、语音识别，甚至回答标准化专业和学术考试中的问题。</p>\n<p>正如自然语言处理的目标是理解自然语言序列一样，计算生物学的一个主要目标是理解生物序列。因此，近年来人们对将自然语言处理中的现代技术应用于生物序列（DNA、RNA、蛋白质）产生了浓厚兴趣。特别是，蛋白质序列数据库（如UniProt）在过去十年中呈指数级增长，在这些海量数据上训练的蛋白质语言模型（pLMs）在复杂问题上取得了令人印象深刻的性能，例如结构预测和变异效应预测等记的蛋白质序列数据集有望包含重要的生物信息。</p>\n<p>类似地，在DNA序列上训练的大型语言模型（LLMs）有望改变基因组学，但为基因组开发有效的模型面临额外的挑战。例如，与作为功能重要单元且尺寸相对较小的蛋白质不同，大多数基因组要大得多，并且通常包含大量复杂的非功能区域，这些区域在数量上超过了功能元件。此外，与数亿个蛋白质序列相比，整个生命树中可用的全基因组序列数量极少，这限制了训练数据中功能重要的DNA元件的多样性。尽管存在这些问题，我们认为在基因组上训练的语言模型——即基因组语言模型（gLMs）——对生物学具有巨大潜力。在本文中，我们回顾了该领域的一些关键机遇和挑战，<u>并概述了开发和评估对基因组学界有用的基因组语言模型应解决的主要考量因素</u>。</p>\n<h2 id=\"2-应用\"><a href=\"#2-应用\" class=\"headerlink\" title=\"2 应用\"></a>2 应用</h2><p>语言模型的通用框架总结在<code>BOX 1</code>中。下面，我们详细阐述基因组语言模型的三个主要应用领域：功能约束预测、序列设计和迁移学习。</p>\n<h3 id=\"2-1-功能约束预测\"><a href=\"#2-1-功能约束预测\" class=\"headerlink\" title=\"2.1 功能约束预测\"></a>2.1 功能约束预测</h3><p>基因组语言模型一个有趣的应用是在无需任何任务监督的情况下预测基因组位点的功能约束。这种方法的一个显著优势是它不依赖于标记（例如某个变异是否致病），而标记通常数量有限且存在偏差。其核心思想是，参考基因组（通常来自健康个体）中有害变异的含量相对较低。因此，在这些数据上训练的模型倾向于给有害变异分配较低的概率。这一观察结果为使用<strong>两个等位基因之间的对数似然比</strong>（LLR）——即$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$——来估计它们的相对适应性提供了依据。</p>\n<p><font size=2 color='grey'><strong>BOX 1</strong>：通用语言模型框架</p>\n<p>从高层次来看，语言模型的训练目标是学习如下形式的条件概率分布：</p>\n<p>在掩码语言建模（MLM）中为 $(\\mathbb{P}[X_{i}|X_{- \\text{Masked}}])$（其中$(i \\in \\text{Masked})$），在因果语言建模（CLM）中为 $(\\mathbb{P}[X_{k}|X_{1:k-1}])$。这里，$(X&#x3D;(X_{1},X_{2},\\dots))$ 表示“标记”（如核苷酸或氨基酸）序列，“Masked”表示被掩码的位置集合。自然语言处理近期取得进展的关键在于，不再手动设计简单的上下文依赖参数模型，而是让数据自己说话，并通过利用强大的深度学习架构，随着观测数据的增加来拟合更复杂的模型。图1展示了用于DNA的语言建模框架。虽然模型训练的目的是利用未掩码位点的信息预测每个掩码位点的核苷酸，但它会学习位置特异性的上下文表示（称为嵌入，即一个高维向量），随后该向量会转换为在 ${A,C,G,T}$ 上的概率分布。这些嵌入和概率分布均具有位置特异性，可应用于基因组学中的许多问题。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1：基因组语言模型的训练和应用\"></p>\n<p><font size=2 color='grey'>左侧示意图展示了基因组语言模型的训练过程。两个等位基因之间的对数似然比（LLR，具体为$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$）是功能约束的良好无监督预测因子（功能约束预测）。通过从学习到的概率分布中采样，可以生成新的序列（序列设计）。输入序列中每个标记的向量表示（称为嵌入）可以被提取出来，并适配于不同的下游任务（迁移学习）。</font></p>\n<p>在蛋白质序列模型中，最初引入了使用对数似然比进行功能约束预测的方法，在预测错义变异效应方面取得了出色成果。将这种方法扩展到基因组范围，GPN首次使用基因组语言模型进行全基因组功能约束预测，在模式植物拟南芥（<em>Arabidopsis thaliana</em>）中取得了最先进的结果。为说明基因组语言模型如何预测功能约束，我们注意到基因组语言模型能够学习<code>转录因子结合位点（TFBS）基序</code>，理解哪些位置受到约束，哪些位置不受约束（<strong>图2a</strong>）。此外，尽管<code>GPN</code>模型仅在拟南芥的一个基因组上训练，但它的对数似然比得分与拟南芥自然种群中的等位基因频率相关（<strong>图2b</strong>）。随后，<code>AgroNT</code>和<code>PlantCaduceus</code>在其他植物物种中也取得了优异结果。然而，对于人类基因组，核苷酸转换器（NT）的对数似然比性能低于现有的基准模型。与此同时，<code>GPNMSA</code>利用跨多种脊椎动物物种的全基因组多序列比对（MSA），实现了最先进的性能。需要注意的是，<u>观察到的核苷酸分布不仅受功能约束驱动，还受突变偏差影响；将此信息明确纳入功能约束预测是未来研究的一个有前景的方向</u>。</p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2：应用示例\"></p>\n<p><font size=2 color='grey'>（a）基因组语言模型在启动子区域预测的序列标志图（顶部），突出显示了与假定功能性转录因子结合位点匹配的基序（底部序列标志图）。（b）变异次要等位基因频率（MAF）与基因组语言模型得分（对数似然比）之间的相关性。（c）基因组语言模型可以用不同的控制标签提示，设计在特定细胞类型中驱动高表达或低表达的启动子序列。（d）不同基因组窗口类别的基因组语言模型嵌入可视化，表明学习到的表示包含有用信息，如基因区域。注：面板a、b、d使用GPN模型生成。</font></p>\n<p>对于单核苷酸多态性（SNP），在掩码语言模型中只需对变异位置进行一次掩码查询即可计算对数似然比，而在因果语言模型中则需要对参考序列和替代序列进行两次查询。因果语言模型可以轻松处理多个替换、插入和缺失，而掩码语言模型必须采用更耗时的伪对数似然比方法。除对数似然比外，还提出了其他用于功能约束预测的得分，例如嵌入空间中的距离或突变周围位置核苷酸概率的变化。尽管对数似然比在蛋白质语言模型和基因组语言模型领域都被广泛使用，但深入理解这些替代得分在哪些场景下有用仍然很重要。</p>\n<p>基因组学中有两类主要的变异效应预测器：<strong>一类是功能约束预测器</strong>，包括基因组语言模型和传统的保守性得分；<strong>另一类是活性预测器</strong>，如基因表达预测器<code>Enformer</code>或剪接预测器<code>SpliceAI</code>。这两类模型存在关联：如果某个位点的变异受到选择，它会在某些情况下诱导活性变化（例如，在肢体发育过程中某个基因的转录变化），最终影响高级性状（例如，多指畸形）。功能约束模型涵盖了影响整体生物体适应性的所有可能机制和场景，而活性模型仅反映了它们明确训练过的机制和场景（某些数据，如人类大脑发育过程中的蛋白质表达，获取难度较大）。另一方面，活性模型可以指出变异发挥作用的特定机制和场景，而功能约束模型则不提供机制解释。</p>\n<p>关于功能性变异的优先排序，还有一些额外的考量。对于两个在不同基因中引起相似表达倍数变化的变异，即使它们的表达水平在生理耐受性上存在巨大差异，活性模型通常也会给出相似的得分。另一方面，不受可检测选择影响的性状仍可能具有科学或医学意义。在这种情况下，功能约束模型在优先排序影响该性状的变异方面能力有限，尤其是当这些变异效应量较小时（如在复杂性状全基因组关联研究（GWAS）中常见的情况）。然而，尽管基因组语言模型的对数似然比在这种情况下可能效果不佳，但基因组语言模型学习到的嵌入（<strong>BOX 1</strong>）在有标记数据的额外监督下仍可能具有价值。</p>\n<h3 id=\"2-2-序列设计\"><a href=\"#2-2-序列设计\" class=\"headerlink\" title=\"2.2 序列设计\"></a>2.2 序列设计</h3><p>设计新的生物序列对学术界和工业界研究团体都极具吸引力，因为它在药物发现与递送、农业改良、生物修复以及生物研究工具开发等方面具有巨大潜力。在此，我们描述使用<code>因果语言模型</code>（<strong>BOX 1</strong>）进行序列生成的方法，这是最常用的方法。具体而言，序列生成任务被分解为一系列下一个标记预测问题。从给定的序列片段（称为提示或控制标签）开始，语言模型可以递归地预测下一个标记，从而生成完整的新序列。蛋白质语言模型已被证明是蛋白质设计的强大工具。除编码序列外，非编码序列的设计也至关重要，因为它在基因和细胞治疗以及合成生物学等领域有应用。此类设计任务以前通过有监督的活性模型解决，但最近有多项研究探索使用基因组语言模型来应对这一挑战，如下所述。</p>\n<p><code>regLM</code>模型基于因果基因组语言模型<code>HyenaDNA</code>构建，用于<strong>从头生成启动子和增强子序列</strong>。HyenaDNA模型在带有前置控制标签的调控序列上进行训练或微调。然后，使用训练好的模型生成带有给定标签的新调控序列（<strong>图2c</strong>）。作者在酵母和人类细胞系中对生成序列的多样性和活性进行了计算评估，证明这些序列具有预期的功能以及真实且多样的序列特征。</p>\n<p>基因组语言模型在多模态设计任务中具有独特潜力，例如通过将蛋白质-RNA复合物统一为DNA序列设计来生成此类复合物。<u>例如，在原核生物基因组上训练的基因组语言模型EVO被用于设计新的CRISPR-Cas系统</u>。该模型使用带有前置Cas亚型特异性提示的CRISPR-Cas序列数据集进行微调。微调后的模型能够生成与亚型提示匹配的新CRISPR-Cas序列，且其预测结构与天然存在的系统相似。</p>\n<p>此外，<u>基因组语言模型还有可能用于在染色体或基因组尺度上设计有组织的功能性DNA序列</u>。最近，两个基因组语言模型<code>MegaDNA</code>和<code>EVO</code>探索了原核生物基因组的此类设计任务。EVO用于生成20个约650 Mbp大小的序列。研究发现，生成的序列具有真实的编码序列密度、具有预测二级结构和球状折叠的蛋白质序列，以及合理的tRNA序列。MegaDNA用于生成长达96 kbp的完整噬菌体基因组。除验证编码序列外，作者还在生成的序列中识别出包括启动子和核糖体结合位点在内的功能性调控元件。然而，此类大规模DNA序列设计任务仍然具有挑战性。研究发现，<u>EVO生成的序列缺乏功能原核生物基因组中通常存在的高度保守标记基因，且预测的蛋白质结构与天然蛋白质数据库的匹配度有限。最近的一项独立评估表明，MegaDNA生成的基因组序列组成与天然基因组仍有很大差异</u>。因此，需要进一步研究改进方法，以实现使用基因组语言模型从头设计完全功能性的基因组。</p>\n<h3 id=\"2-3-迁移学习\"><a href=\"#2-3-迁移学习\" class=\"headerlink\" title=\"2.3 迁移学习\"></a>2.3 迁移学习</h3><p>通过功能基因组学实验训练的用于预测注释的神经网络已被广泛用于解释基因组元件的功能。<u>一个重要的应用是预测变异对分子表型的影响，例如基因表达和剪接</u>。神经网络能够解释基因组位点之间复杂相互作用的能力，使其成为解决这些重要问题的必备工具，但合适的训练数据通常难以收集，因此数量有限。为了在预测任务上实现泛化，模型需要能够识别广泛的功能重要序列元件，这可能需要大量的数据和计算资源。为克服单个任务数据不足的限制，开发者采用了迁移学习方法——即利用在一个任务上训练模型获得的知识来改进相关任务性能的技术。具体而言，大多数用于预测功能注释的神经网络都经过训练以同时预测多种注释，迫使这些模型学习单一的统一表示。这进而提高了它们的泛化性能。</p>\n<p>语言模型也可用于迁移学习（有关迁移学习在自然语言处理中的应用，请参见<strong>BOX 2</strong>）。一种技术是特征提取：在学习预测核苷酸的上下文依赖分布时，基因组语言模型将输入的基因组序列转换为中间向量表示<strong>BOX 1</strong>）。这些表示可能提炼了相关信息，因此可用作另一个模型的特征。例如，<u>基因组语言模型嵌入的可视化显示，在没有任何监督的情况下，模型已经学会区分不同类别的基因组元件，如编码序列和非翻译区（<strong>图2d</strong>）</u>。不同层的嵌入可以为不同任务提供有用信息。利用语言模型进行迁移学习的另一种方法是将其用作预训练模型，即在下游任务上继续训练它们。这种技术称为微调。在某个任务上微调预训练的神经网络，会隐式地对其参数进行正则化，使得网络的预测综合了来自两个任务的知识。因此，对神经网络进行预训练通常会提高其在下游任务上的泛化性能。在最近的研究中，<code>SegmentNT</code>模型（通过微调核苷酸转换器（NT）基因组语言模型以实现<strong>基因和顺式调控元件注释</strong>任务而开发）在该任务上取得了最先进的性能。研究表明，使用预训练模型是其取得成功的关键。类似地，NT家族的另一个模型<code>AgroNT</code>在多种植物物种上进行预训练，然后在选定的作物物种上微调以预测染色质可及性和基因表达。<code>DNABERT-S</code>将对比学习与预训练的<code>DNABERT-2</code>嵌入相结合，用于<strong>宏基因组分箱</strong>。<code>IsoFormer</code>是DNA和蛋白质语言模型之间多模态迁移学习的一个例子，用于<strong>预测转录本亚型表达</strong>。这些最近的成功表明，微调后的基因组语言模型可能在各种基因组解释任务上取得显著进展。</p>\n<p>最近有两项研究评估了多个基因组语言模型在人类基因组预测任务中的性能，发现它们通常不会优于非基因组语言模型基准。这些结果基于冻结的嵌入；评估完整的微调过程将提供更多见解。尽管基因组语言模型已经非常适合展示迁移学习在研究较少的生物体中的价值，但要使其在人类遗传学（已有高质量标记数据和精心设计的模型）中提供显著价值，可能还需要进一步的创新。一个重要的问题是，缩放假设对基因组语言模型的适用程度如何，即增加未标记数据和计算资源在多大程度上能持续提高模型性能。最近的一项蛋白质语言模型研究发现，缩放仅改进了蛋白质结构预测，而没有改进大多数其他任务（如功能或性质预测），因此基因组语言模型任务也应受到同样的审视。</p>\n<p><font size=2 color='grey'> <strong>BOX 2</strong>：自然语言处理中的迁移学习<br>为了在大多数任务（包括情感分析、问答和词性标注等典型任务）上实现泛化，自然语言处理模型需要理解语法和语义。然而，这些任务的特定数据通常有限。利用在原始文本数据（来源于文章、书籍和网站）上训练的大型语言模型进行迁移学习，已在这些问题上取得了突破性进展。如今，几乎所有最先进的自然语言处理模型都是从大型语言模型改编而来。</font></p>\n<p>迁移学习技术是近年来自然语言模型蓬勃发展的基础。特别是，可广泛适配于下游任务的预训练模型（称为“基础模型”）的出现，使得机器学习模型的开发方式发生了重大转变。</p>\n<h2 id=\"3-开发\"><a href=\"#3-开发\" class=\"headerlink\" title=\"3 开发\"></a>3 开发</h2><p>现在，我们描述开发有用的基因组语言模型的关键组成部分；<strong>图3</strong>展示了总结开发流程的示意图。我们首先阐述选择和准备训练数据的重要性，然后讨论架构和训练决策，接着考虑基因组语言模型的解释和基准测试。我们的目标是<u>深入了解开发有效且高效的基因组语言模型所涉及的方法和挑战</u>。为全面展示该领域的当前状况，我们在<strong>表1</strong>中列出了一些我们已知的现有基因组语言模型，并总结了它们的设计决策。</p>\n<h3 id=\"3-1-训练数据\"><a href=\"#3-1-训练数据\" class=\"headerlink\" title=\"3.1 训练数据\"></a>3.1 训练数据</h3><p>机器学习模型的性能在很大程度上受其架构和训练数据的影响。卷积神经网络（CNNs）、Transformer 和状态空间模型（SSMs）等各种模型架构已成功应用于广泛的领域，包括自然语言、图像、音频、蛋白质和基因组学。然而，为预训练选择合适的数据需要对特定领域有深入的理解，尤其是<u>在基因组学领域，目前尚无类似于自然语言处理（如Pile）或蛋白质生物学（如UniProt）中那样被普遍接受的精选数据集</u>。</p>\n<p><strong>一个关键的考量因素是数据质量</strong>。例如，在自然语言处理中，数据质量可能指经过编辑或同行评审的数据源，如科学文章或书籍。<u>在蛋白质领域，质量控制包括去除预测的假基因或不再具有功能的截断蛋白质</u>。然而，最近的一项研究发现，作为最常用的基因组语言模型训练数据集（<strong>表1</strong>）的人类参考基因组中，仅有3.3%的碱基受到显著约束且可能具有功能。重要的是，<u>用于训练基因组语言模型的典型基因组序列既包含<code>功能位点</code>，也包含<code>非功能位点</code>，且通常无法将训练样本明确分为<code>高质量</code>和<code>低质量</code>两类</u>。一个提出的解决方案是根据功能证据对训练损失进行碱基级加权。</p>\n<p>在自然语言处理和蛋白质领域，<strong>过滤重复序列</strong>是标准做法，这有助于提高训练效率并减少记忆。尽管人类基因组中高达50%的序列是重复序列（在真核生物中这一比例普遍较高），但很少有基因组语言模型研究提出解决方案（如降低权重或下采样），甚至很少有研究承认这一问题。如果语言模型困惑度的研究也能分别报告非重复区域的困惑度，以区分泛化改进和记忆改进，那将很有启发意义。</p>\n<p><strong>另一个关键问题是如何确保数据量充足</strong>。单个基因组可能不足以训练大型模型，尤其是当非功能区域被下采样或降低权重时。一种方法是添加同一物种的序列变异。然而，在包括人类在内的许多物种中，个体之间的变异相对较少。更常用的方法是<code>跨多个物种进行训练</code>（<strong>表1</strong>），这与蛋白质语言模型的做法类似。随着物种亲缘关系的疏远，调控逻辑的分化速度快于蛋白质。一种提出的方法是<strong>将物种标识符作为额外输入明确添加到模型中</strong>。尽管如此，一个足够大的模型，在有足够基因组上下文的情况下，仍有可能自然地对远缘基因组进行建模，类似于大型语言模型处理多语言数据集的方式。</p>\n<p>如前所述，在原核生物中，已有模型（MegaDNA和EVO）将整个基因组作为上下文。目前，这在真核生物中还不可行，因此产生了<strong>如何将基因组划分为可单独建模的上下文窗口的问题</strong>。许多相互作用局限于邻近位置（如转录因子结合位点基序），这推动了具有相对较小上下文（&lt;6 kb）的模型的开发（**表1**）。然而，也存在明显的长程相互作用，例如同一基因的外显子之间或增强子与启动子之间（可达1 Mb）。如此长的上下文长度带来了计算和统计挑战，研究人员已在努力克服这些挑战。无论选择何种上下文长度，将基因组划分为独立单元（类似于按蛋白质划分蛋白质组的方式）仍然并非易事。例如，<u>一个基因的增强子可能位于另一个基因的内含子中，且多个基因可能由同一个增强子调控。尤其是在跨物种训练时，避免因直系同源和旁系同源导致的数据泄露非常具有挑战性</u>。</p>\n<p>训练数据的选择可能会显著影响基因组语言模型的输出和学习到的表示。自然界中观察到的DNA序列是各种进化过程的结果，其中最主要的是突变和选择。对于某些应用，可能需要精心选择训练数据，以突出这些过程中的某一个。例如，为了进行适应性预测，可能需要排除&#x2F;降低高突变位点（如CpG位点）和非功能区域（如某些类型的重复元件）的权重。</p>\n<h3 id=\"3-2-模型架构\"><a href=\"#3-2-模型架构\" class=\"headerlink\" title=\"3.2 模型架构\"></a>3.2 模型架构</h3><p>在Transformer架构出现之前，<code>卷积神经网络</code>模型已被广泛用于基因组学中的有监督任务。卷积神经网络通过对输入数据应用<code>过滤器</code>，特别<u>擅长捕捉基因组序列中的局部依赖关系和基序</u>。这些模型在预测<strong>DNA-蛋白质结合位点</strong>、<strong>调控元件</strong>和<strong>转录因子结合位点</strong>方面取得了成功。前面提到的用于拟南芥全基因组变异效应预测的基因组语言模型GPN，借鉴了自然语言处理和蛋白质建模中带有改进卷积神经网络层的语言模型的成功经验，用<code>扩张卷积神经网络层</code>替换了Transformer<code>编码器中的自注意力层</code>。</p>\n<p><code>Transformer</code>模型彻底改变了各种机器学习领域，尤其是自然语言处理，并且最近被广泛应用于基因组学建模。自注意力机制允许每个标记同时关注输入序列中的所有位置，使模型能够动态关注序列的相关部分。这种能力在有监督的基因表达任务中检测调控机制方面取得了显著进展。</p>\n<p>尽管Transformer模型具有优势，但它们在基因组学建模中面临一些独特的<strong>挑战</strong>。一个重要问题是，<u>Transformer对相互作用的局部性几乎没有或没有归纳偏置，这使得它们在建模转录因子结合位点等局部基序时数据效率较低</u>。这促使人们开发<strong>卷积神经网络-Transformer混合模型</strong>，如<code>LOGO</code>，其借鉴了<code>Enformer</code>等有监督模型的思路。</p>\n<p><strong>另一个挑战是上下文长度</strong>：自注意力机制导致<strong>计算时间和内存随输入序列长度呈二次方增长</strong>，这使得将Transformer应用于极长的基因组序列变得不切实际。因此，传统基于注意力的基因组语言模型目前能够处理的最长输入长度是<code>NT-v2的12 kb</code>。为解决这一限制，一些基于Transformer的基因组语言模型采用了<code>近似注意力</code>或<code>分层注意力</code>方法，牺牲了所有标记之间的完全成对注意力。这些方法包括在<code>GENA-LM</code>中使用稀疏注意力（将上下文长度扩展到<code>36 kb</code>），以及在<code>MegaDNA</code>中采用MEGABYTE亚二次方分层自注意力（实现<code>了96 kb</code>的上下文长度）。</p>\n<p>为克服自注意力的二次方缩放问题，人们提出了各种状态空间模型（SSMs）作为Transformer的高效替代方案，用于基因组语言模型，其<strong>计算复杂度随序列长度接近线性增长</strong>。基于·层次结构的<code>HyenaDNA</code>能够支持长达<code>100万</code>个核苷酸的输入上下文。<code>EVO</code>是一种结合了Hyena和Transformer架构的混合模型，在8 kb序列上进行预训练，然后在上下文扩展阶段使用<code>131 kb</code>序列进行微调。基于Mamba的状态空间模型构建的<code>Caduceus</code>在<code>131 kb</code>序列上进行训练，同时融入了反向互补等变。</p>\n<h3 id=\"3-3-学习目标\"><a href=\"#3-3-学习目标\" class=\"headerlink\" title=\"3.3 学习目标\"></a>3.3 学习目标</h3><p>如<strong>BOX 1</strong>所述，掩码语言模型（MLM）任务（有时也称为“掩码标记预测”）要求模型根据剩余标记预测以预定概率（通常为15%）随机掩码的标记身份。这一框架已用于训练开创性的大型语言模型BERT和蛋白质语言模型<code>ESM-1b</code>，此后被广泛用于训练基因组语言模型。因果语言模型（CLM）任务（也称为“自回归语言建模”或“下一个标记预测”）要求模型根据前面的标记预测序列中的标记；该任务已用于训练GPT系列大型语言模型。在该任务中，模型以单向从左到右的顺序，根据前面的标记预测下一个标记。这两个任务的共同点是，它们都要求模型根据其他组件作为上下文来预测数据的组件。为了在这些任务上实现泛化，模型必须学习数据的低维表示。这种能力使基因组语言模型能够通过捕捉基因组内的潜在模式和依赖关系来理解和生成基因组序列。<u>在蛋白质建模中，掩码语言模型在表示学习和迁移学习能力方面通常优于因果语言模型</u>。另一方面，因果语言模型是生成任务的传统选择，但最近通过渐进式掩码，掩码语言模型在生成任务上也取得了优异结果。</p>\n<p>为减少输入序列长度并建模更长的上下文，k-mer和字节对编码（BPE）创建了比天然核苷酸词汇表（{A,C,G,T}）更大的人工定义核苷酸词汇表。另一方面，单核苷酸标记化简化了模型解释和归因，并增强了模型处理基因组变异的能力。</p>\n<p>研究人员探索了对训练目标的多种修改，以提供额外的信号并提高性能。例如，<code>GPN-MSA</code>通过脊椎动物物种的全基因组多序列比对（MSA）增强了在人类参考基因组上的掩码语言模型训练，利用相关物种间的保守性获取额外上下文。其局限性在于，全基因组多序列比对仅针对某些物种生成，要在植物中有效应用可能需要进一步开发。此外，即使顺式调控元件的活性保守，其序列也可能快速分化，这限制了通过比对提取的直系同源信息。<code>Species LM</code>通过为每个酵母物种分配一个专用标记，并在训练和推理期间将物种标记附加到输入序列，直接整合了物种信息。核苷酸序列的预训练已扩展到支持与其他模态的交互，如表观遗传学、RNA、蛋白质和自然语言。</p>\n<h3 id=\"3-4-解释\"><a href=\"#3-4-解释\" class=\"headerlink\" title=\"3.4 解释\"></a>3.4 解释</h3><p>尽管深度学习模型在各种预测任务中取得了显著性能，但它们通常缺乏可解释性，常被视为“黑箱”。然而，理解这些模型如何生成预测对于实现更广泛的应用和推进模型开发至关重要。因此，研究人员开发了一系列解释深度学习模型的方法，包括专门针对基因组学的方法。尽管基因组语言模型的解释仍是一个新兴的研究方向，但已有研究表明，一些模型已经学习到了有意义的生物模式。</p>\n<p>从语言模型中提取的序列嵌入通常被用作捕捉丰富上下文信息和序列特征的表示。<u>对基因组语言模型编码的序列嵌入进行无监督聚类，发现输入序列形成了对应于不同基因组类别（如编码序列、内含子、非翻译区等）的明显聚类</u>（<strong>图2d</strong>）。此外，<u>对<code>SpliceBERT</code>嵌入的典型剪接位点和非剪接GT&#x2F;AG位点进行无监督聚类，发现了对应于这两组位点的明显聚类</u>。这些结果表明，模型已经学会捕捉表征基因组中功能元件的关键上下文模式。</p>\n<p>Transformer模型中的注意力机制旨在捕捉输入标记之间的交互模式。因此，解释给定输入序列的注意力权重或注意力图，可以揭示模型学习到的基因组特征。<u>在SpliceBERT中，剪接供体位点和受体位点之间的注意力权重显著高于随机位点对之间的注意力权重；此外，真实供体-受体对之间的交互强度往往高于其他供体和受体位点组合</u>。这些发现表明，模型已经学会了功能交互位点之间的关系。</p>\n<p>一些基因组语言模型还采用核苷酸重建方法来发现模型学习到的序列基序。具体而言，将输入序列的各个位置逐一掩码，然后由训练好的模型根据基因组上下文预测核苷酸的概率分布。每个位点获得的分布可以揭示模型学习到的基序。GPN中采用了这种方法，在重建核苷酸的分布中发现了显著模式。特别是，<strong>模型在功能重要位点的预测通常更有信心</strong>。例如，编码序列和剪接供体&#x2F;受体位点的预测信心通常高于深层内含子位点。此外，在编码序列中，密码子的第三个核苷酸位置（对翻译的氨基酸决定作用最小）的预测信心通常低于前两个核苷酸位置。通过适配<code>TF-MoDISco</code>（一种利用模型预测识别新转录因子结合位点的专用工具），作者还发现了与转录因子结合位点数据库和相关文献中已知基序匹配的序列基序（<strong>图2a</strong>）。类似地，Species LM重建的序列基序也与训练中未见过的物种中已知的DNA和RNA结合蛋白的结合位点匹配，基序重建的准确性取决于正确反映体内结合位点的上下文和基因组区域。此外，重建基序的组成、存在和位置表现出物种特异性模式，这表明<u>基因组语言模型可能成为研究序列基序和调控密码进化的强大工具</u>。</p>\n<p>最近，研究人员通过在某个位置引入点突变并量化其他位置核苷酸概率的变化，研究了基因组语言模型学习到的基因组位置之间的依赖关系。核苷酸依赖分析揭示了模型学习到的功能元件（如转录因子结合位点、剪接位点和RNA）内部和之间的相互作用，包括已知的二级和三级结构接触。值得注意的是，与之前基于预测边际概率分布的方法相比，核苷酸依赖分析能够更稳健地检测结合的转录因子结合位点。</p>\n<h3 id=\"3-5-评估\"><a href=\"#3-5-评估\" class=\"headerlink\" title=\"3.5 评估\"></a>3.5 评估</h3><p>在本节中，我们将讨论如何针对前面描述的三个应用领域对模型性能进行基准测试：预测等位基因的功能约束、生成新的可行序列以及迁移学习。</p>\n<p>有多种类型的数据可以反映等位基因的功能约束，可用于基准测试变异效应预测器。<strong>一类</strong>数据来自将<code>遗传变异的功能差异与读数</code>(readouts)（如报告基因的表达或细胞生长）相关联的实验。这些读数可用于对变异的功能性进行排序，由于影响功能的变异通常也受到选择，因此我们期望这些排序与模型预测的排序相关。这类数据的一个来源是<code>ProteinGym</code>，这是一个广泛使用的实验数据集集合，可用于基准测试错义变异效应预测器。<strong>另一类</strong>数据是<code>临床标记</code>，指示变异是否有致病证据（即是否会增加疾病风险）。致病性变异可能影响生育能力，因此可能具有有害性。因此，我们可以通过评估变异效应预测器作为致病性分类器的性能来对其进行基准测试。在人类遗传学中，变异临床标记的主要来源包括<code>ClinVar</code>、<code>HGMD</code>和<code>OMIM</code>数据库。<strong>第三类</strong>数据是<code>变异频率</code>。由于常见变异不太可能具有高度有害性，它们的预测约束水平应相对高于罕见变异。因此，我们可以根据预测器识别常见变异的能力对其进行基准测试。人类不同祖先群体中等位基因频率数据的主要来源是<code>gnomAD</code>数据库。总之，这些数据可以作为模型泛化性能的独立证据。</p>\n<p>变异效应预测器评估的一个问题是，验证数据与功能约束之间的关系可能不明确。因此，模型可能通过利用数据未能捕捉功能约束的方面在基准测试中表现出色。例如，使用临床标记的一个关键问题是，变异的分类基于是否有充分证据证明它们是良性的或致病性的。由于预测器也可能利用这些证据，它们在标记变异上的基准测试性能可能无法反映其在未标记变异上的真实性能（有关泛化性能的简要讨论，请参见<strong>BOX 3</strong>）。使用等位基因频率数据也存在关键问题：例如，除自然选择的直接作用外，等位基因频率还受突变率、遗传漂变、背景选择和遗传搭车等因素影响。因此，预测器可能通过预测这些过程的影响而非功能约束在基准测试中表现良好。这些问题凸显了需要仔细解释预测器性能原因的重要性，并促使人们呼吁提高预测器训练所使用的数据和方法的透明度。</p>\n<p>生成式序列模型的评估面临一系列独特挑战。评估语言模型生成能力的一种基本方法是比较它们在有效序列集上的困惑度。然而，要评估模型设计新序列的能力，需要衡量它们是否能够识别既可行又新颖的序列。因此，模型在测试集上的困惑度可能无法可靠地表明其在设计任务中的实用性。相反，可能需要采用全面的方法，检查生成序列的广泛特性。例如，最近用于调控序列设计的基准测试工具<code>Polygraph</code>提出了一系列分析方法，用于研究序列组成、基序模式和预测的功能活性。对于全基因组或染色体设计任务，可能还需要评估必需基因和功能性调控元件的存在和位置，以及它们之间的相互作用。最终，设计的序列需要通过实验评估，以确定它们是否能实现预期功能。</p>\n<p>最后，评估基因组语言模型在迁移学习中的性能面临一个独特挑战：任何基准测试集（可能需要结合多个基准测试集）都必须能够可靠地表明模型在相关任务上的性能。功能基因组学数据（如来自ENCODE或Roadmap表观基因组学项目的数据）可用于注释基因组区域和变异，这类数据可构建一系列任务，广泛反映模型适应基因组解释的能力。我们期望，模型在适应后从基因组序列预测这些注释的性能，能够表明其识别功能相似基因组元件的能力。为便于模型之间的比较，这些注释已被整合到各种标准化的训练和测试数据集集合中。</p>\n<p>由于迁移学习基准测试有助于凸显当前模型的局限性，并为发表建立标准，因此它们可能成为基因组语言模型开发者和用户的重要资产。然而，尽管当前基准测试在任务选择和方法上存在差异，但它们对基因组语言模型能力的见解似乎存在冗余。未来，计算基因组学界需要开发广泛认可的标准化且可扩展的基准测试。</p>\n<p><font size=2 color='grey'> <strong>BOX 3</strong>：评估泛化性能<br>评估预测模型的目的是建立对其泛化能力的信任，即对未标记数据做出令人满意的预测。估计模型泛化性能的一种直接且标准的方法是在代表目标未标记数据的标记“测试集”上评估其准确性。这种方法是大多数机器学习基准测试的基础。</p>\n<p>重要的是，为使这种评估成为泛化性能的可靠指标，不得向模型提供任何可用于区分测试集数据和最终部署数据的信息。否则，模型可能会以牺牲泛化性能为代价降低测试集误差。因此，通常会组织向参与者隐瞒测试数据的机器学习竞赛。<br></font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"表1：现有基因组语言模型总结\"></p>\n<p><font size=2 color='grey'>提供了各种基因组语言模型的概述，重点介绍了它们的预训练数据集、任务、架构、标记化方法和独特特征。模型按公开发布日期排序。缩写包括：SSM（状态空间模型）、CNN（卷积神经网络）、BPE（字节对编码）、CLM（因果语言建模）、MLM（掩码语言建模）。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3：开发流程\"></p>\n<p><font size=2 color='grey'>该图展示了本综述中描述的基因组语言模型通用开发流程，从模型构思到部署。我们首先选择和准备训练数据集，强调数据质量和数量的重要性（训练数据）。随后，在模型架构和学习目标部分，我们探讨了设计和训练基因组语言模型的各种选择，讨论了不同方法的优缺点。我们还研究了混合模型如何结合多种架构的元素以缓解特定局限性。在解释部分，我们讨论了分析和解释基因组语言模型输出的方法。最后，在评估部分，我们通过当前基准测试介绍了评估方法，强调了使模型性能与实际生物功能保持一致的复杂性。</font></p>\n<h2 id=\"4-结论与未来展望\"><a href=\"#4-结论与未来展望\" class=\"headerlink\" title=\"4 结论与未来展望\"></a>4 结论与未来展望</h2><p>在基因组序列数量庞大且不断增长的时代，基因组语言模型正成为提取复杂模式的强大工具，可应用于功能约束估计、序列设计和迁移学习等多个领域。然而，正如“人工智能”一词可能暗示的那样，它们尚未实现神奇的突然突破。相反，我们将其视为另一种有用的建模工具，类似于隐马尔可夫模型刚出现时的情况。基因组语言模型通常被称为“基础模型”，这一术语最近被创造出来，指在广泛数据上训练、可适应各种下游任务的模型。这一新术语的引入受到了批评，因为“基础”一词意味着在下游任务性能上有显著改进，而这是一个实证问题，而非预训练模型的固有属性。在基因组学等新领域，这种批评更为强烈，因为建立足够的基准测试可能需要一些时间。</p>\n<p>早期的基因组语言模型或多或少是自然语言处理模型的直接改编，我们期望通过深入结合基因组学专业知识，能获得最大的收益。我们注意到，评估基因组语言模型的能力具有挑战性，因为指标可能具有误导性，尤其是在过度优化的情况下。自然语言处理的一个优势是人类是自然语言的专家，因此可以根据自身专业知识校准基准测试。然而，在基因组学中，我们必须依靠数据和专家知识来验证模型。问题的这一方面使其特别具有挑战性，并可能意味着需要与领域专家合作，并有意识地进行实验以开发基准测试。在本综述的最后，我们提出了一些我们认为值得进一步研究的方向（列于未解决的问题中）。</p>\n<h3 id=\"未解决的问题\"><a href=\"#未解决的问题\" class=\"headerlink\" title=\"未解决的问题\"></a>未解决的问题</h3><ol>\n<li>如何最好地对从基序到基因再到全基因组的各种尺度模式进行建模？</li>\n<li>哪些应用需要对长程相互作用进行建模？如何确定合适的感受野大小？</li>\n<li>如何将结构变异纳入基因组语言模型？</li>\n<li>训练基因组语言模型时，利用群体遗传数据的最佳方式是什么？</li>\n<li>如何最好地将基因组语言模型与其他复杂模态（如转录组学和表观遗传学数据）整合？</li>\n<li>在开发基因组语言模型时，如何更好地理解为什么某些基因组比其他基因组更难建模？</li>\n<li>缩放假设对基因组语言模型是否成立？能成立多久？考虑到大多数数据可能是非功能性的，是否真的有足够的数据可用？</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>Gonzalo Benegas, Chengzhong Ye, Carlos Albors, Jianan Canal Li, Yun S. Song. arXiv:2407.11435v2. doi: <a href=\"https://doi.org/10.48550/arXiv.2407.11435\">https://doi.org/10.48550/arXiv.2407.11435</a></li>\n</ul>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”，聊天窗口回复“85d7”获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]}]}