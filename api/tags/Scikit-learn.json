{"name":"Scikit-learn","postlist":[{"title":"Scikit-learn机器学习实战-PCA","slug":"Scikit-learn机器学习实战-PCA","date":"2024-09-01T08:38:58.000Z","updated":"2024-09-01T09:07:23.418Z","comments":true,"path":"api/articles/Scikit-learn机器学习实战-PCA.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_5_0.png","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>PCA的全称是<strong>Principal Component Analysis</strong>，即主成分分析。这是一种常用的数据分析方法，主要用于数据降维。PCA的主要思想是将原始的高维特征空间通过线性变换投射到一个新的低维特征空间上，同时尽量保持原始数据的方差，使得在新的低维空间中数据的差异性得以保留。这一过程中，通过计算数据集的协方差矩阵，找到其特征值和特征向量，进而确定主成分的方向和贡献率，实现数据的有效降维。</p>\n<p>具体来说，PCA的计算过程包括以下几个步骤：</p>\n<ul>\n<li>数据标准化：将原始数据转换为均值为0，标准差为1的标准化数据，以消除不同量纲对分析结果的影响。</li>\n<li>计算协方差矩阵：标准化后的数据矩阵的协方差矩阵反映了各变量之间的相关性。</li>\n<li>计算特征值和特征向量：对协方差矩阵进行特征值分解，得到特征值和对应的特征向量。特征值的大小反映了对应主成分的重要性，而特征向量则指示了主成分的方向。</li>\n<li>选取主成分：根据特征值的大小，选取前k个主成分，使得这k个主成分的累计贡献率达到一定的阈值（如80%或90%）。</li>\n<li>转换数据到新的主成分空间：将原始数据转换到由选定的主成分构成的新空间中，得到降维后的数据。</li>\n</ul>\n<p>PCA在数据分析和机器学习领域有着广泛的应用，如特征提取、数据压缩、噪声消除、图像识别等。同时，PCA也是一种无监督学习的方法，它不需要数据的标签信息，就可以从数据中提取出有用的特征信息。</p>\n<p>本文通过鸢尾花数据集演示PCA方法，讲解如何确定降维采用的特征向量的数量，并完成降维。包括手写函数实现和通过SK-learn实现代码。</p>\n<h1 id=\"导入数据集\"><a href=\"#导入数据集\" class=\"headerlink\" title=\"导入数据集\"></a>导入数据集</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">url = <span class=\"string\">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class=\"line\">df = pd.read_csv(url)</span><br><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5.1</th>\n      <th>3.5</th>\n      <th>1.4</th>\n      <th>0.2</th>\n      <th>Iris-setosa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 添加列名，分别为 sepal_len, sepal_wid, petal_len, petal_wid, class</span></span><br><span class=\"line\"><span class=\"comment\"># 前四列为特征，最后一列为类别，共有3种类别</span></span><br><span class=\"line\">df.columns=[<span class=\"string\">&#x27;sepal_len&#x27;</span>, <span class=\"string\">&#x27;sepal_wid&#x27;</span>, <span class=\"string\">&#x27;petal_len&#x27;</span>, <span class=\"string\">&#x27;petal_wid&#x27;</span>, <span class=\"string\">&#x27;class&#x27;</span>]</span><br><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_len</th>\n      <th>sepal_wid</th>\n      <th>petal_len</th>\n      <th>petal_wid</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拆分特征和标签</span></span><br><span class=\"line\"></span><br><span class=\"line\">X = df.iloc[:,<span class=\"number\">0</span>:<span class=\"number\">4</span>].values</span><br><span class=\"line\">y = df.iloc[:,<span class=\"number\">4</span>].values</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h1><h2 id=\"特征展示\"><a href=\"#特征展示\" class=\"headerlink\" title=\"特征展示\"></a>特征展示</h2><p>查看特征的取值范围以及其和类别的关系。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入matplotlib库中的pyplot模块，用于绘图</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\"># 导入math库</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义一个字典，映射数字到鸢尾花的种类名称</span></span><br><span class=\"line\">label_dict = &#123;<span class=\"number\">1</span>: <span class=\"string\">&#x27;Iris-Setosa&#x27;</span>,</span><br><span class=\"line\">              <span class=\"number\">2</span>: <span class=\"string\">&#x27;Iris-Versicolor&#x27;</span>,</span><br><span class=\"line\">              <span class=\"number\">3</span>: <span class=\"string\">&#x27;Iris-Virgnica&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义一个字典，映射数字到鸢尾花的特征名称</span></span><br><span class=\"line\">feature_dict = &#123;<span class=\"number\">0</span>: <span class=\"string\">&#x27;sepal length [cm]&#x27;</span>,</span><br><span class=\"line\">                <span class=\"number\">1</span>: <span class=\"string\">&#x27;sepal width [cm]&#x27;</span>,</span><br><span class=\"line\">                <span class=\"number\">2</span>: <span class=\"string\">&#x27;petal length [cm]&#x27;</span>,</span><br><span class=\"line\">                <span class=\"number\">3</span>: <span class=\"string\">&#x27;petal width [cm]&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建一个8x6英寸的图像</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"><span class=\"comment\"># 循环绘制4个子图，每个子图代表一个特征的直方图</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> cnt <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">4</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 在图像中创建2x2的子图，并指定当前子图的位置</span></span><br><span class=\"line\">    plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, cnt+<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 遍历每种鸢尾花类别，绘制直方图</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> lab <span class=\"keyword\">in</span> (<span class=\"string\">&#x27;Iris-setosa&#x27;</span>, <span class=\"string\">&#x27;Iris-versicolor&#x27;</span>, <span class=\"string\">&#x27;Iris-virginica&#x27;</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 绘制指定特征的直方图，使用不同颜色和透明度区分不同类别</span></span><br><span class=\"line\">        plt.hist(X[y==lab, cnt],</span><br><span class=\"line\">                 label=lab,</span><br><span class=\"line\">                 bins=<span class=\"number\">10</span>,</span><br><span class=\"line\">                 alpha=<span class=\"number\">0.3</span>,)</span><br><span class=\"line\">    <span class=\"comment\"># 设置子图的x轴标签</span></span><br><span class=\"line\">    plt.xlabel(feature_dict[cnt])</span><br><span class=\"line\">    <span class=\"comment\"># 添加图例，用于标识不同类别的鸢尾花</span></span><br><span class=\"line\">    plt.legend(loc=<span class=\"string\">&#x27;upper right&#x27;</span>, fancybox=<span class=\"literal\">True</span>, fontsize=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 调整子图间的间距，使布局更加紧凑</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"><span class=\"comment\"># 显示绘制的图像</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_5_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_5_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<ul>\n<li>发现<code>花萼的长度</code>和<code>宽度</code>能够较好的区分3种类别。</li>\n<li>四个特征取值范围差异较大，需要进行标准化。</li>\n</ul>\n<h2 id=\"数据标准化\"><a href=\"#数据标准化\" class=\"headerlink\" title=\"数据标准化\"></a>数据标准化</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 进行数据标准化</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\">X_std = StandardScaler().fit_transform(X)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (X_std)</span><br></pre></td></tr></table></figure>\n\n<pre><code>[[-1.1483555  -0.11805969 -1.35396443 -1.32506301]\n [-1.3905423   0.34485856 -1.41098555 -1.32506301]\n [-1.51163569  0.11339944 -1.29694332 -1.32506301]\n [-1.02726211  1.27069504 -1.35396443 -1.32506301]\n [-0.54288852  1.9650724  -1.18290109 -1.0614657 ]\n [-1.51163569  0.8077768  -1.35396443 -1.19326436]\n [-1.02726211  0.8077768  -1.29694332 -1.32506301]\n [-1.75382249 -0.34951881 -1.35396443 -1.32506301]\n [-1.1483555   0.11339944 -1.29694332 -1.45686167]\n [-0.54288852  1.50215416 -1.29694332 -1.32506301]\n [-1.2694489   0.8077768  -1.23992221 -1.32506301]\n [-1.2694489  -0.11805969 -1.35396443 -1.45686167]\n [-1.87491588 -0.11805969 -1.52502777 -1.45686167]\n [-0.05851493  2.19653152 -1.46800666 -1.32506301]\n [-0.17960833  3.122368   -1.29694332 -1.0614657 ]\n [-0.54288852  1.9650724  -1.41098555 -1.0614657 ]\n [-0.90616871  1.03923592 -1.35396443 -1.19326436]\n [-0.17960833  1.73361328 -1.18290109 -1.19326436]\n [-0.90616871  1.73361328 -1.29694332 -1.19326436]\n [-0.54288852  0.8077768  -1.18290109 -1.32506301]\n [-0.90616871  1.50215416 -1.29694332 -1.0614657 ]\n [-1.51163569  1.27069504 -1.58204889 -1.32506301]\n [-0.90616871  0.57631768 -1.18290109 -0.92966704]\n [-1.2694489   0.8077768  -1.06885886 -1.32506301]\n [-1.02726211 -0.11805969 -1.23992221 -1.32506301]\n [-1.02726211  0.8077768  -1.23992221 -1.0614657 ]\n [-0.78507531  1.03923592 -1.29694332 -1.32506301]\n [-0.78507531  0.8077768  -1.35396443 -1.32506301]\n [-1.3905423   0.34485856 -1.23992221 -1.32506301]\n [-1.2694489   0.11339944 -1.23992221 -1.32506301]\n [-0.54288852  0.8077768  -1.29694332 -1.0614657 ]\n [-0.78507531  2.42799064 -1.29694332 -1.45686167]\n [-0.42179512  2.65944976 -1.35396443 -1.32506301]\n [-1.1483555   0.11339944 -1.29694332 -1.45686167]\n [-1.02726211  0.34485856 -1.46800666 -1.32506301]\n [-0.42179512  1.03923592 -1.41098555 -1.32506301]\n [-1.1483555   0.11339944 -1.29694332 -1.45686167]\n [-1.75382249 -0.11805969 -1.41098555 -1.32506301]\n [-0.90616871  0.8077768  -1.29694332 -1.32506301]\n [-1.02726211  1.03923592 -1.41098555 -1.19326436]\n [-1.63272909 -1.73827353 -1.41098555 -1.19326436]\n [-1.75382249  0.34485856 -1.41098555 -1.32506301]\n [-1.02726211  1.03923592 -1.23992221 -0.79786838]\n [-0.90616871  1.73361328 -1.06885886 -1.0614657 ]\n [-1.2694489  -0.11805969 -1.35396443 -1.19326436]\n [-0.90616871  1.73361328 -1.23992221 -1.32506301]\n [-1.51163569  0.34485856 -1.35396443 -1.32506301]\n [-0.66398191  1.50215416 -1.29694332 -1.32506301]\n [-1.02726211  0.57631768 -1.35396443 -1.32506301]\n [ 1.39460583  0.34485856  0.52773232  0.25652088]\n [ 0.66804545  0.34485856  0.41369009  0.38831953]\n [ 1.27351244  0.11339944  0.64177455  0.38831953]\n [-0.42179512 -1.73827353  0.12858453  0.12472222]\n [ 0.78913885 -0.58097793  0.47071121  0.38831953]\n [-0.17960833 -0.58097793  0.41369009  0.12472222]\n [ 0.54695205  0.57631768  0.52773232  0.52011819]\n [-1.1483555  -1.50681441 -0.27056327 -0.27067375]\n [ 0.91023225 -0.34951881  0.47071121  0.12472222]\n [-0.78507531 -0.81243705  0.07156341  0.25652088]\n [-1.02726211 -2.43265089 -0.15652104 -0.27067375]\n [ 0.06257847 -0.11805969  0.24262675  0.38831953]\n [ 0.18367186 -1.96973265  0.12858453 -0.27067375]\n [ 0.30476526 -0.34951881  0.52773232  0.25652088]\n [-0.30070172 -0.34951881 -0.09949993  0.12472222]\n [ 1.03132564  0.11339944  0.35666898  0.25652088]\n [-0.30070172 -0.11805969  0.41369009  0.38831953]\n [-0.05851493 -0.81243705  0.18560564 -0.27067375]\n [ 0.42585866 -1.96973265  0.41369009  0.38831953]\n [-0.30070172 -1.27535529  0.07156341 -0.1388751 ]\n [ 0.06257847  0.34485856  0.58475344  0.78371551]\n [ 0.30476526 -0.58097793  0.12858453  0.12472222]\n [ 0.54695205 -1.27535529  0.64177455  0.38831953]\n [ 0.30476526 -0.58097793  0.52773232 -0.00707644]\n [ 0.66804545 -0.34951881  0.29964787  0.12472222]\n [ 0.91023225 -0.11805969  0.35666898  0.25652088]\n [ 1.15241904 -0.58097793  0.58475344  0.25652088]\n [ 1.03132564 -0.11805969  0.69879566  0.65191685]\n [ 0.18367186 -0.34951881  0.41369009  0.38831953]\n [-0.17960833 -1.04389617 -0.15652104 -0.27067375]\n [-0.42179512 -1.50681441  0.0145423  -0.1388751 ]\n [-0.42179512 -1.50681441 -0.04247882 -0.27067375]\n [-0.05851493 -0.81243705  0.07156341 -0.00707644]\n [ 0.18367186 -0.81243705  0.75581678  0.52011819]\n [-0.54288852 -0.11805969  0.41369009  0.38831953]\n [ 0.18367186  0.8077768   0.41369009  0.52011819]\n [ 1.03132564  0.11339944  0.52773232  0.38831953]\n [ 0.54695205 -1.73827353  0.35666898  0.12472222]\n [-0.30070172 -0.11805969  0.18560564  0.12472222]\n [-0.42179512 -1.27535529  0.12858453  0.12472222]\n [-0.42179512 -1.04389617  0.35666898 -0.00707644]\n [ 0.30476526 -0.11805969  0.47071121  0.25652088]\n [-0.05851493 -1.04389617  0.12858453 -0.00707644]\n [-1.02726211 -1.73827353 -0.27056327 -0.27067375]\n [-0.30070172 -0.81243705  0.24262675  0.12472222]\n [-0.17960833 -0.11805969  0.24262675 -0.00707644]\n [-0.17960833 -0.34951881  0.24262675  0.12472222]\n [ 0.42585866 -0.34951881  0.29964787  0.12472222]\n [-0.90616871 -1.27535529 -0.44162661 -0.1388751 ]\n [-0.17960833 -0.58097793  0.18560564  0.12472222]\n [ 0.54695205  0.57631768  1.2690068   1.70630611]\n [-0.05851493 -0.81243705  0.75581678  0.91551417]\n [ 1.51569923 -0.11805969  1.21198569  1.17911148]\n [ 0.54695205 -0.34951881  1.04092235  0.78371551]\n [ 0.78913885 -0.11805969  1.15496457  1.31091014]\n [ 2.12116622 -0.11805969  1.61113348  1.17911148]\n [-1.1483555  -1.27535529  0.41369009  0.65191685]\n [ 1.75788602 -0.34951881  1.44007014  0.78371551]\n [ 1.03132564 -1.27535529  1.15496457  0.78371551]\n [ 1.63679263  1.27069504  1.32602791  1.70630611]\n [ 0.78913885  0.34485856  0.75581678  1.04731282]\n [ 0.66804545 -0.81243705  0.869859    0.91551417]\n [ 1.15241904 -0.11805969  0.98390123  1.17911148]\n [-0.17960833 -1.27535529  0.69879566  1.04731282]\n [-0.05851493 -0.58097793  0.75581678  1.57450745]\n [ 0.66804545  0.34485856  0.869859    1.4427088 ]\n [ 0.78913885 -0.11805969  0.98390123  0.78371551]\n [ 2.24225961  1.73361328  1.6681546   1.31091014]\n [ 2.24225961 -1.04389617  1.78219682  1.4427088 ]\n [ 0.18367186 -1.96973265  0.69879566  0.38831953]\n [ 1.27351244  0.34485856  1.09794346  1.4427088 ]\n [-0.30070172 -0.58097793  0.64177455  1.04731282]\n [ 2.24225961 -0.58097793  1.6681546   1.04731282]\n [ 0.54695205 -0.81243705  0.64177455  0.78371551]\n [ 1.03132564  0.57631768  1.09794346  1.17911148]\n [ 1.63679263  0.34485856  1.2690068   0.78371551]\n [ 0.42585866 -0.58097793  0.58475344  0.78371551]\n [ 0.30476526 -0.11805969  0.64177455  0.78371551]\n [ 0.66804545 -0.58097793  1.04092235  1.17911148]\n [ 1.63679263 -0.11805969  1.15496457  0.52011819]\n [ 1.87897942 -0.58097793  1.32602791  0.91551417]\n [ 2.48444641  1.73361328  1.49709126  1.04731282]\n [ 0.66804545 -0.58097793  1.04092235  1.31091014]\n [ 0.54695205 -0.58097793  0.75581678  0.38831953]\n [ 0.30476526 -1.04389617  1.04092235  0.25652088]\n [ 2.24225961 -0.11805969  1.32602791  1.4427088 ]\n [ 0.54695205  0.8077768   1.04092235  1.57450745]\n [ 0.66804545  0.11339944  0.98390123  0.78371551]\n [ 0.18367186 -0.11805969  0.58475344  0.78371551]\n [ 1.27351244  0.11339944  0.92688012  1.17911148]\n [ 1.03132564  0.11339944  1.04092235  1.57450745]\n [ 1.27351244  0.11339944  0.75581678  1.4427088 ]\n [-0.05851493 -0.81243705  0.75581678  0.91551417]\n [ 1.15241904  0.34485856  1.21198569  1.4427088 ]\n [ 1.03132564  0.57631768  1.09794346  1.70630611]\n [ 1.03132564 -0.11805969  0.81283789  1.4427088 ]\n [ 0.54695205 -1.27535529  0.69879566  0.91551417]\n [ 0.78913885 -0.11805969  0.81283789  1.04731282]\n [ 0.42585866  0.8077768   0.92688012  1.4427088 ]\n [ 0.06257847 -0.11805969  0.75581678  0.78371551]]\n</code></pre>\n<h1 id=\"确定特征向量的数量\"><a href=\"#确定特征向量的数量\" class=\"headerlink\" title=\"确定特征向量的数量\"></a>确定特征向量的数量</h1><h2 id=\"协方差矩阵\"><a href=\"#协方差矩阵\" class=\"headerlink\" title=\"协方差矩阵\"></a>协方差矩阵</h2><p>协方差是衡量两个变量总体误差的期望，用于描述两个变量之间的线性关系程度和方向。两个特征间的协方差值越大，表明其相关性越强。</p>\n<p>对于两个随机变量$X$和$Y$，其协方差$Cov(X,Y)$的计算公式为：</p>\n<p>$$Cov(X,Y) &#x3D; E[(X - E[X])(Y - E[Y])]$$</p>\n<p>其中，$E[X]$和$E[Y]$分别是$X$和$Y$的期望值（即均值）。</p>\n<p>在实际应用中，当我们只有样本数据时，我们通常使用样本协方差来估计总体协方差。对于包含$n$个样本点的数据集，样本协方差$s_{xy}$的计算公式为：</p>\n<p>$$s_{xy} &#x3D; \\frac{1}{n-1} \\sum_{i&#x3D;1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$</p>\n<p>其中，$x_i$和$y_i$是样本点，$\\bar{x}$和$\\bar{y}$分别是$X$和$Y$的样本均值，计算公式为：</p>\n<p>$$\\bar{x} &#x3D; \\frac{1}{n} \\sum_{i&#x3D;1}^{n} x_i$$</p>\n<p>$$\\bar{y} &#x3D; \\frac{1}{n} \\sum_{i&#x3D;1}^{n} y_i$$</p>\n<p>注意，在计算样本协方差时，分母是$n-1$而不是$n$，这是为了得到总体协方差的无偏估计。</p>\n<p><strong>以下命令二选一</strong>：</p>\n<ul>\n<li>构造函数计算协方差矩阵</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算特征向量的均值，用于中心化数据</span></span><br><span class=\"line\">mean_vec = np.mean(X_std, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算数据的协方差矩阵，用于理解特征之间的线性关系</span></span><br><span class=\"line\"><span class=\"comment\"># (X_std - mean_vec).T.dot((X_std - mean_vec) )计算的是(X_std - mean_vec)的矩阵乘法</span></span><br><span class=\"line\"><span class=\"comment\"># 除以(X_std.shape[0]-1)是为了获得一个无偏估计</span></span><br><span class=\"line\">cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[<span class=\"number\">0</span>]-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出协方差矩阵，以便于后续分析和使用</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Covariance matrix \\n%s&#x27;</span> %cov_mat)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Covariance matrix \n[[ 1.00675676 -0.10448539  0.87716999  0.82249094]\n [-0.10448539  1.00675676 -0.41802325 -0.35310295]\n [ 0.87716999 -0.41802325  1.00675676  0.96881642]\n [ 0.82249094 -0.35310295  0.96881642  1.00675676]]\n</code></pre>\n<ul>\n<li>使用numpy计算协方差矩阵</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;NumPy covariance matrix: \\n%s&#x27;</span> %np.cov(X_std.T))</span><br></pre></td></tr></table></figure>\n\n<pre><code>NumPy covariance matrix: \n[[ 1.00675676 -0.10448539  0.87716999  0.82249094]\n [-0.10448539  1.00675676 -0.41802325 -0.35310295]\n [ 0.87716999 -0.41802325  1.00675676  0.96881642]\n [ 0.82249094 -0.35310295  0.96881642  1.00675676]]\n</code></pre>\n<p>求协方差矩阵的特征向量和特征值。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 求协方差矩阵</span></span><br><span class=\"line\">cov_mat = np.cov(X_std.T)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 求协方差矩阵的特征向量，返回特征向量（eig_vecs）和特征值（eig_vals）</span></span><br><span class=\"line\">eig_vals, eig_vecs = np.linalg.eig(cov_mat)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Eigenvectors \\n%s&#x27;</span> %eig_vecs)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\nEigenvalues \\n%s&#x27;</span> %eig_vals)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Eigenvectors \n[[ 0.52308496 -0.36956962 -0.72154279  0.26301409]\n [-0.25956935 -0.92681168  0.2411952  -0.12437342]\n [ 0.58184289 -0.01912775  0.13962963 -0.80099722]\n [ 0.56609604 -0.06381646  0.63380158  0.52321917]]\n\nEigenvalues \n[2.92442837 0.93215233 0.14946373 0.02098259]\n</code></pre>\n<p>肉眼观察<code>Eigenvalues</code>，应当取前2个特征值对应的特征向量，因为其最重要。</p>\n<p>创建一个包含特征值和对应特征向量的元组列表。按特征值降序排序这些元组。打印排序后的特征值，确认排序正确。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Make a list of (eigenvalue, eigenvector) tuples</span></span><br><span class=\"line\">eig_pairs = [(np.<span class=\"built_in\">abs</span>(eig_vals[i]), eig_vecs[:,i]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(eig_vals))]</span><br><span class=\"line\"><span class=\"built_in\">print</span> (eig_pairs)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">&#x27;----------&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># Sort the (eigenvalue, eigenvector) tuples from high to low</span></span><br><span class=\"line\">eig_pairs.sort(key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">0</span>], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Visually confirm that the list is correctly sorted by decreasing eigenvalues</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Eigenvalues in descending order:&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> eig_pairs:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(i[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n\n<pre><code>[(np.float64(2.9244283691111117), array([ 0.52308496, -0.25956935,  0.58184289,  0.56609604])), (np.float64(0.9321523302535062), array([-0.36956962, -0.92681168, -0.01912775, -0.06381646])), (np.float64(0.14946373489813364), array([-0.72154279,  0.2411952 ,  0.13962963,  0.63380158])), (np.float64(0.020982592764271016), array([ 0.26301409, -0.12437342, -0.80099722,  0.52321917]))]\n----------\nEigenvalues in descending order:\n2.9244283691111117\n0.9321523302535062\n0.14946373489813364\n0.020982592764271016\n</code></pre>\n<p>计算累计变异解释百分比，以评估前几个主成分能解释的总变异比例。最后输出累计变异解释百分比。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算所有特征值的总和</span></span><br><span class=\"line\">tot = <span class=\"built_in\">sum</span>(eig_vals)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算每个特征值占总和的百分比，并按降序排序</span></span><br><span class=\"line\"><span class=\"comment\"># 这一步的目的是确定每个特征值在总变异中所占的百分比</span></span><br><span class=\"line\">var_exp = [(i / tot)*<span class=\"number\">100</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(eig_vals, reverse=<span class=\"literal\">True</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出每个特征值的变异解释百分比</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(var_exp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算累计变异解释百分比</span></span><br><span class=\"line\"><span class=\"comment\"># 这一步是为了了解前几个主成分可以解释多少总变异</span></span><br><span class=\"line\">cum_var_exp = np.cumsum(var_exp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 累计变异解释百分比</span></span><br><span class=\"line\">cum_var_exp</span><br></pre></td></tr></table></figure>\n\n\n<p>  [np.float64(72.62003332692032), np.float64(23.147406858644143), np.float64(3.711515564584531), np.float64(0.5210442498510259)]</p>\n<p>  array([ 72.62003333,  95.76744019,  99.47895575, 100.        ])</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 演示np.cumsum() 函数的用法</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span> (a)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">&#x27;-----------&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (np.cumsum(a)) <span class=\"comment\"># 元素的累加和</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>[1 2 3 4]\n-----------\n[ 1  3  6 10]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 绘制特征值的重要性</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.bar(<span class=\"built_in\">range</span>(<span class=\"number\">4</span>), var_exp, alpha=<span class=\"number\">0.5</span>, align=<span class=\"string\">&#x27;center&#x27;</span>,</span><br><span class=\"line\">            label=<span class=\"string\">&#x27;individual explained variance&#x27;</span>)</span><br><span class=\"line\">plt.step(<span class=\"built_in\">range</span>(<span class=\"number\">4</span>), cum_var_exp, where=<span class=\"string\">&#x27;mid&#x27;</span>,</span><br><span class=\"line\">             label=<span class=\"string\">&#x27;cumulative explained variance&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Explained variance ratio&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Principal components&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_20_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_20_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>根据上图可以决定取几个特征值进行降维，此例中前两个特征值已经足够（~95.77%）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 根据前两个主要成分构造转换矩阵W</span></span><br><span class=\"line\"><span class=\"comment\"># 选择主要成分分析（PCA）得到的前两个特征向量</span></span><br><span class=\"line\"><span class=\"comment\"># 将特征向量重塑为4x1的矩阵形式，以便进行矩阵操作</span></span><br><span class=\"line\"><span class=\"comment\"># 这两个特征向量代表了数据中方差最大的两个方向</span></span><br><span class=\"line\">matrix_w = np.hstack((eig_pairs[<span class=\"number\">0</span>][<span class=\"number\">1</span>].reshape(<span class=\"number\">4</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                      eig_pairs[<span class=\"number\">1</span>][<span class=\"number\">1</span>].reshape(<span class=\"number\">4</span>,<span class=\"number\">1</span>)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印转换矩阵W，以便于查看和验证结果</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Matrix W:\\n&#x27;</span>, matrix_w)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Matrix W:\n [[ 0.52308496 -0.36956962]\n [-0.25956935 -0.92681168]\n [ 0.58184289 -0.01912775]\n [ 0.56609604 -0.06381646]]\n</code></pre>\n<h1 id=\"矩阵降维\"><a href=\"#矩阵降维\" class=\"headerlink\" title=\"矩阵降维\"></a>矩阵降维</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 标准化数据X_std与权重矩阵matrix_w进行点积运算，用于特征提取和数据转换</span></span><br><span class=\"line\">Y = X_std.dot(matrix_w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出转换后的数据Y</span></span><br><span class=\"line\">Y</span><br></pre></td></tr></table></figure>\n\n\n\n\n<pre><code>array([[-2.10795032,  0.64427554],\n       [-2.38797131,  0.30583307],\n       [-2.32487909,  0.56292316],\n       [-2.40508635, -0.687591  ],\n       [-2.08320351, -1.53025171],\n       [-2.4636848 , -0.08795413],\n       [-2.25174963, -0.25964365],\n       [-2.3645813 ,  1.08255676],\n       [-2.20946338,  0.43707676],\n       [-2.17862017, -1.08221046],\n       [-2.34525657, -0.17122946],\n       [-2.24590315,  0.6974389 ],\n       [-2.66214582,  0.92447316],\n       [-2.2050227 , -1.90150522],\n       [-2.25993023, -2.73492274],\n       [-2.21591283, -1.52588897],\n       [-2.20705382, -0.52623535],\n       [-1.9077081 , -1.4415791 ],\n       [-2.35411558, -1.17088308],\n       [-1.93202643, -0.44083479],\n       [-2.21942518, -0.96477499],\n       [-2.79116421, -0.50421849],\n       [-1.83814105, -0.11729122],\n       [-2.24572458, -0.17450151],\n       [-1.97825353,  0.59734172],\n       [-2.06935091, -0.27755619],\n       [-2.18514506, -0.56366755],\n       [-2.15824269, -0.34805785],\n       [-2.28843932,  0.30256102],\n       [-2.16501749,  0.47232759],\n       [-1.8491597 , -0.45547527],\n       [-2.62023392, -1.84237072],\n       [-2.44885384, -2.1984673 ],\n       [-2.20946338,  0.43707676],\n       [-2.23112223,  0.17266644],\n       [-2.06147331, -0.6957435 ],\n       [-2.20946338,  0.43707676],\n       [-2.45783833,  0.86912843],\n       [-2.1884075 , -0.30439609],\n       [-2.30357329, -0.48039222],\n       [-1.89932763,  2.31759817],\n       [-2.57799771,  0.4400904 ],\n       [-1.98020921, -0.50889705],\n       [-2.14679556, -1.18365675],\n       [-2.09668176,  0.68061705],\n       [-2.39554894, -1.16356284],\n       [-2.41813611,  0.34949483],\n       [-2.24196231, -1.03745802],\n       [-2.22484727, -0.04403395],\n       [ 1.09225538, -0.86148748],\n       [ 0.72045861, -0.59920238],\n       [ 1.2299583 , -0.61280832],\n       [ 0.37598859,  1.756516  ],\n       [ 1.05729685,  0.21303055],\n       [ 0.36816104,  0.58896262],\n       [ 0.73800214, -0.77956125],\n       [-0.52021731,  1.84337921],\n       [ 0.9113379 , -0.02941906],\n       [-0.01292322,  1.02537703],\n       [-0.15020174,  2.65452146],\n       [ 0.42437533,  0.05686991],\n       [ 0.52894687,  1.77250558],\n       [ 0.70241525,  0.18484154],\n       [-0.05385675,  0.42901221],\n       [ 0.86277668, -0.50943908],\n       [ 0.33388091,  0.18785518],\n       [ 0.13504146,  0.7883247 ],\n       [ 1.19457128,  1.63549265],\n       [ 0.13677262,  1.30063807],\n       [ 0.72711201, -0.40394501],\n       [ 0.45564294,  0.41540628],\n       [ 1.21038365,  0.94282042],\n       [ 0.61327355,  0.4161824 ],\n       [ 0.68512164,  0.06335788],\n       [ 0.85951424, -0.25016762],\n       [ 1.23906722,  0.08500278],\n       [ 1.34575245, -0.32669695],\n       [ 0.64732915,  0.22336443],\n       [-0.06728496,  1.05414028],\n       [ 0.10033285,  1.56100021],\n       [-0.00745518,  1.57050182],\n       [ 0.2179082 ,  0.77368423],\n       [ 1.04116321,  0.63744742],\n       [ 0.20719664,  0.27736006],\n       [ 0.42154138, -0.85764157],\n       [ 1.03691937, -0.52112206],\n       [ 1.015435  ,  1.39413373],\n       [ 0.0519502 ,  0.20903977],\n       [ 0.25582921,  1.32747797],\n       [ 0.25384813,  1.11700714],\n       [ 0.60915822, -0.02858679],\n       [ 0.31116522,  0.98711256],\n       [-0.39679548,  2.01314578],\n       [ 0.26536661,  0.85150613],\n       [ 0.07385897,  0.17160757],\n       [ 0.20854936,  0.37771566],\n       [ 0.55843737,  0.15286277],\n       [-0.47853403,  1.53421644],\n       [ 0.23545172,  0.59332536],\n       [ 1.8408037 , -0.86943848],\n       [ 1.13831104,  0.70171953],\n       [ 2.19615974, -0.54916658],\n       [ 1.42613827,  0.05187679],\n       [ 1.8575403 , -0.28797217],\n       [ 2.74511173, -0.78056359],\n       [ 0.34010583,  1.5568955 ],\n       [ 2.29180093, -0.40328242],\n       [ 1.98618025,  0.72876171],\n       [ 2.26382116, -1.91685818],\n       [ 1.35591821, -0.69255356],\n       [ 1.58471851,  0.43102351],\n       [ 1.87342402, -0.41054652],\n       [ 1.23656166,  1.16818977],\n       [ 1.45128483,  0.4451459 ],\n       [ 1.58276283, -0.67521526],\n       [ 1.45956552, -0.25105642],\n       [ 2.43560434, -2.55096977],\n       [ 3.29752602,  0.01266612],\n       [ 1.23377366,  1.71954411],\n       [ 2.03218282, -0.90334021],\n       [ 0.95980311,  0.57047585],\n       [ 2.88717988, -0.38895776],\n       [ 1.31405636,  0.48854962],\n       [ 1.69619746, -1.01153249],\n       [ 1.94868773, -0.99881497],\n       [ 1.1574572 ,  0.31987373],\n       [ 1.007133  , -0.06550254],\n       [ 1.7733922 ,  0.19641059],\n       [ 1.85327106, -0.55077372],\n       [ 2.4234788 , -0.2397454 ],\n       [ 2.31353522, -2.62038074],\n       [ 1.84800289,  0.18799967],\n       [ 1.09649923,  0.29708201],\n       [ 1.1812503 ,  0.81858241],\n       [ 2.79178861, -0.83668445],\n       [ 1.57340399, -1.07118383],\n       [ 1.33614369, -0.420823  ],\n       [ 0.91061354, -0.01965942],\n       [ 1.84350913, -0.66872729],\n       [ 2.00701161, -0.60663655],\n       [ 1.89319854, -0.68227708],\n       [ 1.13831104,  0.70171953],\n       [ 2.03519535, -0.86076914],\n       [ 1.99464025, -1.04517619],\n       [ 1.85977129, -0.37934387],\n       [ 1.54200377,  0.90808604],\n       [ 1.50925493, -0.26460621],\n       [ 1.3690965 , -1.01583909],\n       [ 0.94680339,  0.02182097]])\n</code></pre>\n<p>查看降维前的区分表现。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> lab, col <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>((<span class=\"string\">&#x27;Iris-setosa&#x27;</span>, <span class=\"string\">&#x27;Iris-versicolor&#x27;</span>, <span class=\"string\">&#x27;Iris-virginica&#x27;</span>),</span><br><span class=\"line\">                        (<span class=\"string\">&#x27;blue&#x27;</span>, <span class=\"string\">&#x27;red&#x27;</span>, <span class=\"string\">&#x27;green&#x27;</span>)):</span><br><span class=\"line\">     plt.scatter(X[y==lab, <span class=\"number\">0</span>],</span><br><span class=\"line\">                X[y==lab, <span class=\"number\">1</span>],</span><br><span class=\"line\">                label=lab,</span><br><span class=\"line\">                c=col)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;sepal_len&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;sepal_wid&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_26_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_26_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>查看降维后的区分表现。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize=(<span class=\"number\">6</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"><span class=\"keyword\">for</span> lab, col <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>((<span class=\"string\">&#x27;Iris-setosa&#x27;</span>, <span class=\"string\">&#x27;Iris-versicolor&#x27;</span>, <span class=\"string\">&#x27;Iris-virginica&#x27;</span>),</span><br><span class=\"line\">                        (<span class=\"string\">&#x27;blue&#x27;</span>, <span class=\"string\">&#x27;red&#x27;</span>, <span class=\"string\">&#x27;green&#x27;</span>)):</span><br><span class=\"line\">     plt.scatter(Y[y==lab, <span class=\"number\">0</span>],</span><br><span class=\"line\">                Y[y==lab, <span class=\"number\">1</span>],</span><br><span class=\"line\">                label=lab,</span><br><span class=\"line\">                c=col)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Principal Component 1&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Principal Component 2&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;lower center&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_28_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_28_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h1 id=\"利用SK-LEARN-PCA进行降维\"><a href=\"#利用SK-LEARN-PCA进行降维\" class=\"headerlink\" title=\"利用SK-LEARN PCA进行降维\"></a>利用SK-LEARN PCA进行降维</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 加载鸢尾花数据集</span></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X = iris.data</span><br><span class=\"line\">y = iris.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 数据标准化</span></span><br><span class=\"line\">scaler = StandardScaler()</span><br><span class=\"line\">X_std = scaler.fit_transform(X)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 应用PCA降维</span></span><br><span class=\"line\">pca = PCA()</span><br><span class=\"line\">X_pca = pca.fit_transform(X_std)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 计算特征值总和</span></span><br><span class=\"line\">tot = <span class=\"built_in\">sum</span>(pca.explained_variance_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 计算每个特征值占总和的百分比，并按降序排序</span></span><br><span class=\"line\">var_exp = [(i / tot) * <span class=\"number\">100</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">sorted</span>(pca.explained_variance_, reverse=<span class=\"literal\">True</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 6. 输出每个特征值的变异解释百分比</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;变异解释百分比:&quot;</span>, var_exp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 7. 计算累计变异解释百分比</span></span><br><span class=\"line\">cum_var_exp = np.cumsum(var_exp)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 8. 输出累计变异解释百分比</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;累计变异解释百分比:&quot;</span>, cum_var_exp)</span><br></pre></td></tr></table></figure>\n\n<pre><code>变异解释百分比: [np.float64(72.96244541329987), np.float64(22.850761786701742), np.float64(3.668921889282886), np.float64(0.5178709107154782)]\n累计变异解释百分比: [ 72.96244541  95.8132072   99.48212909 100.        ]\n</code></pre>\n<p>由上述结果同样可见，前两个特征向量累计贡献的方差为95.81%，故取前2个特征向量。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 应用PCA降维到2个主成分</span></span><br><span class=\"line\">pca = PCA(n_components=<span class=\"number\">2</span>)</span><br><span class=\"line\">X_pca = pca.fit_transform(X_std)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 绘制PCA图</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为不同的类别绘制不同颜色的点</span></span><br><span class=\"line\">colors = [<span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>]</span><br><span class=\"line\">markers = [<span class=\"string\">&#x27;s&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>, <span class=\"string\">&#x27;o&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, color, marker <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(<span class=\"built_in\">range</span>(<span class=\"number\">3</span>), colors, markers):</span><br><span class=\"line\">    plt.scatter(x=X_pca[y == idx, <span class=\"number\">0</span>], </span><br><span class=\"line\">                y=X_pca[y == idx, <span class=\"number\">1</span>],</span><br><span class=\"line\">                c=color, </span><br><span class=\"line\">                marker=marker,</span><br><span class=\"line\">                label=iris.target_names[idx])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加标题和标签</span></span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;PCA of Iris Dataset&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Principal Component 1&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Principal Component 2&#x27;</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.grid(<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 显示图形</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_32_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/PCA_files/PCA_32_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h1 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h1><p>关注公众号“生信之巅”，获取更多教程。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n\n\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"AI","path":"api/categories/AI.json"}],"tags":[{"name":"机器学习","path":"api/tags/机器学习.json"},{"name":"Scikit-learn","path":"api/tags/Scikit-learn.json"}]},{"title":"Scikit-learn机器学习实战-HumanResourcesAnalytics","slug":"Scikit-learn机器学习实战-HumanResourcesAnalytics","date":"2024-08-30T14:24:05.000Z","updated":"2024-08-30T14:59:29.868Z","comments":true,"path":"api/articles/Scikit-learn机器学习实战-HumanResourcesAnalytics.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_10_0.png","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>本文构建预测员工是否会离职的模型，并使用模型对员工进行预测。通过本文可以学习到：</p>\n<ul>\n<li>查看数据集的统计信息</li>\n<li>特征工程</li>\n<li>数据集的划分</li>\n<li>数据集的预处理</li>\n<li>数据集的可视化</li>\n<li>模型训练</li>\n<li>模型调参</li>\n<li>模型评估</li>\n<li>模型预测</li>\n</ul>\n<h1 id=\"查看数据集信息\"><a href=\"#查看数据集信息\" class=\"headerlink\" title=\"查看数据集信息\"></a>查看数据集信息</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据</span></span><br><span class=\"line\">url = <span class=\"string\">&#x27;https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/data/ML/HumanResourcesAnalytics/HR_comma_sep.csv&#x27;</span></span><br><span class=\"line\">df = pd.read_csv(url)</span><br><span class=\"line\"><span class=\"comment\">#df = pd.read_csv(&#x27;HR_comma_sep.csv&#x27;)</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.info()) <span class=\"comment\">#474241623</span></span><br><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n\n<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 14999 entries, 0 to 14998\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   satisfaction_level     14999 non-null  float64\n 1   last_evaluation        14999 non-null  float64\n 2   number_project         14999 non-null  int64  \n 3   average_montly_hours   14999 non-null  int64  \n 4   time_spend_company     14999 non-null  int64  \n 5   Work_accident          14999 non-null  int64  \n 6   left                   14999 non-null  int64  \n 7   promotion_last_5years  14999 non-null  int64  \n 8   sales                  14999 non-null  object \n 9   salary                 14999 non-null  object \ndtypes: float64(2), int64(6), object(2)\nmemory usage: 1.1+ MB\nNone\n</code></pre>\n<div style=\"overflow-x: auto; width: 100%;\">\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n</head>\n<body>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n      <th>sales</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<p><strong>header 信息</strong></p>\n<ul>\n<li>satisfaction_level\t员工满意度</li>\n<li>last_evaluation\t员工考核评分</li>\n<li>number_project\t员工参与的项目数</li>\n<li>average_montly_hours\t每个月均工作时长</li>\n<li>time_spend_company\t员工工作年限</li>\n<li>Work_accident\t是否发生过事故</li>\n<li>left\t员工是否离职</li>\n<li>promotion_last_5years\t过去5年中是否有升职</li>\n<li>sales\t员工岗位</li>\n<li>salary 员工薪资水平</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 更正列名</span></span><br><span class=\"line\">df.rename(columns=&#123;<span class=\"string\">&#x27;average_montly_hours&#x27;</span>:<span class=\"string\">&#x27;average_monthly_hours&#x27;</span>, <span class=\"string\">&#x27;sales&#x27;</span>:<span class=\"string\">&#x27;department&#x27;</span>&#125;, </span><br><span class=\"line\">          inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\">df.head()</span><br></pre></td></tr></table></figure>\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_monthly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n      <th>department</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 展示数据集的统计信息，仅展示数值列</span></span><br><span class=\"line\">df.describe()</span><br></pre></td></tr></table></figure>\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_monthly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.612834</td>\n      <td>0.716102</td>\n      <td>3.803054</td>\n      <td>201.050337</td>\n      <td>3.498233</td>\n      <td>0.144610</td>\n      <td>0.238083</td>\n      <td>0.021268</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.248631</td>\n      <td>0.171169</td>\n      <td>1.232592</td>\n      <td>49.943099</td>\n      <td>1.460136</td>\n      <td>0.351719</td>\n      <td>0.425924</td>\n      <td>0.144281</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.090000</td>\n      <td>0.360000</td>\n      <td>2.000000</td>\n      <td>96.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.440000</td>\n      <td>0.560000</td>\n      <td>3.000000</td>\n      <td>156.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.640000</td>\n      <td>0.720000</td>\n      <td>4.000000</td>\n      <td>200.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.820000</td>\n      <td>0.870000</td>\n      <td>5.000000</td>\n      <td>245.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>310.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看各元素的出现次数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">&#x27;Departments:&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (df[<span class=\"string\">&#x27;department&#x27;</span>].value_counts())</span><br><span class=\"line\"><span class=\"built_in\">print</span> (<span class=\"string\">&#x27;\\nSalary:&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (df[<span class=\"string\">&#x27;salary&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>\n\n<pre><code>Departments:\ndepartment\nsales          4140\ntechnical      2720\nsupport        2229\nIT             1227\nproduct_mng     902\nmarketing       858\nRandD           787\naccounting      767\nhr              739\nmanagement      630\nName: count, dtype: int64\n\nSalary:\nsalary\nlow       7316\nmedium    6446\nhigh      1237\nName: count, dtype: int64\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 记录各特征的类型和取值范围</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">satisfaction_level | Satisfaction level of employee based on survey | Continuous | [0.09, 1]</span></span><br><span class=\"line\"><span class=\"string\">last_evaluation | Score based on employee&#x27;s last evaluation | Continuous | [0.36, 1]</span></span><br><span class=\"line\"><span class=\"string\">number_project | Number of projects | Continuous | [2, 7]</span></span><br><span class=\"line\"><span class=\"string\">average_monthly_hours | Average monthly hours | Continuous | [96, 310]</span></span><br><span class=\"line\"><span class=\"string\">time_spend_company | Years at company | Continuous | [2, 10]</span></span><br><span class=\"line\"><span class=\"string\">Work_accident | Whether employee had a work accident | Categorical | &#123;0, 1&#125;</span></span><br><span class=\"line\"><span class=\"string\">left | Whether employee had left (Outcome Variable) | Categorical | &#123;0, 1&#125;</span></span><br><span class=\"line\"><span class=\"string\">promotion_last_5years | Whether employee had a promotion in the last 5 years | Categorical | &#123;0, 1&#125;</span></span><br><span class=\"line\"><span class=\"string\">department | Department employee worked in | Categorical | 10 departments</span></span><br><span class=\"line\"><span class=\"string\">salary | Level of employee&#x27;s salary | Categorical | &#123;low, medium, high&#125;</span></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;\\nsatisfaction_level | Satisfaction level of employee based on survey | Continuous | [0.09, 1]\\nlast_evaluation | Score based on employee&#x27;s last evaluation | Continuous | [0.36, 1]\\nnumber_project | Number of projects | Continuous | [2, 7]\\naverage_monthly_hours | Average monthly hours | Continuous | [96, 310]\\ntime_spend_company | Years at company | Continuous | [2, 10]\\nWork_accident | Whether employee had a work accident | Categorical | &#123;0, 1&#125;\\nleft | Whether employee had left (Outcome Variable) | Categorical | &#123;0, 1&#125;\\npromotion_last_5years | Whether employee had a promotion in the last 5 years | Categorical | &#123;0, 1&#125;\\ndepartment | Department employee worked in | Categorical | 10 departments\\nsalary | Level of employee&#x27;s salary | Categorical | &#123;low, medium, high&#125;\\n&quot;</span><br></pre></td></tr></table></figure>\n\n\n<h1 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h1><ul>\n<li>查找相关性大的特征，只保留其中的一个。</li>\n<li>也可查看与标签（left）相关性较大的特征，如此数据集中的<code>satisfaction_level</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 筛选 DataFrame 中的所有数值列</span></span><br><span class=\"line\">numeric_df = df.select_dtypes(include=[np.number])</span><br><span class=\"line\"><span class=\"comment\"># 计算数值列之间的相关系数</span></span><br><span class=\"line\">numeric_df.corr()</span><br></pre></td></tr></table></figure>\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_monthly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>satisfaction_level</th>\n      <td>1.000000</td>\n      <td>0.105021</td>\n      <td>-0.142970</td>\n      <td>-0.020048</td>\n      <td>-0.100866</td>\n      <td>0.058697</td>\n      <td>-0.388375</td>\n      <td>0.025605</td>\n    </tr>\n    <tr>\n      <th>last_evaluation</th>\n      <td>0.105021</td>\n      <td>1.000000</td>\n      <td>0.349333</td>\n      <td>0.339742</td>\n      <td>0.131591</td>\n      <td>-0.007104</td>\n      <td>0.006567</td>\n      <td>-0.008684</td>\n    </tr>\n    <tr>\n      <th>number_project</th>\n      <td>-0.142970</td>\n      <td>0.349333</td>\n      <td>1.000000</td>\n      <td>0.417211</td>\n      <td>0.196786</td>\n      <td>-0.004741</td>\n      <td>0.023787</td>\n      <td>-0.006064</td>\n    </tr>\n    <tr>\n      <th>average_monthly_hours</th>\n      <td>-0.020048</td>\n      <td>0.339742</td>\n      <td>0.417211</td>\n      <td>1.000000</td>\n      <td>0.127755</td>\n      <td>-0.010143</td>\n      <td>0.071287</td>\n      <td>-0.003544</td>\n    </tr>\n    <tr>\n      <th>time_spend_company</th>\n      <td>-0.100866</td>\n      <td>0.131591</td>\n      <td>0.196786</td>\n      <td>0.127755</td>\n      <td>1.000000</td>\n      <td>0.002120</td>\n      <td>0.144822</td>\n      <td>0.067433</td>\n    </tr>\n    <tr>\n      <th>Work_accident</th>\n      <td>0.058697</td>\n      <td>-0.007104</td>\n      <td>-0.004741</td>\n      <td>-0.010143</td>\n      <td>0.002120</td>\n      <td>1.000000</td>\n      <td>-0.154622</td>\n      <td>0.039245</td>\n    </tr>\n    <tr>\n      <th>left</th>\n      <td>-0.388375</td>\n      <td>0.006567</td>\n      <td>0.023787</td>\n      <td>0.071287</td>\n      <td>0.144822</td>\n      <td>-0.154622</td>\n      <td>1.000000</td>\n      <td>-0.061788</td>\n    </tr>\n    <tr>\n      <th>promotion_last_5years</th>\n      <td>0.025605</td>\n      <td>-0.008684</td>\n      <td>-0.006064</td>\n      <td>-0.003544</td>\n      <td>0.067433</td>\n      <td>0.039245</td>\n      <td>-0.061788</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看离职员工部门分布，发现HR离职员工最多</span></span><br><span class=\"line\">plot = sns.catplot(x=<span class=\"string\">&#x27;department&#x27;</span>, y=<span class=\"string\">&#x27;left&#x27;</span>, kind=<span class=\"string\">&#x27;bar&#x27;</span>, data=df)</span><br><span class=\"line\">plot.set_xticklabels(rotation=<span class=\"number\">45</span>, horizontalalignment=<span class=\"string\">&#x27;right&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_10_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_10_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看工资水平和离职率的关系</span></span><br><span class=\"line\">plot = sns.catplot(x=<span class=\"string\">&#x27;salary&#x27;</span>, y=<span class=\"string\">&#x27;left&#x27;</span>, kind=<span class=\"string\">&#x27;bar&#x27;</span>, data=df);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_11_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_11_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看经理工资水平分布</span></span><br><span class=\"line\">df[df[<span class=\"string\">&#x27;department&#x27;</span>]==<span class=\"string\">&#x27;management&#x27;</span>][<span class=\"string\">&#x27;salary&#x27;</span>].value_counts().plot(kind=<span class=\"string\">&#x27;pie&#x27;</span>, title=<span class=\"string\">&#x27;Management salary level distribution&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_12_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_12_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看研发工资水平分布</span></span><br><span class=\"line\">df[df[<span class=\"string\">&#x27;department&#x27;</span>]==<span class=\"string\">&#x27;RandD&#x27;</span>][<span class=\"string\">&#x27;salary&#x27;</span>].value_counts().plot(kind=<span class=\"string\">&#x27;pie&#x27;</span>, title=<span class=\"string\">&#x27;R&amp;D dept salary level distribution&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_13_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_13_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 绘制员工满意度分布的直方图，并分为两类员工：已离职和未离职</span></span><br><span class=\"line\"><span class=\"comment\"># 生成21个等间距的数值作为直方图的区间，范围从0.0001到1.0001</span></span><br><span class=\"line\">bins = np.linspace(<span class=\"number\">0.0001</span>, <span class=\"number\">1.0001</span>, <span class=\"number\">21</span>)</span><br><span class=\"line\"><span class=\"comment\"># 绘制直方图。首先筛选出已离职员工（df[&#x27;left&#x27;]==1）和未离职员工（df[&#x27;left&#x27;]==0）的满意度数据，使用指定的区间（bins）、透明度（alpha）和标签（label）进行绘制。</span></span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">1</span>][<span class=\"string\">&#x27;satisfaction_level&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.7</span>, label=<span class=\"string\">&#x27;Employees Left&#x27;</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">0</span>][<span class=\"string\">&#x27;satisfaction_level&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.5</span>, label=<span class=\"string\">&#x27;Employees Stayed&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;satisfaction_level&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置x轴的显示范围从0到1.05</span></span><br><span class=\"line\">plt.xlim((<span class=\"number\">0</span>,<span class=\"number\">1.05</span>))</span><br><span class=\"line\"><span class=\"comment\"># 在最合适的位置添加图例</span></span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_14_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_14_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>发现已离职员工对公司的满意度比较低（0~0.5），当然也存在满意度较高（0.8附近）的员工离职的情况。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Last evaluation</span></span><br><span class=\"line\">bins = np.linspace(<span class=\"number\">0.3501</span>, <span class=\"number\">1.0001</span>, <span class=\"number\">14</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">1</span>][<span class=\"string\">&#x27;last_evaluation&#x27;</span>], bins=bins, alpha=<span class=\"number\">1</span>, label=<span class=\"string\">&#x27;Employees Left&#x27;</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">0</span>][<span class=\"string\">&#x27;last_evaluation&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.4</span>, label=<span class=\"string\">&#x27;Employees Stayed&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;last_evaluation&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_16_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_16_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>公司评分高（0.8~1.0）的员工离职了很多，原因可能是这部分员工能力强，跳槽寻求更好的工作机会。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Number of projects </span></span><br><span class=\"line\">bins = np.linspace(<span class=\"number\">1.5</span>, <span class=\"number\">7.5</span>, <span class=\"number\">7</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">1</span>][<span class=\"string\">&#x27;number_project&#x27;</span>], bins=bins, alpha=<span class=\"number\">1</span>, label=<span class=\"string\">&#x27;Employees Left&#x27;</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">0</span>][<span class=\"string\">&#x27;number_project&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.4</span>, label=<span class=\"string\">&#x27;Employees Stayed&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;number_project&#x27;</span>)</span><br><span class=\"line\">plt.grid(axis=<span class=\"string\">&#x27;x&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_18_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_18_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>项目少时离职了，可能因为员工锻炼机会少。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Average monthly hours</span></span><br><span class=\"line\">bins = np.linspace(<span class=\"number\">75</span>, <span class=\"number\">325</span>, <span class=\"number\">11</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">1</span>][<span class=\"string\">&#x27;average_monthly_hours&#x27;</span>], bins=bins, alpha=<span class=\"number\">1</span>, label=<span class=\"string\">&#x27;Employees Left&#x27;</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">0</span>][<span class=\"string\">&#x27;average_monthly_hours&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.4</span>, label=<span class=\"string\">&#x27;Employees Stayed&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;average_monthly_hours&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>);</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_20_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_20_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>工作时长少和多都容易离职。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Years at company </span></span><br><span class=\"line\">bins = np.linspace(<span class=\"number\">1.5</span>, <span class=\"number\">10.5</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">1</span>][<span class=\"string\">&#x27;time_spend_company&#x27;</span>], bins=bins, alpha=<span class=\"number\">1</span>, label=<span class=\"string\">&#x27;Employees Left&#x27;</span>)</span><br><span class=\"line\">plt.hist(df[df[<span class=\"string\">&#x27;left&#x27;</span>]==<span class=\"number\">0</span>][<span class=\"string\">&#x27;time_spend_company&#x27;</span>], bins=bins, alpha=<span class=\"number\">0.4</span>, label=<span class=\"string\">&#x27;Employees Stayed&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;time_spend_company&#x27;</span>)</span><br><span class=\"line\">plt.xlim((<span class=\"number\">1</span>,<span class=\"number\">11</span>))</span><br><span class=\"line\">plt.grid(axis=<span class=\"string\">&#x27;x&#x27;</span>)</span><br><span class=\"line\">plt.xticks(np.arange(<span class=\"number\">2</span>,<span class=\"number\">11</span>))</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_22_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_22_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>工作年限3年，离职率最高。年限越长，离职率越低。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># whether employee had work accident</span></span><br><span class=\"line\">plot = sns.catplot(x=<span class=\"string\">&#x27;Work_accident&#x27;</span>, y=<span class=\"string\">&#x27;left&#x27;</span>, kind=<span class=\"string\">&#x27;bar&#x27;</span>, data=df);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_24_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_24_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>未发生工作事故的离职率较高，难以解释。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#whether employee had promotion in last 5 years</span></span><br><span class=\"line\">plot = sns.catplot(x=<span class=\"string\">&#x27;promotion_last_5years&#x27;</span>, y=<span class=\"string\">&#x27;left&#x27;</span>, kind=<span class=\"string\">&#x27;bar&#x27;</span>, data=df);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_26_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_26_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p>不升职的离职率较高。</p>\n<h1 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h1><h2 id=\"独热编码替换分类数据\"><a href=\"#独热编码替换分类数据\" class=\"headerlink\" title=\"独热编码替换分类数据\"></a>独热编码替换分类数据</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 丢弃标签（left）列</span></span><br><span class=\"line\">X = df.drop(<span class=\"string\">&#x27;left&#x27;</span>, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 提取标签列</span></span><br><span class=\"line\">y = df[<span class=\"string\">&#x27;left&#x27;</span>]</span><br><span class=\"line\"><span class=\"comment\"># 删除部门与工资列，后面会通过独热编码将信息添加回来</span></span><br><span class=\"line\">X.drop([<span class=\"string\">&#x27;department&#x27;</span>,<span class=\"string\">&#x27;salary&#x27;</span>], axis=<span class=\"number\">1</span>, inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># One-hot encoding</span></span><br><span class=\"line\"><span class=\"comment\"># 对工资进行独热编码</span></span><br><span class=\"line\">salary_dummy = pd.get_dummies(df[<span class=\"string\">&#x27;salary&#x27;</span>])</span><br><span class=\"line\"><span class=\"comment\"># 对部门进行独热编码</span></span><br><span class=\"line\">department_dummy = pd.get_dummies(df[<span class=\"string\">&#x27;department&#x27;</span>])</span><br><span class=\"line\">X = pd.concat([X, salary_dummy], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">X = pd.concat([X, department_dummy], axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">X.head()</span><br></pre></td></tr></table></figure>\n\n<div style=\"overflow-x: auto; width: 100%;\">\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_monthly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>promotion_last_5years</th>\n      <th>high</th>\n      <th>low</th>\n      <th>medium</th>\n      <th>IT</th>\n      <th>RandD</th>\n      <th>accounting</th>\n      <th>hr</th>\n      <th>management</th>\n      <th>marketing</th>\n      <th>product_mng</th>\n      <th>sales</th>\n      <th>support</th>\n      <th>technical</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<h2 id=\"拆分训练集和测试集\"><a href=\"#拆分训练集和测试集\" class=\"headerlink\" title=\"拆分训练集和测试集\"></a>拆分训练集和测试集</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 划分训练集和测试集 (70%/30%)</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"数据标准化\"><a href=\"#数据标准化\" class=\"headerlink\" title=\"数据标准化\"></a>数据标准化</h2><ul>\n<li>比较大的数值，算法会认为其比较重要，导致结果不准确。</li>\n<li>数值差异比较大的话，模型收敛较慢。</li>\n<li>因此，需要将数据标准化。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据标准化，这里是一个例子</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\">stdsc = StandardScaler()</span><br><span class=\"line\">X_example = np.array([[ <span class=\"number\">10.</span>, -<span class=\"number\">2.</span>,  <span class=\"number\">23.</span>],</span><br><span class=\"line\">                      [ <span class=\"number\">5.</span>,  <span class=\"number\">32.</span>,  <span class=\"number\">211.</span>],</span><br><span class=\"line\">                      [ <span class=\"number\">10.</span>,  <span class=\"number\">1.</span>, -<span class=\"number\">130.</span>]])</span><br><span class=\"line\">X_example = stdsc.fit_transform(X_example)</span><br><span class=\"line\">X_example = pd.DataFrame(X_example)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (X_example)</span><br><span class=\"line\">X_example.describe()</span><br></pre></td></tr></table></figure>\n\n<pre><code>          0         1         2\n0  0.707107 -0.802454 -0.083658\n1 -1.414214  1.409716  1.264429\n2  0.707107 -0.607262 -1.180771\n</code></pre>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.000000e+00</td>\n      <td>3.000000e+00</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-2.960595e-16</td>\n      <td>-1.110223e-16</td>\n      <td>7.401487e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.224745e+00</td>\n      <td>1.224745e+00</td>\n      <td>1.224745e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.414214e+00</td>\n      <td>-8.024539e-01</td>\n      <td>-1.180771e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-3.535534e-01</td>\n      <td>-7.048582e-01</td>\n      <td>-6.322145e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.071068e-01</td>\n      <td>-6.072624e-01</td>\n      <td>-8.365788e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.071068e-01</td>\n      <td>4.012270e-01</td>\n      <td>5.903856e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.071068e-01</td>\n      <td>1.409716e+00</td>\n      <td>1.264429e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 分别对训练集和测试集进行标准化</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"></span><br><span class=\"line\">stdsc = StandardScaler()</span><br><span class=\"line\"><span class=\"comment\"># transform our training features</span></span><br><span class=\"line\">X_train_std = stdsc.fit_transform(X_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span> (X_train_std[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"comment\"># transform the testing features in the same way</span></span><br><span class=\"line\">X_test_std = stdsc.transform(X_test)</span><br></pre></td></tr></table></figure>\n\n<pre><code>[ 1.40697692 -0.21068428 -0.65422416 -1.37529896 -1.02172591 -0.41080801\n -0.14595719 -0.30564365 -0.98084819  1.16499228 -0.2981308  -0.23781569\n -0.22665375 -0.23057496 -0.21332806 -0.24641294 -0.25073288  1.62416352\n -0.41712208 -0.47247431]\n</code></pre>\n<h1 id=\"构建模型\"><a href=\"#构建模型\" class=\"headerlink\" title=\"构建模型\"></a>构建模型</h1><h2 id=\"随机森林法\"><a href=\"#随机森林法\" class=\"headerlink\" title=\"随机森林法\"></a>随机森林法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 交叉验证（Cross validation）</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> ShuffleSplit</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 进行20折交叉验证</span></span><br><span class=\"line\">cv = ShuffleSplit(n_splits=<span class=\"number\">20</span>, test_size=<span class=\"number\">0.3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建随机森林模型</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\">rf_model = RandomForestClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置RF模型，建立树的数量</span></span><br><span class=\"line\">rf_param = &#123;<span class=\"string\">&#x27;n_estimators&#x27;</span>: <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,<span class=\"number\">11</span>)&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 探索模型参数（最佳树的个数）</span></span><br><span class=\"line\">rf_grid = GridSearchCV(rf_model, rf_param, cv=cv)</span><br><span class=\"line\">rf_grid.fit(X_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出最佳参数和最佳得分</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Parameter with best score:&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(rf_grid.best_params_)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Cross validation score:&#x27;</span>, rf_grid.best_score_)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Parameter with best score:\n&#123;&#39;n_estimators&#39;: 9&#125;\nCross validation score: 0.9835079365079364\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在测试集上评估模型</span></span><br><span class=\"line\">best_rf = rf_grid.best_estimator_</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Test score:&#x27;</span>, best_rf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>\n\n<pre><code>Test score: 0.9884444444444445\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 通过随机森林查看特征的重要性，原理是每次打乱一个特征（或添加噪音），然后看预测结果（错误率）是否发生变化，如果变化大，则该特征对预测结果有影响，否则没有影响</span></span><br><span class=\"line\">features = X.columns</span><br><span class=\"line\">feature_importances = best_rf.feature_importances_</span><br><span class=\"line\"></span><br><span class=\"line\">features_df = pd.DataFrame(&#123;<span class=\"string\">&#x27;Features&#x27;</span>: features, <span class=\"string\">&#x27;Importance Score&#x27;</span>: feature_importances&#125;)</span><br><span class=\"line\">features_df.sort_values(<span class=\"string\">&#x27;Importance Score&#x27;</span>, inplace=<span class=\"literal\">True</span>, ascending=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">features_df</span><br></pre></td></tr></table></figure>\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n<pre><code>.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n</code></pre>\n<p></style></p>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Features</th>\n      <th>Importance Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>satisfaction_level</td>\n      <td>0.260366</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>average_monthly_hours</td>\n      <td>0.186585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>number_project</td>\n      <td>0.179788</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>time_spend_company</td>\n      <td>0.179571</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>last_evaluation</td>\n      <td>0.144083</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Work_accident</td>\n      <td>0.011949</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>low</td>\n      <td>0.006395</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>high</td>\n      <td>0.005206</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>medium</td>\n      <td>0.003336</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>sales</td>\n      <td>0.003200</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>support</td>\n      <td>0.003070</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>technical</td>\n      <td>0.003039</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RandD</td>\n      <td>0.002143</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>IT</td>\n      <td>0.002048</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>accounting</td>\n      <td>0.001887</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>promotion_last_5years</td>\n      <td>0.001799</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>management</td>\n      <td>0.001755</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>hr</td>\n      <td>0.001425</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>product_mng</td>\n      <td>0.001182</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>marketing</td>\n      <td>0.001173</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 计算前五项特征的重要性之和</span></span><br><span class=\"line\">features_df[<span class=\"string\">&#x27;Importance Score&#x27;</span>][:<span class=\"number\">5</span>].<span class=\"built_in\">sum</span>()</span><br></pre></td></tr></table></figure>\n\n<pre><code>np.float64(0.9503925098929926)\n</code></pre>\n<h2 id=\"基于聚类模型的分析\"><a href=\"#基于聚类模型的分析\" class=\"headerlink\" title=\"基于聚类模型的分析\"></a>基于聚类模型的分析</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">data = pd.read_csv(url)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure(figsize = (<span class=\"number\">8</span>,<span class=\"number\">8</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.plot(data.satisfaction_level[data.left == <span class=\"number\">1</span>],data.last_evaluation[data.left == <span class=\"number\">1</span>],<span class=\"string\">&#x27;o&#x27;</span>, alpha = <span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Last Evaluation&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Employees who left&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Satisfaction level&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Employees who stayed&#x27;</span>)</span><br><span class=\"line\">plt.plot(data.satisfaction_level[data.left == <span class=\"number\">0</span>],data.last_evaluation[data.left == <span class=\"number\">0</span>],<span class=\"string\">&#x27;o&#x27;</span>, alpha = <span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.xlim([<span class=\"number\">0.4</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Last Evaluation&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Satisfaction level&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Text(0.5, 0, &#39;Satisfaction level&#39;)\n</code></pre>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_43_1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_43_1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 用KMeans聚类分析</span></span><br><span class=\"line\"><span class=\"comment\"># 导入KMeans聚类算法模块</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> KMeans</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 选取数据中已经离职的员工（left列为1），并从这些数据中删除特定的列</span></span><br><span class=\"line\"><span class=\"comment\"># 这里axis=1表示按列删除，这些列包括：项目数量、月平均工作小时、公司服务时间、工作事故、是否离职、过去5年是否晋升、销售部门和薪水等</span></span><br><span class=\"line\">kmeans_df =  data[data.left == <span class=\"number\">1</span>].drop([ <span class=\"string\">u&#x27;number_project&#x27;</span>,</span><br><span class=\"line\">       <span class=\"string\">u&#x27;average_montly_hours&#x27;</span>, <span class=\"string\">u&#x27;time_spend_company&#x27;</span>, <span class=\"string\">u&#x27;Work_accident&#x27;</span>,</span><br><span class=\"line\">       <span class=\"string\">u&#x27;left&#x27;</span>, <span class=\"string\">u&#x27;promotion_last_5years&#x27;</span>, <span class=\"string\">u&#x27;sales&#x27;</span>, <span class=\"string\">u&#x27;salary&#x27;</span>],axis = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用KMeans算法对处理后的数据进行聚类，设定聚类数为3，并设置随机种子为0以确保结果的可复现性</span></span><br><span class=\"line\"><span class=\"comment\"># 这里fit方法用于训练模型，使其学习数据的聚类结构</span></span><br><span class=\"line\">kmeans = KMeans(n_clusters = <span class=\"number\">3</span>, random_state = <span class=\"number\">0</span>).fit(kmeans_df)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 访问并输出每个聚类中心点的坐标，这些坐标表示了每个聚类的中心位置</span></span><br><span class=\"line\">kmeans.cluster_centers_</span><br></pre></td></tr></table></figure>\n\n<pre><code>array([[0.41014545, 0.51698182],\n       [0.80851586, 0.91170931],\n       [0.11115466, 0.86930085]])\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 筛选出离职员工的数据</span></span><br><span class=\"line\">left = data[data.left == <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用布尔索引和 .loc 方法将 KMeans 聚类的标签分配给离职员工数据</span></span><br><span class=\"line\">left_labels = (data.left == <span class=\"number\">1</span>)</span><br><span class=\"line\">data.loc[left_labels, <span class=\"string\">&#x27;label&#x27;</span>] = kmeans.labels_</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重新获取带有标签的离职员工数据</span></span><br><span class=\"line\">left = data[data.left == <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建一个新的图形窗口</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置 x 轴标签为满意度水平</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Satisfaction Level&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置 y 轴标签为最后一次评估结果</span></span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Last Evaluation&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置图形标题为“离职员工的3个聚类”</span></span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;3 Clusters of employees who left&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制不同聚类的离职员工的满意度水平和最后一次评估结果</span></span><br><span class=\"line\">plt.plot(left.satisfaction_level[left.label==<span class=\"number\">0</span>], left.last_evaluation[left.label==<span class=\"number\">0</span>], <span class=\"string\">&#x27;o&#x27;</span>, alpha=<span class=\"number\">0.2</span>, color=<span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">plt.plot(left.satisfaction_level[left.label==<span class=\"number\">1</span>], left.last_evaluation[left.label==<span class=\"number\">1</span>], <span class=\"string\">&#x27;o&#x27;</span>, alpha=<span class=\"number\">0.2</span>, color=<span class=\"string\">&#x27;g&#x27;</span>)</span><br><span class=\"line\">plt.plot(left.satisfaction_level[left.label==<span class=\"number\">2</span>], left.last_evaluation[left.label==<span class=\"number\">2</span>], <span class=\"string\">&#x27;o&#x27;</span>, alpha=<span class=\"number\">0.2</span>, color=<span class=\"string\">&#x27;b&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加图例，解释不同聚类的含义，并设置图例的位置和字体大小</span></span><br><span class=\"line\">plt.legend([<span class=\"string\">&#x27;Winners&#x27;</span>, <span class=\"string\">&#x27;Frustrated&#x27;</span>, <span class=\"string\">&#x27;Bad Match&#x27;</span>], loc=<span class=\"number\">3</span>, fontsize=<span class=\"number\">15</span>, frameon=<span class=\"literal\">True</span>);</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_45_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/WhoWillLeave_files/WhoWillLeave_45_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h1 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h1><p>关注公众号“生信之巅”</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n\n\n<p><font color=\"#FF0000\"><ruby><b>敬告</b>：使用文中脚本请引用本文网址，请尊重本人的劳动成果，谢谢！<rt><b>Notice</b>: When you use the scripts in this article, please cite the link of this webpage. Thank you!</rt></ruby></font></p>\n","raw":null,"categories":[{"name":"AI","path":"api/categories/AI.json"}],"tags":[{"name":"机器学习","path":"api/tags/机器学习.json"},{"name":"Scikit-learn","path":"api/tags/Scikit-learn.json"}]}]}