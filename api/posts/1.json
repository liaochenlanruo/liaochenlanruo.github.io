{"total":151,"pageSize":10,"pageCount":16,"data":[{"title":"终版实测！CentOS 7.9（glibc 2.17）升级 Go 1.24.4 编译 Ollama 0.13.3，4 张 L4 GPU 满血运行～","slug":"CentOS7中Go1.24.4安装与Ollama0.13.3源码编译","date":"2025-12-16T11:18:18.000Z","updated":"2025-12-16T10:24:48.500Z","comments":true,"path":"api/articles/CentOS7中Go1.24.4安装与Ollama0.13.3源码编译.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>🔥 作为坚守 CentOS 7.9 的运维 &#x2F; 开发者，谁懂啊！官方 Ollama 二进制包直接报错「GLIBC_2.27 not found」，而系统 glibc 2.17 根本没法升级（怕崩系统）😫 但 4 张 NVIDIA L4 GPU（总计 96GB 显存）不能浪费，非要在原生环境跑 Ollama 部署大模型，于是硬着头皮走 Go 编译路线，过程踩遍坑，现在整理成保姆级教程，造福同款老系统用户！</p>\n<h1 id=\"📌-核心背景：为啥非要自己动手？\"><a href=\"#📌-核心背景：为啥非要自己动手？\" class=\"headerlink\" title=\"📌 核心背景：为啥非要自己动手？\"></a>📌 核心背景：为啥非要自己动手？</h1><ul>\n<li><p>系统限制：CentOS 7.9 默认 glibc 2.17，官方 Ollama 所有版本都依赖 glibc≥2.27，直接运行必报错；</p>\n</li>\n<li><p>硬件刚需：4 张 L4 GPU 想最大化算力，原生编译比 Docker 少虚拟化损耗，多卡并行更高效。</p>\n</li>\n<li><p>无替代方案：社区无适配 glibc 2.17 的 Ollama 预编译包，只能源码编译定制。</p>\n</li>\n</ul>\n<h1 id=\"🛠️-全程实操（按自身路径调整）\"><a href=\"#🛠️-全程实操（按自身路径调整）\" class=\"headerlink\" title=\"🛠️ 全程实操（按自身路径调整）\"></a>🛠️ 全程实操（按自身路径调整）</h1><ul>\n<li>版本选择：Go 1.24.4（适配 Ollama 0.13.3，兼容 glibc 2.17）+ Ollama 0.13.3 源码包（<a href=\"https://github.com/ollama/ollama/archive/refs/tags/v0.13.3.tar.gz\">https://github.com/ollama/ollama/archive/refs/tags/v0.13.3.tar.gz</a>）；</li>\n</ul>\n<h2 id=\"1️⃣-升级-Go-到-1-24-4（编译-Ollama-的前提，不同用户路径不同，务必自查！）\"><a href=\"#1️⃣-升级-Go-到-1-24-4（编译-Ollama-的前提，不同用户路径不同，务必自查！）\" class=\"headerlink\" title=\"1️⃣ 升级 Go 到 1.24.4（编译 Ollama 的前提，不同用户路径不同，务必自查！）\"></a>1️⃣ 升级 Go 到 1.24.4（编译 Ollama 的前提，不同用户路径不同，务必自查！）</h2><ul>\n<li>卸载旧 Go（示例路径，替换成自己的！）：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">rm</span> -rf /share/opt/go  <span class=\"comment\"># 我之前装的Go 1.18.2路径</span></span><br><span class=\"line\">sed -i <span class=\"string\">&#x27;/\\/share\\/opt\\/go\\/bin/d&#x27;</span> ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>下载 Go 1.24.4（阿里云镜像，稳定不翻车）：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://mirrors.aliyun.com/golang/go1.24.4.linux-amd64.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\">tar -C /usr/local -xzf go1.24.4.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>配置 Go 环境变量（全局生效）：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vi /etc/profile</span><br></pre></td></tr></table></figure>\n\n<p>新增以下内容：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export GOROOT=/usr/local/go</span><br><span class=\"line\">export PATH=$GOROOT/bin:$PATH</span><br><span class=\"line\">export GOPATH=$HOME/go</span><br><span class=\"line\">export GOPROXY=https://mirrors.aliyun.com/goproxy/,direct  # 国内代理避坑</span><br></pre></td></tr></table></figure>\n\n<p>保存并退出（ESC， shift + ;, wq, 回车），使配置生效：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br></pre></td></tr></table></figure>\n\n\n<ul>\n<li>验证：<code>go version</code> 输出 <code>go1.24.4 linux/amd64</code> 即成功。</li>\n</ul>\n<h2 id=\"2️⃣-下载-Ollama-0-13-3-源码包（无需-git，解压即编译）\"><a href=\"#2️⃣-下载-Ollama-0-13-3-源码包（无需-git，解压即编译）\" class=\"headerlink\" title=\"2️⃣ 下载 Ollama 0.13.3 源码包（无需 git，解压即编译）\"></a>2️⃣ 下载 Ollama 0.13.3 源码包（无需 git，解压即编译）</h2><ul>\n<li><p>下载源码：<code>wget https://github.com/ollama/ollama/archive/refs/tags/v0.13.3.tar.gz</code>；</p>\n</li>\n<li><p>解压进入目录：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -zxvf v0.13.3.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 看清解压后的目录名再进入</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> ollama-0.13.3</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3️⃣-编译-Ollama-0-13-3（适配-glibc-2-17-核心参数）\"><a href=\"#3️⃣-编译-Ollama-0-13-3（适配-glibc-2-17-核心参数）\" class=\"headerlink\" title=\"3️⃣ 编译 Ollama 0.13.3（适配 glibc 2.17 核心参数）\"></a>3️⃣ 编译 Ollama 0.13.3（适配 glibc 2.17 核心参数）</h2><ul>\n<li>配置编译环境变量（静态编译，规避 glibc 版本问题）：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> CGO_ENABLED=1</span><br><span class=\"line\"><span class=\"built_in\">export</span> CGO_CFLAGS=<span class=\"string\">&quot;-D_GLIBCXX_USE_CXX11_ABI=0 -m64 -Wl,--hash-style=gnu -Wl,--as-needed&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> CGO_LDFLAGS=<span class=\"string\">&quot;-lrt -lm -ldl -Wl,--disable-new-dtags -Wl,--rpath=/lib64&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> GOFLAGS=<span class=\"string\">&quot;-buildmode=pie -trimpath&quot;</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> CC=<span class=\"string\">&quot;gcc -static-libgcc -static-libstdc++&quot;</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>执行编译（0.13.3 主入口在根目录 main.go，别写错！）：</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go build -ldflags <span class=\"string\">&quot;-s -w -linkmode=external -extldflags &#x27;-static-libgcc -static-libstdc++ -lm -ldl&#x27;&quot;</span> -o ollama ./main.go</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>验证：<code>./ollama --help</code> 无 GLIBC 报错，将二进制移到系统路径：<code>cp ./ollama /usr/local/bin/</code>，或将当前路径加入环境变量（我选择的后者：&#x2F;share&#x2F;tools&#x2F;ollama-0.13.3）。</li>\n</ul>\n<h2 id=\"4️⃣-配置开机自启（后台稳跑，省心！）\"><a href=\"#4️⃣-配置开机自启（后台稳跑，省心！）\" class=\"headerlink\" title=\"4️⃣ 配置开机自启（后台稳跑，省心！）\"></a>4️⃣ 配置开机自启（后台稳跑，省心！）</h2><ul>\n<li>创建 systemd 服务文件：<code>vi /etc/systemd/system/ollama.service</code>，写入：</li>\n</ul>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Unit]</span><br><span class=\"line\"></span><br><span class=\"line\">Description=Ollama Service</span><br><span class=\"line\"></span><br><span class=\"line\">After=network.target</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\"></span><br><span class=\"line\">Type=simple</span><br><span class=\"line\"></span><br><span class=\"line\">User=root</span><br><span class=\"line\"></span><br><span class=\"line\"># 绑定4张L4 GPU，开启TensorRT加速</span><br><span class=\"line\"></span><br><span class=\"line\">Environment=&quot;CUDA_VISIBLE_DEVICES=0,1,2,3&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">Environment=&quot;OLLAMA_TENSORRT=1&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 自定义模型存放路径，避免占满/root</span><br><span class=\"line\"></span><br><span class=\"line\">Environment=&quot;OLLAMA_MODELS=/share/public_db/ollama/models&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">ExecStart=/share/tools/ollama-0.13.3/ollama serve</span><br><span class=\"line\"></span><br><span class=\"line\">Restart=on-failure</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\"></span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>生效配置：<code>systemctl daemon-reload &amp;&amp; systemctl enable --now ollama</code>；</p>\n</li>\n<li><p>验证服务：<code>systemctl status ollama</code> 显示<code>active(running)</code>即可。</p>\n</li>\n</ul>\n<h2 id=\"5️⃣-环境变量-模型路径优化（长期使用必备）\"><a href=\"#5️⃣-环境变量-模型路径优化（长期使用必备）\" class=\"headerlink\" title=\"5️⃣ 环境变量 + 模型路径优化（长期使用必备）\"></a>5️⃣ 环境变量 + 模型路径优化（长期使用必备）</h2><ul>\n<li>全局配置（&#x2F;etc&#x2F;profile 新增）：</li>\n</ul>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export OLLAMA_MODELS=/share/public_db/ollama/models</span><br><span class=\"line\"></span><br><span class=\"line\">export OLLAMA_TENSORRT=1</span><br><span class=\"line\"></span><br><span class=\"line\">export GOPROXY=https://mirrors.aliyun.com/goproxy/,direct</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>生效：<code>source /etc/profile</code>；</p>\n</li>\n<li><p>模型路径权限（必做！）：</p>\n</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">mkdir</span> -p /share/public_db/ollama/models</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">chmod</span> 755 /share/public_db/ollama/models</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">chown</span> -R root:root /share/public_db/ollama/models</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>测试：<code>ollama pull llama3:8b</code>，模型自动存到<code>/share/public_db/ollama/models</code>，验证路径生效。</li>\n</ul>\n<h1 id=\"✅-最终成果\"><a href=\"#✅-最终成果\" class=\"headerlink\" title=\"✅ 最终成果\"></a>✅ 最终成果</h1><ul>\n<li><p>环境：CentOS 7.9（glibc 2.17）+ Go 1.24.4 + Ollama 0.13.3（原生编译）；</p>\n</li>\n<li><p>硬件：4 张 L4 GPU 满负载运行，llama3:70b（INT4 量化）；</p>\n</li>\n<li><p>稳定性：开机自启无故障，TensorRT 加速加持，延迟大幅降低。</p>\n</li>\n</ul>\n<h1 id=\"🚨-关键避坑点\"><a href=\"#🚨-关键避坑点\" class=\"headerlink\" title=\"🚨 关键避坑点\"></a>🚨 关键避坑点</h1><ol>\n<li><p>Go 路径：不同用户安装位置不同，用<code>which go</code>自查，确保 PATH 优先指向 Go 1.24.4；</p>\n</li>\n<li><p>编译路径：Ollama 0.13.3 主入口是<code>./main.go</code>，别用<code>./cmd/ollama</code>（报目录不存在）；</p>\n</li>\n<li><p>权限：模型路径必须提前赋权，否则拉取模型提示权限拒绝；</p>\n</li>\n<li><p>加速：L4 GPU 开启 OLLAMA_TENSORRT&#x3D;1，推理效率提升 30%+。</p>\n</li>\n</ol>\n<p>老系统也能拿捏大模型！Go 1.24.4+Ollama 0.13.3 这套组合，完美适配 CentOS 7.9，4 张 L4 GPU 终于物尽其用～ 转发给同处境的朋友，少走弯路！🚀</p>\n<p>#CentOS7 #Ollama0.13.3 #Go1.24.4 #glibc2.17 #源码编译 #NVIDIA L4 #大模型部署</p>\n","raw":null,"categories":[{"name":"IT","path":"api/categories/IT.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"系统","path":"api/tags/系统.json"}]},{"title":"加装 GPU 后 IB 网卡（ib0）消失？CentOS 7 自动恢复教程（亲测有效）","slug":"CentOS7加装GPU后IB网卡自动恢复教程","date":"2025-12-16T10:18:18.000Z","updated":"2025-12-16T10:19:38.816Z","comments":true,"path":"api/articles/CentOS7加装GPU后IB网卡自动恢复教程.json","excerpt":null,"keywords":null,"cover":null,"content":"<p>在集群运维中，IB（InfiniBand）网卡是高速数据传输的核心，但很多人遇到过这样的坑：给服务器加装 GPU 扩展卡后，原本正常的 ib0 设备突然消失，无法通过 IB 交换机与其他节点通信。本文结合实际案例，详细拆解问题根源，提供一步到位的自动修复方案，让 ib0 开机即启，无需手动干预。</p>\n<h1 id=\"一、问题背景\"><a href=\"#一、问题背景\" class=\"headerlink\" title=\"一、问题背景\"></a>一、问题背景</h1><ul>\n<li><p><strong>环境</strong>：CentOS 7 服务器（node1），搭载 Mellanox ConnectX 系列双模网卡（支持 IB&#x2F;ETH 模式），原本已配置 IB 模式（ib0 设备），与其他节点通过 IB 交换机实现 20.20.20.0&#x2F;24 网段高速通信。</p>\n</li>\n<li><p><strong>触发条件</strong>：为提升算力加装 GPU 扩展卡后，执行 <code>ip link show ib0</code> 提示 “Device ‘ib0’ does not exist”，IB 网卡失效。</p>\n</li>\n<li><p><strong>核心需求</strong>：恢复 ib0 设备，保持 IB 网段（20.20.20.0&#x2F;24）连通性，实现开机自动配置，不影响 GPU 正常工作。</p>\n</li>\n</ul>\n<h1 id=\"二、问题根源深度解析\"><a href=\"#二、问题根源深度解析\" class=\"headerlink\" title=\"二、问题根源深度解析\"></a>二、问题根源深度解析</h1><p>加装 GPU 后 IB 网卡失效，并非硬件损坏，而是<strong>多重连锁问题</strong>导致：</p>\n<ol>\n<li><p><strong>PCIe 资源冲突</strong>：GPU 占用大量 PCIe 通道，可能触发 BIOS 重置 PCIe 配置，或导致 IB 网卡的 PCIe 资源被占用，驱动加载异常。</p>\n</li>\n<li><p><strong>MLX_OFED 驱动冲突</strong>：服务器原本依赖 Mellanox 官方 OFED 驱动实现 IB 功能，加装 GPU 后，系统原生 RDMA 模块（rdma_cm&#x2F;rdma_ucm）与 OFED 驱动冲突，导致 openibd 服务启动失败（状态码 3&#x2F;NOTIMPLEMENTED），无法初始化 IB 设备。</p>\n</li>\n<li><p><strong>IB 模块未自动加载</strong>：openibd 服务失效后，MLX5 IB 核心模块（mlx5_ib）、IB 协议模块（ib_ipoib 等）无法开机自动加载，IB 网卡虽被识别但未生成 ib0 设备。</p>\n</li>\n</ol>\n<h1 id=\"三、解决方案：systemd-服务实现-ib0-自动初始化\"><a href=\"#三、解决方案：systemd-服务实现-ib0-自动初始化\" class=\"headerlink\" title=\"三、解决方案：systemd 服务实现 ib0 自动初始化\"></a>三、解决方案：systemd 服务实现 ib0 自动初始化</h1><p>无需修复复杂的驱动冲突，也不用手动执行命令，通过创建 systemd 服务，实现 “加载模块→创建 ib0→配置 IP” 全流程自动化，重启后依然生效。</p>\n<h2 id=\"步骤-1：创建-systemd-服务文件\"><a href=\"#步骤-1：创建-systemd-服务文件\" class=\"headerlink\" title=\"步骤 1：创建 systemd 服务文件\"></a>步骤 1：创建 systemd 服务文件</h2><p>创建<code>ib0-init.service</code>服务，适配 CentOS 7 老版本语法，避免参数报错：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vi /etc/systemd/system/ib0-init.service</span><br></pre></td></tr></table></figure>\n\n<p>粘贴以下内容（核心兼容老版本 iproute2，无<code>parent</code>参数）：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Initialize IB0 device (CentOS 7 iproute2 compatible)</span><br><span class=\"line\">After=network.target  # 确保网络服务启动后再执行</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Type=oneshot  # 一次性执行，执行完保持状态</span><br><span class=\"line\"># 核心命令：加载IB模块→创建ib0→启用设备→配置20网段IP</span><br><span class=\"line\">ExecStart=/bin/bash -c &quot;modprobe mlx5_ib; modprobe ib_core; modprobe ib_cm; modprobe ib_ipoib; ip link add ib0 type ipoib; ip link set ib0 up; ip addr add 20.20.20.109/24 dev ib0&quot;</span><br><span class=\"line\"># 停止命令：删除ib0→卸载模块（可选）</span><br><span class=\"line\">ExecStop=/bin/bash -c &quot;ip link delete ib0; modprobe -r ib_ipoib ib_cm ib_core mlx5_ib&quot;</span><br><span class=\"line\">RemainAfterExit=yes  # 执行完后保持服务活跃状态</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target  # 多用户模式下生效</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>说明：<code>20.20.20.101/24</code> 需替换为你的 IB 网段 IP（与其他节点保持同网段）；若集群 IB 分区使用 PKEY（如 0x8001），可在<code>ip link add ib0 type ipoib</code>后添加<code>pkey 0x8001</code>。</li>\n</ul>\n<h2 id=\"步骤-2：启用并启动服务\"><a href=\"#步骤-2：启用并启动服务\" class=\"headerlink\" title=\"步骤 2：启用并启动服务\"></a>步骤 2：启用并启动服务</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 重新加载systemd配置，让新服务生效</span><br><span class=\"line\">sudo systemctl daemon-reload</span><br><span class=\"line\"></span><br><span class=\"line\"># 设置开机自启（关键！重启后自动执行）</span><br><span class=\"line\">sudo systemctl enable ib0-init.service</span><br><span class=\"line\"></span><br><span class=\"line\"># 立即启动服务，无需重启</span><br><span class=\"line\">sudo systemctl start ib0-init.service</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"步骤-3：验证-ib0-是否创建成功\"><a href=\"#步骤-3：验证-ib0-是否创建成功\" class=\"headerlink\" title=\"步骤 3：验证 ib0 是否创建成功\"></a>步骤 3：验证 ib0 是否创建成功</h2><p>执行以下命令，确认配置生效：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 1. 检查ib0设备是否存在（状态UP为正常）</span><br><span class=\"line\">ip link show ib0</span><br><span class=\"line\"># 预期输出：</span><br><span class=\"line\"># 4: ib0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 4096 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000</span><br><span class=\"line\">#    link/ib 00:00:00:00:00:00:00:00 brd 00:00:00:00:00:00:00:00</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 检查IB网段IP是否配置成功</span><br><span class=\"line\">ip addr show ib0 | grep 20.20.20.</span><br><span class=\"line\"># 预期输出：inet 20.20.20.101/24 scope global ib0</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 测试与其他IB节点的连通性（如node2的20.20.20.107）</span><br><span class=\"line\">ping 20.20.20.107 -c 3</span><br><span class=\"line\"># 输出“3 packets transmitted, 3 received”即为连通正常</span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 验证NFS等依赖IB的服务（若有）</span><br><span class=\"line\">sudo mount -a</span><br><span class=\"line\">df -h /share  # 确认IB网段NFS挂载正常</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"步骤-4：重启验证永久生效\"><a href=\"#步骤-4：重启验证永久生效\" class=\"headerlink\" title=\"步骤 4：重启验证永久生效\"></a>步骤 4：重启验证永久生效</h2><p>为确保重启后不失效，执行重启测试：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo reboot</span><br></pre></td></tr></table></figure>\n\n<p>重启后再次执行<code>ip link show ib0</code>和<code>ping ``20.20.20.101</code>，若 ib0 存在且连通正常，说明服务配置成功。</p>\n<h1 id=\"四、关键补充：避坑指南\"><a href=\"#四、关键补充：避坑指南\" class=\"headerlink\" title=\"四、关键补充：避坑指南\"></a>四、关键补充：避坑指南</h1><ol>\n<li><p><strong>模块加载顺序不能乱</strong>：必须先加载<code>mlx5_ib</code>（MLX5 网卡专用 IB 模块），再加载<code>ib_core</code>等协议模块，否则会导致设备创建失败。</p>\n</li>\n<li><p><strong>若 ib0 仍未创建</strong>：</p>\n</li>\n</ol>\n<ul>\n<li><p>执行<code>ibv_devinfo</code>检查物理 IB 设备是否存在（如 mlx5_0），若无输出，需重新安装 Mellanox OFED 驱动（兼容 GPU 驱动版本）。</p>\n</li>\n<li><p>排查 IB 线缆是否插紧、IB 交换机对应端口是否启用（物理链路中断也会导致 ib0 创建失败）。</p>\n</li>\n</ul>\n<ol>\n<li><p><strong>GPU 与 IB 网卡资源冲突</strong>：若重启后 GPU 失效，需进入 BIOS 调整 PCIe 通道分配，将 IB 网卡和 GPU 分配到不同的 PCIe 根复合体，避免资源竞争。</p>\n</li>\n<li><p><strong>兜底方案</strong>：若 IB 模式始终无法恢复，可沿用以太网转发方案（无需 ib0）：</p>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo &quot;20.20.20.0/24 via 10.20.0.1 dev eno1 metric 200&quot; &gt;&gt; /etc/sysconfig/network-scripts/route-eno1</span><br><span class=\"line\"></span><br><span class=\"line\">sudo systemctl restart network</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h1><p>加装 GPU 后 IB 网卡失效的核心是 “驱动冲突 + 模块未自动加载”，通过 systemd 服务可完美解决：无需修改 BIOS、不卸载 GPU 驱动，仅需 3 步配置，即可实现 ib0 开机自动创建、IP 自动配置，恢复 IB 高速传输功能。</p>\n<p>该方案已在生产环境验证，适配 CentOS 7 所有版本，兼容 Mellanox ConnectX-4&#x2F;5&#x2F;6 系列网卡。如果遇到类似问题，欢迎留言交流，分享你的排查经验！</p>\n","raw":null,"categories":[{"name":"IT","path":"api/categories/IT.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"系统","path":"api/tags/系统.json"}]},{"title":"基因组试金石：在中心法则背景下对基因组语言模型进行基准测试","slug":"基因组试金石：在中心法则背景下对基因组语言模型进行基准测试","date":"2025-11-16T08:19:58.000Z","updated":"2025-12-16T10:14:31.821Z","comments":true,"path":"api/articles/基因组试金石：在中心法则背景下对基因组语言模型进行基准测试.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F1.large.jpg","content":"<p>2025年6月，香港科技大学计算机科学与工程系的Yihui Wang、Zhiyuan Cai及Hao Chen（通讯作者）等研究者在bioRxiv预印本发表了题为“Genomic Touchstone: Benchmarking Genomic Language Models in the Context of the Central Dogma”的学术文章。该文章报道了其开发的“Genomic Touchstone”综合基准测试框架，在基因组语言模型（gLMs）评估领域具有建立统一评估标准、指导模型设计与实际应用选择的重要意义。下面我将对文章进行解读。</p>\n<h1 id=\"1-摘要\"><a href=\"#1-摘要\" class=\"headerlink\" title=\"1 摘要\"></a>1 摘要</h1><p>基因组语言模型（gLMs）的出现革新了基因组序列分析，但现有评估缺乏覆盖中心法则全链条的整体框架。本研究提出<code>Genomic Touchstone</code>基准测试框架，涵盖36个任务、88个数据集，包含53.4亿碱基对的基因组序列，跨越<code>DNA</code>、<code>RNA</code>、<code>蛋白质</code>三种分子模态。通过评估34种代表性模型（含Transformer、CNN及Hyena、Mamba等高效架构），得出四大核心发现：<strong>（1）</strong> gLMs在RNA和蛋白质任务上表现比肩甚至优于专门预训练的模型；<strong>（2）</strong> Transformer模型整体领先，但高效序列模型在特定任务中潜力显著；<strong>（3）</strong> gLMs的缩放规律尚未完全明确，更长输入序列和多样化预训练数据持续提升性能，但模型规模增大未必带来更好结果；<strong>（4）</strong> 预训练策略（训练目标、语料组成）对下游泛化能力影响显著。该框架为人类基因组学领域的gLMs评估提供了统一标准，为模型设计和泛化能力研究奠定基础。</p>\n<h1 id=\"2-引言\"><a href=\"#2-引言\" class=\"headerlink\" title=\"2 引言\"></a>2 引言</h1><h2 id=\"2-1-研究背景\"><a href=\"#2-1-研究背景\" class=\"headerlink\" title=\"2.1 研究背景\"></a>2.1 研究背景</h2><p>大型语言模型（LLMs）已革新自然语言处理，受基因组生物代码与人类语言的相似性启发，研究者将LLM框架扩展至生物序列分析，AlphaFold、ESM、DNABERT等模型的成功证明了其潜力。gLMs的设计围绕DNA序列的统计和功能特性展开，但现有评估存在诸多局限：任务覆盖有限，多聚焦分类问题且偏离真实生物分布；缺乏跨中心法则的全面评估，大多仅关注DNA任务；评估协议缺乏区分度，难以指导模型选择。</p>\n<h2 id=\"2-2-研究目标\"><a href=\"#2-2-研究目标\" class=\"headerlink\" title=\"2.2 研究目标\"></a>2.2 研究目标</h2><p>开发一个基于中心法则、一致且具有区分度的综合基准测试框架Genomic Touchstone，系统评估gLMs在DNA、RNA、蛋白质多模态任务中的性能，为生物研究者提供模型选择参考，同时指导未来gLMs的设计与优化。</p>\n<h1 id=\"3-研究结果\"><a href=\"#3-研究结果\" class=\"headerlink\" title=\"3 研究结果\"></a>3 研究结果</h1><h2 id=\"3-1-Genomic-Touchstone框架概述\"><a href=\"#3-1-Genomic-Touchstone框架概述\" class=\"headerlink\" title=\"3.1 Genomic Touchstone框架概述\"></a>3.1 Genomic Touchstone框架概述</h2><h3 id=\"基因组基准框架（Genomic-Touchstone）概述\"><a href=\"#基因组基准框架（Genomic-Touchstone）概述\" class=\"headerlink\" title=\"基因组基准框架（Genomic Touchstone）概述\"></a>基因组基准框架（Genomic Touchstone）概述</h3><p>基因组基准框架（Genomic Touchstone）是一个全面的基准测试框架，旨在对基因组语言模型（gLMs）应对以人为中心的实际生物学挑战的能力进行全面且公正的评估。受中心法则启发——该法则描述了遗传信息从DNA到RNA再到蛋白质的顺畅流动，Genomic Touchstone是首个涵盖跨越DNA、RNA和蛋白质序列模态任务的基准测试（图1），用于严格评估当前基因组语言模型的性能与通用性。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F1.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F1.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1 Genomic Touchstone 概述\"></p>\n<p><font size=2 color='gray'>a：数据整合流程，从组学数据库收集原始资源，经清洗后将DNA、RNA和蛋白质序列转换为统一格式；b：基准测试组成，含36个任务和88个数据集，左侧为9大任务类别，右侧为各模态任务分布；c：基准测试任务覆盖的中心法则核心流程；d-g：基准测试框架 pipeline，包括预训练数据组成、分词策略、模型架构和下游任务分组。</font></p>\n<h3 id=\"基因组层面的核心挑战\"><a href=\"#基因组层面的核心挑战\" class=\"headerlink\" title=\"基因组层面的核心挑战\"></a>基因组层面的核心挑战</h3><p><strong>这些挑战的核心在于基因组本身的复杂性</strong>。DNA是生命的基本分子，承载着细胞功能、发育和进化所需的遗传指令。它包含蛋白质编码基因、非编码RNA以及各种调控基序等多种元件（图1c）。基因组功能注释致力于识别和分类这些元件，以揭示它们在细胞过程中的作用。性能优异的基因组语言模型能够利用从大型基因组数据集获得的知识，检测复杂的序列模式。这种能力可绘制出全面的功能元件图谱，对推进理论基因组学发展和疾病诊断等实际应用都至关重要。</p>\n<p><strong>基因表达受包含启动子、增强子和其他元件的复杂调控网络控制</strong>。准确建模这些机制需要基因组语言模型<code>捕捉长程依赖关系</code>和<code>上下文特异性相互作用</code>，这对于理解基因在不同细胞环境中如何被激活或沉默至关重要。同时，DNA序列中的变异（即使是单核苷酸层面的变异）也可能对基因功能产生深远影响并引发疾病，因此预测这些遗传变异的影响，对于理解发病机制和开发靶向治疗具有重要意义。</p>\n<p>在该领域表现出色的基因组语言模型应能分析突变带来的细微差异，揭示其对基因调控和表型的潜在影响，进而提供关键的预测能力，助力将计算基因组学的见解转化为可行的临床策略。因此，我们对基因组语言模型在DNA层面的评估聚焦于三个类别：<code>基因组功能注释</code>、<code>调控机制建模</code>和<code>遗传变异影响预测</code>（图1b）。这三个类别共包含15项任务，旨在考验模型准确解读和阐释基因组信息多方面特征的能力。</p>\n<hr>\n<h3 id=\"RNA层面的任务设计\"><a href=\"#RNA层面的任务设计\" class=\"headerlink\" title=\"RNA层面的任务设计\"></a>RNA层面的任务设计</h3><p>与主要作为遗传信息储存库的DNA不同，RNA主动将这些指令转化为功能蛋白，调控基因表达并调节细胞对内外刺激的反应（图1c）。作为DNA和蛋白质之间的关键中介，RNA在<code>蛋白质合成</code>、<code>酶活性</code>和<code>基因调控</code>等众多生物学过程中发挥着核心作用。因此，揭示RNA的多样功能，对于理解细胞复杂性和疾病潜在机制至关重要。</p>\n<p>从语言学角度看，<u>RNA和DNA的“词汇表”仅相差一个“字母”：RNA中的尿嘧啶（U）取代了DNA中的胸腺嘧啶（T）</u>。但尿嘧啶和胸腺嘧啶均为与腺嘌呤配对的嘧啶类碱基，结构相似，这表明它们功能相近。基于这种相似性，我们推测RNA和DNA可能处于统一的语义空间中。这意味着<u>基于DNA预训练的基因组语言模型，或许能有效泛化到RNA相关任务</u>。</p>\n<p>受BEACON的启发，我们收集了三类主要的RNA任务：<code>RNA功能研究</code>、<code>转录后调控</code>及<code>RNA工程应用</code>（图1b）。RNA功能研究分析RNA如何调控基因表达并参与疾病发生，为治疗干预提供机制层面的见解；转录后调控聚焦转录后发生的RNA加工、稳定性调控及修饰事件，这些过程共同决定RNA的寿命和调控效果；RNA工程应用则探索RNA在合成生物学中的潜力，以提升其在生物技术和医学领域的应用价值，应对复杂的生物学挑战。</p>\n<hr>\n<h3 id=\"蛋白质层面的评估逻辑\"><a href=\"#蛋白质层面的评估逻辑\" class=\"headerlink\" title=\"蛋白质层面的评估逻辑\"></a>蛋白质层面的评估逻辑</h3><p>通过分子生物学中心法则，蛋白质与DNA紧密相连——该法则描述了遗传信息从DNA到RNA，最终到蛋白质的传递过程。在这一过程中，DNA作为稳定的遗传指令储存库，先转录为信使RNA（mRNA），再翻译为蛋白质。而蛋白质则执行从催化、结构支撑到信号传导和调控的关键细胞功能。这种顺畅的信息传递支撑着所有生物学过程，也体现了基因组序列与其编码的蛋白质组之间的内在联系（图1c）。</p>\n<p>由于基因组（尤其是编码DNA序列CDS）编码了所有蛋白质，基于基因组数据预训练的基因组语言模型不仅能预测DNA序列特征，还能预测蛋白质特性。为评估基因组语言模型处理蛋白质相关任务的能力，我们筛选了一系列涵盖蛋白质生物学多个方面的任务。<u>通过提取每种蛋白质对应的编码DNA序列（CDS），将蛋白质水平的数据集转换为基于DNA的格式</u>。序列获取的具体流程详见方法部分。</p>\n<p>具体而言，我们的任务套件包含三个不同类别（图1b）：<u><strong>首先</strong>是结构分析与预测，评估基因组语言模型直接从序列数据中推断蛋白质二级和三级结构的能力；<strong>其次</strong>是蛋白质功能注释，考察模型根据蛋白质的序列特征识别并赋予其生物学功能的效果；<strong>最后</strong>是蛋白质特性预测，聚焦于预测稳定性、溶解性和结合亲和力等关键理化属性，以此展现模型预测序列变异对蛋白质功能影响的能力</u>。</p>\n<hr>\n<h3 id=\"模型选择与评估设计\"><a href=\"#模型选择与评估设计\" class=\"headerlink\" title=\"模型选择与评估设计\"></a>模型选择与评估设计</h3><p>基于精心筛选的数据集，我们选取了多种基因组语言模型，以及两种基准模型（卷积神经网络CNN和长短期记忆网络LSTM），评估它们在与人类相关任务中的性能。为确保评估全面且具有生物学意义，我们重点关注基于人类基因组数据预训练的模型——包括仅在人类参考基因组上训练的模型，以及使用包含大量人类序列的多物种语料库训练的模型（详见方法部分）。</p>\n<p>所选模型涵盖多种架构，从传统的<code>CNN</code>、<code>LSTM</code>，到基于<code>Transformer</code>的模型，再到<code>BigBird</code>、<code>Hyena</code>和<code>Mamba</code>等新兴架构，每种模型均搭配不同的分词策略（如<code>字符级</code>、<code>k-mer</code>和字节对编码<code>BPE</code>）。模型规模从数百万参数的小型架构到高达25亿参数的大规模模型不等，使我们能够探究模型容量对生物序列建模的影响。</p>\n<p>这一系列基于人类数据预训练的模型，让我们得以系统评估架构选择、分词方案和预训练数据对下游人类功能基因组学任务性能的影响。通过在统一的基准测试集（涵盖DNA、RNA和蛋白质层面的任务）上对所有模型进行微调，我们分离出<code>架构设计</code>、<code>预训练策略</code>和<code>参数规模</code>等特定建模因素的影响。纳入RNA和蛋白质语言模型，进一步使我们能够探索这些模型跨分子模态的泛化能力。</p>\n<p>值得注意的是，<strong>没有任何单一模型在所有任务中持续优于其他模型</strong>（图2a）；即使是表现最佳的模型，平均排名也仅为7.3，这凸显了当前基因组模型固有的权衡取舍和专门化特性。这种差异性强调了多维度评估的重要性，也表明不同任务可能受益于不同的归纳偏好。最后，我们扩展分析以验证大语言模型（LLM）中观察到的缩放定律是否适用于基因组领域，探究模型容量和数据构成如何共同影响在健康相关及更广泛生物学场景中的泛化能力。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F2.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F2.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2 gLMs基准测试结果分析\"></p>\n<p><font color='grey' size=2> a. 基于整体性能的模型平均排名。每个圆圈代表一个模型，颜色深浅对应排名（颜色越深表示性能越优），中心位置显示数字排名。b-d. 各模型在DNA(b)、RNA(c)和蛋白质(d)基准测试中的任务特定性能分布（点状图）与平均性能分布（黑色菱形）。各模态中排名前五的模型以红色高亮显示，其余模型则以蓝色标注。</font></p>\n<h2 id=\"3-2-DNA相关任务性能\"><a href=\"#3-2-DNA相关任务性能\" class=\"headerlink\" title=\"3.2 DNA相关任务性能\"></a>3.2 DNA相关任务性能</h2><p>DNA任务分为<code>基因组功能注释</code>、<code>调控机制建模</code>、<code>遗传变异效应预测</code>三类，核心结果如下：</p>\n<ul>\n<li><strong>基因组功能注释</strong>：<code>剪接位点预测</code>（SpliceBERT的F1分数0.918）和<code>CpG甲基化预测</code>（NTv2-500m-Multi的F1分数0.957）任务表现优异；<code>表观遗传标记预测</code>难度最高（顶级模型F1分数仅0.380）；<u>输入序列长度提升显著改善物种分类等任务性能，长上下文模型（如Hyena-Large）在8192碱基对以上序列中表现突出</u>。</li>\n<li><strong>调控机制建模</strong>：<code>增强子-启动子相互作用</code>预测表现较好（DNABERT2的F1分数0.941）；<code>基因表达预测</code>（Generator-1.2b的$R^2$&#x3D;0.548）和<code>增强子活性预测</code>（NT-2.5b-1000g的Spearman分数0.317）性能中等，模型差异显著。</li>\n<li><strong>遗传变异效应预测</strong>：<code>BRCA1/2 SNV功能影响分类</code>任务表现最佳（NT-2.5b-1000g的F1分数0.893）；<code>致病性分类</code>整体难度高（顶级模型F1分数仅0.391）；<code>GPN</code>在遗传疾病分类中领先（F1分数0.725）。</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F3.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F3.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3 基因组功能注释任务模型性能\"></p>\n<p><font size=2 color='gray'>a：6项代表性基因组功能注释基准测试中前20个模型的F1分数（***: P&lt;0.001, *: P&lt;0.05），不同模型在不同任务中表现各异；b：不同输入序列长度下的物种分类性能，左图为多个模型在不同序列长度下的平均F1分数分布及趋势线，右图显示长序列长度显著提升F1分数，长上下文模型在8192碱基对以上序列中独占优势。</font></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F4.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F4.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图4. 模型在调控机制建模任务与基因变异效应预测任务中的表现\"></p>\n<p><font size=2 color='gray'>a. 调控机制建模任务的前20个模型，涵盖调控活性预测、增强子活性预测、增强子-启动子相互作用预测及基因表达预测（***：P &lt; 0.001）。b. 基因变异效应预测任务的表现，包括遗传疾病分类、致病性分类、剪接变异效应预测以及BRCA1&#x2F;2 SNV 功能影响分类（***：P &lt; 0.001）。</font></p>\n<h2 id=\"3-3-RNA相关任务性能\"><a href=\"#3-3-RNA相关任务性能\" class=\"headerlink\" title=\"3.3 RNA相关任务性能\"></a>3.3 RNA相关任务性能</h2><p>RNA任务分为<code>RNA功能研究</code>、<code>转录后调控</code>、<code>RNA工程应用</code>三类，核心发现：</p>\n<ul>\n<li><u>DNA预训练gLMs在几乎所有RNA任务中优于RNA预训练模型</u>，即使参数规模相当（如DNABERT2、NTv2-100m-Multi vs RNAErnie、RNAFM）。</li>\n<li><code>非编码RNA分类</code>（Caduceus-Ps的F1分数0.960）和<code>APA异构体预测</code>（Caduceus-Ps的Spearman分数0.929）表现突出；<code>平均核糖体负载</code>预测（Hyena-Medium的Spearman分数0.812）和<code>mRNA稳定性</code>预测（Generator-1.2b的Spearman分数0.554）呈现模型差异。</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F5.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F5.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图5 RNA水平任务模型性能\"></p>\n<p><font size=2 color='gray'>a：RNA序列转换为DNA输入的示意图，尿嘧啶（U）替换为胸腺嘧啶（T）后进行分词和模型输入；b：RNA预训练与DNA预训练模型在RNA任务上的性能对比，DNA模型（蓝色）显著优于RNA模型（红色）（***: P &lt; 0.001）；c-e：不同RNA任务类别中前20个模型的性能，包括RNA功能研究（c）、转录后调控（d）和RNA工程应用（e）（***: P&lt;0.001, **: P &lt; 0.01, *: P &lt; 0.05）。</font></p>\n<h2 id=\"3-4-蛋白质相关任务性能\"><a href=\"#3-4-蛋白质相关任务性能\" class=\"headerlink\" title=\"3.4 蛋白质相关任务性能\"></a>3.4 蛋白质相关任务性能</h2><p>蛋白质任务分为<code>结构分析与预测</code>、<code>功能注释</code>、<code>性质预测</code>三类，核心结果：</p>\n<ul>\n<li><u>DNA预训练gLMs在多数蛋白质任务中优于蛋白质预训练模型</u>（如NTv2-500m-Multi在7&#x2F;10项任务中超越ESM-2）。</li>\n<li>蛋白质<code>结构域分类</code>（NTv2-500m-Multi的F1分数1.0）和<code>跨膜区域</code>预测（Generator-1.2b的F1分数0.782）表现优异；<code>酶分类</code>任务整体难度较高（Generator-1.2b的F1分数0.423）；<code>蛋白质稳定性</code>预测中ESM-1b领先（Spearman分数0.762）。</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F6.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F6.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图6 模型在精选蛋白质水平基准测试中的表现\"></p>\n<p><font size=2 color='gray'>a. 密集式蛋白质层面基准测试模型性能。密码子数据集构建流程：蛋白质分子经计算机模拟消化为多肽，翻译为氨基酸序列，再逆向翻译为核苷酸（密码子）序列，经过过滤和注释后生成任务就绪数据集。b. 蛋白质与DNA预训练模型在蛋白质任务上的性能对比。DNA模型（蓝色）显著优于蛋白质模型（绿色），统计学显著性高（*P&lt;0.05）。为确保公平比较，我们选取了参数量相近的模型：DNA模型采用NTv2-500m-Multi和NT-500m-1000G，蛋白质模型采用 ESM -1b和 ESM -2——所有模型参数量均约5亿。c. 结构分析与预测任务前20名模型表现，包括二级结构分析和跨膜区域预测（***：P&lt;0.001，*：P&lt;0.05）。d. 蛋白质功能注释任务前20名模型表现，涵盖蛋白质变体分类、翻译后修饰预测、蛋白质结构域分类及酶分类（***：P&lt;0.001）。e. 蛋白质性质预测任务前20名模型表现，包括β-内酰胺酶活性预测、荧光预测、蛋白质稳定性预测及熔点预测（***：P&lt;0.001）。</font></p>\n<h2 id=\"3-5-模型架构、缩放规律与预训练策略洞察\"><a href=\"#3-5-模型架构、缩放规律与预训练策略洞察\" class=\"headerlink\" title=\"3.5 模型架构、缩放规律与预训练策略洞察\"></a>3.5 模型架构、缩放规律与预训练策略洞察</h2><ul>\n<li><strong>架构影响</strong>：Transformer 模型占据前15名中的14个，整体性能领先，但SSM-based模型（如Caduceus、Hyena）在长序列任务中具有潜力，线性时间复杂度优势显著。</li>\n<li><strong>缩放规律</strong>：NT系列模型呈现明确缩放趋势（参数增加、预训练数据多样化提升性能），但其他模型未表现出一致规律，短序列预训练限制了模型潜力发挥。</li>\n<li><strong>预训练策略</strong>：多物种预训练数据（如NT-2.5b-Multi）、长输入序列预训练显著提升模型泛化能力；融入生物先验的预训练目标（如Generator模型）带来性能增益。</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F7.large.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/F7.large.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图7 模型与任务的基准测试洞察\"><br><font size=2 color='gray'>a：模型参数与平均基准测试性能的关系，每个点代表一个预训练模型，x轴为参数规模（对数尺度），y轴为平均评估分数；b：多物种预训练与单一人类数据预训练模型的性能分布对比；c：不同架构模型的性能对比，Transformer架构仍是主流，SSM-based模型具有潜力；d：输入序列长度达32768碱基对时的模型F1分数，长上下文窗口模型随序列长度增加增益显著。</font></p>\n<h1 id=\"4-讨论\"><a href=\"#4-讨论\" class=\"headerlink\" title=\"4 讨论\"></a>4 讨论</h1><h2 id=\"4-1-核心结论\"><a href=\"#4-1-核心结论\" class=\"headerlink\" title=\"4.1 核心结论\"></a>4.1 核心结论</h2><p>Genomic Touchstone建立了首个覆盖中心法则全链条的gLMs评估框架，证实了DNA预训练gLMs在跨模态任务中的泛化能力；Transformer模型整体表现最优，但高效架构在特定场景具有应用价值；<u>模型性能受架构设计、缩放策略和预训练配置的共同影响，多物种、长序列预训练是关键优化方向</u>。</p>\n<h2 id=\"4-2-研究局限与未来方向\"><a href=\"#4-2-研究局限与未来方向\" class=\"headerlink\" title=\"4.2 研究局限与未来方向\"></a>4.2 研究局限与未来方向</h2><ul>\n<li><strong>局限包括</strong>：未开展从头预训练的对照实验、未涵盖生成式任务、以人类数据为中心、缺乏湿实验验证任务。</li>\n<li><strong>未来方向</strong>：开发兼顾性能与效率的新型架构、构建条件生成模型、扩展多物种评估框架、开发gLMs驱动的交互式AI实验辅助工具。</li>\n</ul>\n<h1 id=\"5-研究方法\"><a href=\"#5-研究方法\" class=\"headerlink\" title=\"5 研究方法\"></a>5 研究方法</h1><h2 id=\"5-1-基准测试模型\"><a href=\"#5-1-基准测试模型\" class=\"headerlink\" title=\"5.1 基准测试模型\"></a>5.1 基准测试模型</h2><p>涵盖基线模型（CNN、LSTM）、基因组语言模型（DNABERT系列、GPN、Nucleotide Transformer系列等）、RNA语言模型（RNAFM、SpliceBERT、RNAErnie）、蛋白质语言模型（ESM-1b、ESM-2），详细信息如下表：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/T1.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/T1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"表1 模型列表\"></p>\n<h2 id=\"5-2-基准测试数据集\"><a href=\"#5-2-基准测试数据集\" class=\"headerlink\" title=\"5.2 基准测试数据集\"></a>5.2 基准测试数据集</h2><p>涵盖DNA、RNA、蛋白质三类模态的36项任务，88个数据集，关键信息如下（部分核心数据集）：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/T2.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/05/T2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"表2 数据集列表\"></p>\n<h2 id=\"5-3-实验设置\"><a href=\"#5-3-实验设置\" class=\"headerlink\" title=\"5.3 实验设置\"></a>5.3 实验设置</h2><ul>\n<li><p><strong>微调细节</strong>：所有模型使用预训练权重初始化，添加任务特定头（回归任务用单层回归头，分类任务用softmax分类头），AdamW优化器+余弦学习率调度器，基于验证集损失选择最优 epoch。</p>\n</li>\n<li><p><strong>评估指标</strong>：</p>\n<ul>\n<li><p><strong>分类任务</strong>：准确率（Accuracy）、F1分数、宏F1分数（Macro-F1）</p>\n<ul>\n<li>$Accuracy &#x3D; \\frac{TP+TN}{TP+TN+FP+FN}$</li>\n<li>$F1 &#x3D; 2 × \\frac{Precision × Recall}{Precision + Recall}$（其中$Precision &#x3D; \\frac{TP}{TP+FP}$，$Recall &#x3D; \\frac{TP}{TP+FN}$）</li>\n<li>$Macro-F1 &#x3D; \\frac{1}{N} \\sum_{i&#x3D;1}^{N} F1_i$（N为类别数，$F1_i$为第i类的F1分数）</li>\n</ul>\n</li>\n<li><p><strong>回归任务</strong>：决定系数（$R^2$）、斯皮尔曼等级相关系数（ρ）</p>\n<ul>\n<li>$R^2 &#x3D; 1 - \\frac{\\sum_{i&#x3D;1}^{n}(y_i - \\hat{y}<em>i)^2}{\\sum</em>{i&#x3D;1}^{n}(y_i - \\overline{y})^2}$（$y_i$为真实值，$\\hat{y}_i$为预测值，$\\overline{y}$为真实值均值）</li>\n<li>$\\rho &#x3D; 1 - \\frac{6 \\cdot \\sum d_i^2}{n(n^2 - 1)}$（$d_i$为预测值与真实值的秩差，n为样本数）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>计算资源</strong>：5亿参数以下模型使用单张NVIDIA RTX 3090 GPU，5亿参数以上模型使用单张NVIDIA H800 GPU。</p>\n</li>\n</ul>\n<h2 id=\"5-4-数据可用性\"><a href=\"#5-4-数据可用性\" class=\"headerlink\" title=\"5.4 数据可用性\"></a>5.4 数据可用性</h2><table>\n<thead>\n<tr>\n<th>Database</th>\n<th>Link</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>DNA</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>EPDnew</td>\n<td><a href=\"https://epd.expasy.org/epd/\">https://epd.expasy.org/epd/</a></td>\n</tr>\n<tr>\n<td>ENCODE</td>\n<td><a href=\"https://www.encodeproject.org/\">https://www.encodeproject.org/</a></td>\n</tr>\n<tr>\n<td>GENCODE</td>\n<td><a href=\"https://www.gencodegenes.org/\">https://www.gencodegenes.org/</a></td>\n</tr>\n<tr>\n<td>Ensembl</td>\n<td><a href=\"https://www.ensembl.org/\">https://www.ensembl.org</a></td>\n</tr>\n<tr>\n<td>RefSeq</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/refseq/\">https://www.ncbi.nlm.nih.gov/refseq/</a></td>\n</tr>\n<tr>\n<td>GEO</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/geo\">https://www.ncbi.nlm.nih.gov/geo</a></td>\n</tr>\n<tr>\n<td>ClinVar</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/clinvar/\">https://www.ncbi.nlm.nih.gov/clinvar/</a></td>\n</tr>\n<tr>\n<td>SpliceVarDB</td>\n<td><a href=\"https://splicevardb.org/\">https://splicevardb.org</a></td>\n</tr>\n<tr>\n<td><strong>RNA</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>Rfam</td>\n<td><a href=\"https://rfam.org/\">https://rfam.org</a></td>\n</tr>\n<tr>\n<td>PaxDb</td>\n<td><a href=\"https://pax-db.org/\">https://pax-db.org</a></td>\n</tr>\n<tr>\n<td>GEO</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/geo\">https://www.ncbi.nlm.nih.gov/geo</a></td>\n</tr>\n<tr>\n<td>RMBase</td>\n<td><a href=\"https://rna.sysu.edu.cn/rmbase\">https://rna.sysu.edu.cn/rmbase</a></td>\n</tr>\n<tr>\n<td>RADAR</td>\n<td><a href=\"http://rnaedit.com/\">http://rnaedit.com</a></td>\n</tr>\n<tr>\n<td>EMBL-EBI</td>\n<td><a href=\"https://www.ebi.ac.uk/gxa/home\">https://www.ebi.ac.uk/gxa/home</a></td>\n</tr>\n<tr>\n<td>SRA</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/sra\">https://www.ncbi.nlm.nih.gov/sra</a></td>\n</tr>\n<tr>\n<td>GenBank</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/genbank\">https://www.ncbi.nlm.nih.gov/genbank</a></td>\n</tr>\n<tr>\n<td>Ensembl</td>\n<td><a href=\"https://www.ensembl.org/\">https://www.ensembl.org</a></td>\n</tr>\n<tr>\n<td><strong>Protein</strong></td>\n<td></td>\n</tr>\n<tr>\n<td>UniProt</td>\n<td><a href=\"https://www.uniprot.org/\">https://www.uniprot.org/</a></td>\n</tr>\n<tr>\n<td>GENCODE</td>\n<td><a href=\"https://www.gencodegenes.org/\">https://www.gencodegenes.org/</a></td>\n</tr>\n<tr>\n<td>Protein Data Bank</td>\n<td><a href=\"https://www.rcsb.org/\">https://www.rcsb.org/</a></td>\n</tr>\n<tr>\n<td>ProteomicsDB</td>\n<td><a href=\"https://www.proteomicsdb.org/\">https://www.proteomicsdb.org/</a></td>\n</tr>\n</tbody></table>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><ul>\n<li>Yihui Wang, Zhiyuan Cai, Qian Zeng, Yihang Gao, Jiarui Ouyang, Yingxue Xu, Shu Yang, Sunan He, Yuxiang Nie, Yu Cai, Fengtao Zhou, Cheng Jin, Xi Wang, Zhi Xie, Danqing Zhu, Ting Xie, Kwang-Ting Cheng, Can Yang, Xi Fu, Jiguang Wang, Kang Zhang, Jianhua Yao, Raul Rabadan, Hao Chen. Genomic Touchstone: Benchmarking Genomic Language Models in the Context of the Central Dogma. bioRxiv 2025.06.25.661622; doi: <a href=\"https://doi.org/10.1101/2025.06.25.661622\">https://doi.org/10.1101/2025.06.25.661622</a></li>\n</ul>\n<h1 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h1><p>关注公众号“生信之巅”。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"Segmentation models实战","slug":"Segmentation-models实战","date":"2025-11-16T02:42:14.000Z","updated":"2025-11-23T02:03:51.679Z","comments":true,"path":"api/articles/Segmentation-models实战.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp","content":"<h1 id=\"1-Segmentation-models-简介\"><a href=\"#1-Segmentation-models-简介\" class=\"headerlink\" title=\"1. Segmentation models 简介\"></a>1. Segmentation models 简介</h1><p>使用Transformer骨干网络的分割模型（如Nucleotide Transformer、Enformer、Borzoi）可用于单核苷酸分辨率下的基因组元件预测。例如，<code>SegmentNT</code>能在长达30kb的序列（可扩展至50kbp）中<strong>预测14种不同类别的人类基因组元件</strong>，并表现出优异的性能。</p>\n<p>所有模型均搭配一维U-Net分割头，以单核苷酸分辨率预测序列中多种基因组元件的位置。这些元件包括基因元件（蛋白质编码基因、长链非编码RNA、5’非翻译区、3’非翻译区、外显子、内含子、剪接受体位点和供体位点）和调控元件（polyA signal、组织非特异性和组织特异性启动子及增强子，以及CTCF结合位点）。</p>\n<ul>\n<li>📜 <strong><a href=\"https://www.nature.com/articles/s41592-025-02881-2\">Read the Paper (Nature Methods 2025)</a></strong></li>\n<li>🤗 <strong><a href=\"https://huggingface.co/collections/InstaDeepAI/segmentnt-65eb4941c57808b4a3fe1319\">SegmentNT Hugging Face Collection</a></strong></li>\n<li>🚀 <strong><a href=\"https://colab.research.google.com/#fileId=https%3A//huggingface.co/InstaDeepAI/segment_nt/blob/main/inference_segment_nt.ipynb\">SegmentNT Inference Notebook (HF)</a></strong></li>\n</ul>\n<img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt= \"Performance on downstream tasks\" width=\"600\">\n\n<p><em>Fig. 1: SegmentNT localizes genomics elements at nucleotide resolution.</em></p>\n<h1 id=\"2-如何使用-🚀\"><a href=\"#2-如何使用-🚀\" class=\"headerlink\" title=\"2. 如何使用 🚀\"></a>2. 如何使用 🚀</h1><h2 id=\"2-1-安装并加载模块\"><a href=\"#2-1-安装并加载模块\" class=\"headerlink\" title=\"2.1 安装并加载模块\"></a>2.1 安装并加载模块</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">!pip install boto3</span><br><span class=\"line\">!pip install matplotlib</span><br><span class=\"line\">!pip install biopython</span><br><span class=\"line\">!pip install dm-haiku</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple</span><br><span class=\"line\">Requirement already satisfied: boto3 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (1.28.2)</span><br><span class=\"line\">Requirement already satisfied: botocore&lt;1.32.0,&gt;=1.31.2 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from boto3) (1.31.2)</span><br><span class=\"line\">Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from boto3) (1.0.1)</span><br><span class=\"line\">Requirement already satisfied: s3transfer&lt;0.7.0,&gt;=0.6.0 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from boto3) (0.6.1)</span><br><span class=\"line\">Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from botocore&lt;1.32.0,&gt;=1.31.2-&gt;boto3) (2.8.2)</span><br><span class=\"line\">Requirement already satisfied: urllib3&lt;1.27,&gt;=1.25.4 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from botocore&lt;1.32.0,&gt;=1.31.2-&gt;boto3) (1.26.16)</span><br><span class=\"line\">Requirement already satisfied: six&gt;=1.5 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.32.0,&gt;=1.31.2-&gt;boto3) (1.16.0)</span><br><span class=\"line\"></span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -&gt; \u001b[0m\u001b[32;49m24.1.2\u001b[0m</span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m</span><br><span class=\"line\">Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple</span><br><span class=\"line\">Requirement already satisfied: matplotlib in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (3.7.2)</span><br><span class=\"line\">Requirement already satisfied: contourpy&gt;=1.0.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (1.1.0)</span><br><span class=\"line\">Requirement already satisfied: cycler&gt;=0.10 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (0.11.0)</span><br><span class=\"line\">Requirement already satisfied: fonttools&gt;=4.22.0 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (4.41.0)</span><br><span class=\"line\">Requirement already satisfied: kiwisolver&gt;=1.0.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (1.4.4)</span><br><span class=\"line\">Requirement already satisfied: numpy&gt;=1.20 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (1.25.1)</span><br><span class=\"line\">Requirement already satisfied: packaging&gt;=20.0 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (23.1)</span><br><span class=\"line\">Requirement already satisfied: pillow&gt;=6.2.0 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (10.0.0)</span><br><span class=\"line\">Requirement already satisfied: pyparsing&lt;3.1,&gt;=2.3.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (3.0.9)</span><br><span class=\"line\">Requirement already satisfied: python-dateutil&gt;=2.7 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from matplotlib) (2.8.2)</span><br><span class=\"line\">Requirement already satisfied: six&gt;=1.5 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)</span><br><span class=\"line\"></span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -&gt; \u001b[0m\u001b[32;49m24.1.2\u001b[0m</span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m</span><br><span class=\"line\">Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple</span><br><span class=\"line\">Requirement already satisfied: biopython in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (1.81)</span><br><span class=\"line\">Requirement already satisfied: numpy in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from biopython) (1.25.1)</span><br><span class=\"line\"></span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -&gt; \u001b[0m\u001b[32;49m24.1.2\u001b[0m</span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m</span><br><span class=\"line\">Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple</span><br><span class=\"line\">Requirement already satisfied: dm-haiku in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (0.0.9)</span><br><span class=\"line\">Requirement already satisfied: absl-py&gt;=0.7.1 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from dm-haiku) (1.4.0)</span><br><span class=\"line\">Requirement already satisfied: jmp&gt;=0.0.2 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from dm-haiku) (0.0.4)</span><br><span class=\"line\">Requirement already satisfied: numpy&gt;=1.18.0 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from dm-haiku) (1.25.1)</span><br><span class=\"line\">Requirement already satisfied: tabulate&gt;=0.8.9 in /home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages (from dm-haiku) (0.9.0)</span><br><span class=\"line\"></span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -&gt; \u001b[0m\u001b[32;49m24.1.2\u001b[0m</span><br><span class=\"line\">\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> nucleotide_transformer</span><br><span class=\"line\"><span class=\"keyword\">except</span>:</span><br><span class=\"line\">    !pip install git+https://github.com/instadeepai/nucleotide-transformer@main |tail -n <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> nucleotide_transformer</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"string\">&quot;COLAB_TPU_ADDR&quot;</span> <span class=\"keyword\">in</span> os.environ:</span><br><span class=\"line\">    <span class=\"keyword\">from</span> jax.tools <span class=\"keyword\">import</span> colab_tpu</span><br><span class=\"line\"></span><br><span class=\"line\">    colab_tpu.setup_tpu()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-2-SegmentNT\"><a href=\"#2-2-SegmentNT\" class=\"headerlink\" title=\"2.2 SegmentNT\"></a>2.2 SegmentNT</h2><p>⚠️ SegmentNT 模型采用 <a href=\"https://www.nature.com/articles/s41592-024-02523-z\">核苷酸转换器（NT）</a> 作为骨干网络，训练数据为 30,000 个核苷酸序列（对应 5001 个标记，包含 CLS 标记）。但研究表明，SegmentNT 可泛化至 50,000 bp（碱基对）的序列。由于 30,000 bp 的训练长度超过了核苷酸转换器所能处理的最大长度（2048 个 6-mer 标记），因此采用了 Yarn 缩放技术。</p>\n<p>默认情况下，<code>缩放系数（rescaling factor）</code> 已设置为训练时使用的值。若需对 30kbp 至 50kbp 之间的序列进行推理，需在 <code>get_pretrained_segment_nt_model</code> 函数中传入 <code>rescaling_factor</code> 参数，其值计算公式为：</p>\n<p><strong>rescaling_factor &#x3D; 最大核苷酸数 &#x2F; 核苷酸转换器最大标记数</strong></p>\n<p>其中，<code>推理时 DNA 标记数（num_dna_tokens_inference）</code> 指推理过程中的标记总数（例如 40008 个碱基对的序列对应 6669 个标记），<code>核苷酸转换器最大标记数（max_num_tokens_nt）</code> 为骨干网络核苷酸转换器的训练最大标记数，即 <code>2048</code>。</p>\n<p>🚧 <font color=\"#FF0000\">SegmentNT 模型不支持输入序列中包含任何 “<strong>N</strong>” 碱基。原因是每个核苷酸需被标记化为 <code>6-mer</code> 形式，而包含一个或多个 “N” 碱基的序列无法满足这一标记化要求。</font></p>\n<h3 id=\"2-2-1-🔍-示例代码\"><a href=\"#2-2-1-🔍-示例代码\" class=\"headerlink\" title=\"2.2.1 🔍 示例代码\"></a>2.2.1 🔍 <strong>示例代码</strong></h3><p>下面这段代码的核心功能是使用预训练的<code>segment_nt</code>模型对 DNA 序列进行基因组特征预测（如预测序列是否为内含子 intron 等），并展示了从模型加载、数据预处理到并行推理的完整流程。具体包括：</p>\n<ul>\n<li><strong>环境配置</strong>：指定 JAX 使用 CPU 设备，避免内存泄漏，同时准备多设备并行计算环境。</li>\n<li><strong>模型加载</strong>：加载预训练的segment_nt模型，包括模型参数、前向计算函数、分词器和配置信息，并通过 Haiku 和 JAX 的并行接口（pmap）适配多设备计算。</li>\n<li><strong>数据处理</strong>：将输入的 DNA 序列通过分词器转换为模型可识别的 token ids，并转换为 JAX 数组格式。</li>\n<li><strong>并行推理</strong>：在多个 CPU 设备上并行运行模型，输出 DNA 序列对应各类基因组特征的预测概率，并重点提取了 “intron”（内含子）的预测概率。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入所需库：haiku用于构建神经网络，jax用于高性能数值计算，jax.numpy是jax的numpy接口</span></span><br><span class=\"line\"><span class=\"comment\"># nucleotide_transformer.pretrained中的get_pretrained_segment_nt_model用于获取预训练的核苷酸序列模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> haiku <span class=\"keyword\">as</span> hk</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax.numpy <span class=\"keyword\">as</span> jnp</span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.pretrained <span class=\"keyword\">import</span> get_pretrained_segment_nt_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置JAX默认使用CPU作为计算设备，避免在其他设备（如GPU）上可能出现的内存泄漏问题，增强代码稳定性</span></span><br><span class=\"line\">jax.config.update(<span class=\"string\">&quot;jax_platform_name&quot;</span>, <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定计算后端为CPU，获取所有可用的CPU设备，并计算设备数量</span></span><br><span class=\"line\">backend = <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">devices = jax.devices(backend)</span><br><span class=\"line\">num_devices = <span class=\"built_in\">len</span>(devices)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Devices found: <span class=\"subst\">&#123;devices&#125;</span>&quot;</span>)  <span class=\"comment\"># 打印找到的设备信息</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># DNA序列token数量（不包含前缀的CLS token）需要能被下采样块数量的2的幂整除（此处下采样块对应的值为4）</span></span><br><span class=\"line\">max_num_nucleotides = <span class=\"number\">8</span>  <span class=\"comment\"># 定义最大核苷酸数量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 断言检查：确保max_num_nucleotides能被4整除，否则抛出错误（保证模型输入尺寸兼容）</span></span><br><span class=\"line\"><span class=\"keyword\">assert</span> max_num_nucleotides % <span class=\"number\">4</span> == <span class=\"number\">0</span>, (</span><br><span class=\"line\">    <span class=\"string\">&quot;The number of DNA tokens (excluding the CLS token prepended) needs to be dividible by&quot;</span></span><br><span class=\"line\">     <span class=\"string\">&quot;2 to the power of the number of downsampling block, i.e 4.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取预训练的segment_nt模型：包括模型参数、前向计算函数、分词器和模型配置</span></span><br><span class=\"line\"><span class=\"comment\"># 其中：</span></span><br><span class=\"line\"><span class=\"comment\"># - model_name指定模型名为&quot;segment_nt&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># - embeddings_layers_to_save指定保存第29层的嵌入特征</span></span><br><span class=\"line\"><span class=\"comment\"># - attention_maps_to_save指定保存(1,4)和(7,10)位置的注意力图</span></span><br><span class=\"line\"><span class=\"comment\"># - max_positions指定最大位置数（包含CLS token，因此为max_num_nucleotides + 1）</span></span><br><span class=\"line\">parameters, forward_fn, tokenizer, config = get_pretrained_segment_nt_model(</span><br><span class=\"line\">    model_name=<span class=\"string\">&quot;segment_nt&quot;</span>,</span><br><span class=\"line\">    embeddings_layers_to_save=(<span class=\"number\">29</span>,),</span><br><span class=\"line\">    attention_maps_to_save=((<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">7</span>, <span class=\"number\">10</span>)),</span><br><span class=\"line\">    max_positions=max_num_nucleotides + <span class=\"number\">1</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 用haiku.transform转换前向函数，使其符合haiku的函数式编程范式</span></span><br><span class=\"line\">forward_fn = hk.transform(forward_fn)</span><br><span class=\"line\"><span class=\"comment\"># 使用jax.pmap对前向计算函数进行并行映射，指定计算设备，donate_argnums=(0,)表示允许释放参数的内存</span></span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 准备输入数据并进行分词</span></span><br><span class=\"line\">sequences = [<span class=\"string\">&quot;ATTCCGATTCCGATTCCAACGGATTATTCCGATTAACCGATTCCAATT&quot;</span>, <span class=\"string\">&quot;ATTTCTCTCTCTCTCTGAGATCGATGATTTCTCTCTCATCGAACTATG&quot;</span>]  <span class=\"comment\"># 两个DNA序列示例</span></span><br><span class=\"line\"><span class=\"comment\"># 对序列进行批量分词，提取token ids（忽略元组中的第一个元素，保留token ids）</span></span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\"><span class=\"comment\"># 将token ids转换为jax数组（int32类型），作为模型输入</span></span><br><span class=\"line\">tokens = jnp.asarray(tokens_ids, dtype=jnp.int32)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化随机种子，并将随机键复制到所有设备（多设备并行时保持一致性）</span></span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\"><span class=\"comment\"># 将模型参数复制到所有设备</span></span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br><span class=\"line\"><span class=\"comment\"># 将输入token复制到所有设备</span></span><br><span class=\"line\">tokens = jax.device_put_replicated(tokens, devices=devices)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对输入序列进行模型推理</span></span><br><span class=\"line\">outs = apply_fn(parameters, keys, tokens)</span><br><span class=\"line\"><span class=\"comment\"># 从推理结果中获取基因组特征的logits（未归一化的概率）</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># 将logits通过softmax转换为概率，并取最后一个维度的结果</span></span><br><span class=\"line\">probabilities = jnp.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[...,-<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Probabilities shape: <span class=\"subst\">&#123;probabilities.shape&#125;</span>&quot;</span>)  <span class=\"comment\"># 打印概率的形状</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印模型可预测的基因组特征（如intron、exon等）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Features inferred: <span class=\"subst\">&#123;config.features&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取&quot;intron&quot;（内含子）特征在特征列表中的索引</span></span><br><span class=\"line\">idx_intron = config.features.index(<span class=\"string\">&quot;intron&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 提取&quot;intron&quot;对应的概率</span></span><br><span class=\"line\">probabilities_intron = probabilities[..., idx_intron]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Intron probabilities shape: <span class=\"subst\">&#123;probabilities_intron.shape&#125;</span>&quot;</span>)  <span class=\"comment\"># 打印内含子概率的形状</span></span><br></pre></td></tr></table></figure>\n\n<p>支持的模型名:</p>\n<ul>\n<li><strong>segment_nt</strong></li>\n<li><strong>segment_nt_multi_species</strong></li>\n</ul>\n<h3 id=\"2-2-2-完整代码\"><a href=\"#2-2-2-完整代码\" class=\"headerlink\" title=\"2.2.2 完整代码\"></a>2.2.2 完整代码</h3><p>下面的代码展示了如何对 10kb 和 50kb 序列进行推理，以及如何绘制概率分布图以复现论文中的图 1（Fig.1d）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> Bio <span class=\"keyword\">import</span> SeqIO</span><br><span class=\"line\"><span class=\"keyword\">import</span> gzip</span><br><span class=\"line\"><span class=\"keyword\">import</span> haiku <span class=\"keyword\">as</span> hk</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax.numpy <span class=\"keyword\">as</span> jnp</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.pretrained <span class=\"keyword\">import</span> get_pretrained_segment_nt_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify &quot;cpu&quot; as default (but you can decide to use GPU or TPU in the next cell)</span></span><br><span class=\"line\">jax.config.update(<span class=\"string\">&quot;jax_platform_name&quot;</span>, <span class=\"string\">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Devices found: [CpuDevice(id=0)]\n</code></pre>\n<p><strong>（1）指定后端设备</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Use either &quot;cpu&quot;, &quot;gpu&quot; or &quot;tpu&quot;</span></span><br><span class=\"line\">backend = <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">devices = jax.devices(backend)</span><br><span class=\"line\">num_devices = <span class=\"built_in\">len</span>(devices)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Devices found: <span class=\"subst\">&#123;devices&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>（2）定义用于绘制概率的函数</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># seaborn settings</span></span><br><span class=\"line\">sns.set_style(<span class=\"string\">&quot;whitegrid&quot;</span>)</span><br><span class=\"line\">sns.set_context(</span><br><span class=\"line\">    <span class=\"string\">&quot;notebook&quot;</span>,</span><br><span class=\"line\">    font_scale=<span class=\"number\">1</span>,</span><br><span class=\"line\">    rc=&#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;font.size&quot;</span>: <span class=\"number\">14</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;axes.titlesize&quot;</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;axes.labelsize&quot;</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;xtick.labelsize&quot;</span>: <span class=\"number\">16</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;ytick.labelsize&quot;</span>: <span class=\"number\">16</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;legend.fontsize&quot;</span>: <span class=\"number\">16</span>,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;xtick.bottom&#x27;</span>] = <span class=\"literal\">True</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">&#x27;ytick.left&#x27;</span>] = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set colors</span></span><br><span class=\"line\">colors = sns.color_palette(<span class=\"string\">&quot;Set2&quot;</span>).as_hex()</span><br><span class=\"line\">colors2 = sns.color_palette(<span class=\"string\">&quot;husl&quot;</span>).as_hex()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange order of the features to match Fig.3 from the paper.</span></span><br><span class=\"line\">features_rearranged = [</span><br><span class=\"line\"> <span class=\"string\">&#x27;protein_coding_gene&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;lncRNA&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;5UTR&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;3UTR&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;exon&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;intron&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;splice_donor&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;splice_acceptor&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;promoter_Tissue_specific&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;promoter_Tissue_invariant&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;enhancer_Tissue_specific&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;enhancer_Tissue_invariant&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;CTCF-bound&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;polyA_signal&#x27;</span>,</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot_features</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">    predicted_probabilities_all,</span></span><br><span class=\"line\"><span class=\"params\">    seq_length: <span class=\"built_in\">int</span>,</span></span><br><span class=\"line\"><span class=\"params\">    features: <span class=\"type\">List</span>[<span class=\"built_in\">str</span>],</span></span><br><span class=\"line\"><span class=\"params\">    order_to_plot: <span class=\"type\">List</span>[<span class=\"built_in\">str</span>],</span></span><br><span class=\"line\"><span class=\"params\">    fig_width=<span class=\"number\">8</span>,</span></span><br><span class=\"line\"><span class=\"params\"></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Function to plot labels and predicted probabilities.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">        predicted_probabilities_all: Probabilities per genomic feature for each</span></span><br><span class=\"line\"><span class=\"string\">            nucleotides in the DNA sequence.</span></span><br><span class=\"line\"><span class=\"string\">        seq_length: DNA sequence length.</span></span><br><span class=\"line\"><span class=\"string\">        feature: Genomic features to plot.</span></span><br><span class=\"line\"><span class=\"string\">        order_to_plot: Order in which to plot the genomic features. This needs to be</span></span><br><span class=\"line\"><span class=\"string\">            specified in order to match the order presented in the Fig.3 of the paper</span></span><br><span class=\"line\"><span class=\"string\">        fig_width: Width of the figure</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    sc = <span class=\"number\">1.8</span></span><br><span class=\"line\">    n_panels = <span class=\"number\">7</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># fig, axes = plt.subplots(n_panels, 1, figsize=(fig_width * sc, (n_panels + 2) * sc), height_ratios=[6] + [2] * (n_panels-1))</span></span><br><span class=\"line\">    _, axes = plt.subplots(n_panels, <span class=\"number\">1</span>, figsize=(fig_width * sc, (n_panels + <span class=\"number\">4</span>) * sc))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> n, feat <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(order_to_plot):</span><br><span class=\"line\">        feat_id = features.index(feat)</span><br><span class=\"line\">        prob_dist = predicted_probabilities_all[:, feat_id]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Use the appropriate subplot</span></span><br><span class=\"line\">        ax = axes[n // <span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            id_color = colors[feat_id]</span><br><span class=\"line\">        <span class=\"keyword\">except</span>:</span><br><span class=\"line\">            id_color = colors2[feat_id - <span class=\"number\">8</span>]</span><br><span class=\"line\">        ax.plot(</span><br><span class=\"line\">            prob_dist,</span><br><span class=\"line\">            color=id_color,</span><br><span class=\"line\">            label=feat,</span><br><span class=\"line\">            linestyle=<span class=\"string\">&quot;-&quot;</span>,</span><br><span class=\"line\">            linewidth=<span class=\"number\">1.5</span>,</span><br><span class=\"line\">        )</span><br><span class=\"line\">        ax.set_xlim(<span class=\"number\">0</span>, seq_length)</span><br><span class=\"line\">        ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        ax.spines[<span class=\"string\">&#x27;bottom&#x27;</span>].set_color(<span class=\"string\">&#x27;black&#x27;</span>)</span><br><span class=\"line\">        ax.spines[<span class=\"string\">&#x27;top&#x27;</span>].set_color(<span class=\"string\">&#x27;black&#x27;</span>)</span><br><span class=\"line\">        ax.spines[<span class=\"string\">&#x27;right&#x27;</span>].set_color(<span class=\"string\">&#x27;black&#x27;</span>)</span><br><span class=\"line\">        ax.spines[<span class=\"string\">&#x27;left&#x27;</span>].set_color(<span class=\"string\">&#x27;black&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> <span class=\"built_in\">range</span> (<span class=\"number\">0</span>,n_panels):</span><br><span class=\"line\">        axes[a].set_ylim(<span class=\"number\">0</span>, <span class=\"number\">1.05</span>)</span><br><span class=\"line\">        axes[a].set_ylabel(<span class=\"string\">&quot;Prob.&quot;</span>)</span><br><span class=\"line\">        axes[a].legend(loc=<span class=\"string\">&quot;upper left&quot;</span>, bbox_to_anchor=(<span class=\"number\">1</span>, <span class=\"number\">1</span>), borderaxespad=<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> a != (n_panels-<span class=\"number\">1</span>):</span><br><span class=\"line\">            axes[a].tick_params(axis=<span class=\"string\">&#x27;x&#x27;</span>, which=<span class=\"string\">&#x27;both&#x27;</span>, bottom=<span class=\"literal\">True</span>, top=<span class=\"literal\">False</span>, labelbottom=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Set common x-axis label</span></span><br><span class=\"line\">    axes[-<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">&quot;Nucleotides&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># axes[0].axis(&#x27;off&#x27;)  # Turn off the axis</span></span><br><span class=\"line\">    axes[n_panels-<span class=\"number\">1</span>].grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">    axes[n_panels-<span class=\"number\">1</span>].tick_params(axis=<span class=\"string\">&#x27;y&#x27;</span>, which=<span class=\"string\">&#x27;both&#x27;</span>, left=<span class=\"literal\">True</span>, right=<span class=\"literal\">False</span>, labelleft=<span class=\"literal\">True</span>, labelright=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    axes[<span class=\"number\">0</span>].set_title(<span class=\"string\">&quot;Probabilities predicted over all genomics features&quot;</span>, fontweight=<span class=\"string\">&quot;bold&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><strong>（3）获取人的 20号染色体序列</strong></p>\n<p>为了重现Segment-NT论文中的图表，我们在此检索下载人类20号染色体的文件</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">! wget https://ftp.ensembl.org/pub/release-<span class=\"number\">111</span>/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome<span class=\"number\">.20</span>.fa.gz</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    --2024-07-23 09:38:24--  https://ftp.ensembl.org/pub/release-111/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz</span><br><span class=\"line\">    Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.169</span><br><span class=\"line\">    Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.169|:443... connected.</span><br><span class=\"line\">    HTTP request sent, awaiting response... 200 OK</span><br><span class=\"line\">    Length: 18833053 (18M) [application/x-gzip]</span><br><span class=\"line\">    Saving to: ‘Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz’</span><br><span class=\"line\">    </span><br><span class=\"line\">    Homo_sapiens.GRCh38 100%[===================&gt;]  17,96M  1,77MB/s    in 10s     </span><br><span class=\"line\">    </span><br><span class=\"line\">    2024-07-23 09:38:35 (1,75 MB/s) - ‘Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz’ saved [18833053/18833053]</span><br><span class=\"line\">```` </span><br><span class=\"line\"></span><br><span class=\"line\">```python</span><br><span class=\"line\">fasta_path = &quot;Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">with gzip.open(fasta_path, &quot;rt&quot;) as handle:</span><br><span class=\"line\">    record = next(SeqIO.parse(handle, &quot;fasta&quot;))</span><br><span class=\"line\">    chr20 = str(record.seq)</span><br></pre></td></tr></table></figure>\n\n<p><strong>（4）对10kb基因组序列进行推断</strong>（不需要改变前向函数中的重新缩放因子）</p>\n<p><strong>① 实例化SegmentNT推理函数</strong></p>\n<p>以下代码允许您下载其中一个Segment-NT模型的权重。它会返回权重字典、haiku前向函数、分词器和配置字典。</p>\n<p>与<code>get_pretrained_nucleotide_transformer</code>函数类似，您还可以指定：</p>\n<ol>\n<li>您希望收集嵌入的层（例如，(5, 10, 20) 表示获取第5、10和20层的嵌入）</li>\n<li>您希望收集的注意力图（例如，((1,4), (7,18)) 表示获取对应于第1层第4头和第7层第18头的注意力图）。请参考配置以查看模型中的层数和头数。</li>\n<li>您将进行推理计算的序列中的最大标记数。您可以输入不超过模型配置中指定的值（包含将自动添加到序列开头的类标记），但为了优化内存和推理时间，我们建议将此数字尽可能设小。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The number of DNA tokens (excluding the CLS token prepended) needs to be dividible by</span></span><br><span class=\"line\"><span class=\"comment\"># the square of the number of downsampling block, i.e 4.</span></span><br><span class=\"line\">max_num_nucleotides = <span class=\"number\">1668</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> max_num_nucleotides % <span class=\"number\">4</span> == <span class=\"number\">0</span>, (</span><br><span class=\"line\">    <span class=\"string\">&quot;The number of DNA tokens (excluding the CLS token prepended) needs to be dividible by&quot;</span></span><br><span class=\"line\">     <span class=\"string\">&quot;2 to the power of the number of downsampling block, i.e 4.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># If max_num_nucleotides is larger than what was used to train Segment-NT, the rescaling</span></span><br><span class=\"line\"><span class=\"comment\"># factor needs to be adapted.</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> max_num_nucleotides + <span class=\"number\">1</span> &gt; <span class=\"number\">5001</span>:</span><br><span class=\"line\">    inference_rescaling_factor = (max_num_nucleotides + <span class=\"number\">1</span>) / <span class=\"number\">2048</span></span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    inference_rescaling_factor=<span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># If this download fails at one point, restarting it will not work.</span></span><br><span class=\"line\"><span class=\"comment\"># Before rerunning the cell, make sure to delete the cache by executing:</span></span><br><span class=\"line\"><span class=\"comment\"># ! rm -rf ~/.cache/nucleotide_transformer/</span></span><br><span class=\"line\">parameters, forward_fn, tokenizer, config = get_pretrained_segment_nt_model(</span><br><span class=\"line\">    model_name=<span class=\"string\">&quot;segment_nt&quot;</span>,</span><br><span class=\"line\">    rescaling_factor=inference_rescaling_factor,</span><br><span class=\"line\">    embeddings_layers_to_save=(<span class=\"number\">29</span>,),</span><br><span class=\"line\">    attention_maps_to_save=((<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">7</span>, <span class=\"number\">10</span>)),</span><br><span class=\"line\">    max_positions=max_num_nucleotides + <span class=\"number\">1</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\">forward_fn = hk.transform(forward_fn)</span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Put required quantities for the inference on the devices. This step is not</span></span><br><span class=\"line\"><span class=\"comment\"># reproduced in the second inference since the quantities will already be loaded</span></span><br><span class=\"line\"><span class=\"comment\"># on the devices !</span></span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br></pre></td></tr></table></figure>\n\n<pre><code>Downloading model&#39;s hyperparameters json file...\nDownloaded model&#39;s hyperparameters.\nDownloading model&#39;s weights...\nDownloaded model&#39;s weights...\n</code></pre>\n<p><strong>② 对DNA序列进行分词</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">idx_start = <span class=\"number\">2650520</span></span><br><span class=\"line\"></span><br><span class=\"line\">idx_stop = idx_start + max_num_nucleotides*<span class=\"number\">6</span></span><br><span class=\"line\"></span><br><span class=\"line\">sequences = [chr20[idx_start:idx_stop]]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens_str = [b[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This stacks the batch so that it is repeated across the devices. This is done</span></span><br><span class=\"line\"><span class=\"comment\"># in order to allow for replication even if one has more than one device.</span></span><br><span class=\"line\"><span class=\"comment\"># To take advantage of the multiple devices and infer different sequences on</span></span><br><span class=\"line\"><span class=\"comment\"># each of the devices, make sure to change this line into a reshape.</span></span><br><span class=\"line\"><span class=\"comment\"># a reshape</span></span><br><span class=\"line\">tokens = jnp.stack([jnp.asarray(tokens_ids, dtype=jnp.int32)]*num_devices, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">tokens.shape</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>(1, 1, 1669)\n</code></pre>\n<p><strong>③ 对生成的批次进行推理</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs = apply_fn(parameters, keys, tokens)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[...,-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/home/hugo/anaconda3/envs/trix/lib/python3.10/site-packages/jax/interpreters/mlir.py:622: UserWarning: Some donated buffers were not usable: ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,8192]), ShapedArray(float32[4096,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[4107,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[4107]), ShapedArray(float32[1024,4107]), ShapedArray(float32[1024]), ShapedArray(float32[1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[168]), ShapedArray(float32[1024,168]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,1024]), ShapedArray(float32[2048]), ShapedArray(float32[3,1024,2048]), ShapedArray(float32[2048]), ShapedArray(float32[3,2048,2048]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,1024]), ShapedArray(float32[2048]), ShapedArray(float32[3,2048,2048]), ShapedArray(float32[2048]), ShapedArray(float32[3,2048,2048]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,2048]), ShapedArray(float32[1024]), ShapedArray(float32[3,1024,1024]).</span><br><span class=\"line\">See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.</span><br><span class=\"line\">  warnings.warn(f&quot;Some donated buffers were not usable: &#123;&#x27;, &#x27;.join(unused_donations)&#125;.\\n&#123;msg&#125;&quot;)</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">probabilities.shape</span><br></pre></td></tr></table></figure>\n\n<pre><code>(1, 1, 10008, 14)\n</code></pre>\n<p><strong>④ 绘制这条DNA序列上14个基因组特征的概率图</strong></p>\n<p>请注意，SegmentNT论文中的图1是用SegmentNT-10kb实现的，而这里使用的是SegmentNT-30kb，这就解释了为什么概率并非完全相同。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot_features(</span><br><span class=\"line\">    probabilities[<span class=\"number\">0</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">    probabilities.shape[-<span class=\"number\">2</span>],</span><br><span class=\"line\">    fig_width=<span class=\"number\">20</span>,</span><br><span class=\"line\">    features=config.features,</span><br><span class=\"line\">    order_to_plot=features_rearranged</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_26_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_26_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<p><strong>（5）对50kb的基因组序列进行推断并绘图</strong>（需要更改前向函数中的重新缩放因子）</p>\n<p><strong>① 实例化SegmentNT推理函数</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The number of DNA tokens (excluding the CLS token prepended) needs to be dividible by</span></span><br><span class=\"line\"><span class=\"comment\"># the square of the number of downsampling block, i.e 4.</span></span><br><span class=\"line\">max_num_nucleotides = <span class=\"number\">8332</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">assert</span> max_num_nucleotides % <span class=\"number\">4</span> == <span class=\"number\">0</span>, (</span><br><span class=\"line\">    <span class=\"string\">&quot;The number of DNA tokens (excluding the CLS token prepended) needs to be dividible by&quot;</span></span><br><span class=\"line\">     <span class=\"string\">&quot;2 to the power of the number of downsampling block, i.e 4.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># If max_num_nucleotides is larger than what was used to train Segment-NT, the rescaling</span></span><br><span class=\"line\"><span class=\"comment\"># factor needs to be adapted.</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> max_num_nucleotides + <span class=\"number\">1</span> &gt; <span class=\"number\">5001</span>:</span><br><span class=\"line\">    inference_rescaling_factor = (max_num_nucleotides + <span class=\"number\">1</span>) / <span class=\"number\">2048</span></span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    inference_rescaling_factor=<span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The parameters have already been downloaded above</span></span><br><span class=\"line\"><span class=\"comment\"># so we do not instantiate them. However we instantiate a new forward function</span></span><br><span class=\"line\"><span class=\"comment\"># where the context length extension needed is in effect.</span></span><br><span class=\"line\">_, forward_fn, tokenizer, config = get_pretrained_segment_nt_model(</span><br><span class=\"line\">    model_name=<span class=\"string\">&quot;segment_nt&quot;</span>,</span><br><span class=\"line\">    rescaling_factor=inference_rescaling_factor,</span><br><span class=\"line\">    embeddings_layers_to_save=(<span class=\"number\">29</span>,),</span><br><span class=\"line\">    attention_maps_to_save=((<span class=\"number\">1</span>, <span class=\"number\">4</span>), (<span class=\"number\">7</span>, <span class=\"number\">10</span>)),</span><br><span class=\"line\">    max_positions=max_num_nucleotides + <span class=\"number\">1</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\">forward_fn = hk.transform(forward_fn)</span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br></pre></td></tr></table></figure>\n\n<p><strong>② 对DNA序列进行分词</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">idx_start = <span class=\"number\">5099984</span></span><br><span class=\"line\">idx_stop = idx_start + max_num_nucleotides*<span class=\"number\">6</span></span><br><span class=\"line\"></span><br><span class=\"line\">sequences = [chr20[idx_start:idx_stop]]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens_str = [b[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This stacks the batch so that it is repeated across the devices. This is done</span></span><br><span class=\"line\"><span class=\"comment\"># in order to allow for replication even if one has more than one device.</span></span><br><span class=\"line\"><span class=\"comment\"># To take advantage of the multiple devices and infer different sequences on</span></span><br><span class=\"line\"><span class=\"comment\"># each of the devices, make sure to change this line into a reshape.</span></span><br><span class=\"line\"><span class=\"comment\"># a reshape</span></span><br><span class=\"line\">tokens = jnp.asarray(tokens_ids, dtype=jnp.int32)[<span class=\"literal\">None</span>, :]</span><br><span class=\"line\">tokens.shape, idx_stop</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<pre><code>((1, 1, 8333), 5149976)\n</code></pre>\n<p><strong>③ 对生成的批次进行推理</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs = apply_fn(parameters, keys, tokens)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[...,-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n<p><strong>④ 绘制这条DNA序列上14个基因组特征的概率图</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot_features(</span><br><span class=\"line\">    probabilities[<span class=\"number\">0</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">    probabilities.shape[-<span class=\"number\">2</span>],</span><br><span class=\"line\">    fig_width=<span class=\"number\">20</span>,</span><br><span class=\"line\">    features=config.features,</span><br><span class=\"line\">    order_to_plot=features_rearranged</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_35_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_35_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h2 id=\"2-3-SegmentEnformer\"><a href=\"#2-3-SegmentEnformer\" class=\"headerlink\" title=\"2.3 SegmentEnformer\"></a>2.3 SegmentEnformer</h2><p>SegmentEnformer借助了<a href=\"https://www.nature.com/articles/s41592-021-01252-x\">Enformer</a>，它移除了预测头，并用一个一维U-Net分割头取而代之，以单核苷酸分辨率<strong>预测序列中多种基因组元件的位置</strong>。</p>\n<h3 id=\"2-3-1-🔍-示例\"><a href=\"#2-3-1-🔍-示例\" class=\"headerlink\" title=\"2.3.1 🔍 示例\"></a>2.3.1 🔍 示例</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> haiku <span class=\"keyword\">as</span> hk</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax.numpy <span class=\"keyword\">as</span> jnp</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.enformer.pretrained <span class=\"keyword\">import</span> get_pretrained_segment_enformer_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.enformer.features <span class=\"keyword\">import</span> FEATURES</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize CPU as default JAX device. This makes the code robust to memory leakage on</span></span><br><span class=\"line\"><span class=\"comment\"># the devices.</span></span><br><span class=\"line\">jax.config.update(<span class=\"string\">&quot;jax_platform_name&quot;</span>, <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">backend = <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">devices = jax.devices(backend)</span><br><span class=\"line\">num_devices = <span class=\"built_in\">len</span>(devices)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load model</span></span><br><span class=\"line\">parameters, state, forward_fn, tokenizer, config = get_pretrained_segment_enformer_model()</span><br><span class=\"line\">forward_fn = hk.transform_with_state(forward_fn)</span><br><span class=\"line\"></span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Replicate over devices</span></span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br><span class=\"line\">state = jax.device_put_replicated(state, devices=devices)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get data and tokenize it</span></span><br><span class=\"line\">sequences = [<span class=\"string\">&quot;A&quot;</span> * <span class=\"number\">196_608</span>]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens = jnp.stack([jnp.asarray(tokens_ids, dtype=jnp.int32)] * num_devices, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs, state = apply_fn(parameters, state, keys, tokens)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[..., -<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get probabilities associated with intron</span></span><br><span class=\"line\">idx_intron = FEATURES.index(<span class=\"string\">&quot;intron&quot;</span>)</span><br><span class=\"line\">probabilities_intron = probabilities[..., idx_intron]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Intron probabilities shape: <span class=\"subst\">&#123;probabilities_intron.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-3-2-完整代码\"><a href=\"#2-3-2-完整代码\" class=\"headerlink\" title=\"2.3.2 完整代码\"></a>2.3.2 完整代码</h3><p>下列代码展示了如何对一个196,608bp 的序列进行推断并绘制概率图。模块导入、基因组下载、绘图函数如前所述，不再重复。</p>\n<p><strong>（1）实例化SegmentEnformer推理函数</strong></p>\n<p>以下代码允许您下载SegmentEnformer的权重。它会返回权重字典、haiku前向函数、分词器和配置字典。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters, state, forward_fn, tokenizer, config = get_pretrained_segment_enformer_model()</span><br></pre></td></tr></table></figure>\n\n<pre><code>Downloading model&#39;s weights...\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">forward_fn = hk.transform_with_state(forward_fn)</span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Put required quantities for the inference on the devices. This step is not</span></span><br><span class=\"line\"><span class=\"comment\"># reproduced in the second inference since the quantities will already be loaded</span></span><br><span class=\"line\"><span class=\"comment\"># on the devices !</span></span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br><span class=\"line\">state = jax.device_put_replicated(state, devices=devices)</span><br></pre></td></tr></table></figure>\n\n<p><strong>（2）DNA序列分词</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_nucleotides = <span class=\"number\">196_608</span></span><br><span class=\"line\">idx_start = <span class=\"number\">2650520</span></span><br><span class=\"line\"></span><br><span class=\"line\">idx_stop = idx_start + num_nucleotides</span><br><span class=\"line\"></span><br><span class=\"line\">sequences = [chr20[idx_start:idx_stop]]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens_str = [b[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This stacks the batch so that it is repeated across the devices. This is done</span></span><br><span class=\"line\"><span class=\"comment\"># in order to allow for replication even if one has more than one device.</span></span><br><span class=\"line\"><span class=\"comment\"># To take advantage of the multiple devices and infer different sequences on</span></span><br><span class=\"line\"><span class=\"comment\"># each of the devices, make sure to change this line into a reshape.</span></span><br><span class=\"line\"><span class=\"comment\"># a reshape</span></span><br><span class=\"line\">tokens = jnp.stack([jnp.asarray(tokens_ids, dtype=jnp.int32)]*num_devices, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">tokens.shape</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<pre><code>(1, 1, 196608)\n</code></pre>\n<p><strong>（3）对生成的批次进行推断</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs, state = apply_fn(parameters, state, keys, tokens) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[...,-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">probabilities.shape</span><br></pre></td></tr></table></figure>\n\n\n<pre><code>(1, 1, 196608, 14)\n</code></pre>\n<p><strong>（4）绘制该DNA序列中14个基因组特征的概率图</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot_features(</span><br><span class=\"line\">    probabilities[<span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">    probabilities.shape[-<span class=\"number\">2</span>],</span><br><span class=\"line\">    fig_width=<span class=\"number\">20</span>,</span><br><span class=\"line\">    features=FEATURES,</span><br><span class=\"line\">    order_to_plot=features_rearranged</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_48_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_48_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h2 id=\"2-4-SegmentBorzoi\"><a href=\"#2-4-SegmentBorzoi\" class=\"headerlink\" title=\"2.4 SegmentBorzoi\"></a>2.4 SegmentBorzoi</h2><p>SegmentBorzoi利用了<a href=\"https://www.nature.com/articles/s41588-024-02053-6\">Borzoi</a>，它移除了预测头，并将其替换为一个一维U-Net分割头，以<strong>预测序列中多种基因组元素的位置</strong>。</p>\n<h3 id=\"2-4-1-🔍-示例\"><a href=\"#2-4-1-🔍-示例\" class=\"headerlink\" title=\"2.4.1 🔍 示例\"></a>2.4.1 🔍 示例</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> haiku <span class=\"keyword\">as</span> hk</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax</span><br><span class=\"line\"><span class=\"keyword\">import</span> jax.numpy <span class=\"keyword\">as</span> jnp</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.borzoi.pretrained <span class=\"keyword\">import</span> get_pretrained_segment_borzoi_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> nucleotide_transformer.enformer.features <span class=\"keyword\">import</span> FEATURES</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize CPU as default JAX device. This makes the code robust to memory leakage on</span></span><br><span class=\"line\"><span class=\"comment\"># the devices.</span></span><br><span class=\"line\">jax.config.update(<span class=\"string\">&quot;jax_platform_name&quot;</span>, <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">backend = <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">devices = jax.devices(backend)</span><br><span class=\"line\">num_devices = <span class=\"built_in\">len</span>(devices)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load model</span></span><br><span class=\"line\">parameters, state, forward_fn, tokenizer, config = get_pretrained_segment_borzoi_model()</span><br><span class=\"line\">forward_fn = hk.transform_with_state(forward_fn)</span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Replicate over devices</span></span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br><span class=\"line\">state = jax.device_put_replicated(state, devices=devices)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get data and tokenize it</span></span><br><span class=\"line\">sequences = [<span class=\"string\">&quot;A&quot;</span> * <span class=\"number\">524_288</span>]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens = jnp.stack([jnp.asarray(tokens_ids, dtype=jnp.int32)] * num_devices, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs, state = apply_fn(parameters, state, keys, tokens)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[..., -<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get probabilities associated with intron</span></span><br><span class=\"line\">idx_intron = FEATURES.index(<span class=\"string\">&quot;intron&quot;</span>)</span><br><span class=\"line\">probabilities_intron = probabilities[..., idx_intron]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Intron probabilities shape: <span class=\"subst\">&#123;probabilities_intron.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-4-2-完整代码\"><a href=\"#2-4-2-完整代码\" class=\"headerlink\" title=\"2.4.2 完整代码\"></a>2.4.2 完整代码</h3><p>下述代码展示了如何对一个196608 bp （524288bp？）的序列进行推断并绘制概率图。模块导入、基因组下载、绘图函数如前所述，不再重复。</p>\n<p><strong>（1）实例化SegmentBorzoi推理函数</strong></p>\n<p>以下代码允许您下载SegmentBorzoi的权重。它会返回权重字典、haiku前向函数、分词器和配置字典。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters, state, forward_fn, tokenizer, config = get_pretrained_segment_borzoi_model()</span><br></pre></td></tr></table></figure>\n\n<pre><code>Downloading model&#39;s weights...\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">forward_fn = hk.transform_with_state(forward_fn)</span><br><span class=\"line\">apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(<span class=\"number\">0</span>,))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Put required quantities for the inference on the devices. This step is not</span></span><br><span class=\"line\"><span class=\"comment\"># reproduced in the second inference since the quantities will already be loaded</span></span><br><span class=\"line\"><span class=\"comment\"># on the devices !</span></span><br><span class=\"line\">random_key = jax.random.PRNGKey(seed=<span class=\"number\">0</span>)</span><br><span class=\"line\">keys = jax.device_put_replicated(random_key, devices=devices)</span><br><span class=\"line\">parameters = jax.device_put_replicated(parameters, devices=devices)</span><br><span class=\"line\">state = jax.device_put_replicated(state, devices=devices)</span><br></pre></td></tr></table></figure>\n\n<p><strong>（2）DNA 序列分词</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_nucleotides = <span class=\"number\">524_288</span></span><br><span class=\"line\"></span><br><span class=\"line\">idx_start = <span class=\"number\">2650520</span></span><br><span class=\"line\">idx_stop = idx_start + num_nucleotides</span><br><span class=\"line\"></span><br><span class=\"line\">sequences = [chr20[idx_start:idx_stop]]</span><br><span class=\"line\">tokens_ids = [b[<span class=\"number\">1</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\">tokens_str = [b[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> tokenizer.batch_tokenize(sequences)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># This stacks the batch so that it is repeated across the devices. This is done</span></span><br><span class=\"line\"><span class=\"comment\"># in order to allow for replication even if one has more than one device.</span></span><br><span class=\"line\"><span class=\"comment\"># To take advantage of the multiple devices and infer different sequences on</span></span><br><span class=\"line\"><span class=\"comment\"># each of the devices, make sure to change this line into a reshape.</span></span><br><span class=\"line\"><span class=\"comment\"># a reshape</span></span><br><span class=\"line\">tokens = jnp.stack([jnp.asarray(tokens_ids, dtype=jnp.int32)]*num_devices, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">tokens.shape</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<pre><code>(1, 1, 524288)\n</code></pre>\n<p><strong>（3）对生成的批次进行推断</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Infer</span></span><br><span class=\"line\">outs, state = apply_fn(parameters, state, keys, tokens) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Obtain the logits over the genomic features</span></span><br><span class=\"line\">logits = outs[<span class=\"string\">&quot;logits&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># Transform them on probabilities</span></span><br><span class=\"line\">probabilities = np.asarray(jax.nn.softmax(logits, axis=-<span class=\"number\">1</span>))[...,-<span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">probabilities.shape</span><br></pre></td></tr></table></figure>\n\n\n<pre><code>(1, 1, 196608, 14)\n</code></pre>\n<p><strong>（4）绘制该DNA序列中14个基因组特征的概率图</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plot_features(</span><br><span class=\"line\">    probabilities[<span class=\"number\">0</span>, <span class=\"number\">0</span>],</span><br><span class=\"line\">    probabilities.shape[-<span class=\"number\">2</span>],</span><br><span class=\"line\">    fig_width=<span class=\"number\">20</span>,</span><br><span class=\"line\">    features=FEATURES,</span><br><span class=\"line\">    order_to_plot=features_rearranged</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_61_0.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Segmentation_models%E5%AE%9E%E6%88%98_61_0.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"png\"></p>\n<h1 id=\"参考文献-📚\"><a href=\"#参考文献-📚\" class=\"headerlink\" title=\"参考文献 📚\"></a>参考文献 📚</h1><ul>\n<li>[1] de Almeida, B.P., Dalla-Torre, H., Richard, G. et al. Annotating the genome at single-nucleotide resolution with DNA foundation models. Nat Methods (2025). <a href=\"https://doi.org/10.1038/s41592-025-02881-2\">https://doi.org/10.1038/s41592-025-02881-2</a></li>\n</ul>\n<h1 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h1><table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"使用DNA基础模型在单核苷酸分辨率上注释基因组","slug":"使用DNA基础模型在单核苷酸分辨率上注释基因组","date":"2025-11-13T11:26:15.000Z","updated":"2025-11-13T12:25:57.636Z","comments":true,"path":"api/articles/使用DNA基础模型在单核苷酸分辨率上注释基因组.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp","content":"<p>2025年9月，InstaDeep（英国伦敦）、BioNTech（德国美因茨）、哥本哈根大学计算机系等机构的Bernardo P. de Almeida、Hugo Dalla-Torre（共同第一作者）、Thomas Pierrot（通讯作者）等研究者在《Nature Methods》期刊发表了题为“Annotating the genome at single-nucleotide resolution with DNA foundation models”的学术文章。该文章报道了其开发的基因组注释模型家族（SegmentNT、SegmentEnformer、SegmentBorzoi），在基因组功能元件注释领域具有突破传统工具局限性、实现14种基因及调控元件单核苷酸分辨率精准注释的重要意义。</p>\n<h1 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1 前言\"></a>1 前言</h1><h2 id=\"1-1-研究背景\"><a href=\"#1-1-研究背景\" class=\"headerlink\" title=\"1.1 研究背景\"></a>1.1 研究背景</h2><p>基因组注释模型是现代生物学研究的核心工具，可直接从DNA序列中识别<code>基因</code>、<code>外显子-内含子</code>结构及其他<code>功能元件</code>。随着测序技术发展，已测序基因组数量呈指数增长，精准高效的DNA序列注释不仅有助于解析遗传结构，还对遗传变异预测、计算机模拟序列设计等应用至关重要。</p>\n<p>现有注释工具存在明显局限：基于隐马尔可夫模型的工具（如AUGUSTUS）虽具备单核苷酸分辨率，但难以建模生物复杂性，预测基因异构体和全染色体注释时需依赖实验数据；调控元件识别工具多针对特定元件单独开发，训练数据集规模有限且分布与实际应用场景差异大，泛化能力不足。</p>\n<p>DNA基础模型（参数达数亿至数十亿，训练数据达数千亿至数万亿token）的出现为解决上述问题提供了新思路，其可通过无监督或监督训练学习通用序列表征，适配多种下游任务。</p>\n<h2 id=\"1-2-研究目标\"><a href=\"#1-2-研究目标\" class=\"headerlink\" title=\"1.2 研究目标\"></a>1.2 研究目标</h2><p><code>将基因组注释问题构建为多标签语义分割任务</code>，利用预训练DNA基础模型微调，开发能在单核苷酸分辨率下注释14种基因及调控元件的通用模型，突破传统工具的元件特异性和序列长度限制，提升跨物种泛化能力。</p>\n<h1 id=\"2-研究方法\"><a href=\"#2-研究方法\" class=\"headerlink\" title=\"2 研究方法\"></a>2 研究方法</h1><h2 id=\"2-1-基因组分割模型架构\"><a href=\"#2-1-基因组分割模型架构\" class=\"headerlink\" title=\"2.1 基因组分割模型架构\"></a>2.1 基因组分割模型架构</h2><h3 id=\"2-1-1-SegmentNT架构\"><a href=\"#2-1-1-SegmentNT架构\" class=\"headerlink\" title=\"2.1.1 SegmentNT架构\"></a>2.1.1 SegmentNT架构</h3><p><code>SegmentNT</code>以预训练DNA基础模型<code>Nucleotide Transformer</code>（NT-Multispecies-v2，500M参数）为DNA编码器，采用<code>6-mer</code>分词器提取序列嵌入特征（序列长度N与token数L满足$L≈N&#x2F;6$）。<u>模型替换NT的原始语言模型头，引入<code>1D U-Net</code>分割头，包含<code>2个下采样</code>卷积块和<code>2个上采样</code>卷积块，各块分别含2048和4096个卷积核，序列长度分别为 $L&#x2F;2$ 和 $L&#x2F;4$，总参数6300万</u>。</p>\n<p>U-Net输出张量形状为$(N, K, 2)$（K&#x3D;14种元件），经softmax层后<u>得到每个核苷酸属于每种元件的概率$P$及非概率$1-P$</u>。模型允许单个核苷酸属于多种元件，二元分类阈值设为<strong>0.5</strong>。</p>\n<h3 id=\"2-1-2-SegmentEnformer与SegmentBorzoi架构\"><a href=\"#2-1-2-SegmentEnformer与SegmentBorzoi架构\" class=\"headerlink\" title=\"2.1.2 SegmentEnformer与SegmentBorzoi架构\"></a>2.1.2 SegmentEnformer与SegmentBorzoi架构</h3><p><code>将Enformer和Borzoi作为DNA编码器</code>，其原始架构含卷积-下采样块及自注意力块（Enformer分辨率128 bp，Borzoi分辨率32 bp）。在两模型最后一层表征（预测头前）添加U-Net分割头，分别命名为SegmentEnformer和SegmentBorzoi，保持与SegmentNT一致的训练和验证超参数。</p>\n<h2 id=\"2-2-模型训练与评估\"><a href=\"#2-2-模型训练与评估\" class=\"headerlink\" title=\"2.2 模型训练与评估\"></a>2.2 模型训练与评估</h2><h3 id=\"2-2-1-训练参数\"><a href=\"#2-2-1-训练参数\" class=\"headerlink\" title=\"2.2.1 训练参数\"></a>2.2.1 训练参数</h3><ul>\n<li><strong>优化器</strong>：Adam，学习率$5×10^{-5}$</li>\n<li><strong>批次大小</strong>：256</li>\n<li><strong>训练数据量</strong>：SegmentNT-3kb模型训练102.4亿token（2048万条序列），10kb、20kb、30kb模型基于前一尺寸最佳检查点初始化并微调（如30kb模型额外训练25.6亿token，51万条序列）</li>\n<li><strong>损失函数</strong>：焦点损失（$γ&#x3D;2$），聚焦稀疏元件对应的“困难样本”</li>\n<li><strong>硬件</strong>：8块H100 GPU，训练时长20小时（3kb模型）</li>\n</ul>\n<h3 id=\"2-2-2-数据集分割\"><a href=\"#2-2-2-数据集分割\" class=\"headerlink\" title=\"2.2.2 数据集分割\"></a>2.2.2 数据集分割</h3><p><strong>按染色体划分训练集、验证集和测试集</strong>：20、21号染色体为测试集，22号为验证集，其余为训练集。<u>排除测试集中与训练&#x2F;验证集基因同源的片段（未剔除可能影响这些区域性能的同源远端调控元件）</u>，验证集和测试集采用固定滑动窗口采样，测试集进行10次随机采样以计算置信区间。</p>\n<h3 id=\"2-2-3-评估指标\"><a href=\"#2-2-3-评估指标\" class=\"headerlink\" title=\"2.2.3 评估指标\"></a>2.2.3 评估指标</h3><ul>\n<li><strong>核苷酸水平指标</strong>：马修斯相关系数（MCC）、精确率-召回率曲线下面积（auPRC）、雅卡尔相似度（Jaccard）、F1分数</li>\n<li><strong>区域水平指标</strong>：片段重叠分数（SOV），使用默认λ&#x3D;1.0 （代码： <a href=\"http://dna.cs.miami.edu/SOV/%EF%BC%89\">http://dna.cs.miami.edu/SOV/）</a></li>\n</ul>\n<h2 id=\"2-3-模型消融与基线设置\"><a href=\"#2-3-模型消融与基线设置\" class=\"headerlink\" title=\"2.3 模型消融与基线设置\"></a>2.3 模型消融与基线设置</h2><h3 id=\"2-3-1-消融实验模型\"><a href=\"#2-3-1-消融实验模型\" class=\"headerlink\" title=\"2.3.1 消融实验模型\"></a>2.3.1 消融实验模型</h3><ol>\n<li>以NT v1 2.5B 1000G模型为骨干（总参数26亿）</li>\n<li>仅微调U-Net分割头的SegmentNT-3kb模型（5.63亿参数）</li>\n<li>编码器随机初始化的SegmentNT模型（全参数训练或仅训练分割头）</li>\n<li>直接输入one-hot编码的U-Net模型（6300万或2.52亿参数）</li>\n<li>one-hot编码经线性层扩展至1024维嵌入的U-Net模型（6600万参数）</li>\n</ol>\n<h3 id=\"2-3-2-基线模型\"><a href=\"#2-3-2-基线模型\" class=\"headerlink\" title=\"2.3.2 基线模型\"></a>2.3.2 基线模型</h3><ul>\n<li><strong>BPNet</strong>：2个版本（嵌入维度64对应12万参数，1024对应2900万参数）</li>\n<li><strong>SpliceAI</strong>：3个版本（嵌入维度32对应70万参数，256对应4400万参数，920对应5.73亿参数）</li>\n</ul>\n<h2 id=\"2-4-上下文长度扩展方法\"><a href=\"#2-4-上下文长度扩展方法\" class=\"headerlink\" title=\"2.4 上下文长度扩展方法\"></a>2.4 上下文长度扩展方法</h2><p>由于SegmentNT的DNA编码器采用的旋转位置编码（RoPE）在训练时的最大序列长度为2048个token，因此在对更长序列进行推理时，其性能会迅速下降。此前已有多项研究提出了对RoPE的改进方案，以更好地处理长序列的评估或微调任务，例如采用位置插值法或“NTK感知的缩放旋转位置编码”（NTK-aware scaled RoPE）。</p>\n<p>Peng等人提出了一种适用于未见过序列长度的RoPE适配方案，名为YaRN。经过测试，与直接使用“NTK感知的缩放旋转位置编码”相比，YaRN在扩展SegmentNT的序列长度方面并未带来性能提升。由于后者的实现更为简便，作者最终选择采用该方法来扩展SegmentNT的上下文长度。</p>\n<p>设隐藏层神经元集合为(D)，序列向量为$(x_{1}, …, x_{L} \\in \\mathbb{R}^{|D|})$，则“NTK感知的旋转位置编码”可通过以下公式描述：</p>\n<p>$f^′_{w}(x_{m}, m, θ_{d}) &#x3D; f_{w}(x_{m}, g(m), h(θ_{d}))$</p>\n<p>其中，(d)表示嵌入维度上的位置，(m)表示嵌入在序列中的位置，(J)为RoPE函数，(w)表示可学习参数（权重），$(g(m)&#x3D;m)$，$(h(\\theta_{d})&#x3D;b^{\\prime-\\frac{2d}{|D|}})$，$(b’&#x3D;b \\cdot s^{\\frac{|D|}{|D|-2}})$，最终满足$(\\frac{2\\pi}{\\theta_{d}}&#x3D;2\\pi b^{\\frac{2d}{10}})$。</p>\n<p>为完整说明，(b)是旋转位置编码中使用的指数基，(b’)是对(b)进行缩放后的版本，用于适配NTK感知的缩放逻辑和上下文长度。缩放因子(s)的计算方式为$(s&#x3D;\\frac{L’}{L})$，其中(L’)为扩展后的上下文长度，(L)为训练时的上下文长度（对于NT-Multispecies-v2（500M）模型，(L&#x3D;2048)个token）。</p>\n<p>对于采用“NTK感知的旋转位置编码”训练的SegmentNT模型，所有长度小于其训练长度的序列，在评估时均使用训练过程中采用的同一缩放因子。具体而言，SegmentNT-30kb模型的训练缩放因子(s&#x3D;2.44)，因此对长度小于30,000 bp的序列进行推理时，仍使用(s&#x3D;2.44)；而对50 kb序列进行评估时，缩放因子则调整为(s&#x3D;4.07)。</p>\n<h2 id=\"2-5-多物种训练\"><a href=\"#2-5-多物种训练\" class=\"headerlink\" title=\"2.5 多物种训练\"></a>2.5 多物种训练</h2><p>基于人类SegmentNT-30kb模型，加入小鼠（mm10）、鸡（galGal6）、果蝇（dm6）、斑马鱼（danRer11）、秀丽隐杆线虫（ce11）的注释数据进行微调，得到多物种模型。各物种数据权重：人类5、小鼠4、鸡&#x2F;果蝇&#x2F;斑马鱼2、线虫1。各物种单独划分验证集和测试集（如小鼠：验证集chr19，测试集chr18）。</p>\n<h2 id=\"2-6-基因组注释数据来源\"><a href=\"#2-6-基因组注释数据来源\" class=\"headerlink\" title=\"2.6 基因组注释数据来源\"></a>2.6 基因组注释数据来源</h2><h3 id=\"2-6-1-人类基因组元件数据\"><a href=\"#2-6-1-人类基因组元件数据\" class=\"headerlink\" title=\"2.6.1 人类基因组元件数据\"></a>2.6.1 人类基因组元件数据</h3><p>14种元件分为基因元件（蛋白质编码基因、长链非编码RNA、5’UTR、3’UTR、外显子、内含子、剪接受体位点、剪接供体位点）和调控元件（多聚腺苷酸信号、组织不变型&#x2F;组织特异性启动子、组织不变型&#x2F;组织特异性增强子、CTCF结合位点）。基因元件和多聚腺苷酸信号来自GENCODE V44注释（排除三级转录本），调控元件来自ENCODE的SCREEN数据库。</p>\n<h3 id=\"2-6-2-多物种数据集\"><a href=\"#2-6-2-多物种数据集\" class=\"headerlink\" title=\"2.6.2 多物种数据集\"></a>2.6.2 多物种数据集</h3><p>聚焦7种核心基因元件（蛋白质编码基因、5’UTR、3’UTR、外显子、内含子、剪接受体位点、剪接供体位点），注释数据来自Ensembl数据库。测试集含10种动物（如野牛、鲸鱼、猫等）和5种植物（拟南芥、大豆、水稻、小麦、玉米）。</p>\n<h2 id=\"2-7-基准测试方法\"><a href=\"#2-7-基准测试方法\" class=\"headerlink\" title=\"2.7 基准测试方法\"></a>2.7 基准测试方法</h2><h3 id=\"2-7-1-基因注释基准\"><a href=\"#2-7-1-基因注释基准\" class=\"headerlink\" title=\"2.7.1 基因注释基准\"></a>2.7.1 基因注释基准</h3><p>与AUGUSTUS在三种场景对比：30kb基因片段（仅主异构体）、30kb基因片段（所有异构体）、全染色体（所有异构体），评估指标为F1分数、MCC、精确率、召回率、SOV。</p>\n<h3 id=\"2-7-2-剪接位点预测基准\"><a href=\"#2-7-2-剪接位点预测基准\" class=\"headerlink\" title=\"2.7.2 剪接位点预测基准\"></a>2.7.2 剪接位点预测基准</h3><p>与SpliceAI、Pangolin在两种测试集对比：SpliceAI的mRNA测试集（适配30kb窗口，移除含N序列）、SegmentNT的全染色体测试集（仅保留正义链基因），评估指标为auPRC、MCC、top-k准确率。</p>\n<h3 id=\"2-7-3-调控元件定位基准\"><a href=\"#2-7-3-调控元件定位基准\" class=\"headerlink\" title=\"2.7.3 调控元件定位基准\"></a>2.7.3 调控元件定位基准</h3><p>与滑动窗口方法（NT微调模型、DeePromoter）对比，将组织不变型和组织特异性启动子&#x2F;增强子合并为单一类别，评估指标为auPRC，计算单A100 GPU上的推理时间。</p>\n<h1 id=\"3-实验结果\"><a href=\"#3-实验结果\" class=\"headerlink\" title=\"3 实验结果\"></a>3 实验结果</h1><h2 id=\"3-1-SegmentNT：DNA序列核苷酸分辨率分割模型\"><a href=\"#3-1-SegmentNT：DNA序列核苷酸分辨率分割模型\" class=\"headerlink\" title=\"3.1 SegmentNT：DNA序列核苷酸分辨率分割模型\"></a>3.1 SegmentNT：DNA序列核苷酸分辨率分割模型</h2><h3 id=\"3-1-1-模型性能基础表现\"><a href=\"#3-1-1-模型性能基础表现\" class=\"headerlink\" title=\"3.1.1 模型性能基础表现\"></a>3.1.1 模型性能基础表现</h3><p>SegmentNT-3kb在14种元件上表现出高核苷酸分辨率定位能力，外显子、剪接位点、3’UTR和组织不变型启动子的测试MCC均高于0.5，长链非编码RNA和CTCF结合位点最难预测（MCC低于0.1）。</p>\n<p>SegmentNT-10kb（平均MCC 0.42）性能优于3kb版本（0.37），蛋白质编码基因、3’UTR、外显子和内含子的提升尤为显著，表明这些元件依赖更长序列上下文（如图1c所示）。</p>\n<h3 id=\"3-1-2-基因位点注释示例\"><a href=\"#3-1-2-基因位点注释示例\" class=\"headerlink\" title=\"3.1.2 基因位点注释示例\"></a>3.1.2 基因位点注释示例</h3><p>在包含NOP56基因（正义链）和IDH3B基因（反义链）的10kb窗口中，SegmentNT-10kb准确预测了两种基因的蛋白质编码属性、5’UTR和3’UTR位置、剪接位点、外显子-内含子结构及多聚腺苷酸信号，同时捕获了NOP56基因的组织特异性和组织不变型启动子，以及区域内的多个增强子（如图1d所示）。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig01.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1 SegmentNT在核苷酸分辨率下定位基因组元件\"></p>\n<p><font size=2 color='grey'>图注：a. SegmentNT神经网络架构，含预训练DNA编码器（NT22）和U-Net分割头，输出各基因组元件的核苷酸分辨率概率；b. 1D U-Net分割头结构，含2个下采样和2个上采样卷积块及跳跃连接，标注各层维度（N为核苷酸数，L为DNA token数，$L≈N&#x2F;6$）；c. SegmentNT-3kb和10kb模型在14种基因组元件上的MCC性能（数据为10次测试集采样的均值±95%置信区间）；d. NOP56&#x2F;IDH3B基因位点的14种元件注释及预测概率示例，含基因异构体、外显子-内含子结构及调控元件；e. SegmentNT与不同消融模型和架构的性能对比（指标为MCC、Jaccard、F1、auPRC、SOV，数据为14种元件的均值±标准差，列归一化颜色标度）。</font></p>\n<h2 id=\"3-2-预训练DNA编码器的核心作用\"><a href=\"#3-2-预训练DNA编码器的核心作用\" class=\"headerlink\" title=\"3.2 预训练DNA编码器的核心作用\"></a>3.2 预训练DNA编码器的核心作用</h2><h3 id=\"3-2-1-消融实验结果\"><a href=\"#3-2-1-消融实验结果\" class=\"headerlink\" title=\"3.2.1 消融实验结果\"></a>3.2.1 消融实验结果</h3><p>直接输入one-hot编码的U-Net模型性能显著降低，平均MCC仅0.07-0.11，远低于SegmentNT-3kb的0.37，证明DNA编码器的重要性。</p>\n<p>随机初始化NT编码器的模型，平均MCC仅0.16，且收敛速度比预训练编码器模型慢7倍，表明基因组自监督预训练能大幅提升模型性能。</p>\n<p>同时微调NT编码器和U-Net头的模型性能最优，且基于多物种预训练NT的SegmentNT优于人类基因组预训练NT模型（如图1e所示）。</p>\n<h3 id=\"3-2-2-与基线模型对比\"><a href=\"#3-2-2-与基线模型对比\" class=\"headerlink\" title=\"3.2.2 与基线模型对比\"></a>3.2.2 与基线模型对比</h3><p>原始SpliceAI架构（平均MCC 0.18）性能优于BPNet（0.10）、U-Net和随机初始化NT模型，缩放后SpliceAI平均MCC达0.27，但仍远低于SegmentNT-3kb的0.37（如图1e所示）。</p>\n<h2 id=\"3-3-SegmentNT对长序列的泛化能力\"><a href=\"#3-3-SegmentNT对长序列的泛化能力\" class=\"headerlink\" title=\"3.3 SegmentNT对长序列的泛化能力\"></a>3.3 SegmentNT对长序列的泛化能力</h2><h3 id=\"3-3-1-不同长度模型性能对比\"><a href=\"#3-3-1-不同长度模型性能对比\" class=\"headerlink\" title=\"3.3.1 不同长度模型性能对比\"></a>3.3.1 不同长度模型性能对比</h3><p>随着训练序列长度增加（3kb→10kb→20kb→30kb），模型平均MCC持续提升，SegmentNT-30kb达到最高（0.45），蛋白质编码基因、3’UTR、外显子和内含子的性能改善尤为明显（如图2a、2b所示）。</p>\n<h3 id=\"3-3-2-上下文长度扩展效果\"><a href=\"#3-3-2-上下文长度扩展效果\" class=\"headerlink\" title=\"3.3.2 上下文长度扩展效果\"></a>3.3.2 上下文长度扩展效果</h3><p>SegmentNT-10kb经上下文扩展后，在长序列上性能显著提升：100kb序列的平均MCC从0.07提升至0.26（如图2c所示）。</p>\n<p>所有SegmentNT模型中，SegmentNT-30kb在各序列长度下均表现最佳，50kb序列输入时平均MCC达0.47，100kb时仍保持0.45的高值（如图2d所示）。</p>\n<h3 id=\"3-3-3-长序列注释示例\"><a href=\"#3-3-3-长序列注释示例\" class=\"headerlink\" title=\"3.3.3 长序列注释示例\"></a>3.3.3 长序列注释示例</h3><p>在含TMEM230&#x2F;PCNA&#x2F;CDS2三个重叠基因的50kb区域，SegmentNT-30kb准确预测了所有14种元件的位置和概率，单次输出70万个预测结果（14×50000）（如图2e所示）。</p>\n<h3 id=\"3-3-4-错误预测分析\"><a href=\"#3-3-4-错误预测分析\" class=\"headerlink\" title=\"3.3.4 错误预测分析\"></a>3.3.4 错误预测分析</h3><p>所有元件的错误预测不仅集中在区域边缘，还富集于标记区域内部，调控元件的内部错误预测占比高于边缘，表明性能瓶颈源于部分区域的整体预测效果不佳，而非边缘效应。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig02.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig02.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2 SegmentNT在不同序列长度下的适配与泛化\"></p>\n<p><font size=2 color='grey'>图注：a. 不同长度SegmentNT模型在14种元件上的MCC性能（数据为10次测试集采样的均值±95%置信区间）；b. 各模型在14种元件上的平均MCC（数据为14种元件的均值±95%置信区间，每种元件经10次采样）；c. 上下文扩展对SegmentNT-10kb在不同长度序列上的性能影响（平均MCC）；d. 各SegmentNT模型在不同输入序列长度下的平均MCC（虚线为50kb最优推理长度）；e. TMEM230&#x2F;PCNA&#x2F;CDS2基因位点50kb区域的14种元件注释及预测概率示例。</font></p>\n<h2 id=\"3-4-不同基础模型作为DNA编码器的性能对比\"><a href=\"#3-4-不同基础模型作为DNA编码器的性能对比\" class=\"headerlink\" title=\"3.4 不同基础模型作为DNA编码器的性能对比\"></a>3.4 不同基础模型作为DNA编码器的性能对比</h2><h3 id=\"3-4-1-30kb输入序列下的性能\"><a href=\"#3-4-1-30kb输入序列下的性能\" class=\"headerlink\" title=\"3.4.1 30kb输入序列下的性能\"></a>3.4.1 30kb输入序列下的性能</h3><p>SegmentNT平均MCC（0.45）优于SegmentEnformer（0.34）和SegmentBorzoi（0.35）。SegmentNT在基因元件（蛋白质编码基因、UTR、外显子等）和短序列元件（剪接位点、多聚腺苷酸信号）上表现突出，而SegmentEnformer和SegmentBorzoi在长链非编码RNA、CTCF结合位点及调控元件上性能更优（如图3b、3c所示）。</p>\n<h3 id=\"3-4-2-扩展输入序列长度后的性能\"><a href=\"#3-4-2-扩展输入序列长度后的性能\" class=\"headerlink\" title=\"3.4.2 扩展输入序列长度后的性能\"></a>3.4.2 扩展输入序列长度后的性能</h3><p>SegmentEnformer（196kb输入）和SegmentBorzoi（524kb输入）相较于30kb版本性能整体提升，蛋白质编码基因、长链非编码RNA和内含子的改善最为显著。SegmentBorzoi在UTR区域的额外提升源于其RNA测序数据预训练（如图3b、3c所示）。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig03.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig03.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3 不同基础模型作为DNA编码器的性能对比\"></p>\n<p><font size=2 color='grey'>图注：a. SegmentNT、SegmentEnformer、SegmentBorzoi的架构示意图（括号内为输入输出维度，Enformer输出对应128bp bins，Borzoi对应32bp bins）；b. 不同模型在14种元件上的MCC性能（数据为10次测试集采样的均值±95%置信区间）；c. 各模型在14种元件上的平均MCC（数据为14种元件的均值±95%置信区间）。</font></p>\n<h2 id=\"3-5-与现有基因注释工具的对比\"><a href=\"#3-5-与现有基因注释工具的对比\" class=\"headerlink\" title=\"3.5 与现有基因注释工具的对比\"></a>3.5 与现有基因注释工具的对比</h2><h3 id=\"3-5-1-主异构体注释场景\"><a href=\"#3-5-1-主异构体注释场景\" class=\"headerlink\" title=\"3.5.1 主异构体注释场景\"></a>3.5.1 主异构体注释场景</h3><p>SegmentNT-30kb在剪接供体位点上性能优于AUGUSTUS，内含子和剪接受体位点性能相当，编码序列（CDS）区域因精确率较低表现稍差（如图4a、4b所示）。</p>\n<h3 id=\"3-5-2-所有异构体注释场景\"><a href=\"#3-5-2-所有异构体注释场景\" class=\"headerlink\" title=\"3.5.2 所有异构体注释场景\"></a>3.5.2 所有异构体注释场景</h3><p>在30kb基因片段和全染色体测试集中，SegmentNT-30kb在所有基因元件上的F1分数和MCC均优于AUGUSTUS，且兼具更高的精确率和召回率（如图4c、4d、4e所示）。</p>\n<h3 id=\"3-5-3-区域水平评估\"><a href=\"#3-5-3-区域水平评估\" class=\"headerlink\" title=\"3.5.3 区域水平评估\"></a>3.5.3 区域水平评估</h3><p>基于SOV分数的区域水平评估显示，SegmentNT-30kb在所有场景下仍优于AUGUSTUS，但全染色体测试集的性能提升幅度小于核苷酸水平指标（如图4f、4g、4h所示）。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig04.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig04.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图4 与AUGUSTUS基因预测性能对比\"></p>\n<p><font size=2 color='grey'>图注：a、c、d. 不同数据集（主异构体30kb片段、所有异构体30kb片段、所有异构体全染色体）中两种模型在各基因元件上的F1分数；b. 主异构体30kb片段数据集的精确率-召回率曲线；e. 所有异构体全染色体数据集的精确率-召回率曲线；f、g、h. 不同数据集下的SOV分数（误差线为95%置信区间，全染色体数据为10次采样均值±95%置信区间）。</font></p>\n<h2 id=\"3-6-剪接位点预测性能\"><a href=\"#3-6-剪接位点预测性能\" class=\"headerlink\" title=\"3.6 剪接位点预测性能\"></a>3.6 剪接位点预测性能</h2><h3 id=\"3-6-1-基因位点示例\"><a href=\"#3-6-1-基因位点示例\" class=\"headerlink\" title=\"3.6.1 基因位点示例\"></a>3.6.1 基因位点示例</h3><p>在EBF4基因位点，SegmentNT-30kb准确预测了所有外显子、内含子及剪接位点（包括起始处的可变外显子），而SpliceAI和Pangolin存在转录本边界外的假阳性预测（如图5a所示）。</p>\n<h3 id=\"3-6-2-mRNA测试集性能\"><a href=\"#3-6-2-mRNA测试集性能\" class=\"headerlink\" title=\"3.6.2 mRNA测试集性能\"></a>3.6.2 mRNA测试集性能</h3><p>SegmentNT-30kb与SpliceAI、Pangolin性能相当：剪接供体位点auPRC均为0.93-0.94，剪接受体位点auPRC为0.93-0.96（如图5b、5c、5d所示）。</p>\n<h3 id=\"3-6-3-全染色体测试集性能\"><a href=\"#3-6-3-全染色体测试集性能\" class=\"headerlink\" title=\"3.6.3 全染色体测试集性能\"></a>3.6.3 全染色体测试集性能</h3><p>SegmentNT-30kb的MCC高于SpliceAI和Pangolin，auPRC表现相当（剪接供体0.68-0.74，剪接受体0.70-0.72），剪接供体位点的top-k准确率更优（如图5e、5f、5g所示）。</p>\n<h3 id=\"3-6-4-非编码RNA剪接位点预测\"><a href=\"#3-6-4-非编码RNA剪接位点预测\" class=\"headerlink\" title=\"3.6.4 非编码RNA剪接位点预测\"></a>3.6.4 非编码RNA剪接位点预测</h3><p>SegmentNT和Pangolin在非编码RNA剪接位点上的性能低于SpliceAI，提示编码序列的相关信号可能驱动剪接检测性能（补充图6c）。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig05.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig05.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图5 SegmentNT在剪接位点预测上的性能\"></p>\n<p><font size=2 color='grey'>图注：a. EBF4基因位点的剪接元件预测示例（红色星号标记SpliceAI&#x2F;Pangolin的错误预测区域）；b. mRNA测试集上的MCC性能（误差线为100次自助抽样的95%置信区间）；c、d. mRNA测试集的精确率-召回率曲线及auPRC值；e. 人类全染色体测试集的MCC性能；f、g. 人类全染色体测试集的精确率-召回率曲线及auPRC值；h. 多物种全染色体测试集的平均MCC；i、j. 多物种剪接供体&#x2F;受体位点的auPRC雷达图。</font></p>\n<h2 id=\"3-7-调控元件定位性能\"><a href=\"#3-7-调控元件定位性能\" class=\"headerlink\" title=\"3.7 调控元件定位性能\"></a>3.7 调控元件定位性能</h2><p>SegmentNT-30kb在启动子和增强子注释上优于滑动窗口基线模型，SegmentEnformer表现最佳（补充图7b、7c）。DeePromoter在 curated测试集上性能优异，但在基因组序列语境中泛化能力差于滑动窗口NT模型。</p>\n<p>SegmentNT家族模型的推理速度更快，单次完成所有核苷酸预测，适用于遗传变异候选区域和个性化基因组的快速评估（补充图7d）。</p>\n<h2 id=\"3-8-SegmentNT的跨物种泛化能力\"><a href=\"#3-8-SegmentNT的跨物种泛化能力\" class=\"headerlink\" title=\"3.8 SegmentNT的跨物种泛化能力\"></a>3.8 SegmentNT的跨物种泛化能力</h2><h3 id=\"3-8-1-人类模型的跨物种表现\"><a href=\"#3-8-1-人类模型的跨物种表现\" class=\"headerlink\" title=\"3.8.1 人类模型的跨物种表现\"></a>3.8.1 人类模型的跨物种表现</h3><p>人类SegmentNT-30kb模型在不同物种中均表现出高性能，外显子和剪接位点的MCC最高（与进化保守性相关）。亲缘关系较近的物种（如大猩猩、猕猴）性能较好，进化距离较远的动物和植物性能下降（如图6b、6c所示）。</p>\n<h3 id=\"3-8-2-物种进化距离与性能关联\"><a href=\"#3-8-2-物种进化距离与性能关联\" class=\"headerlink\" title=\"3.8.2 物种进化距离与性能关联\"></a>3.8.2 物种进化距离与性能关联</h3><p>随着与人类的分化时间增加，各基因元件的MCC呈下降趋势，外显子和剪接位点的下降幅度最小（如图6c所示）。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig06.webp\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/03/Fig06.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图6 SegmentNT的跨物种泛化能力\"></p>\n<p><font size=2 color='grey'>图注：a. 多物种模型微调与跨物种评估示意图；b. 人类模型在各物种基因元件上的MCC性能（按与人类的分化时间排序）；c. 基因元件MCC与进化分化时间的关联（相同进化距离物种的MCC均值）；d-g. 人类模型与多物种模型在训练物种、近缘动物、远缘动物、植物上的性能雷达图；h. 四种代表性物种的各元件MCC对比；i. 与AUGUSTUS在不同物种基因注释上的平均MCC对比（误差线为95%置信区间）。</font></p>\n<h2 id=\"3-9-多物种SegmentNT模型的泛化提升\"><a href=\"#3-9-多物种SegmentNT模型的泛化提升\" class=\"headerlink\" title=\"3.9 多物种SegmentNT模型的泛化提升\"></a>3.9 多物种SegmentNT模型的泛化提升</h2><h3 id=\"3-9-1-训练物种性能\"><a href=\"#3-9-1-训练物种性能\" class=\"headerlink\" title=\"3.9.1 训练物种性能\"></a>3.9.1 训练物种性能</h3><p>多物种模型在训练物种的测试染色体上性能优于人类模型（如图6d所示）。</p>\n<h3 id=\"3-9-2-未见过物种的泛化\"><a href=\"#3-9-2-未见过物种的泛化\" class=\"headerlink\" title=\"3.9.2 未见过物种的泛化\"></a>3.9.2 未见过物种的泛化</h3><ul>\n<li>人类近缘动物（分化时间&lt;1000万年）：两模型性能相当（平均MCC 0.62 vs 0.64）</li>\n<li>人类远缘动物（分化时间&gt;1000万年）：多物种模型平均MCC从0.49提升至0.57</li>\n<li>植物物种：多物种模型平均MCC从0.34提升至0.45，即使未经过植物基因组训练仍表现出显著改善（如图6e、6f、6g所示）。</li>\n</ul>\n<h3 id=\"3-9-3-与AUGUSTUS的对比\"><a href=\"#3-9-3-与AUGUSTUS的对比\" class=\"headerlink\" title=\"3.9.3 与AUGUSTUS的对比\"></a>3.9.3 与AUGUSTUS的对比</h3><p>多物种模型在除拟南芥外的所有物种上，基因注释性能均优于AUGUSTUS（如图6i所示）。</p>\n<h1 id=\"4-讨论\"><a href=\"#4-讨论\" class=\"headerlink\" title=\"4 讨论\"></a>4 讨论</h1><h2 id=\"4-1-核心结论\"><a href=\"#4-1-核心结论\" class=\"headerlink\" title=\"4.1 核心结论\"></a>4.1 核心结论</h2><ol>\n<li>提出的DNA基础模型微调方法，实现了14种基因组元件的单核苷酸分辨率注释，SegmentNT模型可处理长达50kb的DNA序列，单次输出70万个预测结果，效率显著。</li>\n<li>预训练DNA编码器是模型高性能的关键，相较于直接使用one-hot编码或随机初始化编码器，性能提升显著，且上下文长度扩展方法有效突破了序列长度限制。</li>\n<li>不同DNA编码器各具优势：SegmentNT在基因元件和短序列元件上表现最佳，SegmentEnformer和SegmentBorzoi在调控元件上更具优势，可根据任务需求选择。</li>\n<li>人类SegmentNT模型具有天然的跨物种泛化能力，多物种模型进一步提升了对远缘动物和植物的注释性能，为未充分研究物种的基因组注释提供了高效工具。</li>\n</ol>\n<h2 id=\"4-2-研究展望\"><a href=\"#4-2-研究展望\" class=\"headerlink\" title=\"4.2 研究展望\"></a>4.2 研究展望</h2><ol>\n<li>扩展SegmentNT的上下文长度，结合自然语言处理领域的长序列建模技术和状态空间模型，开发下一代模型。</li>\n<li>细化调控元件分类，按细胞类型拆分启动子和增强子，提升细胞类型特异性调控密码的预测精度。</li>\n<li>探索SegmentNT在遗传变异影响评估、癌症基因组分析等领域的应用，整合实验数据进一步优化注释流程。</li>\n<li>扩充多物种模型的训练物种范围，纳入更多植物物种及基因组重排显著的物种，提升序列多样性覆盖。</li>\n</ol>\n<h1 id=\"数据获取说明\"><a href=\"#数据获取说明\" class=\"headerlink\" title=\"数据获取说明\"></a>数据获取说明</h1><p>SegmentNT训练数据来源于公开资源。基因注释数据来自gencode（<a href=\"https://www.gencodegenes.org/%EF%BC%89%E5%92%8CEnsembl%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88https://\">https://www.gencodegenes.org/）和Ensembl数据库（https://</a> <a href=\"http://www.ensembl.org).人类调控元件数据来自encode的筛选数据库(https//screen.wenglab.org/%EF%BC%89%E3%80%82\">www.ensembl.org）。人类调控元件数据来自encode的筛选数据库（https://screen.wenglab.org/）。</a> 进化距离数据取自生命时间树（<a href=\"https://timetree.org/\">Timetree of Life</a>）。SpliceAI测试集数据源自Illumina Basespace平台（<a href=\"https://basespace.illumina.com/projects/66029966/%EF%BC%89%E3%80%82\">https://basespace.illumina.com/projects/66029966/）。</a> 交互式浏览器会话，展示人类SegmentNT-30kb模型在测试染色体20和21上位于 <a href=\"https://tinyurl.com/23837bnl\">https://tinyurl.com/23837bnl</a> 区域的标签与预测结果。</p>\n<h1 id=\"代码资源说明\"><a href=\"#代码资源说明\" class=\"headerlink\" title=\"代码资源说明\"></a>代码资源说明</h1><p>人类及多物种SegmentNT-30kb模型、SegmentEnformer和SegmentBorzoi模型的模型权重，以及Jax语言的推理代码，可通过GitHub（<a href=\"https://github.com/instadeepai/nucleotide-transformer?tab=readme-ov-file#-segmentnt--family-segmentenformer-segmentborzoi\">https://github.com/instadeepai/nucleotide-transformer?tab=readme-ov-file#-segmentnt--family-segmentenformer-segmentborzoi</a>）获取研究使用。HuggingFace平台上的PyTorch版本模型可访问（<a href=\"https://huggingface.co/collections/InstaDeepAI/segmentnt-65eb4941c57808b4a3fe1319\">https:&#x2F;&#x2F; huggingface.co&#x2F;collections&#x2F;InstaDeepAI&#x2F;segmentnt-65eb4941c57 808b4a3fe1319</a>）。示例笔记本可在<a href=\"https://colab.research.google.com/#fileId=https\">Google Colab</a>获取。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>[1] de Almeida, B.P., Dalla-Torre, H., Richard, G. et al. Annotating the genome at single-nucleotide resolution with DNA foundation models. Nat Methods (2025). <a href=\"https://doi.org/10.1038/s41592-025-02881-2\">https://doi.org/10.1038/s41592-025-02881-2</a></li>\n</ul>\n<h1 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h1><p>关注公众号“生信之巅”。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"基因组语言模型的机遇与挑战","slug":"基因组语言模型的机遇与挑战","date":"2025-11-11T15:08:16.000Z","updated":"2025-11-11T15:11:30.465Z","comments":true,"path":"api/articles/基因组语言模型的机遇与挑战.json","excerpt":null,"keywords":null,"cover":"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>大型语言模型（LLMs）正在对广泛的科学领域产生变革性影响，尤其是在生物医学领域。正如自然语言处理（NLP）的目标是理解单词序列一样，生物学的一个主要目标是理解生物序列。基因组语言模型（gLMs）是在DNA序列上训练的大型语言模型，有望显著增进我们对基因组的理解，以及不同尺度的DNA元件如何相互作用以产生复杂功能。为展示这一潜力，我们重点介绍了基因组语言模型的关键应用，包括<code>功能约束预测</code>、<code>序列设计</code>和<code>迁移学习</code>。然而，尽管近期取得了显著进展，开发有效且高效的基因组语言模型仍面临诸多挑战，特别是对于具有大型复杂基因组的物种。在此，我们探讨了开发和评估基因组语言模型的主要考量因素。</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>人工智能&#x2F;机器学习（AI&#x2F;ML）的最新进展对广泛的科学学科产生了深远影响，彻底改变了建模、数据分析、解释和发现的方法。这一发展的关键支柱之一是自监督学习，通过在大量未标记数据上进行训练，模型能够学习复杂特征及其相互作用。这种范式尤其改变了自然语言处理领域，使人工智能模型在多个具有挑战性的任务上达到人类水平，包括翻译、语音识别，甚至回答标准化专业和学术考试中的问题。</p>\n<p>正如自然语言处理的目标是理解自然语言序列一样，计算生物学的一个主要目标是理解生物序列。因此，近年来人们对将自然语言处理中的现代技术应用于生物序列（DNA、RNA、蛋白质）产生了浓厚兴趣。特别是，蛋白质序列数据库（如UniProt）在过去十年中呈指数级增长，在这些海量数据上训练的蛋白质语言模型（pLMs）在复杂问题上取得了令人印象深刻的性能，例如结构预测和变异效应预测等记的蛋白质序列数据集有望包含重要的生物信息。</p>\n<p>类似地，在DNA序列上训练的大型语言模型（LLMs）有望改变基因组学，但为基因组开发有效的模型面临额外的挑战。例如，与作为功能重要单元且尺寸相对较小的蛋白质不同，大多数基因组要大得多，并且通常包含大量复杂的非功能区域，这些区域在数量上超过了功能元件。此外，与数亿个蛋白质序列相比，整个生命树中可用的全基因组序列数量极少，这限制了训练数据中功能重要的DNA元件的多样性。尽管存在这些问题，我们认为在基因组上训练的语言模型——即基因组语言模型（gLMs）——对生物学具有巨大潜力。在本文中，我们回顾了该领域的一些关键机遇和挑战，<u>并概述了开发和评估对基因组学界有用的基因组语言模型应解决的主要考量因素</u>。</p>\n<h2 id=\"2-应用\"><a href=\"#2-应用\" class=\"headerlink\" title=\"2 应用\"></a>2 应用</h2><p>语言模型的通用框架总结在<code>BOX 1</code>中。下面，我们详细阐述基因组语言模型的三个主要应用领域：功能约束预测、序列设计和迁移学习。</p>\n<h3 id=\"2-1-功能约束预测\"><a href=\"#2-1-功能约束预测\" class=\"headerlink\" title=\"2.1 功能约束预测\"></a>2.1 功能约束预测</h3><p>基因组语言模型一个有趣的应用是在无需任何任务监督的情况下预测基因组位点的功能约束。这种方法的一个显著优势是它不依赖于标记（例如某个变异是否致病），而标记通常数量有限且存在偏差。其核心思想是，参考基因组（通常来自健康个体）中有害变异的含量相对较低。因此，在这些数据上训练的模型倾向于给有害变异分配较低的概率。这一观察结果为使用<strong>两个等位基因之间的对数似然比</strong>（LLR）——即$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$——来估计它们的相对适应性提供了依据。</p>\n<p><font size=2 color='grey'><strong>BOX 1</strong>：通用语言模型框架</p>\n<p>从高层次来看，语言模型的训练目标是学习如下形式的条件概率分布：</p>\n<p>在掩码语言建模（MLM）中为 $(\\mathbb{P}[X_{i}|X_{- \\text{Masked}}])$（其中$(i \\in \\text{Masked})$），在因果语言建模（CLM）中为 $(\\mathbb{P}[X_{k}|X_{1:k-1}])$。这里，$(X&#x3D;(X_{1},X_{2},\\dots))$ 表示“标记”（如核苷酸或氨基酸）序列，“Masked”表示被掩码的位置集合。自然语言处理近期取得进展的关键在于，不再手动设计简单的上下文依赖参数模型，而是让数据自己说话，并通过利用强大的深度学习架构，随着观测数据的增加来拟合更复杂的模型。图1展示了用于DNA的语言建模框架。虽然模型训练的目的是利用未掩码位点的信息预测每个掩码位点的核苷酸，但它会学习位置特异性的上下文表示（称为嵌入，即一个高维向量），随后该向量会转换为在 ${A,C,G,T}$ 上的概率分布。这些嵌入和概率分布均具有位置特异性，可应用于基因组学中的许多问题。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1：基因组语言模型的训练和应用\"></p>\n<p><font size=2 color='grey'>左侧示意图展示了基因组语言模型的训练过程。两个等位基因之间的对数似然比（LLR，具体为$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$）是功能约束的良好无监督预测因子（功能约束预测）。通过从学习到的概率分布中采样，可以生成新的序列（序列设计）。输入序列中每个标记的向量表示（称为嵌入）可以被提取出来，并适配于不同的下游任务（迁移学习）。</font></p>\n<p>在蛋白质序列模型中，最初引入了使用对数似然比进行功能约束预测的方法，在预测错义变异效应方面取得了出色成果。将这种方法扩展到基因组范围，GPN首次使用基因组语言模型进行全基因组功能约束预测，在模式植物拟南芥（<em>Arabidopsis thaliana</em>）中取得了最先进的结果。为说明基因组语言模型如何预测功能约束，我们注意到基因组语言模型能够学习<code>转录因子结合位点（TFBS）基序</code>，理解哪些位置受到约束，哪些位置不受约束（<strong>图2a</strong>）。此外，尽管<code>GPN</code>模型仅在拟南芥的一个基因组上训练，但它的对数似然比得分与拟南芥自然种群中的等位基因频率相关（<strong>图2b</strong>）。随后，<code>AgroNT</code>和<code>PlantCaduceus</code>在其他植物物种中也取得了优异结果。然而，对于人类基因组，核苷酸转换器（NT）的对数似然比性能低于现有的基准模型。与此同时，<code>GPNMSA</code>利用跨多种脊椎动物物种的全基因组多序列比对（MSA），实现了最先进的性能。需要注意的是，<u>观察到的核苷酸分布不仅受功能约束驱动，还受突变偏差影响；将此信息明确纳入功能约束预测是未来研究的一个有前景的方向</u>。</p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2：应用示例\"></p>\n<p><font size=2 color='grey'>（a）基因组语言模型在启动子区域预测的序列标志图（顶部），突出显示了与假定功能性转录因子结合位点匹配的基序（底部序列标志图）。（b）变异次要等位基因频率（MAF）与基因组语言模型得分（对数似然比）之间的相关性。（c）基因组语言模型可以用不同的控制标签提示，设计在特定细胞类型中驱动高表达或低表达的启动子序列。（d）不同基因组窗口类别的基因组语言模型嵌入可视化，表明学习到的表示包含有用信息，如基因区域。注：面板a、b、d使用GPN模型生成。</font></p>\n<p>对于单核苷酸多态性（SNP），在掩码语言模型中只需对变异位置进行一次掩码查询即可计算对数似然比，而在因果语言模型中则需要对参考序列和替代序列进行两次查询。因果语言模型可以轻松处理多个替换、插入和缺失，而掩码语言模型必须采用更耗时的伪对数似然比方法。除对数似然比外，还提出了其他用于功能约束预测的得分，例如嵌入空间中的距离或突变周围位置核苷酸概率的变化。尽管对数似然比在蛋白质语言模型和基因组语言模型领域都被广泛使用，但深入理解这些替代得分在哪些场景下有用仍然很重要。</p>\n<p>基因组学中有两类主要的变异效应预测器：<strong>一类是功能约束预测器</strong>，包括基因组语言模型和传统的保守性得分；<strong>另一类是活性预测器</strong>，如基因表达预测器<code>Enformer</code>或剪接预测器<code>SpliceAI</code>。这两类模型存在关联：如果某个位点的变异受到选择，它会在某些情况下诱导活性变化（例如，在肢体发育过程中某个基因的转录变化），最终影响高级性状（例如，多指畸形）。功能约束模型涵盖了影响整体生物体适应性的所有可能机制和场景，而活性模型仅反映了它们明确训练过的机制和场景（某些数据，如人类大脑发育过程中的蛋白质表达，获取难度较大）。另一方面，活性模型可以指出变异发挥作用的特定机制和场景，而功能约束模型则不提供机制解释。</p>\n<p>关于功能性变异的优先排序，还有一些额外的考量。对于两个在不同基因中引起相似表达倍数变化的变异，即使它们的表达水平在生理耐受性上存在巨大差异，活性模型通常也会给出相似的得分。另一方面，不受可检测选择影响的性状仍可能具有科学或医学意义。在这种情况下，功能约束模型在优先排序影响该性状的变异方面能力有限，尤其是当这些变异效应量较小时（如在复杂性状全基因组关联研究（GWAS）中常见的情况）。然而，尽管基因组语言模型的对数似然比在这种情况下可能效果不佳，但基因组语言模型学习到的嵌入（<strong>BOX 1</strong>）在有标记数据的额外监督下仍可能具有价值。</p>\n<h3 id=\"2-2-序列设计\"><a href=\"#2-2-序列设计\" class=\"headerlink\" title=\"2.2 序列设计\"></a>2.2 序列设计</h3><p>设计新的生物序列对学术界和工业界研究团体都极具吸引力，因为它在药物发现与递送、农业改良、生物修复以及生物研究工具开发等方面具有巨大潜力。在此，我们描述使用<code>因果语言模型</code>（<strong>BOX 1</strong>）进行序列生成的方法，这是最常用的方法。具体而言，序列生成任务被分解为一系列下一个标记预测问题。从给定的序列片段（称为提示或控制标签）开始，语言模型可以递归地预测下一个标记，从而生成完整的新序列。蛋白质语言模型已被证明是蛋白质设计的强大工具。除编码序列外，非编码序列的设计也至关重要，因为它在基因和细胞治疗以及合成生物学等领域有应用。此类设计任务以前通过有监督的活性模型解决，但最近有多项研究探索使用基因组语言模型来应对这一挑战，如下所述。</p>\n<p><code>regLM</code>模型基于因果基因组语言模型<code>HyenaDNA</code>构建，用于<strong>从头生成启动子和增强子序列</strong>。HyenaDNA模型在带有前置控制标签的调控序列上进行训练或微调。然后，使用训练好的模型生成带有给定标签的新调控序列（<strong>图2c</strong>）。作者在酵母和人类细胞系中对生成序列的多样性和活性进行了计算评估，证明这些序列具有预期的功能以及真实且多样的序列特征。</p>\n<p>基因组语言模型在多模态设计任务中具有独特潜力，例如通过将蛋白质-RNA复合物统一为DNA序列设计来生成此类复合物。<u>例如，在原核生物基因组上训练的基因组语言模型EVO被用于设计新的CRISPR-Cas系统</u>。该模型使用带有前置Cas亚型特异性提示的CRISPR-Cas序列数据集进行微调。微调后的模型能够生成与亚型提示匹配的新CRISPR-Cas序列，且其预测结构与天然存在的系统相似。</p>\n<p>此外，<u>基因组语言模型还有可能用于在染色体或基因组尺度上设计有组织的功能性DNA序列</u>。最近，两个基因组语言模型<code>MegaDNA</code>和<code>EVO</code>探索了原核生物基因组的此类设计任务。EVO用于生成20个约650 Mbp大小的序列。研究发现，生成的序列具有真实的编码序列密度、具有预测二级结构和球状折叠的蛋白质序列，以及合理的tRNA序列。MegaDNA用于生成长达96 kbp的完整噬菌体基因组。除验证编码序列外，作者还在生成的序列中识别出包括启动子和核糖体结合位点在内的功能性调控元件。然而，此类大规模DNA序列设计任务仍然具有挑战性。研究发现，<u>EVO生成的序列缺乏功能原核生物基因组中通常存在的高度保守标记基因，且预测的蛋白质结构与天然蛋白质数据库的匹配度有限。最近的一项独立评估表明，MegaDNA生成的基因组序列组成与天然基因组仍有很大差异</u>。因此，需要进一步研究改进方法，以实现使用基因组语言模型从头设计完全功能性的基因组。</p>\n<h3 id=\"2-3-迁移学习\"><a href=\"#2-3-迁移学习\" class=\"headerlink\" title=\"2.3 迁移学习\"></a>2.3 迁移学习</h3><p>通过功能基因组学实验训练的用于预测注释的神经网络已被广泛用于解释基因组元件的功能。<u>一个重要的应用是预测变异对分子表型的影响，例如基因表达和剪接</u>。神经网络能够解释基因组位点之间复杂相互作用的能力，使其成为解决这些重要问题的必备工具，但合适的训练数据通常难以收集，因此数量有限。为了在预测任务上实现泛化，模型需要能够识别广泛的功能重要序列元件，这可能需要大量的数据和计算资源。为克服单个任务数据不足的限制，开发者采用了迁移学习方法——即利用在一个任务上训练模型获得的知识来改进相关任务性能的技术。具体而言，大多数用于预测功能注释的神经网络都经过训练以同时预测多种注释，迫使这些模型学习单一的统一表示。这进而提高了它们的泛化性能。</p>\n<p>语言模型也可用于迁移学习（有关迁移学习在自然语言处理中的应用，请参见<strong>BOX 2</strong>）。一种技术是特征提取：在学习预测核苷酸的上下文依赖分布时，基因组语言模型将输入的基因组序列转换为中间向量表示<strong>BOX 1</strong>）。这些表示可能提炼了相关信息，因此可用作另一个模型的特征。例如，<u>基因组语言模型嵌入的可视化显示，在没有任何监督的情况下，模型已经学会区分不同类别的基因组元件，如编码序列和非翻译区（<strong>图2d</strong>）</u>。不同层的嵌入可以为不同任务提供有用信息。利用语言模型进行迁移学习的另一种方法是将其用作预训练模型，即在下游任务上继续训练它们。这种技术称为微调。在某个任务上微调预训练的神经网络，会隐式地对其参数进行正则化，使得网络的预测综合了来自两个任务的知识。因此，对神经网络进行预训练通常会提高其在下游任务上的泛化性能。在最近的研究中，<code>SegmentNT</code>模型（通过微调核苷酸转换器（NT）基因组语言模型以实现<strong>基因和顺式调控元件注释</strong>任务而开发）在该任务上取得了最先进的性能。研究表明，使用预训练模型是其取得成功的关键。类似地，NT家族的另一个模型<code>AgroNT</code>在多种植物物种上进行预训练，然后在选定的作物物种上微调以预测染色质可及性和基因表达。<code>DNABERT-S</code>将对比学习与预训练的<code>DNABERT-2</code>嵌入相结合，用于<strong>宏基因组分箱</strong>。<code>IsoFormer</code>是DNA和蛋白质语言模型之间多模态迁移学习的一个例子，用于<strong>预测转录本亚型表达</strong>。这些最近的成功表明，微调后的基因组语言模型可能在各种基因组解释任务上取得显著进展。</p>\n<p>最近有两项研究评估了多个基因组语言模型在人类基因组预测任务中的性能，发现它们通常不会优于非基因组语言模型基准。这些结果基于冻结的嵌入；评估完整的微调过程将提供更多见解。尽管基因组语言模型已经非常适合展示迁移学习在研究较少的生物体中的价值，但要使其在人类遗传学（已有高质量标记数据和精心设计的模型）中提供显著价值，可能还需要进一步的创新。一个重要的问题是，缩放假设对基因组语言模型的适用程度如何，即增加未标记数据和计算资源在多大程度上能持续提高模型性能。最近的一项蛋白质语言模型研究发现，缩放仅改进了蛋白质结构预测，而没有改进大多数其他任务（如功能或性质预测），因此基因组语言模型任务也应受到同样的审视。</p>\n<p><font size=2 color='grey'> <strong>BOX 2</strong>：自然语言处理中的迁移学习<br>为了在大多数任务（包括情感分析、问答和词性标注等典型任务）上实现泛化，自然语言处理模型需要理解语法和语义。然而，这些任务的特定数据通常有限。利用在原始文本数据（来源于文章、书籍和网站）上训练的大型语言模型进行迁移学习，已在这些问题上取得了突破性进展。如今，几乎所有最先进的自然语言处理模型都是从大型语言模型改编而来。</font></p>\n<p>迁移学习技术是近年来自然语言模型蓬勃发展的基础。特别是，可广泛适配于下游任务的预训练模型（称为“基础模型”）的出现，使得机器学习模型的开发方式发生了重大转变。</p>\n<h2 id=\"3-开发\"><a href=\"#3-开发\" class=\"headerlink\" title=\"3 开发\"></a>3 开发</h2><p>现在，我们描述开发有用的基因组语言模型的关键组成部分；<strong>图3</strong>展示了总结开发流程的示意图。我们首先阐述选择和准备训练数据的重要性，然后讨论架构和训练决策，接着考虑基因组语言模型的解释和基准测试。我们的目标是<u>深入了解开发有效且高效的基因组语言模型所涉及的方法和挑战</u>。为全面展示该领域的当前状况，我们在<strong>表1</strong>中列出了一些我们已知的现有基因组语言模型，并总结了它们的设计决策。</p>\n<h3 id=\"3-1-训练数据\"><a href=\"#3-1-训练数据\" class=\"headerlink\" title=\"3.1 训练数据\"></a>3.1 训练数据</h3><p>机器学习模型的性能在很大程度上受其架构和训练数据的影响。卷积神经网络（CNNs）、Transformer 和状态空间模型（SSMs）等各种模型架构已成功应用于广泛的领域，包括自然语言、图像、音频、蛋白质和基因组学。然而，为预训练选择合适的数据需要对特定领域有深入的理解，尤其是<u>在基因组学领域，目前尚无类似于自然语言处理（如Pile）或蛋白质生物学（如UniProt）中那样被普遍接受的精选数据集</u>。</p>\n<p><strong>一个关键的考量因素是数据质量</strong>。例如，在自然语言处理中，数据质量可能指经过编辑或同行评审的数据源，如科学文章或书籍。<u>在蛋白质领域，质量控制包括去除预测的假基因或不再具有功能的截断蛋白质</u>。然而，最近的一项研究发现，作为最常用的基因组语言模型训练数据集（<strong>表1</strong>）的人类参考基因组中，仅有3.3%的碱基受到显著约束且可能具有功能。重要的是，<u>用于训练基因组语言模型的典型基因组序列既包含<code>功能位点</code>，也包含<code>非功能位点</code>，且通常无法将训练样本明确分为<code>高质量</code>和<code>低质量</code>两类</u>。一个提出的解决方案是根据功能证据对训练损失进行碱基级加权。</p>\n<p>在自然语言处理和蛋白质领域，<strong>过滤重复序列</strong>是标准做法，这有助于提高训练效率并减少记忆。尽管人类基因组中高达50%的序列是重复序列（在真核生物中这一比例普遍较高），但很少有基因组语言模型研究提出解决方案（如降低权重或下采样），甚至很少有研究承认这一问题。如果语言模型困惑度的研究也能分别报告非重复区域的困惑度，以区分泛化改进和记忆改进，那将很有启发意义。</p>\n<p><strong>另一个关键问题是如何确保数据量充足</strong>。单个基因组可能不足以训练大型模型，尤其是当非功能区域被下采样或降低权重时。一种方法是添加同一物种的序列变异。然而，在包括人类在内的许多物种中，个体之间的变异相对较少。更常用的方法是<code>跨多个物种进行训练</code>（<strong>表1</strong>），这与蛋白质语言模型的做法类似。随着物种亲缘关系的疏远，调控逻辑的分化速度快于蛋白质。一种提出的方法是<strong>将物种标识符作为额外输入明确添加到模型中</strong>。尽管如此，一个足够大的模型，在有足够基因组上下文的情况下，仍有可能自然地对远缘基因组进行建模，类似于大型语言模型处理多语言数据集的方式。</p>\n<p>如前所述，在原核生物中，已有模型（MegaDNA和EVO）将整个基因组作为上下文。目前，这在真核生物中还不可行，因此产生了<strong>如何将基因组划分为可单独建模的上下文窗口的问题</strong>。许多相互作用局限于邻近位置（如转录因子结合位点基序），这推动了具有相对较小上下文（&lt;6 kb）的模型的开发（**表1**）。然而，也存在明显的长程相互作用，例如同一基因的外显子之间或增强子与启动子之间（可达1 Mb）。如此长的上下文长度带来了计算和统计挑战，研究人员已在努力克服这些挑战。无论选择何种上下文长度，将基因组划分为独立单元（类似于按蛋白质划分蛋白质组的方式）仍然并非易事。例如，<u>一个基因的增强子可能位于另一个基因的内含子中，且多个基因可能由同一个增强子调控。尤其是在跨物种训练时，避免因直系同源和旁系同源导致的数据泄露非常具有挑战性</u>。</p>\n<p>训练数据的选择可能会显著影响基因组语言模型的输出和学习到的表示。自然界中观察到的DNA序列是各种进化过程的结果，其中最主要的是突变和选择。对于某些应用，可能需要精心选择训练数据，以突出这些过程中的某一个。例如，为了进行适应性预测，可能需要排除&#x2F;降低高突变位点（如CpG位点）和非功能区域（如某些类型的重复元件）的权重。</p>\n<h3 id=\"3-2-模型架构\"><a href=\"#3-2-模型架构\" class=\"headerlink\" title=\"3.2 模型架构\"></a>3.2 模型架构</h3><p>在Transformer架构出现之前，<code>卷积神经网络</code>模型已被广泛用于基因组学中的有监督任务。卷积神经网络通过对输入数据应用<code>过滤器</code>，特别<u>擅长捕捉基因组序列中的局部依赖关系和基序</u>。这些模型在预测<strong>DNA-蛋白质结合位点</strong>、<strong>调控元件</strong>和<strong>转录因子结合位点</strong>方面取得了成功。前面提到的用于拟南芥全基因组变异效应预测的基因组语言模型GPN，借鉴了自然语言处理和蛋白质建模中带有改进卷积神经网络层的语言模型的成功经验，用<code>扩张卷积神经网络层</code>替换了Transformer<code>编码器中的自注意力层</code>。</p>\n<p><code>Transformer</code>模型彻底改变了各种机器学习领域，尤其是自然语言处理，并且最近被广泛应用于基因组学建模。自注意力机制允许每个标记同时关注输入序列中的所有位置，使模型能够动态关注序列的相关部分。这种能力在有监督的基因表达任务中检测调控机制方面取得了显著进展。</p>\n<p>尽管Transformer模型具有优势，但它们在基因组学建模中面临一些独特的<strong>挑战</strong>。一个重要问题是，<u>Transformer对相互作用的局部性几乎没有或没有归纳偏置，这使得它们在建模转录因子结合位点等局部基序时数据效率较低</u>。这促使人们开发<strong>卷积神经网络-Transformer混合模型</strong>，如<code>LOGO</code>，其借鉴了<code>Enformer</code>等有监督模型的思路。</p>\n<p><strong>另一个挑战是上下文长度</strong>：自注意力机制导致<strong>计算时间和内存随输入序列长度呈二次方增长</strong>，这使得将Transformer应用于极长的基因组序列变得不切实际。因此，传统基于注意力的基因组语言模型目前能够处理的最长输入长度是<code>NT-v2的12 kb</code>。为解决这一限制，一些基于Transformer的基因组语言模型采用了<code>近似注意力</code>或<code>分层注意力</code>方法，牺牲了所有标记之间的完全成对注意力。这些方法包括在<code>GENA-LM</code>中使用稀疏注意力（将上下文长度扩展到<code>36 kb</code>），以及在<code>MegaDNA</code>中采用MEGABYTE亚二次方分层自注意力（实现<code>了96 kb</code>的上下文长度）。</p>\n<p>为克服自注意力的二次方缩放问题，人们提出了各种状态空间模型（SSMs）作为Transformer的高效替代方案，用于基因组语言模型，其<strong>计算复杂度随序列长度接近线性增长</strong>。基于·层次结构的<code>HyenaDNA</code>能够支持长达<code>100万</code>个核苷酸的输入上下文。<code>EVO</code>是一种结合了Hyena和Transformer架构的混合模型，在8 kb序列上进行预训练，然后在上下文扩展阶段使用<code>131 kb</code>序列进行微调。基于Mamba的状态空间模型构建的<code>Caduceus</code>在<code>131 kb</code>序列上进行训练，同时融入了反向互补等变。</p>\n<h3 id=\"3-3-学习目标\"><a href=\"#3-3-学习目标\" class=\"headerlink\" title=\"3.3 学习目标\"></a>3.3 学习目标</h3><p>如<strong>BOX 1</strong>所述，掩码语言模型（MLM）任务（有时也称为“掩码标记预测”）要求模型根据剩余标记预测以预定概率（通常为15%）随机掩码的标记身份。这一框架已用于训练开创性的大型语言模型BERT和蛋白质语言模型<code>ESM-1b</code>，此后被广泛用于训练基因组语言模型。因果语言模型（CLM）任务（也称为“自回归语言建模”或“下一个标记预测”）要求模型根据前面的标记预测序列中的标记；该任务已用于训练GPT系列大型语言模型。在该任务中，模型以单向从左到右的顺序，根据前面的标记预测下一个标记。这两个任务的共同点是，它们都要求模型根据其他组件作为上下文来预测数据的组件。为了在这些任务上实现泛化，模型必须学习数据的低维表示。这种能力使基因组语言模型能够通过捕捉基因组内的潜在模式和依赖关系来理解和生成基因组序列。<u>在蛋白质建模中，掩码语言模型在表示学习和迁移学习能力方面通常优于因果语言模型</u>。另一方面，因果语言模型是生成任务的传统选择，但最近通过渐进式掩码，掩码语言模型在生成任务上也取得了优异结果。</p>\n<p>为减少输入序列长度并建模更长的上下文，k-mer和字节对编码（BPE）创建了比天然核苷酸词汇表（{A,C,G,T}）更大的人工定义核苷酸词汇表。另一方面，单核苷酸标记化简化了模型解释和归因，并增强了模型处理基因组变异的能力。</p>\n<p>研究人员探索了对训练目标的多种修改，以提供额外的信号并提高性能。例如，<code>GPN-MSA</code>通过脊椎动物物种的全基因组多序列比对（MSA）增强了在人类参考基因组上的掩码语言模型训练，利用相关物种间的保守性获取额外上下文。其局限性在于，全基因组多序列比对仅针对某些物种生成，要在植物中有效应用可能需要进一步开发。此外，即使顺式调控元件的活性保守，其序列也可能快速分化，这限制了通过比对提取的直系同源信息。<code>Species LM</code>通过为每个酵母物种分配一个专用标记，并在训练和推理期间将物种标记附加到输入序列，直接整合了物种信息。核苷酸序列的预训练已扩展到支持与其他模态的交互，如表观遗传学、RNA、蛋白质和自然语言。</p>\n<h3 id=\"3-4-解释\"><a href=\"#3-4-解释\" class=\"headerlink\" title=\"3.4 解释\"></a>3.4 解释</h3><p>尽管深度学习模型在各种预测任务中取得了显著性能，但它们通常缺乏可解释性，常被视为“黑箱”。然而，理解这些模型如何生成预测对于实现更广泛的应用和推进模型开发至关重要。因此，研究人员开发了一系列解释深度学习模型的方法，包括专门针对基因组学的方法。尽管基因组语言模型的解释仍是一个新兴的研究方向，但已有研究表明，一些模型已经学习到了有意义的生物模式。</p>\n<p>从语言模型中提取的序列嵌入通常被用作捕捉丰富上下文信息和序列特征的表示。<u>对基因组语言模型编码的序列嵌入进行无监督聚类，发现输入序列形成了对应于不同基因组类别（如编码序列、内含子、非翻译区等）的明显聚类</u>（<strong>图2d</strong>）。此外，<u>对<code>SpliceBERT</code>嵌入的典型剪接位点和非剪接GT&#x2F;AG位点进行无监督聚类，发现了对应于这两组位点的明显聚类</u>。这些结果表明，模型已经学会捕捉表征基因组中功能元件的关键上下文模式。</p>\n<p>Transformer模型中的注意力机制旨在捕捉输入标记之间的交互模式。因此，解释给定输入序列的注意力权重或注意力图，可以揭示模型学习到的基因组特征。<u>在SpliceBERT中，剪接供体位点和受体位点之间的注意力权重显著高于随机位点对之间的注意力权重；此外，真实供体-受体对之间的交互强度往往高于其他供体和受体位点组合</u>。这些发现表明，模型已经学会了功能交互位点之间的关系。</p>\n<p>一些基因组语言模型还采用核苷酸重建方法来发现模型学习到的序列基序。具体而言，将输入序列的各个位置逐一掩码，然后由训练好的模型根据基因组上下文预测核苷酸的概率分布。每个位点获得的分布可以揭示模型学习到的基序。GPN中采用了这种方法，在重建核苷酸的分布中发现了显著模式。特别是，<strong>模型在功能重要位点的预测通常更有信心</strong>。例如，编码序列和剪接供体&#x2F;受体位点的预测信心通常高于深层内含子位点。此外，在编码序列中，密码子的第三个核苷酸位置（对翻译的氨基酸决定作用最小）的预测信心通常低于前两个核苷酸位置。通过适配<code>TF-MoDISco</code>（一种利用模型预测识别新转录因子结合位点的专用工具），作者还发现了与转录因子结合位点数据库和相关文献中已知基序匹配的序列基序（<strong>图2a</strong>）。类似地，Species LM重建的序列基序也与训练中未见过的物种中已知的DNA和RNA结合蛋白的结合位点匹配，基序重建的准确性取决于正确反映体内结合位点的上下文和基因组区域。此外，重建基序的组成、存在和位置表现出物种特异性模式，这表明<u>基因组语言模型可能成为研究序列基序和调控密码进化的强大工具</u>。</p>\n<p>最近，研究人员通过在某个位置引入点突变并量化其他位置核苷酸概率的变化，研究了基因组语言模型学习到的基因组位置之间的依赖关系。核苷酸依赖分析揭示了模型学习到的功能元件（如转录因子结合位点、剪接位点和RNA）内部和之间的相互作用，包括已知的二级和三级结构接触。值得注意的是，与之前基于预测边际概率分布的方法相比，核苷酸依赖分析能够更稳健地检测结合的转录因子结合位点。</p>\n<h3 id=\"3-5-评估\"><a href=\"#3-5-评估\" class=\"headerlink\" title=\"3.5 评估\"></a>3.5 评估</h3><p>在本节中，我们将讨论如何针对前面描述的三个应用领域对模型性能进行基准测试：预测等位基因的功能约束、生成新的可行序列以及迁移学习。</p>\n<p>有多种类型的数据可以反映等位基因的功能约束，可用于基准测试变异效应预测器。<strong>一类</strong>数据来自将<code>遗传变异的功能差异与读数</code>(readouts)（如报告基因的表达或细胞生长）相关联的实验。这些读数可用于对变异的功能性进行排序，由于影响功能的变异通常也受到选择，因此我们期望这些排序与模型预测的排序相关。这类数据的一个来源是<code>ProteinGym</code>，这是一个广泛使用的实验数据集集合，可用于基准测试错义变异效应预测器。<strong>另一类</strong>数据是<code>临床标记</code>，指示变异是否有致病证据（即是否会增加疾病风险）。致病性变异可能影响生育能力，因此可能具有有害性。因此，我们可以通过评估变异效应预测器作为致病性分类器的性能来对其进行基准测试。在人类遗传学中，变异临床标记的主要来源包括<code>ClinVar</code>、<code>HGMD</code>和<code>OMIM</code>数据库。<strong>第三类</strong>数据是<code>变异频率</code>。由于常见变异不太可能具有高度有害性，它们的预测约束水平应相对高于罕见变异。因此，我们可以根据预测器识别常见变异的能力对其进行基准测试。人类不同祖先群体中等位基因频率数据的主要来源是<code>gnomAD</code>数据库。总之，这些数据可以作为模型泛化性能的独立证据。</p>\n<p>变异效应预测器评估的一个问题是，验证数据与功能约束之间的关系可能不明确。因此，模型可能通过利用数据未能捕捉功能约束的方面在基准测试中表现出色。例如，使用临床标记的一个关键问题是，变异的分类基于是否有充分证据证明它们是良性的或致病性的。由于预测器也可能利用这些证据，它们在标记变异上的基准测试性能可能无法反映其在未标记变异上的真实性能（有关泛化性能的简要讨论，请参见<strong>BOX 3</strong>）。使用等位基因频率数据也存在关键问题：例如，除自然选择的直接作用外，等位基因频率还受突变率、遗传漂变、背景选择和遗传搭车等因素影响。因此，预测器可能通过预测这些过程的影响而非功能约束在基准测试中表现良好。这些问题凸显了需要仔细解释预测器性能原因的重要性，并促使人们呼吁提高预测器训练所使用的数据和方法的透明度。</p>\n<p>生成式序列模型的评估面临一系列独特挑战。评估语言模型生成能力的一种基本方法是比较它们在有效序列集上的困惑度。然而，要评估模型设计新序列的能力，需要衡量它们是否能够识别既可行又新颖的序列。因此，模型在测试集上的困惑度可能无法可靠地表明其在设计任务中的实用性。相反，可能需要采用全面的方法，检查生成序列的广泛特性。例如，最近用于调控序列设计的基准测试工具<code>Polygraph</code>提出了一系列分析方法，用于研究序列组成、基序模式和预测的功能活性。对于全基因组或染色体设计任务，可能还需要评估必需基因和功能性调控元件的存在和位置，以及它们之间的相互作用。最终，设计的序列需要通过实验评估，以确定它们是否能实现预期功能。</p>\n<p>最后，评估基因组语言模型在迁移学习中的性能面临一个独特挑战：任何基准测试集（可能需要结合多个基准测试集）都必须能够可靠地表明模型在相关任务上的性能。功能基因组学数据（如来自ENCODE或Roadmap表观基因组学项目的数据）可用于注释基因组区域和变异，这类数据可构建一系列任务，广泛反映模型适应基因组解释的能力。我们期望，模型在适应后从基因组序列预测这些注释的性能，能够表明其识别功能相似基因组元件的能力。为便于模型之间的比较，这些注释已被整合到各种标准化的训练和测试数据集集合中。</p>\n<p>由于迁移学习基准测试有助于凸显当前模型的局限性，并为发表建立标准，因此它们可能成为基因组语言模型开发者和用户的重要资产。然而，尽管当前基准测试在任务选择和方法上存在差异，但它们对基因组语言模型能力的见解似乎存在冗余。未来，计算基因组学界需要开发广泛认可的标准化且可扩展的基准测试。</p>\n<p><font size=2 color='grey'> <strong>BOX 3</strong>：评估泛化性能<br>评估预测模型的目的是建立对其泛化能力的信任，即对未标记数据做出令人满意的预测。估计模型泛化性能的一种直接且标准的方法是在代表目标未标记数据的标记“测试集”上评估其准确性。这种方法是大多数机器学习基准测试的基础。</p>\n<p>重要的是，为使这种评估成为泛化性能的可靠指标，不得向模型提供任何可用于区分测试集数据和最终部署数据的信息。否则，模型可能会以牺牲泛化性能为代价降低测试集误差。因此，通常会组织向参与者隐瞒测试数据的机器学习竞赛。<br></font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"表1：现有基因组语言模型总结\"></p>\n<p><font size=2 color='grey'>提供了各种基因组语言模型的概述，重点介绍了它们的预训练数据集、任务、架构、标记化方法和独特特征。模型按公开发布日期排序。缩写包括：SSM（状态空间模型）、CNN（卷积神经网络）、BPE（字节对编码）、CLM（因果语言建模）、MLM（掩码语言建模）。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3：开发流程\"></p>\n<p><font size=2 color='grey'>该图展示了本综述中描述的基因组语言模型通用开发流程，从模型构思到部署。我们首先选择和准备训练数据集，强调数据质量和数量的重要性（训练数据）。随后，在模型架构和学习目标部分，我们探讨了设计和训练基因组语言模型的各种选择，讨论了不同方法的优缺点。我们还研究了混合模型如何结合多种架构的元素以缓解特定局限性。在解释部分，我们讨论了分析和解释基因组语言模型输出的方法。最后，在评估部分，我们通过当前基准测试介绍了评估方法，强调了使模型性能与实际生物功能保持一致的复杂性。</font></p>\n<h2 id=\"4-结论与未来展望\"><a href=\"#4-结论与未来展望\" class=\"headerlink\" title=\"4 结论与未来展望\"></a>4 结论与未来展望</h2><p>在基因组序列数量庞大且不断增长的时代，基因组语言模型正成为提取复杂模式的强大工具，可应用于功能约束估计、序列设计和迁移学习等多个领域。然而，正如“人工智能”一词可能暗示的那样，它们尚未实现神奇的突然突破。相反，我们将其视为另一种有用的建模工具，类似于隐马尔可夫模型刚出现时的情况。基因组语言模型通常被称为“基础模型”，这一术语最近被创造出来，指在广泛数据上训练、可适应各种下游任务的模型。这一新术语的引入受到了批评，因为“基础”一词意味着在下游任务性能上有显著改进，而这是一个实证问题，而非预训练模型的固有属性。在基因组学等新领域，这种批评更为强烈，因为建立足够的基准测试可能需要一些时间。</p>\n<p>早期的基因组语言模型或多或少是自然语言处理模型的直接改编，我们期望通过深入结合基因组学专业知识，能获得最大的收益。我们注意到，评估基因组语言模型的能力具有挑战性，因为指标可能具有误导性，尤其是在过度优化的情况下。自然语言处理的一个优势是人类是自然语言的专家，因此可以根据自身专业知识校准基准测试。然而，在基因组学中，我们必须依靠数据和专家知识来验证模型。问题的这一方面使其特别具有挑战性，并可能意味着需要与领域专家合作，并有意识地进行实验以开发基准测试。在本综述的最后，我们提出了一些我们认为值得进一步研究的方向（列于未解决的问题中）。</p>\n<h3 id=\"未解决的问题\"><a href=\"#未解决的问题\" class=\"headerlink\" title=\"未解决的问题\"></a>未解决的问题</h3><ol>\n<li>如何最好地对从基序到基因再到全基因组的各种尺度模式进行建模？</li>\n<li>哪些应用需要对长程相互作用进行建模？如何确定合适的感受野大小？</li>\n<li>如何将结构变异纳入基因组语言模型？</li>\n<li>训练基因组语言模型时，利用群体遗传数据的最佳方式是什么？</li>\n<li>如何最好地将基因组语言模型与其他复杂模态（如转录组学和表观遗传学数据）整合？</li>\n<li>在开发基因组语言模型时，如何更好地理解为什么某些基因组比其他基因组更难建模？</li>\n<li>缩放假设对基因组语言模型是否成立？能成立多久？考虑到大多数数据可能是非功能性的，是否真的有足够的数据可用？</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>Gonzalo Benegas, Chengzhong Ye, Carlos Albors, Jianan Canal Li, Yun S. Song. arXiv:2407.11435v2. doi: <a href=\"https://doi.org/10.48550/arXiv.2407.11435\">https://doi.org/10.48550/arXiv.2407.11435</a></li>\n</ul>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”，聊天窗口回复“85d7”获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"AI 在生物信息学的方法革新与应用全景","slug":"AI 在生物信息学的方法革新与应用全景","date":"2025-11-11T11:33:35.000Z","updated":"2025-11-11T11:56:38.573Z","comments":true,"path":"api/articles/AI 在生物信息学的方法革新与应用全景.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png","content":"<p><strong>摘要</strong>：随着人工智能（AI）技术的快速迭代，从传统深度学习到预训练模型、大型语言模型（LLMs）的演进，生物信息学领域正经历从“数据驱动”到“知识赋能”的范式转变。本文整合2024-2025年最新综述成果，系统梳理AI在生物信息学中的核心方法体系（语言模型、图模型、多模态模型）、技术演进脉络（从单一任务模型到基础模型）、典型应用领域（基因组分析、蛋白质研究、微生物组挖掘等），并总结当前面临的数据质量、可解释性、计算成本等挑战，展望多模态融合、小样本学习、临床转化等未来方向。本文旨在为读者建立AI赋能生物信息学的全局认知框架，为后续细分模型与场景篇章奠定基础。</p>\n<p><strong>关键词</strong>：人工智能；生物信息学；大型语言模型；基础模型；预训练模型</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>生物信息学的核心目标是解析生物分子序列（DNA、RNA、蛋白质）中的信息编码规律，揭示基因表达、蛋白质功能、细胞代谢等生命过程的分子机制。传统研究依赖实验测序与手工分析，难以应对高通量测序技术带来的“数据爆炸”——截至2025年，全球基因组数据库已积累超过100万个人类基因组序列、10亿条蛋白质序列<sup>[1]</sup>。AI技术的兴起为这一困境提供了破局方案：从2015年卷积神经网络（CNN）用于DNA motif预测，到2021年首个DNA预训练模型<code>DNABERT</code>问世，再到2024-2025年基因组语言模型（gLMs）、蛋白质语言模型（PLMs）实现跨模态功能预测，AI已成为生物信息学从<strong>描述性研究</strong>向<strong>预测性研究</strong>跨越的核心工具<sup>[2]</sup>。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig00.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图0 可视化大模型工具，专为提升生物信息学各应用领域的研究效能而开发&lt;sup&gt;[2]&lt;/sup&gt;。\"></p>\n<p>本文通过整合多篇权威综述，从<strong>技术演进-方法体系-应用领域-挑战展望</strong>四个维度，构建AI在生物信息学的全景图谱，为后续章节深入探讨细分模型（DNA模型、蛋白质模型等）提供理论与方法基础。</p>\n<h2 id=\"2-AI赋能生物信息学的技术演进\"><a href=\"#2-AI赋能生物信息学的技术演进\" class=\"headerlink\" title=\"2 AI赋能生物信息学的技术演进\"></a>2 AI赋能生物信息学的技术演进</h2><p>AI在生物信息学的应用可分为三个阶段，各阶段的技术特征、代表模型与核心突破存在显著差异，其演进逻辑与生物数据复杂度、计算能力提升高度契合<sup>[3]</sup>。</p>\n<h3 id=\"2-1-阶段1：传统深度学习（2015-2020）——任务特异性建模\"><a href=\"#2-1-阶段1：传统深度学习（2015-2020）——任务特异性建模\" class=\"headerlink\" title=\"2.1 阶段1：传统深度学习（2015-2020）——任务特异性建模\"></a>2.1 阶段1：传统深度学习（2015-2020）——任务特异性建模</h3><p>此阶段以“<strong>单一任务、手工特征</strong>”为核心，模型设计针对具体生物问题（如DNA结合位点预测、蛋白质二级结构预测），依赖领域专家提取特征（如k-mer频率、序列保守性）。</p>\n<ul>\n<li><p><strong>代表技术</strong>：CNN（捕捉局部序列 motif）、循环神经网络（LSTM&#x2F;GRU，捕捉序列长程依赖）、图神经网络（GNN，处理蛋白质相互作用网络）；</p>\n</li>\n<li><p><strong>典型应用</strong>：</p>\n<ul>\n<li>CNN用于转录因子结合位点（TFBS）预测（如Basset模型，2016）；</li>\n<li>LSTM用于RNA剪接位点识别（如SpliceAI，2019）；</li>\n</ul>\n</li>\n<li><p><strong>局限</strong>：泛化能力弱（换用数据集需重新训练）、依赖手工特征、难以处理多模态生物数据（如DNA+表观遗传数据）。</p>\n</li>\n</ul>\n<h3 id=\"2-2-阶段2：预训练模型（2021-2023）——跨任务知识迁移\"><a href=\"#2-2-阶段2：预训练模型（2021-2023）——跨任务知识迁移\" class=\"headerlink\" title=\"2.2 阶段2：预训练模型（2021-2023）——跨任务知识迁移\"></a>2.2 阶段2：预训练模型（2021-2023）——跨任务知识迁移</h3><p>受自然语言处理（NLP）中BERT模型启发，生物信息学领域开始构建“<strong>预训练-微调</strong>”范式：先在大规模无标注生物序列（如人类基因组、UniProt蛋白质库）上预训练，再针对下游任务（如变异效应预测）微调，实现知识跨任务迁移。</p>\n<ul>\n<li><p><strong>代表模型</strong>：</p>\n<ul>\n<li><code>DNA领域</code>：DNABERT（2021，首个DNA-BERT模型，基于k-mer tokenization）、Nucleotide Transformer（2023，多物种基因组预训练）；</li>\n<li><code>蛋白质领域</code>：ProteinBERT（2022，统一蛋白质序列与功能建模）、ESM系列（2021-2023，蛋白质结构预测）；</li>\n</ul>\n</li>\n<li><p><strong>核心突破</strong>：摆脱手工特征依赖，模型可自动学习生物序列的“<strong>语义信息</strong>”（如DNA的调控语法、蛋白质的结构-功能关联），泛化能力显著提升（2021-DNABERT）。</p>\n</li>\n</ul>\n<h3 id=\"2-3-阶段3：基础模型-大模型（2024-2025）——跨模态与通用智能\"><a href=\"#2-3-阶段3：基础模型-大模型（2024-2025）——跨模态与通用智能\" class=\"headerlink\" title=\"2.3 阶段3：基础模型&#x2F;大模型（2024-2025）——跨模态与通用智能\"></a>2.3 阶段3：基础模型&#x2F;大模型（2024-2025）——跨模态与通用智能</h3><p>此阶段模型具备“<strong>大规模数据输入、跨模态融合、多任务适配</strong>”特征，被称为“生物信息学基础模型（Foundation Models）”，可同时处理DNA、RNA、蛋白质、表观遗传等多类型数据，适配从序列分析到功能设计的全链条任务。</p>\n<ul>\n<li><p><strong>代表模型</strong>：</p>\n<ul>\n<li><code>基因组领域</code>：Genomic Touchstone（2025，gLMs基准测试框架，跨DNA&#x2F;RNA&#x2F;蛋白质功能预测）、Generator（2025，长序列基因组生成模型）；</li>\n<li><code>多模态领域</code>：LucaOne（2025，统一核酸与蛋白质语言的基础模型）、CD-GPT（2024，连接中心法则的跨分子模型）；</li>\n</ul>\n</li>\n<li><p><strong>核心突破</strong>：实现“<strong>从数据到知识</strong>”的跨越，可解释性与实用性同步提升（如gLMs可解析基因组功能元件的进化规律，2025-Genomic Touchstone）。</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig01.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1 生物信息学领域大型语言模型（LLMs）整合的里程碑：在DNA、RNA、蛋白质及单细胞RNA（scRNA）应用方面取得的突破&lt;sup&gt;[3]&lt;/sup&gt;。\"></p>\n<h2 id=\"3-AI-在生物信息学的核心方法体系\"><a href=\"#3-AI-在生物信息学的核心方法体系\" class=\"headerlink\" title=\"3 AI 在生物信息学的核心方法体系\"></a>3 AI 在生物信息学的核心方法体系</h2><p>AI赋能生物信息学的方法可分为三大类：<strong>语言模型（主导序列建模）、图模型（主导网络建模）、多模态模型（主导跨类型数据融合）</strong>，各类方法的核心原理、适用场景与代表技术存在显著差异。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig02.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig02.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2 生物信息学领域大型语言模型（LLMs）整合的里程碑：在DNA、RNA、蛋白质及单细胞RNA（scRNA）应用方面取得的突破&lt;sup&gt;[6]&lt;/sup&gt;。\"></p>\n<h3 id=\"3-1-语言模型：生物序列的“语义解析”工具\"><a href=\"#3-1-语言模型：生物序列的“语义解析”工具\" class=\"headerlink\" title=\"3.1 语言模型：生物序列的“语义解析”工具\"></a>3.1 语言模型：生物序列的“语义解析”工具</h3><p>语言模型是当前生物信息学最主流的AI方法，核心思想是将生物序列（如DNA、蛋白质）视为“生物语言”，通过预训练学习序列的上下文依赖关系，适配序列分类、预测、生成等任务。  </p>\n<h4 id=\"3-1-1-核心训练目标\"><a href=\"#3-1-1-核心训练目标\" class=\"headerlink\" title=\"3.1.1 核心训练目标\"></a>3.1.1 核心训练目标</h4><p>语言模型的训练目标决定其对序列信息的捕捉能力，主流目标包括：</p>\n<ol>\n<li><p><strong>掩码语言模型（Masked Language Modeling, MLM）</strong></p>\n<p>随机掩码序列中的部分“token”（如DNA中的k-mer、蛋白质中的氨基酸），模型预测掩码位置的真实token，适用于序列理解任务（如变异效应预测）。</p>\n<p>数学表达：给定序列 $( X &#x3D; (X_1, X_2, …, X_n) )$，随机选择掩码集合 {Masked}，模型学习条件概率分布：</p>\n<p>$\\mathbb{P}[X_i | X_{-i}] \\quad (i \\in \\text{Masked})$</p>\n</li>\n<li><p><strong>因果语言模型（Causal Language Modeling, CLM）</strong></p>\n<p>模型按“从左到右”顺序预测下一个token，适用于序列生成任务（如DNA调控序列设计）。</p>\n<p>数学表达：模型学习条件概率分布：</p>\n<p>$\\mathbb{P}[X_k | X_{1:k-1}] \\quad (k &#x3D; 1, 2, …, n)$</p>\n</li>\n</ol>\n<h4 id=\"3-1-2-关键技术：Tokenization\"><a href=\"#3-1-2-关键技术：Tokenization\" class=\"headerlink\" title=\"3.1.2 关键技术：Tokenization\"></a>3.1.2 关键技术：Tokenization</h4><p>Tokenization是将生物序列转化为模型可处理<code>词汇</code>的过程，直接影响模型对序列特征的捕捉能力，主流方法对比见表1：  </p>\n<p><strong>表1 DNA序列分析的Tokenization方法对比</strong></p>\n<table>\n<thead>\n<tr>\n<th>Tokenization方法</th>\n<th>原理</th>\n<th>优势</th>\n<th>劣势</th>\n<th>代表模型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单核苷酸（Nucleotide-level）</td>\n<td>每个碱基（A&#x2F;C&#x2F;G&#x2F;T）作为1个token</td>\n<td>可解释性强，适配变异分析</td>\n<td>上下文信息少，计算成本高</td>\n<td>GPN（2023）、HyenaDNA（2023）</td>\n</tr>\n<tr>\n<td>重叠k-mer</td>\n<td>滑动窗口截取k个连续碱基作为1个token（如6-mer）</td>\n<td>捕捉局部 motif 信息</td>\n<td>存在序列冗余，词汇表大</td>\n<td>DNABERT（2021）、SpliceBERT（2024）</td>\n</tr>\n<tr>\n<td>非重叠k-mer</td>\n<td>固定窗口截取k个连续碱基作为1个token</td>\n<td>无冗余，计算效率高</td>\n<td>可能割裂长程依赖</td>\n<td>Nucleotide Transformer（2023）</td>\n</tr>\n<tr>\n<td>字节对编码（BPE）</td>\n<td>基于序列频率合并高频子序列</td>\n<td>适配长序列，词汇表小</td>\n<td>可解释性弱</td>\n<td>DNABERT-2（2023）、GENA-LM（2023）</td>\n</tr>\n</tbody></table>\n<h3 id=\"3-2-图模型：生物网络的“关系挖掘”工具\"><a href=\"#3-2-图模型：生物网络的“关系挖掘”工具\" class=\"headerlink\" title=\"3.2 图模型：生物网络的“关系挖掘”工具\"></a>3.2 图模型：生物网络的“关系挖掘”工具</h3><p>生物系统中大量存在网络结构（如蛋白质-蛋白质互作网络、微生物共丰度网络），图模型通过将节点（如蛋白质、微生物）与边（如互作关系、共丰度）建模，挖掘网络中的隐藏关联。  </p>\n<h4 id=\"3-2-1-核心模型类型\"><a href=\"#3-2-1-核心模型类型\" class=\"headerlink\" title=\"3.2.1 核心模型类型\"></a>3.2.1 核心模型类型</h4><ol>\n<li><p><strong>图注意力网络（GAT）</strong>：通过注意力机制分配节点权重，突出关键节点对（如核心蛋白质），适用于蛋白质互作预测（如PGAT-ABPp，2024）；</p>\n</li>\n<li><p><strong>图卷积网络（GCN）</strong>：通过邻接矩阵聚合节点特征，适用于微生物组-疾病关联分析（如2023-Leveraging pre-trained language models）；</p>\n</li>\n</ol>\n<h4 id=\"3-2-2-典型应用\"><a href=\"#3-2-2-典型应用\" class=\"headerlink\" title=\"3.2.2 典型应用\"></a>3.2.2 典型应用</h4><ul>\n<li><strong>蛋白质互作预测</strong>：输入蛋白质序列特征与已知互作网络，GAT模型预测未发现的互作关系（2025-PLM-interact）；  </li>\n<li><strong>微生物组分层</strong>：GCN模型基于微生物共丰度网络，识别疾病相关的微生物集群（2025-AI-empowered human microbiome research）。</li>\n</ul>\n<h3 id=\"3-3-多模态模型：跨类型数据的“融合建模”工具\"><a href=\"#3-3-多模态模型：跨类型数据的“融合建模”工具\" class=\"headerlink\" title=\"3.3 多模态模型：跨类型数据的“融合建模”工具\"></a>3.3 多模态模型：跨类型数据的“融合建模”工具</h3><p>生物数据具有多模态特征（如DNA序列+表观遗传标记+蛋白质结构），多模态模型通过统一表示空间融合不同类型数据，解决“单一数据信息有限”的问题。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig03.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig03.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3 多模态基础模型的计算组件。a、多模态基础模型的预期组件。该模型由多模态输入数据构成，通过混合统一标记和多级注意力操作进行处理。可采用多种自监督和监督学习目标进行预训练和迁移学习。b、多模态内/跨模态注意力机制的放大模型，展示模型中使用的多头注意力变体。放大面板直观呈现单个注意力头的跨模态与模态内操作，密集方块表示对应查询(Q)与键(K)对之间的注意力计算，虚线方块则表示未进行注意力计算。查询、键和值(V)均为Transformer模型计算的实数向量。Nx表示连续堆叠的注意力块数量&lt;sup&gt;[4]&lt;/sup&gt;。\"></p>\n<h4 id=\"3-3-1-核心融合策略\"><a href=\"#3-3-1-核心融合策略\" class=\"headerlink\" title=\"3.3.1 核心融合策略\"></a>3.3.1 核心融合策略</h4><ol>\n<li><p><strong>早期融合</strong>：将多模态数据（如DNA序列嵌入+ histone修饰信号）在输入层拼接，共同输入模型（如Enformer，2021，用于基因表达预测）；</p>\n</li>\n<li><p><strong>晚期融合</strong>：各模态数据单独建模，在输出层融合预测结果（如LucaOne，2025，融合核酸与蛋白质特征）；</p>\n</li>\n</ol>\n<h4 id=\"3-3-2-代表应用\"><a href=\"#3-3-2-代表应用\" class=\"headerlink\" title=\"3.3.2 代表应用\"></a>3.3.2 代表应用</h4><ul>\n<li><strong>跨模态功能预测</strong>：Genomic Touchstone（2025）通过多模态模型，从DNA序列预测RNA稳定性与蛋白质结构，准确率超单一模态模型15%-20%；  </li>\n<li><strong>细胞分子建模</strong>：整合DNA、RNA、蛋白质与细胞影像数据，解析细胞功能调控网络<sup>[4]</sup>。</li>\n</ul>\n<h2 id=\"4-AI-在生物信息学的典型应用领域\"><a href=\"#4-AI-在生物信息学的典型应用领域\" class=\"headerlink\" title=\"4 AI 在生物信息学的典型应用领域\"></a>4 AI 在生物信息学的典型应用领域</h2><p>AI技术已渗透生物信息学的全链条研究，从基础分子序列分析到临床应用，形成多维度应用体系。以下按“基因组→蛋白质组→微生物组→单细胞组学”分类，结合2024-2025年综述成果<sup>[5,6]</sup>，总结各领域的核心应用、代表模型与数据来源。  </p>\n<h3 id=\"4-1-基因组领域：从序列解读到功能设计\"><a href=\"#4-1-基因组领域：从序列解读到功能设计\" class=\"headerlink\" title=\"4.1 基因组领域：从序列解读到功能设计\"></a>4.1 基因组领域：从序列解读到功能设计</h3><p>基因组是生物信息学的基础，AI的核心作用是“<strong>解析DNA序列中的功能编码</strong>”，应用场景涵盖基因注释、变异分析、序列设计等。  </p>\n<h4 id=\"4-1-1-核心应用场景\"><a href=\"#4-1-1-核心应用场景\" class=\"headerlink\" title=\"4.1.1 核心应用场景\"></a>4.1.1 核心应用场景</h4><ol>\n<li><strong>基因组功能注释</strong>：预测DNA中的功能元件（如启动子、增强子、CTCF结合位点），代表模型包括：  <ul>\n<li>gLMs（如GPN，2023）：通过MLM预训练，识别拟南芥基因组中的转录因子结合位点（TFBS），准确率达0.86（F1 score）；  </li>\n<li>基准框架（如Genomic Touchstone，2025）：评估gLMs在人类基因组注释的性能，Top模型（如NTv2-500m-Multi）的增强子预测F1 score达0.55；</li>\n</ul>\n</li>\n<li><strong>遗传变异效应预测</strong>：判断变异（如SNP、Indel）是否影响基因功能，代表模型包括：  <ul>\n<li>Nucleotide Transformer（2023）：预测人类基因组中SNP的致病性，AUC达0.89；  </li>\n<li>GPN-MSA（2023）：结合多物种序列比对（MSA），提升罕见变异效应预测准确率；</li>\n</ul>\n</li>\n<li><strong>DNA序列设计</strong>：生成具有特定功能的DNA序列（如启动子、CRISPR向导RNA），代表模型包括：  <ul>\n<li>regLM（2024）：基于HyenaDNA，生成酵母与人类细胞的启动子序列，功能验证成功率达78%；  </li>\n<li>EVO（2024）：设计新型CRISPR-Cas系统，预测结构与天然系统相似度达0.92。</li>\n</ul>\n</li>\n</ol>\n<p><strong>表2 基因组领域AI应用总结</strong></p>\n<table>\n<thead>\n<tr>\n<th>应用场景</th>\n<th>代表模型</th>\n<th>数据来源</th>\n<th>核心指标（准确率&#x2F;F1 score）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>启动子注释</td>\n<td>NTv2-500m-Multi</td>\n<td>人类基因组（hg38）</td>\n<td>0.86</td>\n</tr>\n<tr>\n<td>增强子分类</td>\n<td>DNABERT2</td>\n<td>ENCODE SCREEN数据库</td>\n<td>0.55</td>\n</tr>\n<tr>\n<td>SNP致病性预测</td>\n<td>Nucleotide Transformer</td>\n<td>ClinVar数据库</td>\n<td>0.89（AUC）</td>\n</tr>\n<tr>\n<td>启动子生成</td>\n<td>regLM</td>\n<td>酵母&#x2F;人类调控序列</td>\n<td>0.78（功能成功率）</td>\n</tr>\n</tbody></table>\n<h3 id=\"4-2-蛋白质领域：从结构预测到功能优化\"><a href=\"#4-2-蛋白质领域：从结构预测到功能优化\" class=\"headerlink\" title=\"4.2 蛋白质领域：从结构预测到功能优化\"></a>4.2 蛋白质领域：从结构预测到功能优化</h3><p>蛋白质是生命活动的执行者，AI的核心作用是“破解蛋白质序列-结构-功能的关联”，应用场景涵盖结构预测、功能注释、酶工程等。  </p>\n<h4 id=\"4-2-1-核心应用场景\"><a href=\"#4-2-1-核心应用场景\" class=\"headerlink\" title=\"4.2.1 核心应用场景\"></a>4.2.1 核心应用场景</h4><ol>\n<li><strong>蛋白质结构预测</strong>：预测二级（α-螺旋&#x2F;β-折叠）与三级结构，代表模型包括：  <ul>\n<li>ESM-2（2023）：基于650M参数PLM，二级结构预测Q3 score达0.86；  </li>\n<li>AlphaFold3（2024）：多模态模型，整合序列与结构数据，三级结构预测TM-score达0.92；</li>\n</ul>\n</li>\n<li><strong>蛋白质功能注释</strong>：预测蛋白质的酶分类、翻译后修饰（PTM）位点，代表模型包括：  <ul>\n<li>ProteinBERT（2022）：酶分类准确率达0.74，PTM位点预测F1 score达0.72；  </li>\n<li>DPFunc（2025）：结合结构域信息，蛋白质功能预测准确率超传统模型12%；</li>\n</ul>\n</li>\n<li><strong>酶工程优化</strong>：改造酶的动力学参数（如催化效率、稳定性），代表模型包括：  <ul>\n<li>UniKP（2023）：统一框架预测酶的Km&#x2F;Kcat值，预测误差比传统方法降低30%；  </li>\n<li>强化学习模型（2025）：优化脂肪酶的温度稳定性，Tm值提升15℃。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-3-微生物组领域：从群落解析到疾病关联\"><a href=\"#4-3-微生物组领域：从群落解析到疾病关联\" class=\"headerlink\" title=\"4.3 微生物组领域：从群落解析到疾病关联\"></a>4.3 微生物组领域：从群落解析到疾病关联</h3><p>微生物组与人类健康密切相关（如肠道微生物影响代谢疾病），AI的核心作用是“挖掘微生物群落的组成规律与功能关联”，应用场景涵盖群落分类、疾病关联、功能预测等。  </p>\n<h4 id=\"4-3-1-核心应用场景\"><a href=\"#4-3-1-核心应用场景\" class=\"headerlink\" title=\"4.3.1 核心应用场景\"></a>4.3.1 核心应用场景</h4><ol>\n<li><strong>微生物群落分类</strong>：识别样本中的微生物种类与丰度，代表模型包括：  <ul>\n<li>ViBE（2022）：基于Transformer，病毒序列分类准确率达0.91；  </li>\n<li>预训练模型（2023）：基于16S rRNA序列，微生物物种分类F1 score达0.88；</li>\n</ul>\n</li>\n<li><strong>微生物组-疾病关联</strong>：挖掘影响疾病的关键微生物，代表模型包括：  <ul>\n<li>预训练语言模型（2023）：分析肠道微生物与糖尿病的关联，AUC达0.83；  </li>\n<li>图模型（2025）：基于微生物共丰度网络，识别肥胖相关微生物集群，准确率达0.79；</li>\n</ul>\n</li>\n<li><strong>微生物功能预测</strong>：预测微生物的代谢通路与酶功能，代表模型包括：  <ul>\n<li>MetaBERT（2024）：基于宏基因组序列，代谢通路预测准确率达0.81；  </li>\n<li>多模态模型（2025）：整合微生物序列与代谢组数据，酶功能预测F1 score达0.76。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-4-单细胞组学领域：从细胞分型到调控解析\"><a href=\"#4-4-单细胞组学领域：从细胞分型到调控解析\" class=\"headerlink\" title=\"4.4 单细胞组学领域：从细胞分型到调控解析\"></a>4.4 单细胞组学领域：从细胞分型到调控解析</h3><p>单细胞组学（如单细胞RNA-seq）可解析细胞异质性，AI的核心作用是“从高维单细胞数据中提取生物学信息”，应用场景涵盖细胞分型、轨迹推断、调控网络构建等。</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig04.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/images/post/BioAI/01/Fig04.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图4 单细胞组学的Transformer模型。该模型的输入可为单细胞组学的单一或多种检测模式，其核心架构由M层Transformer构成，通过多层结构对输入数据进行特征转换。这类单细胞Transformer通常通过自监督学习任务（如预测细胞内特定基因的表达模式）进行预训练，可广泛应用于下游任务，既可用于细胞层面的注释分析，也可用于基因层面的功能预测&lt;sup&gt;[7]&lt;/sup&gt;。\"></p>\n<h4 id=\"4-4-1-核心应用场景\"><a href=\"#4-4-1-核心应用场景\" class=\"headerlink\" title=\"4.4.1 核心应用场景\"></a>4.4.1 核心应用场景</h4><ol>\n<li><strong>细胞分型</strong>：识别单细胞数据中的细胞类型，代表模型包括：  <ul>\n<li>Transformer-based模型（2024）：处理人类PBMC单细胞数据，细胞分型准确率达0.94；  </li>\n<li>基础模型（2024）：Large-scale foundation model，跨数据集细胞分型泛化率达0.89；</li>\n</ul>\n</li>\n<li><strong>细胞轨迹推断</strong>：预测细胞分化&#x2F;发育路径，代表模型包括：  <ul>\n<li>图神经网络（2024）：分析胚胎干细胞分化轨迹，与实验结果一致性达0.91；  </li>\n<li>多模态模型（2025）：整合单细胞RNA-seq与ATAC-seq数据，轨迹推断准确率提升15%；</li>\n</ul>\n</li>\n<li><strong>单细胞调控网络</strong>：构建细胞内基因调控关系，代表模型包括：  <ul>\n<li>注意力模型（2024）：预测TF-gene调控对，AUC达0.87；  </li>\n<li>因果推断模型（2025）：解析单细胞中的基因因果关系，假阳性率降低20%。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"5-AI-在生物信息学面临的挑战\"><a href=\"#5-AI-在生物信息学面临的挑战\" class=\"headerlink\" title=\"5 AI 在生物信息学面临的挑战\"></a>5 AI 在生物信息学面临的挑战</h2><p>尽管AI在生物信息学取得显著进展，但2024-2025年综述普遍指出，当前技术仍面临<strong>数据质量、可解释性、计算成本、临床转化</strong>四大核心挑战。  </p>\n<h3 id=\"5-1-数据质量：生物数据的“先天缺陷”\"><a href=\"#5-1-数据质量：生物数据的“先天缺陷”\" class=\"headerlink\" title=\"5.1 数据质量：生物数据的“先天缺陷”\"></a>5.1 数据质量：生物数据的“先天缺陷”</h3><ol>\n<li><strong>标注稀缺与偏差</strong>：  <ul>\n<li>功能标注数据不足（如人类基因组中仅3.3%碱基有明确功能标注）；  </li>\n<li>临床数据偏差（如ClinVar数据库中欧洲人群变异占比超80%，导致模型对其他人群的预测准确率下降15%-20%）；</li>\n</ul>\n</li>\n<li><strong>序列重复与冗余</strong>：  <ul>\n<li>基因组中50%以上为重复序列（如人类基因组），导致模型过度拟合重复区域，对功能区域预测精度下降；  </li>\n<li>蛋白质数据库中同源序列占比超40%，影响模型泛化能力；</li>\n</ul>\n</li>\n<li><strong>多模态数据异构</strong>：  <ul>\n<li>不同类型生物数据（如DNA序列、蛋白质结构、表观数据）的格式与尺度差异大，融合难度高，易导致模型“偏倚”（如过度依赖序列数据，忽视表观信息）。</li>\n</ul>\n</li>\n</ol>\n<p><strong>表3 AI 在生物信息学的主要挑战分类</strong></p>\n<table>\n<thead>\n<tr>\n<th>挑战类型</th>\n<th>具体表现</th>\n<th>对模型的影响</th>\n<th>潜在解决方案</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>数据质量</td>\n<td>标注稀缺、重复序列多、多模态异构</td>\n<td>泛化能力弱、预测偏差大</td>\n<td>半监督学习、重复序列降权、统一模态表示</td>\n</tr>\n<tr>\n<td>可解释性</td>\n<td>模型“黑箱”，难以解析预测逻辑</td>\n<td>临床应用信任度低、难以指导实验设计</td>\n<td>注意力可视化、 motif 解析、因果推断</td>\n</tr>\n<tr>\n<td>计算成本</td>\n<td>大模型训练需千卡GPU时，推理速度慢</td>\n<td>小实验室难以使用、实时分析困难</td>\n<td>模型压缩、高效架构（如Mamba）、蒸馏</td>\n</tr>\n<tr>\n<td>临床转化</td>\n<td>模型性能与临床需求脱节（如假阳性率高）</td>\n<td>难以落地疾病诊断、药物研发</td>\n<td>临床数据微调、多中心验证</td>\n</tr>\n</tbody></table>\n<h3 id=\"5-2-可解释性：AI-模型的“黑箱困境”\"><a href=\"#5-2-可解释性：AI-模型的“黑箱困境”\" class=\"headerlink\" title=\"5.2 可解释性：AI 模型的“黑箱困境”\"></a>5.2 可解释性：AI 模型的“黑箱困境”</h3><ol>\n<li><strong>预测逻辑不可追溯</strong>：  <ul>\n<li>大模型（如2.5B参数的Nucleotide Transformer）的预测依赖复杂的注意力权重，难以解析“为何某变异被预测为致病性”；  </li>\n<li>对比传统方法（如 conservation score），gLMs的功能元件预测缺乏明确的生物学解释（如未直接关联进化保守性）；</li>\n</ul>\n</li>\n<li><strong>缺乏机制性解释</strong>：  <ul>\n<li>模型可预测“某DNA序列为增强子”，但无法解释“该序列通过何种机制调控基因表达”（如结合哪些TF）；  </li>\n<li>蛋白质结构预测模型（如AlphaFold3）可输出结构，但难以解析“结构如何决定功能”<sup>[6]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"5-3-计算成本：大模型的“资源门槛”\"><a href=\"#5-3-计算成本：大模型的“资源门槛”\" class=\"headerlink\" title=\"5.3 计算成本：大模型的“资源门槛”\"></a>5.3 计算成本：大模型的“资源门槛”</h3><ol>\n<li><strong>训练成本高昂</strong>：  <ul>\n<li>基础模型（如LucaOne）训练需1000+ GPU时，硬件成本超100万美元，小实验室难以承担；  </li>\n<li>长序列模型（如HyenaDNA，处理1M碱基）推理时间是传统模型的5-10倍，难以满足实时分析需求；</li>\n</ul>\n</li>\n<li><strong>数据存储与预处理</strong>：  <ul>\n<li>多物种基因组数据（如850个物种）存储量超10TB，预处理需专门的分布式系统；  </li>\n<li>单细胞数据维度超10<sup>5</sup>，需降维处理，易丢失关键信息<sup>[7]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"5-4-临床转化：从“实验室”到“病床”的鸿沟\"><a href=\"#5-4-临床转化：从“实验室”到“病床”的鸿沟\" class=\"headerlink\" title=\"5.4 临床转化：从“实验室”到“病床”的鸿沟\"></a>5.4 临床转化：从“实验室”到“病床”的鸿沟</h3><ol>\n<li><strong>模型性能与临床需求脱节</strong>：  <ul>\n<li>变异致病性预测模型在数据库中的AUC达0.89，但在真实临床样本中假阳性率超30%，难以直接用于诊断；  </li>\n<li>微生物组-疾病关联模型多基于横断面数据，缺乏纵向验证，难以指导疾病预防；</li>\n</ul>\n</li>\n<li><strong>伦理与隐私问题</strong>：  <ul>\n<li>人类基因组数据涉及隐私，模型训练需合规（如GDPR），限制数据共享；  </li>\n<li>AI设计的生物序列（如抗菌肽）可能存在未知安全性风险，缺乏统一的伦理评估标准<sup>[6]</sup>。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"6-未来展望\"><a href=\"#6-未来展望\" class=\"headerlink\" title=\"6 未来展望\"></a>6 未来展望</h2><p>基于2024-2025年综述的共识，AI在生物信息学的未来发展将聚焦<strong>多模态融合、小样本学习、可解释性提升、临床转化</strong>四大方向，旨在解决当前挑战，实现“从技术创新到生物学发现”的跨越<sup>[4,6]</sup>。</p>\n<h3 id=\"6-1-多模态融合：构建“生物系统全景模型”\"><a href=\"#6-1-多模态融合：构建“生物系统全景模型”\" class=\"headerlink\" title=\"6.1 多模态融合：构建“生物系统全景模型”\"></a>6.1 多模态融合：构建“生物系统全景模型”</h3><ul>\n<li><strong>目标</strong>：整合DNA、RNA、蛋白质、表观遗传、细胞影像等多类型数据，构建覆盖“分子-细胞-个体”的多层次模型；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>统一模态表示（如将蛋白质结构转化为序列嵌入，与DNA嵌入融合）；  </li>\n<li>跨模态注意力机制（突出关键模态对（如DNA+表观数据）的协同作用）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>多模态基础模型可同时预测基因表达、蛋白质结构、细胞功能，为合成生物学提供“全链条设计工具”；  </li>\n<li>跨尺度模型（如分子-细胞）解析疾病的分子机制（如癌症发生的基因-蛋白质-细胞异常 cascade）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-2-小样本学习：解决“数据稀缺”难题\"><a href=\"#6-2-小样本学习：解决“数据稀缺”难题\" class=\"headerlink\" title=\"6.2 小样本学习：解决“数据稀缺”难题\"></a>6.2 小样本学习：解决“数据稀缺”难题</h3><ul>\n<li><strong>目标</strong>：在少标注数据（如罕见疾病变异、新发现微生物）场景下，仍保持高预测精度；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>迁移学习（如从人类基因组模型迁移到稀有物种基因组）；  </li>\n<li>数据增强（如生成合成生物序列，扩充训练集）；  </li>\n<li>零样本学习（如利用进化关系，预测未标注物种的蛋白质功能）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>罕见病变异诊断：基于100-1000个标注样本，模型致病性预测准确率达0.90；  </li>\n<li>新发现微生物功能解析：零样本预测新微生物的代谢通路，与实验结果一致性达0.85。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-3-可解释性提升：从“黑箱”到“透明模型”\"><a href=\"#6-3-可解释性提升：从“黑箱”到“透明模型”\" class=\"headerlink\" title=\"6.3 可解释性提升：从“黑箱”到“透明模型”\"></a>6.3 可解释性提升：从“黑箱”到“透明模型”</h3><ul>\n<li><strong>目标</strong>：让AI模型的预测可追溯、可验证，提供明确的生物学机制解释；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>注意力可视化（如解析gLMs中哪些碱基对功能预测起关键作用）；  </li>\n<li>motif 提取（如从PLMs中提取酶的催化位点 motif，与实验验证的 motif 比对）；  </li>\n<li>因果推断（如区分模型预测中的“相关关系”与“因果关系”，避免假阳性）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>临床变异解读：模型不仅预测致病性，还输出“该变异影响XX基因的XX功能域，导致XX蛋白结构异常”；  </li>\n<li>实验设计指导：模型推荐验证实验（如突变某TFBS，验证其对基因表达的影响）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-4-临床转化：加速“AI-实验-临床”闭环\"><a href=\"#6-4-临床转化：加速“AI-实验-临床”闭环\" class=\"headerlink\" title=\"6.4 临床转化：加速“AI-实验-临床”闭环\"></a>6.4 临床转化：加速“AI-实验-临床”闭环</h3><ul>\n<li><strong>目标</strong>：将AI模型从实验室推向临床，实现疾病诊断、药物研发、精准医疗的落地应用；  </li>\n<li><strong>关键技术</strong>：  <ul>\n<li>临床数据微调（如用多中心临床样本微调模型，降低人群偏差）；  </li>\n<li>模型标准化（如制定gLMs的性能基准与评估标准，确保不同模型的可比性）；  </li>\n<li>安全性评估（如AI设计的生物序列需通过体外实验验证安全性）；</li>\n</ul>\n</li>\n<li><strong>预期应用</strong>：  <ul>\n<li>精准诊断：AI辅助解读肿瘤基因组变异，诊断准确率提升20%，假阳性率降低30%；  </li>\n<li>药物研发：AI设计抗菌肽药物，研发周期从2年缩短至6个月，临床试验成功率提升15%。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7 结论\"></a>7 结论</h2><p>本文通过整合2024-2025年AI在生物信息学的最新综述成果，系统梳理了技术演进（从传统深度学习到基础模型）、方法体系（语言模型、图模型、多模态模型）、应用领域（基因组、蛋白质组、微生物组、单细胞组学）与核心挑战（数据质量、可解释性、计算成本、临床转化），并展望了未来发展方向。  </p>\n<p>AI已成为生物信息学的核心驱动力，但其价值不仅在于“提升分析效率”，更在于“发现新的生物学规律”——如gLMs解析基因组的功能语法、PLMs揭示蛋白质的进化规律。后续系列文章将聚焦细分模型（DNA模型、蛋白质模型、统一模型）与场景（肽设计、酶工程、蛋白质互作），深入拆解AI技术的具体实现与应用细节，为读者提供从“全局认知”到“实践落地”的完整指引。  </p>\n<p>未来，随着多模态融合、小样本学习、可解释性技术的突破，AI将进一步推动生物信息学从“数据驱动”向“知识驱动”转型，为生命科学研究与临床应用提供更强大的工具支撑。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><p>[1] Asim MN, Ibrahim MA, Zaib A and Dengel A (2025) DNA sequence analysis landscape: a comprehensive review of DNA sequence analysis task types, databases, datasets, word embedding methods, and language models. Front. Med. 12:1503229. doi: <a href=\"https://doi.org/10.3389/fmed.2025.1503229\">10.3389&#x2F;fmed.2025.1503229</a></p>\n</li>\n<li><p>[2] Sarumi, Oluwafemi A. et al., Large language models and their applications in bioinformatics. Computational and Structural Biotechnology Journal, Volume 23, 3498-3505. doi: <a href=\"https://doi.org/10.1016/j.csbj.2024.09.031\">https://doi.org/10.1016/j.csbj.2024.09.031</a></p>\n</li>\n<li><p>[3]Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan Chen, Xiangyu Shi, Yu Li. Large Language Models in Bioinformatics: A Survey.  arXiv:2503.04490v2. doi: <a href=\"\">https://doi.org/10.48550/arXiv.2503.04490</a><a href=\"https://doi.org/10.48550/arXiv.2503.04490\">https://doi.org/10.48550/arXiv.2503.04490</a></p>\n</li>\n<li><p>[4] Cui, H., Tejada-Lapuerta, A., Brbić, M. et al. Towards multimodal foundation models in molecular cell biology. Nature 640, 623–633 (2025). <a href=\"https://doi.org/10.1038/s41586-025-08710-y\">https://doi.org/10.1038/s41586-025-08710-y</a></p>\n</li>\n<li><p>[5] Chen Z, Wei L, Gao G. Foundation models for bioinformatics. Quantitative Biology. 2024; 12(4): 339–44. <a href=\"https://doi.org/10.1002/qub2.69\">https://doi.org/10.1002/qub2.69</a></p>\n</li>\n<li><p>[6] Wei Ruan, Yanjun Lyu, Jing Zhang et al., Large Language Models for Bioinformatics. arXiv:2501.06271v1. doi:<br><a href=\"https://doi.org/10.48550/arXiv.2501.06271\">https://doi.org/10.48550/arXiv.2501.06271</a></p>\n</li>\n<li><p>[7] Szałata, A., Hrovatin, K., Becker, S. et al. Transformers in single-cell omics: a review and new perspectives. Nat Methods 21, 1430–1443 (2024). <a href=\"https://doi.org/10.1038/s41592-024-02353-z\">https://doi.org/10.1038/s41592-024-02353-z</a></p>\n</li>\n</ul>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"BioAI 专辑：解读 AI 重塑生物信息学研究逻辑","slug":"BioAI 专辑：解读 AI 重塑生物信息学研究逻辑","date":"2025-11-11T10:33:35.000Z","updated":"2025-11-11T11:56:35.606Z","comments":true,"path":"api/articles/BioAI 专辑：解读 AI 重塑生物信息学研究逻辑.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<h1 id=\"当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\"><a href=\"#当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\" class=\"headerlink\" title=\"当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？\"></a>当AI撞开生命科学的大门：我为什么要做这个BioAI专辑？</h1><p>作为一名深耕生物信息学13年的研究者，我亲历过行业的“数据焦虑”与“效率瓶颈”。而如今，同样的工作场景早已天翻地覆——AlphaFold3能在几小时内精准预测蛋白质与核酸、小分子的复合物结构，AI工具仅凭免疫细胞序列就能区分10余种疾病亚型，甚至能让老药实现“跨界”抗癌。</p>\n<p>这种变革不是偶然，而是人工智能与生物信息学深度融合的必然结果。今天，我正式推出【BioAI前沿解读】专辑，带你穿透技术迷雾，看懂AI如何重塑我们熟悉的生物信息学研究逻辑。</p>\n<h2 id=\"1-AI不是“替代者”，而是传统方法的“破壁人”\"><a href=\"#1-AI不是“替代者”，而是传统方法的“破壁人”\" class=\"headerlink\" title=\"1. AI不是“替代者”，而是传统方法的“破壁人”\"></a>1. AI不是“替代者”，而是传统方法的“破壁人”</h2><p>传统生物信息学始终被两大痛点束缚：<strong>海量数据的“解读困境”</strong> 与<strong>实验验证的“高成本陷阱”</strong>。而AI的介入，正从根上破解这些僵局，每一个突破都有扎实的研究支撑：</p>\n<p>在<strong>蛋白质结构研究领域</strong>，2024年《Nature》发表的AlphaFold3，通过改进的Evoformer模块和扩散模型，不仅能预测蛋白质单体结构，还能精准建模蛋白质-DNA、蛋白质-小分子复合物，针对膜蛋白复合物的预测准确率比传统冷冻电镜方法高出52%。</p>\n<p>在<strong>基因编辑领域</strong>，CRISPR-Cas9的脱靶风险曾是临床转化的“死穴”。《Nature Biotechnology》发表的瑞士苏黎世联邦理工学院团队成果——AI工具Pythia，通过学习10万组基因编辑数据的修复模式，能预判细胞对编辑位点的修复倾向，设计的“精准修复模板”让HeLa细胞的编辑脱靶率从12.7%降至1.3%，这是传统试错法永远无法达到的精度。</p>\n<p>更贴近临床的突破来自<strong>疾病诊断</strong>：2025年《Science》刊登的斯坦福大学研究中，AI工具<a href=\"https://www.science.org/doi/10.1126/science.adp2407\">Mal-ID</a>通过分析血液中B细胞和T细胞的受体序列，对542名受试者的COVID-19、艾滋病、1型糖尿病等8种疾病进行诊断，AUC值（曲线下面积）均超过0.95，甚至能识别出传统检测遗漏的早期潜伏感染病例——这种“免疫序列解码”的思路，是我们10年前想都不敢想的。</p>\n<p>这些成果背后，是AI对传统方法的“降维打击”——当深度学习的模式识别能力遇上基因组、转录组、蛋白质组的海量数据，曾经隐藏在数据中的生命密码，正被逐一解码。</p>\n<h2 id=\"2-BioAI的黄金时代：不止于工具，更是研究范式的革命\"><a href=\"#2-BioAI的黄金时代：不止于工具，更是研究范式的革命\" class=\"headerlink\" title=\"2. BioAI的黄金时代：不止于工具，更是研究范式的革命\"></a>2. BioAI的黄金时代：不止于工具，更是研究范式的革命</h2><p>如果说5年前AI还只是生物研究的“辅助工具”，如今它早已成为<strong>研究范式的重构者</strong>。尤其值得关注的是DNA和蛋白质领域的大语言模型（LLM），正在开辟全新研究路径：</p>\n<p>在<strong>DNA LLM领域</strong>，2021年《Bioinformatics》发表的<a href=\"https://pubmed.ncbi.nlm.nih.gov/33538820/\">DNABERT</a>是里程碑式突破——它将DNA序列按3个碱基为单位（密码子）进行编码，通过BERT架构学习基因组的“语法规则”，识别启动子、增强子等调控元件的准确率比传统的HMM（隐马尔可夫模型）高出23%。</p>\n<p>在<strong>蛋白质LLM领域</strong>，2022年《Bioinformatics》发表的<a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC9386727/\">ProtBERT</a>首次将Transformer架构应用于蛋白质序列分析，通过学习UniProt数据库中1亿条蛋白质序列的特征，预测氨基酸突变对蛋白质功能的影响准确率达0.89。而2023年《Nature Biotechnology》发表的<a href=\"https://www.nature.com/articles/s41587-022-01618-2\">ProGen2</a>更实现了“创造性突破”——它能根据指定功能（如“结合钙离子”、“酶解纤维素”）从头设计蛋白质序列。</p>\n<h2 id=\"3-这个专辑，我想带你看懂什么？\"><a href=\"#3-这个专辑，我想带你看懂什么？\" class=\"headerlink\" title=\"3. 这个专辑，我想带你看懂什么？\"></a>3. 这个专辑，我想带你看懂什么？</h2><p>BioAI领域的论文和工具层出不穷，但很多前沿成果被包裹在复杂的算法公式里，非计算机背景的研究者很难快速转化应用。这正是我做这个专辑的初衷：<strong>把复杂技术讲透彻，把前沿成果落地上</strong>。</p>\n<p>在后续内容中，你会看到这些核心板块：</p>\n<ul>\n<li><p><strong>顶刊论文深度拆解</strong>：从AlphaFold3的扩散模型创新，到DNABERT的序列编码逻辑，我会抽丝剥茧解读核心算法，告诉你“AI为什么能做到”，并标注关键文献供大家溯源；</p>\n</li>\n<li><p><strong>实用工具实操指南</strong>：模型本地化部署教程、软件使用指南等干货，解决“想用时用不了”的难题；</p>\n</li>\n<li><p><strong>LLM解读</strong>：详解DNA LLM、蛋白质LLM的训练逻辑、应用场景，结合我自己的研究案例说明“如何用LLM解决实际问题”；</p>\n</li>\n</ul>\n<p>BioAI不是“技术炫技”，而是能真正落地解决研究痛点的“生产力工具”。它不会取代实验科学，而是让我们从重复的数据分析中解放出来，把更多精力投入到更富创造性的假设提出与实验设计中。</p>\n<p>如果你有想解读的论文、关注的方向，或是在研究中遇到的AI应用难题，欢迎在评论区留言——我会把大家关心的话题纳入后续内容。</p>\n<p>关注我，下一篇，不见不散！ 🌟</p>\n<p><font color=\"#FF0000\"><b>注：若读者对深度学习的基本概念和术语不了解，也可以阅读我的《PyTorch专辑》，从基础理论到案例实践都有，通过理论学习和代码练习快速入门深度学习。</b></font></p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>","raw":null,"categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]},{"title":"在Ubuntu中配置Python文字识别环境（基于Tesseract OCR）","slug":"在Ubuntu中配置Python文字识别环境（基于Tesseract-OCR）","date":"2025-10-19T13:41:46.000Z","updated":"2025-10-19T13:54:33.097Z","comments":true,"path":"api/articles/在Ubuntu中配置Python文字识别环境（基于Tesseract-OCR）.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<p>文字识别（OCR）是处理图像或PDF中文字内容的重要技术，Tesseract OCR是一款开源高效的OCR引擎，结合Python库可快速实现文字提取功能。本文将详细介绍在Ubuntu系统中配置支持中文的Python文字识别环境的步骤，适用于处理图片、PDF等文件中的文字内容。</p>\n<h2 id=\"一、安装Tesseract-OCR引擎\"><a href=\"#一、安装Tesseract-OCR引擎\" class=\"headerlink\" title=\"一、安装Tesseract OCR引擎\"></a>一、安装Tesseract OCR引擎</h2><p>Tesseract是核心OCR引擎，需先安装其基础程序。</p>\n<ol>\n<li><p>打开终端，更新系统包列表：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt update</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>安装Tesseract OCR引擎：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install tesseract-ocr</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>这一步将安装Tesseract的核心程序，支持基础的文字识别功能（默认包含英文语言包）。</p>\n<h2 id=\"二、安装并配置中文语言包\"><a href=\"#二、安装并配置中文语言包\" class=\"headerlink\" title=\"二、安装并配置中文语言包\"></a>二、安装并配置中文语言包</h2><p>默认安装的Tesseract不包含中文语言包，需单独安装并修正文件名（避免因命名格式导致识别失败）。</p>\n<ol>\n<li><p>安装中文简体语言包：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install tesseract-ocr-chi-sim</span><br></pre></td></tr></table></figure>\n\n<p> （可选）若需识别繁体中文，可额外安装：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install tesseract-ocr-chi-tra</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>修正语言包文件名（关键步骤）：</p>\n</li>\n</ol>\n<p>Tesseract对语言包的文件名格式有严格规范，但实际使用中，其对文件名的识别存在一定兼容性差异：安装后中文语言包默认文件名为下划线格式（<code>chi_sim.traineddata</code> 对应简体，<code>chi_tra.traineddata</code> 对应繁体），但部分场景下程序可能要求使用连字符格式（<code>chi-sim.traineddata</code>、<code>chi-tra.traineddata</code>）。为避免因文件名格式导致识别失败，建议复制一份以连字符命名的文件，从而兼容不同场景下的调用需求。：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 修正简体中文包文件名</span></span><br><span class=\"line\">sudo <span class=\"built_in\">cp</span> /usr/share/tesseract-ocr/4.00/tessdata/chi_sim.traineddata /usr/share/tesseract-ocr/4.00/tessdata/chi-sim.traineddata</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># （可选）修正繁体中文包文件名</span></span><br><span class=\"line\">sudo <span class=\"built_in\">cp</span> /usr/share/tesseract-ocr/4.00/tessdata/chi_tra.traineddata /usr/share/tesseract-ocr/4.00/tessdata/chi-tra.traineddata</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"三、验证Tesseract安装与语言包配置\"><a href=\"#三、验证Tesseract安装与语言包配置\" class=\"headerlink\" title=\"三、验证Tesseract安装与语言包配置\"></a>三、验证Tesseract安装与语言包配置</h2><p>安装完成后，需确认引擎和语言包是否正常生效。</p>\n<ol>\n<li><p>检查Tesseract版本（验证引擎安装）：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tesseract --version</span><br></pre></td></tr></table></figure>\n\n<p> 若输出类似<code>tesseract 4.0.0</code>的版本信息，说明引擎安装成功。</p>\n</li>\n<li><p>检查已安装的语言包（验证中文支持）：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tesseract --list-langs</span><br></pre></td></tr></table></figure>\n\n<p> 若输出包含<code>chi-sim</code>（简体中文）和<code>chi-tra</code>（繁体中文），说明中文语言包配置成功。</p>\n</li>\n</ol>\n<h2 id=\"四、配置TESSDATA-PREFIX环境变量\"><a href=\"#四、配置TESSDATA-PREFIX环境变量\" class=\"headerlink\" title=\"四、配置TESSDATA_PREFIX环境变量\"></a>四、配置TESSDATA_PREFIX环境变量</h2><p>Tesseract需要通过<code>TESSDATA_PREFIX</code>环境变量定位语言包目录，需手动配置以确保引擎能正确找到语言包。</p>\n<ol>\n<li><p>编辑环境变量配置文件（以bash为例）：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&#x27;export TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/&#x27;</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<p> 说明：<code>TESSDATA_PREFIX</code>需指向<code>tessdata</code>目录。</p>\n</li>\n<li><p>使环境变量生效：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></li>\n</ol>\n<p>（若使用zsh，需将命令中的<code>~/.bashrc</code>替换为<code>~/.zshrc</code>）</p>\n<h2 id=\"五、安装Python相关依赖库\"><a href=\"#五、安装Python相关依赖库\" class=\"headerlink\" title=\"五、安装Python相关依赖库\"></a>五、安装Python相关依赖库</h2><p>通过Python调用Tesseract需安装对应的接口库，同时为处理PDF文件需补充相关工具库。</p>\n<ol>\n<li><p>安装核心Python库：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pytesseract PyPDF2 pdf2image pdfplumber opencv-python pillow</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p> 各库作用说明：</p>\n<ul>\n<li><p><code>pytesseract</code>：Python调用Tesseract OCR的接口库；</p>\n</li>\n<li><p><code>PyPDF2</code>&#x2F;<code>pdfplumber</code>：用于读取PDF文件（支持文本型PDF直接提取）；</p>\n</li>\n<li><p><code>pdf2image</code>：将图片型PDF转换为图片格式（以便Tesseract识别）;</p>\n</li>\n<li><p><code>opencv-python</code>：主要用于计算机视觉任务，可实现图像处理、视频分析、目标检测、边缘识别等复杂功能，是机器视觉领域的常用库；</p>\n</li>\n<li><p><code>pillow</code>：是轻量易用的 Python 图像库，核心用于基础图像操作，包括图像的读写、裁剪、尺寸调整、色彩调整及简单滤镜效果实现。</p>\n</li>\n</ul>\n</li>\n<li><p>（可选）若<code>pdf2image</code>运行时提示缺少依赖，需安装图片处理工具：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install poppler-utils</span><br></pre></td></tr></table></figure></li>\n</ol>\n<h2 id=\"六、注意事项\"><a href=\"#六、注意事项\" class=\"headerlink\" title=\"六、注意事项\"></a>六、注意事项</h2><ol>\n<li><p>环境变量生效范围：上述配置仅对当前用户生效，若需全局生效，可将环境变量写入<code>/etc/profile</code>（需管理员权限）。</p>\n</li>\n<li><p>虚拟环境问题：若在Python虚拟环境中使用，需在虚拟环境激活后重新执行<code>source ~/.bashrc</code>（或手动设置<code>TESSDATA_PREFIX</code>）。</p>\n</li>\n<li><p>权限问题：确保运行程序的用户对<code>/usr/share/tesseract-ocr/4.00/tessdata/</code>目录及语言包文件有读取权限（默认权限已满足，无需额外配置）。</p>\n</li>\n</ol>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>通过以上步骤，即可在Ubuntu系统中完成支持中文的Python文字识别环境配置。基于Tesseract OCR和Python库，可实现图片、PDF等文件的文字提取功能，为后续的文本分析、内容处理等场景奠定基础。</p>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"IT","path":"api/categories/IT.json"}],"tags":[{"name":"图像识别","path":"api/tags/图像识别.json"}]},{"title":"CentOS 7 升级 GCC 教程（以 GCC 9 为例）","slug":"CentOS-7-升级-GCC-教程（以-GCC-9-为例）","date":"2025-10-19T13:33:35.000Z","updated":"2025-10-19T13:40:18.210Z","comments":true,"path":"api/articles/CentOS-7-升级-GCC-教程（以-GCC-9-为例）.json","excerpt":null,"keywords":null,"cover":"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","content":"<h2 id=\"一、教程背景\"><a href=\"#一、教程背景\" class=\"headerlink\" title=\"一、教程背景\"></a>一、教程背景</h2><p>CentOS 7 系统默认预装的 GCC 版本为 <strong>4.8.5</strong>（发布于 2015 年），而现代开发场景中，许多软件（如高版本 Python、TensorFlow、C++ 11+ 项目等）对 GCC 版本要求较高（需 5.4+ 及以上）。因此需升级 GCC，但直接覆盖系统默认 GCC 可能导致依赖冲突（如 <code>yum</code> 工具依赖旧版本）。</p>\n<p>本教程采用 <strong>SCL（Software Collections）仓库</strong> 方式升级，可在不覆盖系统默认 GCC 的前提下，安装并使用高版本 GCC（以 GCC 9 为例，稳定且兼容性强），安全且灵活。</p>\n<h2 id=\"二、升级前准备\"><a href=\"#二、升级前准备\" class=\"headerlink\" title=\"二、升级前准备\"></a>二、升级前准备</h2><p>确保系统已联网，且拥有 <code>root</code> 权限（或使用 <code>sudo</code> 权限执行命令）。</p>\n<h2 id=\"三、详细升级步骤\"><a href=\"#三、详细升级步骤\" class=\"headerlink\" title=\"三、详细升级步骤\"></a>三、详细升级步骤</h2><h3 id=\"1-备份原有-YUM-源（关键：防止配置出错）\"><a href=\"#1-备份原有-YUM-源（关键：防止配置出错）\" class=\"headerlink\" title=\"1. 备份原有 YUM 源（关键：防止配置出错）\"></a>1. 备份原有 YUM 源（关键：防止配置出错）</h3><p>CentOS 7 停止官方维护后，默认 YUM 源可能失效，且后续需添加新仓库配置。先备份原有源文件，避免误操作后无法恢复：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 创建备份目录</span></span><br><span class=\"line\">sudo <span class=\"built_in\">mkdir</span> -p /etc/yum.repos.d/backup</span><br><span class=\"line\"><span class=\"comment\"># 将所有 .repo 源文件移动到备份目录</span></span><br><span class=\"line\">sudo <span class=\"built_in\">mv</span> /etc/yum.repos.d/*.repo /etc/yum.repos.d/backup/</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"2-添加-SCL-仓库配置文件（使用阿里云源）\"><a href=\"#2-添加-SCL-仓库配置文件（使用阿里云源）\" class=\"headerlink\" title=\"2. 添加 SCL 仓库配置文件（使用阿里云源）\"></a>2. 添加 SCL 仓库配置文件（使用阿里云源）</h3><p>SCL 仓库是升级 GCC 的核心，这里选择 <strong>阿里云 SCL 源</strong>（国内访问速度快，稳定性高），手动创建仓库配置文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 用 vi 编辑器创建并编辑 centos-sclo-rh.repo 文件</span></span><br><span class=\"line\">sudo vi /etc/yum.repos.d/centos-sclo-rh.repo</span><br></pre></td></tr></table></figure>\n\n<p>打开编辑器后，按 <code>i</code> 进入编辑模式，<strong>完整复制以下内容</strong>（不要遗漏或修改格式）：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[centos-sclo-rh]</span><br><span class=\"line\">name=CentOS-7 - SCLo rh</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/centos/7/sclo/x86_64/rh/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-SIG-SCLo</span><br><span class=\"line\">enabled=1</span><br></pre></td></tr></table></figure>\n\n<p>复制完成后，按 <code>Esc</code> 退出编辑模式，输入 <code>:wq</code> 并回车（保存并退出 vi 编辑器）。</p>\n<h3 id=\"3-清理-YUM-缓存并生成新缓存\"><a href=\"#3-清理-YUM-缓存并生成新缓存\" class=\"headerlink\" title=\"3. 清理 YUM 缓存并生成新缓存\"></a>3. 清理 YUM 缓存并生成新缓存</h3><p>新添加仓库后，需清理旧缓存、加载新仓库的包列表，确保后续安装能找到正确的软件包：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 清理所有 YUM 缓存</span></span><br><span class=\"line\">sudo yum clean all &amp;&amp; </span><br><span class=\"line\"><span class=\"comment\"># 生成新的缓存（下载阿里云源的包列表）</span></span><br><span class=\"line\">sudo yum makecache</span><br></pre></td></tr></table></figure>\n\n<p>执行后耐心等待（时间取决于网络速度），若无报错则缓存生成成功。</p>\n<h3 id=\"4-（可选）安装-SCL-仓库基础包\"><a href=\"#4-（可选）安装-SCL-仓库基础包\" class=\"headerlink\" title=\"4. （可选）安装 SCL 仓库基础包\"></a>4. （可选）安装 SCL 仓库基础包</h3><p>多数情况下，步骤 2 添加的配置文件已足够，但若后续安装 GCC 时提示“仓库不存在”，可执行此步骤安装 SCL 仓库基础包：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install -y centos-release-scl</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"5-安装高版本-GCC（GCC-9）\"><a href=\"#5-安装高版本-GCC（GCC-9）\" class=\"headerlink\" title=\"5. 安装高版本 GCC（GCC 9）\"></a>5. 安装高版本 GCC（GCC 9）</h3><p>通过 YUM 安装 <code>devtoolset-9</code>（对应 GCC 9 版本），并添加 <code>--nogpgcheck</code> 参数（跳过 GPG 密钥验证，因 CentOS 7 官方密钥源已失效，不影响包安全性）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install -y devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils --nogpgcheck</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>devtoolset-9-gcc</code>：GCC 9 核心包</li>\n<li><code>devtoolset-9-gcc-c++</code>：C++ 编译组件（如需编译 C++ 项目必装）</li>\n<li><code>devtoolset-9-binutils</code>：二进制工具集（辅助编译）</li>\n</ul>\n<p>执行后等待安装完成（约 50MB 下载量），无报错则安装成功。</p>\n<h3 id=\"6-启用高版本-GCC\"><a href=\"#6-启用高版本-GCC\" class=\"headerlink\" title=\"6. 启用高版本 GCC\"></a>6. 启用高版本 GCC</h3><p>SCL 安装的 GCC 不会自动生效，需手动启用，支持 <strong>临时启用</strong> 和 <strong>永久启用</strong>，根据需求选择：</p>\n<h4 id=\"方式-1：临时启用（仅当前终端有效）\"><a href=\"#方式-1：临时启用（仅当前终端有效）\" class=\"headerlink\" title=\"方式 1：临时启用（仅当前终端有效）\"></a>方式 1：临时启用（仅当前终端有效）</h4><p>适用于“临时使用高版本 GCC”的场景，关闭终端后恢复默认 GCC 4.8.5：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scl <span class=\"built_in\">enable</span> devtoolset-9 bash</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"方式-2：永久启用（推荐）\"><a href=\"#方式-2：永久启用（推荐）\" class=\"headerlink\" title=\"方式 2：永久启用（推荐）\"></a>方式 2：永久启用（推荐）</h4><p>若需每次登录终端都自动使用 GCC 9，可将启用命令写入环境变量文件，分“当前用户”和“全局所有用户”两种场景：</p>\n<h5 id=\"场景-A：仅当前用户生效（推荐普通用户）\"><a href=\"#场景-A：仅当前用户生效（推荐普通用户）\" class=\"headerlink\" title=\"场景 A：仅当前用户生效（推荐普通用户）\"></a>场景 A：仅当前用户生效（推荐普通用户）</h5><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将启用命令写入当前用户的 .bashrc 文件</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;source /opt/rh/devtoolset-9/enable&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class=\"line\"><span class=\"comment\"># 立即生效（无需重启终端）</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"场景-B：全局所有用户生效（需-root-权限）\"><a href=\"#场景-B：全局所有用户生效（需-root-权限）\" class=\"headerlink\" title=\"场景 B：全局所有用户生效（需 root 权限）\"></a>场景 B：全局所有用户生效（需 root 权限）</h5><p>适用于多用户服务器，所有用户登录后均使用 GCC 9：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 切换到 root 用户（若当前非 root）</span></span><br><span class=\"line\">su root</span><br><span class=\"line\"><span class=\"comment\"># 将启用命令写入全局环境变量文件 /etc/profile</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;source /opt/rh/devtoolset-9/enable&quot;</span> &gt;&gt; /etc/profile</span><br><span class=\"line\"><span class=\"comment\"># 立即生效</span></span><br><span class=\"line\"><span class=\"built_in\">source</span> /etc/profile</span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"7-验证-GCC-升级结果\"><a href=\"#7-验证-GCC-升级结果\" class=\"headerlink\" title=\"7. 验证 GCC 升级结果\"></a>7. 验证 GCC 升级结果</h3><p>执行以下命令查看当前 GCC 版本，确认是否升级成功：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -v</span><br></pre></td></tr></table></figure>\n\n<p>若输出类似以下内容（版本号为 9.3.1 及以上），则说明升级成功：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using built-in specs.</span><br><span class=\"line\">COLLECT_GCC=gcc</span><br><span class=\"line\">COLLECT_LTO_WRAPPER=/opt/rh/devtoolset-9/root/usr/libexec/gcc/x86_64-redhat-linux/9/lto-wrapper</span><br><span class=\"line\">Target: x86_64-redhat-linux</span><br><span class=\"line\">Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/opt/rh/devtoolset-9/root/usr --mandir=/opt/rh/devtoolset-9/root/usr/share/man --infodir=/opt/rh/devtoolset-9/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --with-default-libstdcxx-abi=gcc4-compatible --enable-plugin --enable-initfini-array --with-isl=/builddir/build/BUILD/gcc-9.3.1-20200408/obj-x86_64-redhat-linux/isl-install --disable-libmpx --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux</span><br><span class=\"line\">Thread model: posix</span><br><span class=\"line\">gcc version 9.3.1 20200408 (Red Hat 9.3.1-2.2.el7) (GCC)</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"四、常见问题与注意事项\"><a href=\"#四、常见问题与注意事项\" class=\"headerlink\" title=\"四、常见问题与注意事项\"></a>四、常见问题与注意事项</h2><ol>\n<li><p><strong>若需安装其他 GCC 版本</strong>：<br>本教程以 GCC 9 为例，若需安装 GCC 10，只需将命令中的 <code>devtoolset-9</code> 替换为 <code>devtoolset-10</code>（如 <code>devtoolset-10-gcc</code>），其他步骤一致。</p>\n</li>\n<li><p><strong>系统默认 GCC 未被覆盖</strong>：<br>SCL 安装的 GCC 位于 <code>/opt/rh/devtoolset-9/root/usr/bin/</code>，系统默认 GCC（4.8.5）仍在 <code>/usr/bin/gcc</code>，若需临时使用旧版本，可直接执行 <code>/usr/bin/gcc -v</code>。</p>\n</li>\n<li><p><strong>安装时提示“无可用软件包”</strong>：<br>重新执行步骤 3（清理并生成缓存），或检查步骤 2 的仓库配置文件是否正确（确保 <code>baseurl</code> 未写错）。</p>\n</li>\n</ol>\n<h2 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h2><p>通过本教程，可在 CentOS 7 上安全升级 GCC 至 9 版本（或更高），满足现代软件开发需求，且不影响系统原有依赖。若后续需编译软件（如 Python、C++ 项目），直接使用 <code>gcc</code> 或 <code>g++</code> 命令即可调用高版本工具。</p>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","raw":null,"categories":[{"name":"IT","path":"api/categories/IT.json"}],"tags":[{"name":"Linux","path":"api/tags/Linux.json"},{"name":"系统","path":"api/tags/系统.json"}]}]}