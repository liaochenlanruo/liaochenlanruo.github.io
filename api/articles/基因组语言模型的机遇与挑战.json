{"title":"基因组语言模型的机遇与挑战","slug":"基因组语言模型的机遇与挑战","date":"2025-11-11T15:08:16.000Z","updated":"2025-11-11T15:11:30.465Z","comments":true,"path":"api/articles/基因组语言模型的机遇与挑战.json","excerpt":null,"covers":["https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png","https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png","https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png","https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png","https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg","https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png"],"content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>大型语言模型（LLMs）正在对广泛的科学领域产生变革性影响，尤其是在生物医学领域。正如自然语言处理（NLP）的目标是理解单词序列一样，生物学的一个主要目标是理解生物序列。基因组语言模型（gLMs）是在DNA序列上训练的大型语言模型，有望显著增进我们对基因组的理解，以及不同尺度的DNA元件如何相互作用以产生复杂功能。为展示这一潜力，我们重点介绍了基因组语言模型的关键应用，包括<code>功能约束预测</code>、<code>序列设计</code>和<code>迁移学习</code>。然而，尽管近期取得了显著进展，开发有效且高效的基因组语言模型仍面临诸多挑战，特别是对于具有大型复杂基因组的物种。在此，我们探讨了开发和评估基因组语言模型的主要考量因素。</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>人工智能&#x2F;机器学习（AI&#x2F;ML）的最新进展对广泛的科学学科产生了深远影响，彻底改变了建模、数据分析、解释和发现的方法。这一发展的关键支柱之一是自监督学习，通过在大量未标记数据上进行训练，模型能够学习复杂特征及其相互作用。这种范式尤其改变了自然语言处理领域，使人工智能模型在多个具有挑战性的任务上达到人类水平，包括翻译、语音识别，甚至回答标准化专业和学术考试中的问题。</p>\n<p>正如自然语言处理的目标是理解自然语言序列一样，计算生物学的一个主要目标是理解生物序列。因此，近年来人们对将自然语言处理中的现代技术应用于生物序列（DNA、RNA、蛋白质）产生了浓厚兴趣。特别是，蛋白质序列数据库（如UniProt）在过去十年中呈指数级增长，在这些海量数据上训练的蛋白质语言模型（pLMs）在复杂问题上取得了令人印象深刻的性能，例如结构预测和变异效应预测等记的蛋白质序列数据集有望包含重要的生物信息。</p>\n<p>类似地，在DNA序列上训练的大型语言模型（LLMs）有望改变基因组学，但为基因组开发有效的模型面临额外的挑战。例如，与作为功能重要单元且尺寸相对较小的蛋白质不同，大多数基因组要大得多，并且通常包含大量复杂的非功能区域，这些区域在数量上超过了功能元件。此外，与数亿个蛋白质序列相比，整个生命树中可用的全基因组序列数量极少，这限制了训练数据中功能重要的DNA元件的多样性。尽管存在这些问题，我们认为在基因组上训练的语言模型——即基因组语言模型（gLMs）——对生物学具有巨大潜力。在本文中，我们回顾了该领域的一些关键机遇和挑战，<u>并概述了开发和评估对基因组学界有用的基因组语言模型应解决的主要考量因素</u>。</p>\n<h2 id=\"2-应用\"><a href=\"#2-应用\" class=\"headerlink\" title=\"2 应用\"></a>2 应用</h2><p>语言模型的通用框架总结在<code>BOX 1</code>中。下面，我们详细阐述基因组语言模型的三个主要应用领域：功能约束预测、序列设计和迁移学习。</p>\n<h3 id=\"2-1-功能约束预测\"><a href=\"#2-1-功能约束预测\" class=\"headerlink\" title=\"2.1 功能约束预测\"></a>2.1 功能约束预测</h3><p>基因组语言模型一个有趣的应用是在无需任何任务监督的情况下预测基因组位点的功能约束。这种方法的一个显著优势是它不依赖于标记（例如某个变异是否致病），而标记通常数量有限且存在偏差。其核心思想是，参考基因组（通常来自健康个体）中有害变异的含量相对较低。因此，在这些数据上训练的模型倾向于给有害变异分配较低的概率。这一观察结果为使用<strong>两个等位基因之间的对数似然比</strong>（LLR）——即$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$——来估计它们的相对适应性提供了依据。</p>\n<p><font size=2 color='grey'><strong>BOX 1</strong>：通用语言模型框架</p>\n<p>从高层次来看，语言模型的训练目标是学习如下形式的条件概率分布：</p>\n<p>在掩码语言建模（MLM）中为 $(\\mathbb{P}[X_{i}|X_{- \\text{Masked}}])$（其中$(i \\in \\text{Masked})$），在因果语言建模（CLM）中为 $(\\mathbb{P}[X_{k}|X_{1:k-1}])$。这里，$(X&#x3D;(X_{1},X_{2},\\dots))$ 表示“标记”（如核苷酸或氨基酸）序列，“Masked”表示被掩码的位置集合。自然语言处理近期取得进展的关键在于，不再手动设计简单的上下文依赖参数模型，而是让数据自己说话，并通过利用强大的深度学习架构，随着观测数据的增加来拟合更复杂的模型。图1展示了用于DNA的语言建模框架。虽然模型训练的目的是利用未掩码位点的信息预测每个掩码位点的核苷酸，但它会学习位置特异性的上下文表示（称为嵌入，即一个高维向量），随后该向量会转换为在 ${A,C,G,T}$ 上的概率分布。这些嵌入和概率分布均具有位置特异性，可应用于基因组学中的许多问题。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图1：基因组语言模型的训练和应用\"></p>\n<p><font size=2 color='grey'>左侧示意图展示了基因组语言模型的训练过程。两个等位基因之间的对数似然比（LLR，具体为$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$）是功能约束的良好无监督预测因子（功能约束预测）。通过从学习到的概率分布中采样，可以生成新的序列（序列设计）。输入序列中每个标记的向量表示（称为嵌入）可以被提取出来，并适配于不同的下游任务（迁移学习）。</font></p>\n<p>在蛋白质序列模型中，最初引入了使用对数似然比进行功能约束预测的方法，在预测错义变异效应方面取得了出色成果。将这种方法扩展到基因组范围，GPN首次使用基因组语言模型进行全基因组功能约束预测，在模式植物拟南芥（<em>Arabidopsis thaliana</em>）中取得了最先进的结果。为说明基因组语言模型如何预测功能约束，我们注意到基因组语言模型能够学习<code>转录因子结合位点（TFBS）基序</code>，理解哪些位置受到约束，哪些位置不受约束（<strong>图2a</strong>）。此外，尽管<code>GPN</code>模型仅在拟南芥的一个基因组上训练，但它的对数似然比得分与拟南芥自然种群中的等位基因频率相关（<strong>图2b</strong>）。随后，<code>AgroNT</code>和<code>PlantCaduceus</code>在其他植物物种中也取得了优异结果。然而，对于人类基因组，核苷酸转换器（NT）的对数似然比性能低于现有的基准模型。与此同时，<code>GPNMSA</code>利用跨多种脊椎动物物种的全基因组多序列比对（MSA），实现了最先进的性能。需要注意的是，<u>观察到的核苷酸分布不仅受功能约束驱动，还受突变偏差影响；将此信息明确纳入功能约束预测是未来研究的一个有前景的方向</u>。</p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图2：应用示例\"></p>\n<p><font size=2 color='grey'>（a）基因组语言模型在启动子区域预测的序列标志图（顶部），突出显示了与假定功能性转录因子结合位点匹配的基序（底部序列标志图）。（b）变异次要等位基因频率（MAF）与基因组语言模型得分（对数似然比）之间的相关性。（c）基因组语言模型可以用不同的控制标签提示，设计在特定细胞类型中驱动高表达或低表达的启动子序列。（d）不同基因组窗口类别的基因组语言模型嵌入可视化，表明学习到的表示包含有用信息，如基因区域。注：面板a、b、d使用GPN模型生成。</font></p>\n<p>对于单核苷酸多态性（SNP），在掩码语言模型中只需对变异位置进行一次掩码查询即可计算对数似然比，而在因果语言模型中则需要对参考序列和替代序列进行两次查询。因果语言模型可以轻松处理多个替换、插入和缺失，而掩码语言模型必须采用更耗时的伪对数似然比方法。除对数似然比外，还提出了其他用于功能约束预测的得分，例如嵌入空间中的距离或突变周围位置核苷酸概率的变化。尽管对数似然比在蛋白质语言模型和基因组语言模型领域都被广泛使用，但深入理解这些替代得分在哪些场景下有用仍然很重要。</p>\n<p>基因组学中有两类主要的变异效应预测器：<strong>一类是功能约束预测器</strong>，包括基因组语言模型和传统的保守性得分；<strong>另一类是活性预测器</strong>，如基因表达预测器<code>Enformer</code>或剪接预测器<code>SpliceAI</code>。这两类模型存在关联：如果某个位点的变异受到选择，它会在某些情况下诱导活性变化（例如，在肢体发育过程中某个基因的转录变化），最终影响高级性状（例如，多指畸形）。功能约束模型涵盖了影响整体生物体适应性的所有可能机制和场景，而活性模型仅反映了它们明确训练过的机制和场景（某些数据，如人类大脑发育过程中的蛋白质表达，获取难度较大）。另一方面，活性模型可以指出变异发挥作用的特定机制和场景，而功能约束模型则不提供机制解释。</p>\n<p>关于功能性变异的优先排序，还有一些额外的考量。对于两个在不同基因中引起相似表达倍数变化的变异，即使它们的表达水平在生理耐受性上存在巨大差异，活性模型通常也会给出相似的得分。另一方面，不受可检测选择影响的性状仍可能具有科学或医学意义。在这种情况下，功能约束模型在优先排序影响该性状的变异方面能力有限，尤其是当这些变异效应量较小时（如在复杂性状全基因组关联研究（GWAS）中常见的情况）。然而，尽管基因组语言模型的对数似然比在这种情况下可能效果不佳，但基因组语言模型学习到的嵌入（<strong>BOX 1</strong>）在有标记数据的额外监督下仍可能具有价值。</p>\n<h3 id=\"2-2-序列设计\"><a href=\"#2-2-序列设计\" class=\"headerlink\" title=\"2.2 序列设计\"></a>2.2 序列设计</h3><p>设计新的生物序列对学术界和工业界研究团体都极具吸引力，因为它在药物发现与递送、农业改良、生物修复以及生物研究工具开发等方面具有巨大潜力。在此，我们描述使用<code>因果语言模型</code>（<strong>BOX 1</strong>）进行序列生成的方法，这是最常用的方法。具体而言，序列生成任务被分解为一系列下一个标记预测问题。从给定的序列片段（称为提示或控制标签）开始，语言模型可以递归地预测下一个标记，从而生成完整的新序列。蛋白质语言模型已被证明是蛋白质设计的强大工具。除编码序列外，非编码序列的设计也至关重要，因为它在基因和细胞治疗以及合成生物学等领域有应用。此类设计任务以前通过有监督的活性模型解决，但最近有多项研究探索使用基因组语言模型来应对这一挑战，如下所述。</p>\n<p><code>regLM</code>模型基于因果基因组语言模型<code>HyenaDNA</code>构建，用于<strong>从头生成启动子和增强子序列</strong>。HyenaDNA模型在带有前置控制标签的调控序列上进行训练或微调。然后，使用训练好的模型生成带有给定标签的新调控序列（<strong>图2c</strong>）。作者在酵母和人类细胞系中对生成序列的多样性和活性进行了计算评估，证明这些序列具有预期的功能以及真实且多样的序列特征。</p>\n<p>基因组语言模型在多模态设计任务中具有独特潜力，例如通过将蛋白质-RNA复合物统一为DNA序列设计来生成此类复合物。<u>例如，在原核生物基因组上训练的基因组语言模型EVO被用于设计新的CRISPR-Cas系统</u>。该模型使用带有前置Cas亚型特异性提示的CRISPR-Cas序列数据集进行微调。微调后的模型能够生成与亚型提示匹配的新CRISPR-Cas序列，且其预测结构与天然存在的系统相似。</p>\n<p>此外，<u>基因组语言模型还有可能用于在染色体或基因组尺度上设计有组织的功能性DNA序列</u>。最近，两个基因组语言模型<code>MegaDNA</code>和<code>EVO</code>探索了原核生物基因组的此类设计任务。EVO用于生成20个约650 Mbp大小的序列。研究发现，生成的序列具有真实的编码序列密度、具有预测二级结构和球状折叠的蛋白质序列，以及合理的tRNA序列。MegaDNA用于生成长达96 kbp的完整噬菌体基因组。除验证编码序列外，作者还在生成的序列中识别出包括启动子和核糖体结合位点在内的功能性调控元件。然而，此类大规模DNA序列设计任务仍然具有挑战性。研究发现，<u>EVO生成的序列缺乏功能原核生物基因组中通常存在的高度保守标记基因，且预测的蛋白质结构与天然蛋白质数据库的匹配度有限。最近的一项独立评估表明，MegaDNA生成的基因组序列组成与天然基因组仍有很大差异</u>。因此，需要进一步研究改进方法，以实现使用基因组语言模型从头设计完全功能性的基因组。</p>\n<h3 id=\"2-3-迁移学习\"><a href=\"#2-3-迁移学习\" class=\"headerlink\" title=\"2.3 迁移学习\"></a>2.3 迁移学习</h3><p>通过功能基因组学实验训练的用于预测注释的神经网络已被广泛用于解释基因组元件的功能。<u>一个重要的应用是预测变异对分子表型的影响，例如基因表达和剪接</u>。神经网络能够解释基因组位点之间复杂相互作用的能力，使其成为解决这些重要问题的必备工具，但合适的训练数据通常难以收集，因此数量有限。为了在预测任务上实现泛化，模型需要能够识别广泛的功能重要序列元件，这可能需要大量的数据和计算资源。为克服单个任务数据不足的限制，开发者采用了迁移学习方法——即利用在一个任务上训练模型获得的知识来改进相关任务性能的技术。具体而言，大多数用于预测功能注释的神经网络都经过训练以同时预测多种注释，迫使这些模型学习单一的统一表示。这进而提高了它们的泛化性能。</p>\n<p>语言模型也可用于迁移学习（有关迁移学习在自然语言处理中的应用，请参见<strong>BOX 2</strong>）。一种技术是特征提取：在学习预测核苷酸的上下文依赖分布时，基因组语言模型将输入的基因组序列转换为中间向量表示<strong>BOX 1</strong>）。这些表示可能提炼了相关信息，因此可用作另一个模型的特征。例如，<u>基因组语言模型嵌入的可视化显示，在没有任何监督的情况下，模型已经学会区分不同类别的基因组元件，如编码序列和非翻译区（<strong>图2d</strong>）</u>。不同层的嵌入可以为不同任务提供有用信息。利用语言模型进行迁移学习的另一种方法是将其用作预训练模型，即在下游任务上继续训练它们。这种技术称为微调。在某个任务上微调预训练的神经网络，会隐式地对其参数进行正则化，使得网络的预测综合了来自两个任务的知识。因此，对神经网络进行预训练通常会提高其在下游任务上的泛化性能。在最近的研究中，<code>SegmentNT</code>模型（通过微调核苷酸转换器（NT）基因组语言模型以实现<strong>基因和顺式调控元件注释</strong>任务而开发）在该任务上取得了最先进的性能。研究表明，使用预训练模型是其取得成功的关键。类似地，NT家族的另一个模型<code>AgroNT</code>在多种植物物种上进行预训练，然后在选定的作物物种上微调以预测染色质可及性和基因表达。<code>DNABERT-S</code>将对比学习与预训练的<code>DNABERT-2</code>嵌入相结合，用于<strong>宏基因组分箱</strong>。<code>IsoFormer</code>是DNA和蛋白质语言模型之间多模态迁移学习的一个例子，用于<strong>预测转录本亚型表达</strong>。这些最近的成功表明，微调后的基因组语言模型可能在各种基因组解释任务上取得显著进展。</p>\n<p>最近有两项研究评估了多个基因组语言模型在人类基因组预测任务中的性能，发现它们通常不会优于非基因组语言模型基准。这些结果基于冻结的嵌入；评估完整的微调过程将提供更多见解。尽管基因组语言模型已经非常适合展示迁移学习在研究较少的生物体中的价值，但要使其在人类遗传学（已有高质量标记数据和精心设计的模型）中提供显著价值，可能还需要进一步的创新。一个重要的问题是，缩放假设对基因组语言模型的适用程度如何，即增加未标记数据和计算资源在多大程度上能持续提高模型性能。最近的一项蛋白质语言模型研究发现，缩放仅改进了蛋白质结构预测，而没有改进大多数其他任务（如功能或性质预测），因此基因组语言模型任务也应受到同样的审视。</p>\n<p><font size=2 color='grey'> <strong>BOX 2</strong>：自然语言处理中的迁移学习<br>为了在大多数任务（包括情感分析、问答和词性标注等典型任务）上实现泛化，自然语言处理模型需要理解语法和语义。然而，这些任务的特定数据通常有限。利用在原始文本数据（来源于文章、书籍和网站）上训练的大型语言模型进行迁移学习，已在这些问题上取得了突破性进展。如今，几乎所有最先进的自然语言处理模型都是从大型语言模型改编而来。</font></p>\n<p>迁移学习技术是近年来自然语言模型蓬勃发展的基础。特别是，可广泛适配于下游任务的预训练模型（称为“基础模型”）的出现，使得机器学习模型的开发方式发生了重大转变。</p>\n<h2 id=\"3-开发\"><a href=\"#3-开发\" class=\"headerlink\" title=\"3 开发\"></a>3 开发</h2><p>现在，我们描述开发有用的基因组语言模型的关键组成部分；<strong>图3</strong>展示了总结开发流程的示意图。我们首先阐述选择和准备训练数据的重要性，然后讨论架构和训练决策，接着考虑基因组语言模型的解释和基准测试。我们的目标是<u>深入了解开发有效且高效的基因组语言模型所涉及的方法和挑战</u>。为全面展示该领域的当前状况，我们在<strong>表1</strong>中列出了一些我们已知的现有基因组语言模型，并总结了它们的设计决策。</p>\n<h3 id=\"3-1-训练数据\"><a href=\"#3-1-训练数据\" class=\"headerlink\" title=\"3.1 训练数据\"></a>3.1 训练数据</h3><p>机器学习模型的性能在很大程度上受其架构和训练数据的影响。卷积神经网络（CNNs）、Transformer 和状态空间模型（SSMs）等各种模型架构已成功应用于广泛的领域，包括自然语言、图像、音频、蛋白质和基因组学。然而，为预训练选择合适的数据需要对特定领域有深入的理解，尤其是<u>在基因组学领域，目前尚无类似于自然语言处理（如Pile）或蛋白质生物学（如UniProt）中那样被普遍接受的精选数据集</u>。</p>\n<p><strong>一个关键的考量因素是数据质量</strong>。例如，在自然语言处理中，数据质量可能指经过编辑或同行评审的数据源，如科学文章或书籍。<u>在蛋白质领域，质量控制包括去除预测的假基因或不再具有功能的截断蛋白质</u>。然而，最近的一项研究发现，作为最常用的基因组语言模型训练数据集（<strong>表1</strong>）的人类参考基因组中，仅有3.3%的碱基受到显著约束且可能具有功能。重要的是，<u>用于训练基因组语言模型的典型基因组序列既包含<code>功能位点</code>，也包含<code>非功能位点</code>，且通常无法将训练样本明确分为<code>高质量</code>和<code>低质量</code>两类</u>。一个提出的解决方案是根据功能证据对训练损失进行碱基级加权。</p>\n<p>在自然语言处理和蛋白质领域，<strong>过滤重复序列</strong>是标准做法，这有助于提高训练效率并减少记忆。尽管人类基因组中高达50%的序列是重复序列（在真核生物中这一比例普遍较高），但很少有基因组语言模型研究提出解决方案（如降低权重或下采样），甚至很少有研究承认这一问题。如果语言模型困惑度的研究也能分别报告非重复区域的困惑度，以区分泛化改进和记忆改进，那将很有启发意义。</p>\n<p><strong>另一个关键问题是如何确保数据量充足</strong>。单个基因组可能不足以训练大型模型，尤其是当非功能区域被下采样或降低权重时。一种方法是添加同一物种的序列变异。然而，在包括人类在内的许多物种中，个体之间的变异相对较少。更常用的方法是<code>跨多个物种进行训练</code>（<strong>表1</strong>），这与蛋白质语言模型的做法类似。随着物种亲缘关系的疏远，调控逻辑的分化速度快于蛋白质。一种提出的方法是<strong>将物种标识符作为额外输入明确添加到模型中</strong>。尽管如此，一个足够大的模型，在有足够基因组上下文的情况下，仍有可能自然地对远缘基因组进行建模，类似于大型语言模型处理多语言数据集的方式。</p>\n<p>如前所述，在原核生物中，已有模型（MegaDNA和EVO）将整个基因组作为上下文。目前，这在真核生物中还不可行，因此产生了<strong>如何将基因组划分为可单独建模的上下文窗口的问题</strong>。许多相互作用局限于邻近位置（如转录因子结合位点基序），这推动了具有相对较小上下文（&lt;6 kb）的模型的开发（**表1**）。然而，也存在明显的长程相互作用，例如同一基因的外显子之间或增强子与启动子之间（可达1 Mb）。如此长的上下文长度带来了计算和统计挑战，研究人员已在努力克服这些挑战。无论选择何种上下文长度，将基因组划分为独立单元（类似于按蛋白质划分蛋白质组的方式）仍然并非易事。例如，<u>一个基因的增强子可能位于另一个基因的内含子中，且多个基因可能由同一个增强子调控。尤其是在跨物种训练时，避免因直系同源和旁系同源导致的数据泄露非常具有挑战性</u>。</p>\n<p>训练数据的选择可能会显著影响基因组语言模型的输出和学习到的表示。自然界中观察到的DNA序列是各种进化过程的结果，其中最主要的是突变和选择。对于某些应用，可能需要精心选择训练数据，以突出这些过程中的某一个。例如，为了进行适应性预测，可能需要排除&#x2F;降低高突变位点（如CpG位点）和非功能区域（如某些类型的重复元件）的权重。</p>\n<h3 id=\"3-2-模型架构\"><a href=\"#3-2-模型架构\" class=\"headerlink\" title=\"3.2 模型架构\"></a>3.2 模型架构</h3><p>在Transformer架构出现之前，<code>卷积神经网络</code>模型已被广泛用于基因组学中的有监督任务。卷积神经网络通过对输入数据应用<code>过滤器</code>，特别<u>擅长捕捉基因组序列中的局部依赖关系和基序</u>。这些模型在预测<strong>DNA-蛋白质结合位点</strong>、<strong>调控元件</strong>和<strong>转录因子结合位点</strong>方面取得了成功。前面提到的用于拟南芥全基因组变异效应预测的基因组语言模型GPN，借鉴了自然语言处理和蛋白质建模中带有改进卷积神经网络层的语言模型的成功经验，用<code>扩张卷积神经网络层</code>替换了Transformer<code>编码器中的自注意力层</code>。</p>\n<p><code>Transformer</code>模型彻底改变了各种机器学习领域，尤其是自然语言处理，并且最近被广泛应用于基因组学建模。自注意力机制允许每个标记同时关注输入序列中的所有位置，使模型能够动态关注序列的相关部分。这种能力在有监督的基因表达任务中检测调控机制方面取得了显著进展。</p>\n<p>尽管Transformer模型具有优势，但它们在基因组学建模中面临一些独特的<strong>挑战</strong>。一个重要问题是，<u>Transformer对相互作用的局部性几乎没有或没有归纳偏置，这使得它们在建模转录因子结合位点等局部基序时数据效率较低</u>。这促使人们开发<strong>卷积神经网络-Transformer混合模型</strong>，如<code>LOGO</code>，其借鉴了<code>Enformer</code>等有监督模型的思路。</p>\n<p><strong>另一个挑战是上下文长度</strong>：自注意力机制导致<strong>计算时间和内存随输入序列长度呈二次方增长</strong>，这使得将Transformer应用于极长的基因组序列变得不切实际。因此，传统基于注意力的基因组语言模型目前能够处理的最长输入长度是<code>NT-v2的12 kb</code>。为解决这一限制，一些基于Transformer的基因组语言模型采用了<code>近似注意力</code>或<code>分层注意力</code>方法，牺牲了所有标记之间的完全成对注意力。这些方法包括在<code>GENA-LM</code>中使用稀疏注意力（将上下文长度扩展到<code>36 kb</code>），以及在<code>MegaDNA</code>中采用MEGABYTE亚二次方分层自注意力（实现<code>了96 kb</code>的上下文长度）。</p>\n<p>为克服自注意力的二次方缩放问题，人们提出了各种状态空间模型（SSMs）作为Transformer的高效替代方案，用于基因组语言模型，其<strong>计算复杂度随序列长度接近线性增长</strong>。基于·层次结构的<code>HyenaDNA</code>能够支持长达<code>100万</code>个核苷酸的输入上下文。<code>EVO</code>是一种结合了Hyena和Transformer架构的混合模型，在8 kb序列上进行预训练，然后在上下文扩展阶段使用<code>131 kb</code>序列进行微调。基于Mamba的状态空间模型构建的<code>Caduceus</code>在<code>131 kb</code>序列上进行训练，同时融入了反向互补等变。</p>\n<h3 id=\"3-3-学习目标\"><a href=\"#3-3-学习目标\" class=\"headerlink\" title=\"3.3 学习目标\"></a>3.3 学习目标</h3><p>如<strong>BOX 1</strong>所述，掩码语言模型（MLM）任务（有时也称为“掩码标记预测”）要求模型根据剩余标记预测以预定概率（通常为15%）随机掩码的标记身份。这一框架已用于训练开创性的大型语言模型BERT和蛋白质语言模型<code>ESM-1b</code>，此后被广泛用于训练基因组语言模型。因果语言模型（CLM）任务（也称为“自回归语言建模”或“下一个标记预测”）要求模型根据前面的标记预测序列中的标记；该任务已用于训练GPT系列大型语言模型。在该任务中，模型以单向从左到右的顺序，根据前面的标记预测下一个标记。这两个任务的共同点是，它们都要求模型根据其他组件作为上下文来预测数据的组件。为了在这些任务上实现泛化，模型必须学习数据的低维表示。这种能力使基因组语言模型能够通过捕捉基因组内的潜在模式和依赖关系来理解和生成基因组序列。<u>在蛋白质建模中，掩码语言模型在表示学习和迁移学习能力方面通常优于因果语言模型</u>。另一方面，因果语言模型是生成任务的传统选择，但最近通过渐进式掩码，掩码语言模型在生成任务上也取得了优异结果。</p>\n<p>为减少输入序列长度并建模更长的上下文，k-mer和字节对编码（BPE）创建了比天然核苷酸词汇表（{A,C,G,T}）更大的人工定义核苷酸词汇表。另一方面，单核苷酸标记化简化了模型解释和归因，并增强了模型处理基因组变异的能力。</p>\n<p>研究人员探索了对训练目标的多种修改，以提供额外的信号并提高性能。例如，<code>GPN-MSA</code>通过脊椎动物物种的全基因组多序列比对（MSA）增强了在人类参考基因组上的掩码语言模型训练，利用相关物种间的保守性获取额外上下文。其局限性在于，全基因组多序列比对仅针对某些物种生成，要在植物中有效应用可能需要进一步开发。此外，即使顺式调控元件的活性保守，其序列也可能快速分化，这限制了通过比对提取的直系同源信息。<code>Species LM</code>通过为每个酵母物种分配一个专用标记，并在训练和推理期间将物种标记附加到输入序列，直接整合了物种信息。核苷酸序列的预训练已扩展到支持与其他模态的交互，如表观遗传学、RNA、蛋白质和自然语言。</p>\n<h3 id=\"3-4-解释\"><a href=\"#3-4-解释\" class=\"headerlink\" title=\"3.4 解释\"></a>3.4 解释</h3><p>尽管深度学习模型在各种预测任务中取得了显著性能，但它们通常缺乏可解释性，常被视为“黑箱”。然而，理解这些模型如何生成预测对于实现更广泛的应用和推进模型开发至关重要。因此，研究人员开发了一系列解释深度学习模型的方法，包括专门针对基因组学的方法。尽管基因组语言模型的解释仍是一个新兴的研究方向，但已有研究表明，一些模型已经学习到了有意义的生物模式。</p>\n<p>从语言模型中提取的序列嵌入通常被用作捕捉丰富上下文信息和序列特征的表示。<u>对基因组语言模型编码的序列嵌入进行无监督聚类，发现输入序列形成了对应于不同基因组类别（如编码序列、内含子、非翻译区等）的明显聚类</u>（<strong>图2d</strong>）。此外，<u>对<code>SpliceBERT</code>嵌入的典型剪接位点和非剪接GT&#x2F;AG位点进行无监督聚类，发现了对应于这两组位点的明显聚类</u>。这些结果表明，模型已经学会捕捉表征基因组中功能元件的关键上下文模式。</p>\n<p>Transformer模型中的注意力机制旨在捕捉输入标记之间的交互模式。因此，解释给定输入序列的注意力权重或注意力图，可以揭示模型学习到的基因组特征。<u>在SpliceBERT中，剪接供体位点和受体位点之间的注意力权重显著高于随机位点对之间的注意力权重；此外，真实供体-受体对之间的交互强度往往高于其他供体和受体位点组合</u>。这些发现表明，模型已经学会了功能交互位点之间的关系。</p>\n<p>一些基因组语言模型还采用核苷酸重建方法来发现模型学习到的序列基序。具体而言，将输入序列的各个位置逐一掩码，然后由训练好的模型根据基因组上下文预测核苷酸的概率分布。每个位点获得的分布可以揭示模型学习到的基序。GPN中采用了这种方法，在重建核苷酸的分布中发现了显著模式。特别是，<strong>模型在功能重要位点的预测通常更有信心</strong>。例如，编码序列和剪接供体&#x2F;受体位点的预测信心通常高于深层内含子位点。此外，在编码序列中，密码子的第三个核苷酸位置（对翻译的氨基酸决定作用最小）的预测信心通常低于前两个核苷酸位置。通过适配<code>TF-MoDISco</code>（一种利用模型预测识别新转录因子结合位点的专用工具），作者还发现了与转录因子结合位点数据库和相关文献中已知基序匹配的序列基序（<strong>图2a</strong>）。类似地，Species LM重建的序列基序也与训练中未见过的物种中已知的DNA和RNA结合蛋白的结合位点匹配，基序重建的准确性取决于正确反映体内结合位点的上下文和基因组区域。此外，重建基序的组成、存在和位置表现出物种特异性模式，这表明<u>基因组语言模型可能成为研究序列基序和调控密码进化的强大工具</u>。</p>\n<p>最近，研究人员通过在某个位置引入点突变并量化其他位置核苷酸概率的变化，研究了基因组语言模型学习到的基因组位置之间的依赖关系。核苷酸依赖分析揭示了模型学习到的功能元件（如转录因子结合位点、剪接位点和RNA）内部和之间的相互作用，包括已知的二级和三级结构接触。值得注意的是，与之前基于预测边际概率分布的方法相比，核苷酸依赖分析能够更稳健地检测结合的转录因子结合位点。</p>\n<h3 id=\"3-5-评估\"><a href=\"#3-5-评估\" class=\"headerlink\" title=\"3.5 评估\"></a>3.5 评估</h3><p>在本节中，我们将讨论如何针对前面描述的三个应用领域对模型性能进行基准测试：预测等位基因的功能约束、生成新的可行序列以及迁移学习。</p>\n<p>有多种类型的数据可以反映等位基因的功能约束，可用于基准测试变异效应预测器。<strong>一类</strong>数据来自将<code>遗传变异的功能差异与读数</code>(readouts)（如报告基因的表达或细胞生长）相关联的实验。这些读数可用于对变异的功能性进行排序，由于影响功能的变异通常也受到选择，因此我们期望这些排序与模型预测的排序相关。这类数据的一个来源是<code>ProteinGym</code>，这是一个广泛使用的实验数据集集合，可用于基准测试错义变异效应预测器。<strong>另一类</strong>数据是<code>临床标记</code>，指示变异是否有致病证据（即是否会增加疾病风险）。致病性变异可能影响生育能力，因此可能具有有害性。因此，我们可以通过评估变异效应预测器作为致病性分类器的性能来对其进行基准测试。在人类遗传学中，变异临床标记的主要来源包括<code>ClinVar</code>、<code>HGMD</code>和<code>OMIM</code>数据库。<strong>第三类</strong>数据是<code>变异频率</code>。由于常见变异不太可能具有高度有害性，它们的预测约束水平应相对高于罕见变异。因此，我们可以根据预测器识别常见变异的能力对其进行基准测试。人类不同祖先群体中等位基因频率数据的主要来源是<code>gnomAD</code>数据库。总之，这些数据可以作为模型泛化性能的独立证据。</p>\n<p>变异效应预测器评估的一个问题是，验证数据与功能约束之间的关系可能不明确。因此，模型可能通过利用数据未能捕捉功能约束的方面在基准测试中表现出色。例如，使用临床标记的一个关键问题是，变异的分类基于是否有充分证据证明它们是良性的或致病性的。由于预测器也可能利用这些证据，它们在标记变异上的基准测试性能可能无法反映其在未标记变异上的真实性能（有关泛化性能的简要讨论，请参见<strong>BOX 3</strong>）。使用等位基因频率数据也存在关键问题：例如，除自然选择的直接作用外，等位基因频率还受突变率、遗传漂变、背景选择和遗传搭车等因素影响。因此，预测器可能通过预测这些过程的影响而非功能约束在基准测试中表现良好。这些问题凸显了需要仔细解释预测器性能原因的重要性，并促使人们呼吁提高预测器训练所使用的数据和方法的透明度。</p>\n<p>生成式序列模型的评估面临一系列独特挑战。评估语言模型生成能力的一种基本方法是比较它们在有效序列集上的困惑度。然而，要评估模型设计新序列的能力，需要衡量它们是否能够识别既可行又新颖的序列。因此，模型在测试集上的困惑度可能无法可靠地表明其在设计任务中的实用性。相反，可能需要采用全面的方法，检查生成序列的广泛特性。例如，最近用于调控序列设计的基准测试工具<code>Polygraph</code>提出了一系列分析方法，用于研究序列组成、基序模式和预测的功能活性。对于全基因组或染色体设计任务，可能还需要评估必需基因和功能性调控元件的存在和位置，以及它们之间的相互作用。最终，设计的序列需要通过实验评估，以确定它们是否能实现预期功能。</p>\n<p>最后，评估基因组语言模型在迁移学习中的性能面临一个独特挑战：任何基准测试集（可能需要结合多个基准测试集）都必须能够可靠地表明模型在相关任务上的性能。功能基因组学数据（如来自ENCODE或Roadmap表观基因组学项目的数据）可用于注释基因组区域和变异，这类数据可构建一系列任务，广泛反映模型适应基因组解释的能力。我们期望，模型在适应后从基因组序列预测这些注释的性能，能够表明其识别功能相似基因组元件的能力。为便于模型之间的比较，这些注释已被整合到各种标准化的训练和测试数据集集合中。</p>\n<p>由于迁移学习基准测试有助于凸显当前模型的局限性，并为发表建立标准，因此它们可能成为基因组语言模型开发者和用户的重要资产。然而，尽管当前基准测试在任务选择和方法上存在差异，但它们对基因组语言模型能力的见解似乎存在冗余。未来，计算基因组学界需要开发广泛认可的标准化且可扩展的基准测试。</p>\n<p><font size=2 color='grey'> <strong>BOX 3</strong>：评估泛化性能<br>评估预测模型的目的是建立对其泛化能力的信任，即对未标记数据做出令人满意的预测。估计模型泛化性能的一种直接且标准的方法是在代表目标未标记数据的标记“测试集”上评估其准确性。这种方法是大多数机器学习基准测试的基础。</p>\n<p>重要的是，为使这种评估成为泛化性能的可靠指标，不得向模型提供任何可用于区分测试集数据和最终部署数据的信息。否则，模型可能会以牺牲泛化性能为代价降低测试集误差。因此，通常会组织向参与者隐瞒测试数据的机器学习竞赛。<br></font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"表1：现有基因组语言模型总结\"></p>\n<p><font size=2 color='grey'>提供了各种基因组语言模型的概述，重点介绍了它们的预训练数据集、任务、架构、标记化方法和独特特征。模型按公开发布日期排序。缩写包括：SSM（状态空间模型）、CNN（卷积神经网络）、BPE（字节对编码）、CLM（因果语言建模）、MLM（掩码语言建模）。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" class=\"lazyload placeholder\" data-srcset=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"图3：开发流程\"></p>\n<p><font size=2 color='grey'>该图展示了本综述中描述的基因组语言模型通用开发流程，从模型构思到部署。我们首先选择和准备训练数据集，强调数据质量和数量的重要性（训练数据）。随后，在模型架构和学习目标部分，我们探讨了设计和训练基因组语言模型的各种选择，讨论了不同方法的优缺点。我们还研究了混合模型如何结合多种架构的元素以缓解特定局限性。在解释部分，我们讨论了分析和解释基因组语言模型输出的方法。最后，在评估部分，我们通过当前基准测试介绍了评估方法，强调了使模型性能与实际生物功能保持一致的复杂性。</font></p>\n<h2 id=\"4-结论与未来展望\"><a href=\"#4-结论与未来展望\" class=\"headerlink\" title=\"4 结论与未来展望\"></a>4 结论与未来展望</h2><p>在基因组序列数量庞大且不断增长的时代，基因组语言模型正成为提取复杂模式的强大工具，可应用于功能约束估计、序列设计和迁移学习等多个领域。然而，正如“人工智能”一词可能暗示的那样，它们尚未实现神奇的突然突破。相反，我们将其视为另一种有用的建模工具，类似于隐马尔可夫模型刚出现时的情况。基因组语言模型通常被称为“基础模型”，这一术语最近被创造出来，指在广泛数据上训练、可适应各种下游任务的模型。这一新术语的引入受到了批评，因为“基础”一词意味着在下游任务性能上有显著改进，而这是一个实证问题，而非预训练模型的固有属性。在基因组学等新领域，这种批评更为强烈，因为建立足够的基准测试可能需要一些时间。</p>\n<p>早期的基因组语言模型或多或少是自然语言处理模型的直接改编，我们期望通过深入结合基因组学专业知识，能获得最大的收益。我们注意到，评估基因组语言模型的能力具有挑战性，因为指标可能具有误导性，尤其是在过度优化的情况下。自然语言处理的一个优势是人类是自然语言的专家，因此可以根据自身专业知识校准基准测试。然而，在基因组学中，我们必须依靠数据和专家知识来验证模型。问题的这一方面使其特别具有挑战性，并可能意味着需要与领域专家合作，并有意识地进行实验以开发基准测试。在本综述的最后，我们提出了一些我们认为值得进一步研究的方向（列于未解决的问题中）。</p>\n<h3 id=\"未解决的问题\"><a href=\"#未解决的问题\" class=\"headerlink\" title=\"未解决的问题\"></a>未解决的问题</h3><ol>\n<li>如何最好地对从基序到基因再到全基因组的各种尺度模式进行建模？</li>\n<li>哪些应用需要对长程相互作用进行建模？如何确定合适的感受野大小？</li>\n<li>如何将结构变异纳入基因组语言模型？</li>\n<li>训练基因组语言模型时，利用群体遗传数据的最佳方式是什么？</li>\n<li>如何最好地将基因组语言模型与其他复杂模态（如转录组学和表观遗传学数据）整合？</li>\n<li>在开发基因组语言模型时，如何更好地理解为什么某些基因组比其他基因组更难建模？</li>\n<li>缩放假设对基因组语言模型是否成立？能成立多久？考虑到大多数数据可能是非功能性的，是否真的有足够的数据可用？</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>Gonzalo Benegas, Chengzhong Ye, Carlos Albors, Jianan Canal Li, Yun S. Song. arXiv:2407.11435v2. doi: <a href=\"https://doi.org/10.48550/arXiv.2407.11435\">https://doi.org/10.48550/arXiv.2407.11435</a></li>\n</ul>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”，聊天窗口回复“85d7”获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" class=\"lazyload placeholder\" data-srcset=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","more":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><p>大型语言模型（LLMs）正在对广泛的科学领域产生变革性影响，尤其是在生物医学领域。正如自然语言处理（NLP）的目标是理解单词序列一样，生物学的一个主要目标是理解生物序列。基因组语言模型（gLMs）是在DNA序列上训练的大型语言模型，有望显著增进我们对基因组的理解，以及不同尺度的DNA元件如何相互作用以产生复杂功能。为展示这一潜力，我们重点介绍了基因组语言模型的关键应用，包括<code>功能约束预测</code>、<code>序列设计</code>和<code>迁移学习</code>。然而，尽管近期取得了显著进展，开发有效且高效的基因组语言模型仍面临诸多挑战，特别是对于具有大型复杂基因组的物种。在此，我们探讨了开发和评估基因组语言模型的主要考量因素。</p>\n<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1 引言\"></a>1 引言</h2><p>人工智能&#x2F;机器学习（AI&#x2F;ML）的最新进展对广泛的科学学科产生了深远影响，彻底改变了建模、数据分析、解释和发现的方法。这一发展的关键支柱之一是自监督学习，通过在大量未标记数据上进行训练，模型能够学习复杂特征及其相互作用。这种范式尤其改变了自然语言处理领域，使人工智能模型在多个具有挑战性的任务上达到人类水平，包括翻译、语音识别，甚至回答标准化专业和学术考试中的问题。</p>\n<p>正如自然语言处理的目标是理解自然语言序列一样，计算生物学的一个主要目标是理解生物序列。因此，近年来人们对将自然语言处理中的现代技术应用于生物序列（DNA、RNA、蛋白质）产生了浓厚兴趣。特别是，蛋白质序列数据库（如UniProt）在过去十年中呈指数级增长，在这些海量数据上训练的蛋白质语言模型（pLMs）在复杂问题上取得了令人印象深刻的性能，例如结构预测和变异效应预测等记的蛋白质序列数据集有望包含重要的生物信息。</p>\n<p>类似地，在DNA序列上训练的大型语言模型（LLMs）有望改变基因组学，但为基因组开发有效的模型面临额外的挑战。例如，与作为功能重要单元且尺寸相对较小的蛋白质不同，大多数基因组要大得多，并且通常包含大量复杂的非功能区域，这些区域在数量上超过了功能元件。此外，与数亿个蛋白质序列相比，整个生命树中可用的全基因组序列数量极少，这限制了训练数据中功能重要的DNA元件的多样性。尽管存在这些问题，我们认为在基因组上训练的语言模型——即基因组语言模型（gLMs）——对生物学具有巨大潜力。在本文中，我们回顾了该领域的一些关键机遇和挑战，<u>并概述了开发和评估对基因组学界有用的基因组语言模型应解决的主要考量因素</u>。</p>\n<h2 id=\"2-应用\"><a href=\"#2-应用\" class=\"headerlink\" title=\"2 应用\"></a>2 应用</h2><p>语言模型的通用框架总结在<code>BOX 1</code>中。下面，我们详细阐述基因组语言模型的三个主要应用领域：功能约束预测、序列设计和迁移学习。</p>\n<h3 id=\"2-1-功能约束预测\"><a href=\"#2-1-功能约束预测\" class=\"headerlink\" title=\"2.1 功能约束预测\"></a>2.1 功能约束预测</h3><p>基因组语言模型一个有趣的应用是在无需任何任务监督的情况下预测基因组位点的功能约束。这种方法的一个显著优势是它不依赖于标记（例如某个变异是否致病），而标记通常数量有限且存在偏差。其核心思想是，参考基因组（通常来自健康个体）中有害变异的含量相对较低。因此，在这些数据上训练的模型倾向于给有害变异分配较低的概率。这一观察结果为使用<strong>两个等位基因之间的对数似然比</strong>（LLR）——即$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$——来估计它们的相对适应性提供了依据。</p>\n<p><font size=2 color='grey'><strong>BOX 1</strong>：通用语言模型框架</p>\n<p>从高层次来看，语言模型的训练目标是学习如下形式的条件概率分布：</p>\n<p>在掩码语言建模（MLM）中为 $(\\mathbb{P}[X_{i}|X_{- \\text{Masked}}])$（其中$(i \\in \\text{Masked})$），在因果语言建模（CLM）中为 $(\\mathbb{P}[X_{k}|X_{1:k-1}])$。这里，$(X&#x3D;(X_{1},X_{2},\\dots))$ 表示“标记”（如核苷酸或氨基酸）序列，“Masked”表示被掩码的位置集合。自然语言处理近期取得进展的关键在于，不再手动设计简单的上下文依赖参数模型，而是让数据自己说话，并通过利用强大的深度学习架构，随着观测数据的增加来拟合更复杂的模型。图1展示了用于DNA的语言建模框架。虽然模型训练的目的是利用未掩码位点的信息预测每个掩码位点的核苷酸，但它会学习位置特异性的上下文表示（称为嵌入，即一个高维向量），随后该向量会转换为在 ${A,C,G,T}$ 上的概率分布。这些嵌入和概率分布均具有位置特异性，可应用于基因组学中的许多问题。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig01.png\" alt=\"图1：基因组语言模型的训练和应用\"></p>\n<p><font size=2 color='grey'>左侧示意图展示了基因组语言模型的训练过程。两个等位基因之间的对数似然比（LLR，具体为$(\\log[\\mathbb{P}(X_{i}&#x3D;a|X_{-i})&#x2F;\\mathbb{P}(X_{i}&#x3D;b|X_{-i})])$）是功能约束的良好无监督预测因子（功能约束预测）。通过从学习到的概率分布中采样，可以生成新的序列（序列设计）。输入序列中每个标记的向量表示（称为嵌入）可以被提取出来，并适配于不同的下游任务（迁移学习）。</font></p>\n<p>在蛋白质序列模型中，最初引入了使用对数似然比进行功能约束预测的方法，在预测错义变异效应方面取得了出色成果。将这种方法扩展到基因组范围，GPN首次使用基因组语言模型进行全基因组功能约束预测，在模式植物拟南芥（<em>Arabidopsis thaliana</em>）中取得了最先进的结果。为说明基因组语言模型如何预测功能约束，我们注意到基因组语言模型能够学习<code>转录因子结合位点（TFBS）基序</code>，理解哪些位置受到约束，哪些位置不受约束（<strong>图2a</strong>）。此外，尽管<code>GPN</code>模型仅在拟南芥的一个基因组上训练，但它的对数似然比得分与拟南芥自然种群中的等位基因频率相关（<strong>图2b</strong>）。随后，<code>AgroNT</code>和<code>PlantCaduceus</code>在其他植物物种中也取得了优异结果。然而，对于人类基因组，核苷酸转换器（NT）的对数似然比性能低于现有的基准模型。与此同时，<code>GPNMSA</code>利用跨多种脊椎动物物种的全基因组多序列比对（MSA），实现了最先进的性能。需要注意的是，<u>观察到的核苷酸分布不仅受功能约束驱动，还受突变偏差影响；将此信息明确纳入功能约束预测是未来研究的一个有前景的方向</u>。</p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig02.png\" alt=\"图2：应用示例\"></p>\n<p><font size=2 color='grey'>（a）基因组语言模型在启动子区域预测的序列标志图（顶部），突出显示了与假定功能性转录因子结合位点匹配的基序（底部序列标志图）。（b）变异次要等位基因频率（MAF）与基因组语言模型得分（对数似然比）之间的相关性。（c）基因组语言模型可以用不同的控制标签提示，设计在特定细胞类型中驱动高表达或低表达的启动子序列。（d）不同基因组窗口类别的基因组语言模型嵌入可视化，表明学习到的表示包含有用信息，如基因区域。注：面板a、b、d使用GPN模型生成。</font></p>\n<p>对于单核苷酸多态性（SNP），在掩码语言模型中只需对变异位置进行一次掩码查询即可计算对数似然比，而在因果语言模型中则需要对参考序列和替代序列进行两次查询。因果语言模型可以轻松处理多个替换、插入和缺失，而掩码语言模型必须采用更耗时的伪对数似然比方法。除对数似然比外，还提出了其他用于功能约束预测的得分，例如嵌入空间中的距离或突变周围位置核苷酸概率的变化。尽管对数似然比在蛋白质语言模型和基因组语言模型领域都被广泛使用，但深入理解这些替代得分在哪些场景下有用仍然很重要。</p>\n<p>基因组学中有两类主要的变异效应预测器：<strong>一类是功能约束预测器</strong>，包括基因组语言模型和传统的保守性得分；<strong>另一类是活性预测器</strong>，如基因表达预测器<code>Enformer</code>或剪接预测器<code>SpliceAI</code>。这两类模型存在关联：如果某个位点的变异受到选择，它会在某些情况下诱导活性变化（例如，在肢体发育过程中某个基因的转录变化），最终影响高级性状（例如，多指畸形）。功能约束模型涵盖了影响整体生物体适应性的所有可能机制和场景，而活性模型仅反映了它们明确训练过的机制和场景（某些数据，如人类大脑发育过程中的蛋白质表达，获取难度较大）。另一方面，活性模型可以指出变异发挥作用的特定机制和场景，而功能约束模型则不提供机制解释。</p>\n<p>关于功能性变异的优先排序，还有一些额外的考量。对于两个在不同基因中引起相似表达倍数变化的变异，即使它们的表达水平在生理耐受性上存在巨大差异，活性模型通常也会给出相似的得分。另一方面，不受可检测选择影响的性状仍可能具有科学或医学意义。在这种情况下，功能约束模型在优先排序影响该性状的变异方面能力有限，尤其是当这些变异效应量较小时（如在复杂性状全基因组关联研究（GWAS）中常见的情况）。然而，尽管基因组语言模型的对数似然比在这种情况下可能效果不佳，但基因组语言模型学习到的嵌入（<strong>BOX 1</strong>）在有标记数据的额外监督下仍可能具有价值。</p>\n<h3 id=\"2-2-序列设计\"><a href=\"#2-2-序列设计\" class=\"headerlink\" title=\"2.2 序列设计\"></a>2.2 序列设计</h3><p>设计新的生物序列对学术界和工业界研究团体都极具吸引力，因为它在药物发现与递送、农业改良、生物修复以及生物研究工具开发等方面具有巨大潜力。在此，我们描述使用<code>因果语言模型</code>（<strong>BOX 1</strong>）进行序列生成的方法，这是最常用的方法。具体而言，序列生成任务被分解为一系列下一个标记预测问题。从给定的序列片段（称为提示或控制标签）开始，语言模型可以递归地预测下一个标记，从而生成完整的新序列。蛋白质语言模型已被证明是蛋白质设计的强大工具。除编码序列外，非编码序列的设计也至关重要，因为它在基因和细胞治疗以及合成生物学等领域有应用。此类设计任务以前通过有监督的活性模型解决，但最近有多项研究探索使用基因组语言模型来应对这一挑战，如下所述。</p>\n<p><code>regLM</code>模型基于因果基因组语言模型<code>HyenaDNA</code>构建，用于<strong>从头生成启动子和增强子序列</strong>。HyenaDNA模型在带有前置控制标签的调控序列上进行训练或微调。然后，使用训练好的模型生成带有给定标签的新调控序列（<strong>图2c</strong>）。作者在酵母和人类细胞系中对生成序列的多样性和活性进行了计算评估，证明这些序列具有预期的功能以及真实且多样的序列特征。</p>\n<p>基因组语言模型在多模态设计任务中具有独特潜力，例如通过将蛋白质-RNA复合物统一为DNA序列设计来生成此类复合物。<u>例如，在原核生物基因组上训练的基因组语言模型EVO被用于设计新的CRISPR-Cas系统</u>。该模型使用带有前置Cas亚型特异性提示的CRISPR-Cas序列数据集进行微调。微调后的模型能够生成与亚型提示匹配的新CRISPR-Cas序列，且其预测结构与天然存在的系统相似。</p>\n<p>此外，<u>基因组语言模型还有可能用于在染色体或基因组尺度上设计有组织的功能性DNA序列</u>。最近，两个基因组语言模型<code>MegaDNA</code>和<code>EVO</code>探索了原核生物基因组的此类设计任务。EVO用于生成20个约650 Mbp大小的序列。研究发现，生成的序列具有真实的编码序列密度、具有预测二级结构和球状折叠的蛋白质序列，以及合理的tRNA序列。MegaDNA用于生成长达96 kbp的完整噬菌体基因组。除验证编码序列外，作者还在生成的序列中识别出包括启动子和核糖体结合位点在内的功能性调控元件。然而，此类大规模DNA序列设计任务仍然具有挑战性。研究发现，<u>EVO生成的序列缺乏功能原核生物基因组中通常存在的高度保守标记基因，且预测的蛋白质结构与天然蛋白质数据库的匹配度有限。最近的一项独立评估表明，MegaDNA生成的基因组序列组成与天然基因组仍有很大差异</u>。因此，需要进一步研究改进方法，以实现使用基因组语言模型从头设计完全功能性的基因组。</p>\n<h3 id=\"2-3-迁移学习\"><a href=\"#2-3-迁移学习\" class=\"headerlink\" title=\"2.3 迁移学习\"></a>2.3 迁移学习</h3><p>通过功能基因组学实验训练的用于预测注释的神经网络已被广泛用于解释基因组元件的功能。<u>一个重要的应用是预测变异对分子表型的影响，例如基因表达和剪接</u>。神经网络能够解释基因组位点之间复杂相互作用的能力，使其成为解决这些重要问题的必备工具，但合适的训练数据通常难以收集，因此数量有限。为了在预测任务上实现泛化，模型需要能够识别广泛的功能重要序列元件，这可能需要大量的数据和计算资源。为克服单个任务数据不足的限制，开发者采用了迁移学习方法——即利用在一个任务上训练模型获得的知识来改进相关任务性能的技术。具体而言，大多数用于预测功能注释的神经网络都经过训练以同时预测多种注释，迫使这些模型学习单一的统一表示。这进而提高了它们的泛化性能。</p>\n<p>语言模型也可用于迁移学习（有关迁移学习在自然语言处理中的应用，请参见<strong>BOX 2</strong>）。一种技术是特征提取：在学习预测核苷酸的上下文依赖分布时，基因组语言模型将输入的基因组序列转换为中间向量表示<strong>BOX 1</strong>）。这些表示可能提炼了相关信息，因此可用作另一个模型的特征。例如，<u>基因组语言模型嵌入的可视化显示，在没有任何监督的情况下，模型已经学会区分不同类别的基因组元件，如编码序列和非翻译区（<strong>图2d</strong>）</u>。不同层的嵌入可以为不同任务提供有用信息。利用语言模型进行迁移学习的另一种方法是将其用作预训练模型，即在下游任务上继续训练它们。这种技术称为微调。在某个任务上微调预训练的神经网络，会隐式地对其参数进行正则化，使得网络的预测综合了来自两个任务的知识。因此，对神经网络进行预训练通常会提高其在下游任务上的泛化性能。在最近的研究中，<code>SegmentNT</code>模型（通过微调核苷酸转换器（NT）基因组语言模型以实现<strong>基因和顺式调控元件注释</strong>任务而开发）在该任务上取得了最先进的性能。研究表明，使用预训练模型是其取得成功的关键。类似地，NT家族的另一个模型<code>AgroNT</code>在多种植物物种上进行预训练，然后在选定的作物物种上微调以预测染色质可及性和基因表达。<code>DNABERT-S</code>将对比学习与预训练的<code>DNABERT-2</code>嵌入相结合，用于<strong>宏基因组分箱</strong>。<code>IsoFormer</code>是DNA和蛋白质语言模型之间多模态迁移学习的一个例子，用于<strong>预测转录本亚型表达</strong>。这些最近的成功表明，微调后的基因组语言模型可能在各种基因组解释任务上取得显著进展。</p>\n<p>最近有两项研究评估了多个基因组语言模型在人类基因组预测任务中的性能，发现它们通常不会优于非基因组语言模型基准。这些结果基于冻结的嵌入；评估完整的微调过程将提供更多见解。尽管基因组语言模型已经非常适合展示迁移学习在研究较少的生物体中的价值，但要使其在人类遗传学（已有高质量标记数据和精心设计的模型）中提供显著价值，可能还需要进一步的创新。一个重要的问题是，缩放假设对基因组语言模型的适用程度如何，即增加未标记数据和计算资源在多大程度上能持续提高模型性能。最近的一项蛋白质语言模型研究发现，缩放仅改进了蛋白质结构预测，而没有改进大多数其他任务（如功能或性质预测），因此基因组语言模型任务也应受到同样的审视。</p>\n<p><font size=2 color='grey'> <strong>BOX 2</strong>：自然语言处理中的迁移学习<br>为了在大多数任务（包括情感分析、问答和词性标注等典型任务）上实现泛化，自然语言处理模型需要理解语法和语义。然而，这些任务的特定数据通常有限。利用在原始文本数据（来源于文章、书籍和网站）上训练的大型语言模型进行迁移学习，已在这些问题上取得了突破性进展。如今，几乎所有最先进的自然语言处理模型都是从大型语言模型改编而来。</font></p>\n<p>迁移学习技术是近年来自然语言模型蓬勃发展的基础。特别是，可广泛适配于下游任务的预训练模型（称为“基础模型”）的出现，使得机器学习模型的开发方式发生了重大转变。</p>\n<h2 id=\"3-开发\"><a href=\"#3-开发\" class=\"headerlink\" title=\"3 开发\"></a>3 开发</h2><p>现在，我们描述开发有用的基因组语言模型的关键组成部分；<strong>图3</strong>展示了总结开发流程的示意图。我们首先阐述选择和准备训练数据的重要性，然后讨论架构和训练决策，接着考虑基因组语言模型的解释和基准测试。我们的目标是<u>深入了解开发有效且高效的基因组语言模型所涉及的方法和挑战</u>。为全面展示该领域的当前状况，我们在<strong>表1</strong>中列出了一些我们已知的现有基因组语言模型，并总结了它们的设计决策。</p>\n<h3 id=\"3-1-训练数据\"><a href=\"#3-1-训练数据\" class=\"headerlink\" title=\"3.1 训练数据\"></a>3.1 训练数据</h3><p>机器学习模型的性能在很大程度上受其架构和训练数据的影响。卷积神经网络（CNNs）、Transformer 和状态空间模型（SSMs）等各种模型架构已成功应用于广泛的领域，包括自然语言、图像、音频、蛋白质和基因组学。然而，为预训练选择合适的数据需要对特定领域有深入的理解，尤其是<u>在基因组学领域，目前尚无类似于自然语言处理（如Pile）或蛋白质生物学（如UniProt）中那样被普遍接受的精选数据集</u>。</p>\n<p><strong>一个关键的考量因素是数据质量</strong>。例如，在自然语言处理中，数据质量可能指经过编辑或同行评审的数据源，如科学文章或书籍。<u>在蛋白质领域，质量控制包括去除预测的假基因或不再具有功能的截断蛋白质</u>。然而，最近的一项研究发现，作为最常用的基因组语言模型训练数据集（<strong>表1</strong>）的人类参考基因组中，仅有3.3%的碱基受到显著约束且可能具有功能。重要的是，<u>用于训练基因组语言模型的典型基因组序列既包含<code>功能位点</code>，也包含<code>非功能位点</code>，且通常无法将训练样本明确分为<code>高质量</code>和<code>低质量</code>两类</u>。一个提出的解决方案是根据功能证据对训练损失进行碱基级加权。</p>\n<p>在自然语言处理和蛋白质领域，<strong>过滤重复序列</strong>是标准做法，这有助于提高训练效率并减少记忆。尽管人类基因组中高达50%的序列是重复序列（在真核生物中这一比例普遍较高），但很少有基因组语言模型研究提出解决方案（如降低权重或下采样），甚至很少有研究承认这一问题。如果语言模型困惑度的研究也能分别报告非重复区域的困惑度，以区分泛化改进和记忆改进，那将很有启发意义。</p>\n<p><strong>另一个关键问题是如何确保数据量充足</strong>。单个基因组可能不足以训练大型模型，尤其是当非功能区域被下采样或降低权重时。一种方法是添加同一物种的序列变异。然而，在包括人类在内的许多物种中，个体之间的变异相对较少。更常用的方法是<code>跨多个物种进行训练</code>（<strong>表1</strong>），这与蛋白质语言模型的做法类似。随着物种亲缘关系的疏远，调控逻辑的分化速度快于蛋白质。一种提出的方法是<strong>将物种标识符作为额外输入明确添加到模型中</strong>。尽管如此，一个足够大的模型，在有足够基因组上下文的情况下，仍有可能自然地对远缘基因组进行建模，类似于大型语言模型处理多语言数据集的方式。</p>\n<p>如前所述，在原核生物中，已有模型（MegaDNA和EVO）将整个基因组作为上下文。目前，这在真核生物中还不可行，因此产生了<strong>如何将基因组划分为可单独建模的上下文窗口的问题</strong>。许多相互作用局限于邻近位置（如转录因子结合位点基序），这推动了具有相对较小上下文（&lt;6 kb）的模型的开发（**表1**）。然而，也存在明显的长程相互作用，例如同一基因的外显子之间或增强子与启动子之间（可达1 Mb）。如此长的上下文长度带来了计算和统计挑战，研究人员已在努力克服这些挑战。无论选择何种上下文长度，将基因组划分为独立单元（类似于按蛋白质划分蛋白质组的方式）仍然并非易事。例如，<u>一个基因的增强子可能位于另一个基因的内含子中，且多个基因可能由同一个增强子调控。尤其是在跨物种训练时，避免因直系同源和旁系同源导致的数据泄露非常具有挑战性</u>。</p>\n<p>训练数据的选择可能会显著影响基因组语言模型的输出和学习到的表示。自然界中观察到的DNA序列是各种进化过程的结果，其中最主要的是突变和选择。对于某些应用，可能需要精心选择训练数据，以突出这些过程中的某一个。例如，为了进行适应性预测，可能需要排除&#x2F;降低高突变位点（如CpG位点）和非功能区域（如某些类型的重复元件）的权重。</p>\n<h3 id=\"3-2-模型架构\"><a href=\"#3-2-模型架构\" class=\"headerlink\" title=\"3.2 模型架构\"></a>3.2 模型架构</h3><p>在Transformer架构出现之前，<code>卷积神经网络</code>模型已被广泛用于基因组学中的有监督任务。卷积神经网络通过对输入数据应用<code>过滤器</code>，特别<u>擅长捕捉基因组序列中的局部依赖关系和基序</u>。这些模型在预测<strong>DNA-蛋白质结合位点</strong>、<strong>调控元件</strong>和<strong>转录因子结合位点</strong>方面取得了成功。前面提到的用于拟南芥全基因组变异效应预测的基因组语言模型GPN，借鉴了自然语言处理和蛋白质建模中带有改进卷积神经网络层的语言模型的成功经验，用<code>扩张卷积神经网络层</code>替换了Transformer<code>编码器中的自注意力层</code>。</p>\n<p><code>Transformer</code>模型彻底改变了各种机器学习领域，尤其是自然语言处理，并且最近被广泛应用于基因组学建模。自注意力机制允许每个标记同时关注输入序列中的所有位置，使模型能够动态关注序列的相关部分。这种能力在有监督的基因表达任务中检测调控机制方面取得了显著进展。</p>\n<p>尽管Transformer模型具有优势，但它们在基因组学建模中面临一些独特的<strong>挑战</strong>。一个重要问题是，<u>Transformer对相互作用的局部性几乎没有或没有归纳偏置，这使得它们在建模转录因子结合位点等局部基序时数据效率较低</u>。这促使人们开发<strong>卷积神经网络-Transformer混合模型</strong>，如<code>LOGO</code>，其借鉴了<code>Enformer</code>等有监督模型的思路。</p>\n<p><strong>另一个挑战是上下文长度</strong>：自注意力机制导致<strong>计算时间和内存随输入序列长度呈二次方增长</strong>，这使得将Transformer应用于极长的基因组序列变得不切实际。因此，传统基于注意力的基因组语言模型目前能够处理的最长输入长度是<code>NT-v2的12 kb</code>。为解决这一限制，一些基于Transformer的基因组语言模型采用了<code>近似注意力</code>或<code>分层注意力</code>方法，牺牲了所有标记之间的完全成对注意力。这些方法包括在<code>GENA-LM</code>中使用稀疏注意力（将上下文长度扩展到<code>36 kb</code>），以及在<code>MegaDNA</code>中采用MEGABYTE亚二次方分层自注意力（实现<code>了96 kb</code>的上下文长度）。</p>\n<p>为克服自注意力的二次方缩放问题，人们提出了各种状态空间模型（SSMs）作为Transformer的高效替代方案，用于基因组语言模型，其<strong>计算复杂度随序列长度接近线性增长</strong>。基于·层次结构的<code>HyenaDNA</code>能够支持长达<code>100万</code>个核苷酸的输入上下文。<code>EVO</code>是一种结合了Hyena和Transformer架构的混合模型，在8 kb序列上进行预训练，然后在上下文扩展阶段使用<code>131 kb</code>序列进行微调。基于Mamba的状态空间模型构建的<code>Caduceus</code>在<code>131 kb</code>序列上进行训练，同时融入了反向互补等变。</p>\n<h3 id=\"3-3-学习目标\"><a href=\"#3-3-学习目标\" class=\"headerlink\" title=\"3.3 学习目标\"></a>3.3 学习目标</h3><p>如<strong>BOX 1</strong>所述，掩码语言模型（MLM）任务（有时也称为“掩码标记预测”）要求模型根据剩余标记预测以预定概率（通常为15%）随机掩码的标记身份。这一框架已用于训练开创性的大型语言模型BERT和蛋白质语言模型<code>ESM-1b</code>，此后被广泛用于训练基因组语言模型。因果语言模型（CLM）任务（也称为“自回归语言建模”或“下一个标记预测”）要求模型根据前面的标记预测序列中的标记；该任务已用于训练GPT系列大型语言模型。在该任务中，模型以单向从左到右的顺序，根据前面的标记预测下一个标记。这两个任务的共同点是，它们都要求模型根据其他组件作为上下文来预测数据的组件。为了在这些任务上实现泛化，模型必须学习数据的低维表示。这种能力使基因组语言模型能够通过捕捉基因组内的潜在模式和依赖关系来理解和生成基因组序列。<u>在蛋白质建模中，掩码语言模型在表示学习和迁移学习能力方面通常优于因果语言模型</u>。另一方面，因果语言模型是生成任务的传统选择，但最近通过渐进式掩码，掩码语言模型在生成任务上也取得了优异结果。</p>\n<p>为减少输入序列长度并建模更长的上下文，k-mer和字节对编码（BPE）创建了比天然核苷酸词汇表（{A,C,G,T}）更大的人工定义核苷酸词汇表。另一方面，单核苷酸标记化简化了模型解释和归因，并增强了模型处理基因组变异的能力。</p>\n<p>研究人员探索了对训练目标的多种修改，以提供额外的信号并提高性能。例如，<code>GPN-MSA</code>通过脊椎动物物种的全基因组多序列比对（MSA）增强了在人类参考基因组上的掩码语言模型训练，利用相关物种间的保守性获取额外上下文。其局限性在于，全基因组多序列比对仅针对某些物种生成，要在植物中有效应用可能需要进一步开发。此外，即使顺式调控元件的活性保守，其序列也可能快速分化，这限制了通过比对提取的直系同源信息。<code>Species LM</code>通过为每个酵母物种分配一个专用标记，并在训练和推理期间将物种标记附加到输入序列，直接整合了物种信息。核苷酸序列的预训练已扩展到支持与其他模态的交互，如表观遗传学、RNA、蛋白质和自然语言。</p>\n<h3 id=\"3-4-解释\"><a href=\"#3-4-解释\" class=\"headerlink\" title=\"3.4 解释\"></a>3.4 解释</h3><p>尽管深度学习模型在各种预测任务中取得了显著性能，但它们通常缺乏可解释性，常被视为“黑箱”。然而，理解这些模型如何生成预测对于实现更广泛的应用和推进模型开发至关重要。因此，研究人员开发了一系列解释深度学习模型的方法，包括专门针对基因组学的方法。尽管基因组语言模型的解释仍是一个新兴的研究方向，但已有研究表明，一些模型已经学习到了有意义的生物模式。</p>\n<p>从语言模型中提取的序列嵌入通常被用作捕捉丰富上下文信息和序列特征的表示。<u>对基因组语言模型编码的序列嵌入进行无监督聚类，发现输入序列形成了对应于不同基因组类别（如编码序列、内含子、非翻译区等）的明显聚类</u>（<strong>图2d</strong>）。此外，<u>对<code>SpliceBERT</code>嵌入的典型剪接位点和非剪接GT&#x2F;AG位点进行无监督聚类，发现了对应于这两组位点的明显聚类</u>。这些结果表明，模型已经学会捕捉表征基因组中功能元件的关键上下文模式。</p>\n<p>Transformer模型中的注意力机制旨在捕捉输入标记之间的交互模式。因此，解释给定输入序列的注意力权重或注意力图，可以揭示模型学习到的基因组特征。<u>在SpliceBERT中，剪接供体位点和受体位点之间的注意力权重显著高于随机位点对之间的注意力权重；此外，真实供体-受体对之间的交互强度往往高于其他供体和受体位点组合</u>。这些发现表明，模型已经学会了功能交互位点之间的关系。</p>\n<p>一些基因组语言模型还采用核苷酸重建方法来发现模型学习到的序列基序。具体而言，将输入序列的各个位置逐一掩码，然后由训练好的模型根据基因组上下文预测核苷酸的概率分布。每个位点获得的分布可以揭示模型学习到的基序。GPN中采用了这种方法，在重建核苷酸的分布中发现了显著模式。特别是，<strong>模型在功能重要位点的预测通常更有信心</strong>。例如，编码序列和剪接供体&#x2F;受体位点的预测信心通常高于深层内含子位点。此外，在编码序列中，密码子的第三个核苷酸位置（对翻译的氨基酸决定作用最小）的预测信心通常低于前两个核苷酸位置。通过适配<code>TF-MoDISco</code>（一种利用模型预测识别新转录因子结合位点的专用工具），作者还发现了与转录因子结合位点数据库和相关文献中已知基序匹配的序列基序（<strong>图2a</strong>）。类似地，Species LM重建的序列基序也与训练中未见过的物种中已知的DNA和RNA结合蛋白的结合位点匹配，基序重建的准确性取决于正确反映体内结合位点的上下文和基因组区域。此外，重建基序的组成、存在和位置表现出物种特异性模式，这表明<u>基因组语言模型可能成为研究序列基序和调控密码进化的强大工具</u>。</p>\n<p>最近，研究人员通过在某个位置引入点突变并量化其他位置核苷酸概率的变化，研究了基因组语言模型学习到的基因组位置之间的依赖关系。核苷酸依赖分析揭示了模型学习到的功能元件（如转录因子结合位点、剪接位点和RNA）内部和之间的相互作用，包括已知的二级和三级结构接触。值得注意的是，与之前基于预测边际概率分布的方法相比，核苷酸依赖分析能够更稳健地检测结合的转录因子结合位点。</p>\n<h3 id=\"3-5-评估\"><a href=\"#3-5-评估\" class=\"headerlink\" title=\"3.5 评估\"></a>3.5 评估</h3><p>在本节中，我们将讨论如何针对前面描述的三个应用领域对模型性能进行基准测试：预测等位基因的功能约束、生成新的可行序列以及迁移学习。</p>\n<p>有多种类型的数据可以反映等位基因的功能约束，可用于基准测试变异效应预测器。<strong>一类</strong>数据来自将<code>遗传变异的功能差异与读数</code>(readouts)（如报告基因的表达或细胞生长）相关联的实验。这些读数可用于对变异的功能性进行排序，由于影响功能的变异通常也受到选择，因此我们期望这些排序与模型预测的排序相关。这类数据的一个来源是<code>ProteinGym</code>，这是一个广泛使用的实验数据集集合，可用于基准测试错义变异效应预测器。<strong>另一类</strong>数据是<code>临床标记</code>，指示变异是否有致病证据（即是否会增加疾病风险）。致病性变异可能影响生育能力，因此可能具有有害性。因此，我们可以通过评估变异效应预测器作为致病性分类器的性能来对其进行基准测试。在人类遗传学中，变异临床标记的主要来源包括<code>ClinVar</code>、<code>HGMD</code>和<code>OMIM</code>数据库。<strong>第三类</strong>数据是<code>变异频率</code>。由于常见变异不太可能具有高度有害性，它们的预测约束水平应相对高于罕见变异。因此，我们可以根据预测器识别常见变异的能力对其进行基准测试。人类不同祖先群体中等位基因频率数据的主要来源是<code>gnomAD</code>数据库。总之，这些数据可以作为模型泛化性能的独立证据。</p>\n<p>变异效应预测器评估的一个问题是，验证数据与功能约束之间的关系可能不明确。因此，模型可能通过利用数据未能捕捉功能约束的方面在基准测试中表现出色。例如，使用临床标记的一个关键问题是，变异的分类基于是否有充分证据证明它们是良性的或致病性的。由于预测器也可能利用这些证据，它们在标记变异上的基准测试性能可能无法反映其在未标记变异上的真实性能（有关泛化性能的简要讨论，请参见<strong>BOX 3</strong>）。使用等位基因频率数据也存在关键问题：例如，除自然选择的直接作用外，等位基因频率还受突变率、遗传漂变、背景选择和遗传搭车等因素影响。因此，预测器可能通过预测这些过程的影响而非功能约束在基准测试中表现良好。这些问题凸显了需要仔细解释预测器性能原因的重要性，并促使人们呼吁提高预测器训练所使用的数据和方法的透明度。</p>\n<p>生成式序列模型的评估面临一系列独特挑战。评估语言模型生成能力的一种基本方法是比较它们在有效序列集上的困惑度。然而，要评估模型设计新序列的能力，需要衡量它们是否能够识别既可行又新颖的序列。因此，模型在测试集上的困惑度可能无法可靠地表明其在设计任务中的实用性。相反，可能需要采用全面的方法，检查生成序列的广泛特性。例如，最近用于调控序列设计的基准测试工具<code>Polygraph</code>提出了一系列分析方法，用于研究序列组成、基序模式和预测的功能活性。对于全基因组或染色体设计任务，可能还需要评估必需基因和功能性调控元件的存在和位置，以及它们之间的相互作用。最终，设计的序列需要通过实验评估，以确定它们是否能实现预期功能。</p>\n<p>最后，评估基因组语言模型在迁移学习中的性能面临一个独特挑战：任何基准测试集（可能需要结合多个基准测试集）都必须能够可靠地表明模型在相关任务上的性能。功能基因组学数据（如来自ENCODE或Roadmap表观基因组学项目的数据）可用于注释基因组区域和变异，这类数据可构建一系列任务，广泛反映模型适应基因组解释的能力。我们期望，模型在适应后从基因组序列预测这些注释的性能，能够表明其识别功能相似基因组元件的能力。为便于模型之间的比较，这些注释已被整合到各种标准化的训练和测试数据集集合中。</p>\n<p>由于迁移学习基准测试有助于凸显当前模型的局限性，并为发表建立标准，因此它们可能成为基因组语言模型开发者和用户的重要资产。然而，尽管当前基准测试在任务选择和方法上存在差异，但它们对基因组语言模型能力的见解似乎存在冗余。未来，计算基因组学界需要开发广泛认可的标准化且可扩展的基准测试。</p>\n<p><font size=2 color='grey'> <strong>BOX 3</strong>：评估泛化性能<br>评估预测模型的目的是建立对其泛化能力的信任，即对未标记数据做出令人满意的预测。估计模型泛化性能的一种直接且标准的方法是在代表目标未标记数据的标记“测试集”上评估其准确性。这种方法是大多数机器学习基准测试的基础。</p>\n<p>重要的是，为使这种评估成为泛化性能的可靠指标，不得向模型提供任何可用于区分测试集数据和最终部署数据的信息。否则，模型可能会以牺牲泛化性能为代价降低测试集误差。因此，通常会组织向参与者隐瞒测试数据的机器学习竞赛。<br></font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Table01.png\" alt=\"表1：现有基因组语言模型总结\"></p>\n<p><font size=2 color='grey'>提供了各种基因组语言模型的概述，重点介绍了它们的预训练数据集、任务、架构、标记化方法和独特特征。模型按公开发布日期排序。缩写包括：SSM（状态空间模型）、CNN（卷积神经网络）、BPE（字节对编码）、CLM（因果语言建模）、MLM（掩码语言建模）。</font></p>\n<p><img src=\"https://raw.githubusercontent.com/liaochenlanruo/cdn/master/images/post/BioAI/02/Fig03.png\" alt=\"图3：开发流程\"></p>\n<p><font size=2 color='grey'>该图展示了本综述中描述的基因组语言模型通用开发流程，从模型构思到部署。我们首先选择和准备训练数据集，强调数据质量和数量的重要性（训练数据）。随后，在模型架构和学习目标部分，我们探讨了设计和训练基因组语言模型的各种选择，讨论了不同方法的优缺点。我们还研究了混合模型如何结合多种架构的元素以缓解特定局限性。在解释部分，我们讨论了分析和解释基因组语言模型输出的方法。最后，在评估部分，我们通过当前基准测试介绍了评估方法，强调了使模型性能与实际生物功能保持一致的复杂性。</font></p>\n<h2 id=\"4-结论与未来展望\"><a href=\"#4-结论与未来展望\" class=\"headerlink\" title=\"4 结论与未来展望\"></a>4 结论与未来展望</h2><p>在基因组序列数量庞大且不断增长的时代，基因组语言模型正成为提取复杂模式的强大工具，可应用于功能约束估计、序列设计和迁移学习等多个领域。然而，正如“人工智能”一词可能暗示的那样，它们尚未实现神奇的突然突破。相反，我们将其视为另一种有用的建模工具，类似于隐马尔可夫模型刚出现时的情况。基因组语言模型通常被称为“基础模型”，这一术语最近被创造出来，指在广泛数据上训练、可适应各种下游任务的模型。这一新术语的引入受到了批评，因为“基础”一词意味着在下游任务性能上有显著改进，而这是一个实证问题，而非预训练模型的固有属性。在基因组学等新领域，这种批评更为强烈，因为建立足够的基准测试可能需要一些时间。</p>\n<p>早期的基因组语言模型或多或少是自然语言处理模型的直接改编，我们期望通过深入结合基因组学专业知识，能获得最大的收益。我们注意到，评估基因组语言模型的能力具有挑战性，因为指标可能具有误导性，尤其是在过度优化的情况下。自然语言处理的一个优势是人类是自然语言的专家，因此可以根据自身专业知识校准基准测试。然而，在基因组学中，我们必须依靠数据和专家知识来验证模型。问题的这一方面使其特别具有挑战性，并可能意味着需要与领域专家合作，并有意识地进行实验以开发基准测试。在本综述的最后，我们提出了一些我们认为值得进一步研究的方向（列于未解决的问题中）。</p>\n<h3 id=\"未解决的问题\"><a href=\"#未解决的问题\" class=\"headerlink\" title=\"未解决的问题\"></a>未解决的问题</h3><ol>\n<li>如何最好地对从基序到基因再到全基因组的各种尺度模式进行建模？</li>\n<li>哪些应用需要对长程相互作用进行建模？如何确定合适的感受野大小？</li>\n<li>如何将结构变异纳入基因组语言模型？</li>\n<li>训练基因组语言模型时，利用群体遗传数据的最佳方式是什么？</li>\n<li>如何最好地将基因组语言模型与其他复杂模态（如转录组学和表观遗传学数据）整合？</li>\n<li>在开发基因组语言模型时，如何更好地理解为什么某些基因组比其他基因组更难建模？</li>\n<li>缩放假设对基因组语言模型是否成立？能成立多久？考虑到大多数数据可能是非功能性的，是否真的有足够的数据可用？</li>\n</ol>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li>Gonzalo Benegas, Chengzhong Ye, Carlos Albors, Jianan Canal Li, Yun S. Song. arXiv:2407.11435v2. doi: <a href=\"https://doi.org/10.48550/arXiv.2407.11435\">https://doi.org/10.48550/arXiv.2407.11435</a></li>\n</ul>\n<h2 id=\"加关注\"><a href=\"#加关注\" class=\"headerlink\" title=\"加关注\"></a>加关注</h2><p>关注公众号“生信之巅”，聊天窗口回复“85d7”获取下载链接。</p>\n<table align=\"center\"><tr>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/生信之巅公众号.jpg\" alt=\"生信之巅微信公众号\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-right: 0px;margin-bottom: 5px;align: center;\"></td>\n  <td align=\"center\"><img src=\"https://cdn.jsdelivr.net/gh/liaochenlanruo/cdn@master/img/social/小程序码.png\" alt=\"生信之巅小程序码\" style=\"width: 100px;height: 100px;vertical-align: -20px;border-radius: 0%;margin-left: 0px;margin-bottom: 5px;align: center\"></td>\n</tr></table>\n","categories":[{"name":"BioAI","path":"api/categories/BioAI.json"}],"tags":[{"name":"LLM","path":"api/tags/LLM.json"},{"name":"生物信息","path":"api/tags/生物信息.json"}]}