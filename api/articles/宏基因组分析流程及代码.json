{"title":"宏基因组分析流程及代码","slug":"宏基因组分析流程及代码","date":"2021-01-19T07:24:28.000Z","updated":"2024-03-11T13:07:17.000Z","comments":true,"path":"api/articles/宏基因组分析流程及代码.json","excerpt":"本文阐述宏基因组物种分类、组装、bining、基因预测及注释……","covers":null,"content":"<p>本文阐述宏基因组物种分类、组装、bining、基因预测及注释……</p>\n<span id=\"more\"></span>\n\n<h1 id=\"A、软件列表及安装\"><a href=\"#A、软件列表及安装\" class=\"headerlink\" title=\"A、软件列表及安装\"></a>A、软件列表及安装</h1><h2 id=\"A-1-分类相关\"><a href=\"#A-1-分类相关\" class=\"headerlink\" title=\"A.1 分类相关\"></a>A.1 分类相关</h2><h3 id=\"A-1-1-metaphlan-3-0\"><a href=\"#A-1-1-metaphlan-3-0\" class=\"headerlink\" title=\"A.1.1 metaphlan 3.0\"></a>A.1.1 metaphlan 3.0</h3><p>MetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequencing data.</p>\n<h4 id=\"a-安装主文件\"><a href=\"#a-安装主文件\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n metaphlan python=3.7 metaphlan</span><br><span class=\"line\">$ conda activate metaphlan</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装数据库\"><a href=\"#b-安装数据库\" class=\"headerlink\" title=\"b. 安装数据库\"></a>b. 安装数据库</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metaphlan --install</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"c-安装依赖包\"><a href=\"#c-安装依赖包\" class=\"headerlink\" title=\"c. 安装依赖包\"></a>c. 安装依赖包</h4><ul>\n<li>hclust<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda install -c bioconda hclust2</span><br></pre></td></tr></table></figure></li>\n<li>R, vegan, ape <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda install r-base r-vegan r-ape</span><br></pre></td></tr></table></figure></li>\n<li>rbiom<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ R</span><br><span class=\"line\">$ install.packages(<span class=\"string\">&quot;rbiom&quot;</span>)</span><br><span class=\"line\">$ quit()</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"A-1-2-gtdbtk\"><a href=\"#A-1-2-gtdbtk\" class=\"headerlink\" title=\"A.1.2 gtdbtk\"></a>A.1.2 <a href=\"https://ecogenomics.github.io/GTDBTk/\">gtdbtk</a></h3><h4 id=\"a-Hardware-requirements\"><a href=\"#a-Hardware-requirements\" class=\"headerlink\" title=\"a. Hardware requirements\"></a>a. Hardware requirements</h4><table>\n<thead>\n<tr>\n<th>Domain</th>\n<th>Memory</th>\n<th>Storage</th>\n<th>Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Archaea</td>\n<td>~8 GB</td>\n<td>~27 GB</td>\n<td>~1 hour &#x2F; 1,000 genomes @ 64 CPUs</td>\n</tr>\n<tr>\n<td>Bacteria</td>\n<td>~150 GB</td>\n<td>~27 GB</td>\n<td>~1 hour &#x2F; 1,000 genomes @ 64 CPUs</td>\n</tr>\n</tbody></table>\n<h4 id=\"b-Install-GTDB-Tk-with-conda\"><a href=\"#b-Install-GTDB-Tk-with-conda\" class=\"headerlink\" title=\"b. Install GTDB-Tk with conda\"></a>b. Install GTDB-Tk with conda</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n gtdbtk -c conda-forge -c bioconda gtdbtk</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"c-GTDB-Tk-reference-data\"><a href=\"#c-GTDB-Tk-reference-data\" class=\"headerlink\" title=\"c. GTDB-Tk reference data\"></a>c. GTDB-Tk reference data</h4><ul>\n<li><strong>Note that different versions of the GTDB release data may not run on all versions of GTDB-Tk, below are all supported versions:</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>GTDB Release</th>\n<th>Minimum version</th>\n<th>Maximum version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>R95</td>\n<td>1.3.0</td>\n<td>N&#x2F;A</td>\n</tr>\n<tr>\n<td>R89</td>\n<td>0.3.0</td>\n<td>0.1.2</td>\n</tr>\n<tr>\n<td>R86.2</td>\n<td>0.2.1</td>\n<td>0.2.2</td>\n</tr>\n<tr>\n<td>R86</td>\n<td>0.1.0</td>\n<td>0.1.6</td>\n</tr>\n<tr>\n<td>R83</td>\n<td>0.0.6</td>\n<td>0.0.7</td>\n</tr>\n</tbody></table>\n<ul>\n<li>Download the reference data</li>\n</ul>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ wget https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/auxillary_files/gtdbtk_r95_data.tar.gz</span><br><span class=\"line\">  </span><br><span class=\"line\">$ tar xvzf gtdbtk_r95_data.tar.gz</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：GTDB-Tk requires an environment variable named GTDBTK_DATA_PATH to be set to the directory containing the unarchived GTDB-Tk reference data.</p>\n<ul>\n<li>You can automatically alias GTDBTK_DATA_PATH whenever the environment is activated by editing {gtdbtk environment path}&#x2F;etc&#x2F;conda&#x2F;activate.d&#x2F;gtdbtk.sh, e.g.:</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Determine the GTDB-Tk environment path</span></span><br><span class=\"line\">$ conda activate gtdbtk</span><br><span class=\"line\">$ <span class=\"built_in\">which</span> gtdbtk</span><br><span class=\"line\"><span class=\"comment\"># /miniconda3/envs/gtdbtk-1.3.0/bin/gtdbtk</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Edit the activate file</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">&quot;export GTDBTK_DATA_PATH=/path/to/release/package/&quot;</span> &gt; /miniconda3/envs/gtdbtk-1.3.0/etc/conda/activate.d/gtdbtk.sh</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"A-1-3-Kraken2\"><a href=\"#A-1-3-Kraken2\" class=\"headerlink\" title=\"A.1.3 Kraken2\"></a>A.1.3 <a href=\"https://github.com/DerrickWood/kraken2\">Kraken2</a></h3><h4 id=\"a-Hardware-requirements-1\"><a href=\"#a-Hardware-requirements-1\" class=\"headerlink\" title=\"a. Hardware requirements\"></a>a. Hardware requirements</h4><ul>\n<li>Disk space: Construction of a Kraken 2 standard database requires approximately 100 GB of disk space. A test on 01 Jan 2018 of the default installation showed 42 GB of disk space was used to store the genomic library files, 26 GB was used to store the taxonomy information from NCBI, and 29 GB was used to store the Kraken 2 compact hash table.</li>\n<li>Memory: To run efficiently, Kraken 2 requires enough free memory to hold the database (primarily the hash table) in RAM. While this can be accomplished with a ramdisk, Kraken 2 will by default load the database into process-local RAM; the –memory-mapping switch to kraken2 will avoid doing so. The default database size is 29 GB (as of Jan. 2018), and you will need slightly more than that in RAM if you want to build the default database.</li>\n</ul>\n<h4 id=\"b-Install-Kraken2-with-conda\"><a href=\"#b-Install-Kraken2-with-conda\" class=\"headerlink\" title=\"b. Install Kraken2 with conda\"></a>b. Install Kraken2 with conda</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n kraken2 kraken2</span><br></pre></td></tr></table></figure>\n<h4 id=\"c-Build-the-database\"><a href=\"#c-Build-the-database\" class=\"headerlink\" title=\"c. Build the database\"></a>c. Build the database</h4><ul>\n<li>下载数据库。找到一个存储空间比较大的目录并进入，运行如下命令，这里下载的数据库包括archaea，bacteria，plasmid，viral，fungi，protozoa，UniVec和UniVec_Core：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> bash -c <span class=\"string\">&#x27;for i in archaea bacteria plasmid viral fungi protozoa UniVec UniVec_Core; do kraken2-build --download-library $i --threads 24 --db db_name; done&#x27;</span> &amp;</span><br></pre></td></tr></table></figure></li>\n<li>下载分类信息<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> kraken2-build --download-taxonomy --threads 24 --db db_name &amp;</span><br></pre></td></tr></table></figure></li>\n<li>建立索引<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> kraken2-build --build --threads 24 --db db_name &amp;</span><br></pre></td></tr></table></figure>\n<h4 id=\"d-序列分类\"><a href=\"#d-序列分类\" class=\"headerlink\" title=\"d. 序列分类\"></a>d. 序列分类</h4></li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kraken2 --paired --threads 24 --unclassified-out unclassified<span class=\"comment\">#.fq --classified-out classified#.fq --output outfile --confidence 0.5 --memory-mapping --use-names --report reportname --report-zero-counts --db $DBNAME reads1 read2</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"A-2-组装、Bining、质量评估\"><a href=\"#A-2-组装、Bining、质量评估\" class=\"headerlink\" title=\"A.2 组装、Bining、质量评估\"></a>A.2 组装、Bining、质量评估</h2><h3 id=\"A-2-1-metawrap\"><a href=\"#A-2-1-metawrap\" class=\"headerlink\" title=\"A.2.1 metawrap\"></a>A.2.1 metawrap</h3><p>MetaWRAP is a pipeline for genome-resolved metagenomic data analysis.</p>\n<h4 id=\"a-安装主文件-1\"><a href=\"#a-安装主文件-1\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n metawrap python=2.7 metaphlan</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装其他分析工具到metawrap环境中\"><a href=\"#b-安装其他分析工具到metawrap环境中\" class=\"headerlink\" title=\"b. 安装其他分析工具到metawrap环境中\"></a>b. 安装其他分析工具到metawrap环境中</h4><ul>\n<li><strong>cd-hit</strong></li>\n<li><strong>coverm</strong> DNA read coverage and relative abundance calculator focused on metagenomics applications</li>\n<li><strong>bamm</strong> Metagenomics-focused BAM file manipulation</li>\n<li><strong>unitem</strong> Ensemble binning strategies for combining the output of multiple binning methods</li>\n<li><strong>humann2</strong> The HMP Unified Metabolic Analysis Network 2</li>\n<li><strong><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">graphlan</a></strong> </li>\n<li><strong><a href=\"https://pypi.org/project/export2graphlan/\">export2graphlan</a></strong> </li>\n<li><strong><a href=\"https://data.ace.uq.edu.au/public/CheckM_databases/\">checkm database</a></strong><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activeta metawrap</span><br><span class=\"line\">$ conda install cd-hit coverm bamm unitem humann2 graphlan export2graphlan</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 找到一个合适的目录并cd进入以便存储checkm数据库</span></span><br><span class=\"line\">$ wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz</span><br><span class=\"line\">$ tar zxvf checkm_data_2015_01_16.tar.gz</span><br><span class=\"line\">$ checkm data setRoot</span><br><span class=\"line\"><span class=\"comment\"># 随后输入数据库所在的full path</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"A-3-非冗余基因功能注释\"><a href=\"#A-3-非冗余基因功能注释\" class=\"headerlink\" title=\"A.3 非冗余基因功能注释\"></a>A.3 非冗余基因功能注释</h2><h3 id=\"A-3-1-eggNOG-mapper\"><a href=\"#A-3-1-eggNOG-mapper\" class=\"headerlink\" title=\"A.3.1 eggNOG-mapper\"></a>A.3.1 eggNOG-mapper</h3><p>功能注释，uniref, eggNOG, KEGG, GO; CAZy; VFDB; CARD; TCDB; PHI。</p>\n<h3 id=\"A-3-2-EnrichM\"><a href=\"#A-3-2-EnrichM\" class=\"headerlink\" title=\"A.3.2 EnrichM\"></a>A.3.2 EnrichM</h3><p><a href=\"https://github.com/geronimp/enrichM\">EnrichM</a> is a set of comparative genomics tools for large sets of metagenome assembled genomes (MAGs). The current functionality includes:</p>\n<ul>\n<li>A basic annotation pipeline for MAGs.</li>\n<li>A pipeline to determine the metabolic pathways that are encoded by MAGs, using KEGG modules as a reference (although custom pathways can be specified)</li>\n<li>A pipeline to identify genes or metabolic pathways that are enriched within and between user-defined groups of genomes (groups can be genomes that are related functionally, phylogenetically, recovered from different environments, etc).</li>\n<li>To construct metabolic networks from annotated population genomes.</li>\n<li>Construct random forest machine learning models from the functional composition of either MAGs, metagenomes or transcriptomes.</li>\n<li>Apply these random forest machine learning models to classify new MAGs metagenomes.</li>\n</ul>\n<h4 id=\"a-安装主文件-2\"><a href=\"#a-安装主文件-2\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n enrichm python=3</span><br><span class=\"line\">$ conda install enrichm</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装数据库-1\"><a href=\"#b-安装数据库-1\" class=\"headerlink\" title=\"b. 安装数据库\"></a>b. 安装数据库</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 约5.7 G</span></span><br><span class=\"line\">$ enrichm data</span><br></pre></td></tr></table></figure>\n<p><strong>报错</strong> ：</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;data.py”, line 114, in do<br>    version_remote &#x3D; urllib.request.urlopen(self.ftp + self.VERSION).readline().strip().decode(“utf-8”)<br>AttributeError: module ‘urllib’ has no attribute ‘request’</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;bin&#x2F;enrichm”, line 342, in &lt;module&gt;<br>    run.run_enrichm(args, sys.argv)<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;run.py”, line 288, in run_enrichm<br>    d.do(args.uninstall, args.dry)<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;data.py”, line 117, in do<br>    “Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a>“)<br>Exception: Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a></p>\n</blockquote>\n<p><strong>解决方案：将data.py中的’import urllib’替换为’import urllib.request’</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim /home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py</span><br></pre></td></tr></table></figure>\n<h4 id=\"c-Sepcifying-the-location-of-the-EnrichM-database\"><a href=\"#c-Sepcifying-the-location-of-the-EnrichM-database\" class=\"headerlink\" title=\"c. Sepcifying the location of the EnrichM database\"></a>c. Sepcifying the location of the EnrichM database</h4><p>If you would like to store the EnrichM database outside of your home directory, move you need to tell EnrichM where to look. To do this, export a BASH variable named “ENRICHM_DB”:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">export</span> ENRICHM_DB=/path/to/database/ &gt;&gt;~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<p><strong>注意</strong> ：&#x2F;path&#x2F;to&#x2F;database&#x2F;根据实际情况而定！<br><strong>报错</strong>：</p>\n<blockquote>\n<p>$ enrichm<br>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;bin&#x2F;enrichm”, line 38, in &lt;module&gt;<br>    from enrichm.run import Run<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;run.py”, line 24, in &lt;module&gt;<br>    from enrichm.network_analyzer import NetworkAnalyser<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;network_analyzer.py”, line 22, in &lt;module&gt;<br>    from enrichm.network_builder import NetworkBuilder<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;network_builder.py”, line 24, in &lt;module&gt;<br>    from enrichm.databases import Databases<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;databases.py”, line 28, in &lt;module&gt;<br>    class Databases:<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;databases.py”, line 36, in Databases<br>    PICKLE_VERSION &#x3D; open(os.path.join(CUR_DATABASE_DIR, ‘VERSION’)).readline().strip()<br>FileNotFoundError: [Errno 2] No such file or directory: ‘&#x2F;new_data&#x2F;hualin&#x2F;db&#x2F;enrichm_database_v10&#x2F;26-11-2018&#x2F;VERSION’</p>\n</blockquote>\n<p><strong>Solve</strong>: 将下载的数据库文件全部复制一份到“<strong>26-11-2018</strong>”目录中，否则后续运行annotaton时会提示找不到数据库文件。</p>\n<h1 id=\"B、数据分析\"><a href=\"#B、数据分析\" class=\"headerlink\" title=\"B、数据分析\"></a>B、数据分析</h1><h2 id=\"B-1-使用metaphlan从Reads中获取物种分类信息\"><a href=\"#B-1-使用metaphlan从Reads中获取物种分类信息\" class=\"headerlink\" title=\"B.1 使用metaphlan从Reads中获取物种分类信息\"></a>B.1 使用metaphlan从Reads中获取物种分类信息</h2><h3 id=\"Step-1-激活环境\"><a href=\"#Step-1-激活环境\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metaphlan</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-对paired-end-Reads进行注释\"><a href=\"#Step-2-对paired-end-Reads进行注释\" class=\"headerlink\" title=\"Step 2. 对paired-end Reads进行注释\"></a>Step 2. 对paired-end Reads进行注释</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metaphlan Reads1,Reads2 --input_type fastq --bowtie2out Str1.bowtie2.bz2 --<span class=\"built_in\">nproc</span> 10 -o Str1_profiled.txt</span><br></pre></td></tr></table></figure>\n<p>Reads1和Reads2分别代表双端测序得到的正向和反向数据；–input_type指定文件格式，我们拿到的下机数据一般为fastq格式；–bowtie2out参数将会保存运行产生的中间文件以便后续重新运行程序时作为输入文件；–nproc指定使用的线程数量；-o指定输出文件名。</p>\n<h3 id=\"Step-3-汇总所有的结果文件\"><a href=\"#Step-3-汇总所有的结果文件\" class=\"headerlink\" title=\"Step 3. 汇总所有的结果文件\"></a>Step 3. 汇总所有的结果文件</h3><p>对所有的文件均运行Step 2 ，产生了多个输出文件（*_profiled.txt），可以将它们汇总到一个文件中（merged_abundance_table.txt），便于后续对多个样品进行相互比较。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ merge_metaphlan_tables.py *_profiled.txt &gt; merged_abundance_table.txt</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-4-从合并的文件中提取种水平的分类\"><a href=\"#Step-4-从合并的文件中提取种水平的分类\" class=\"headerlink\" title=\"Step 4. 从合并的文件中提取种水平的分类\"></a>Step 4. 从合并的文件中提取种水平的分类</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ grep -E <span class=\"string\">&quot;s__|clade&quot;</span> merged_abundance_table.txt | sed <span class=\"string\">&#x27;s/^.*s__//g&#x27;</span> | <span class=\"built_in\">cut</span> -f1,3-8 | sed -e <span class=\"string\">&#x27;s/clade_name/body_site/g&#x27;</span> &gt; merged_abundance_table_species.txt</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Step-5-绘制样本间种水平的热图\"><a href=\"#Step-5-绘制样本间种水平的热图\" class=\"headerlink\" title=\"Step 5. 绘制样本间种水平的热图\"></a>Step 5. 绘制样本间种水平的热图</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hclust2.py -i merged_abundance_table_species.txt -o abundance_heatmap_species.png --ftop 50 --f_dist_f braycurtis --s_dist_f braycurtis --cell_aspect_ratio 0.5 -l --flabel_size 10 --slabel_size 10 --max_flabel_len 100 --max_slabel_len 100 --minv 0.1 --dpi 300</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-6-计算样本间的unifrac距离\"><a href=\"#Step-6-计算样本间的unifrac距离\" class=\"headerlink\" title=\"Step 6. 计算样本间的unifrac距离\"></a>Step 6. 计算样本间的unifrac距离</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载依赖的tree文件和脚本,与要分析的文件放于同一目录下</span></span><br><span class=\"line\">$ wget https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/mpa_v30_CHOCOPhlAn_201901_species_tree.nwk</span><br><span class=\"line\">$ wget https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/calculate_unifrac.R</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 开始计算距离</span></span><br><span class=\"line\">$ Rscript plot_unifrac.R merged_abundance_table.txt mpa_v30_CHOCOPhlAn_201901_species_tree.nwk unifrac_merged_abundance_table.txt</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-7-绘制cladogram图\"><a href=\"#Step-7-绘制cladogram图\" class=\"headerlink\" title=\"Step 7. 绘制cladogram图\"></a>Step 7. 绘制cladogram图</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 激活依赖软件所在的环境</span></span><br><span class=\"line\">$ conda activate metawrap</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成绘图所需的文件</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -n +2 merged_abundance_table.txt | <span class=\"built_in\">cut</span> -f1,3- &gt; merged_abundance_table_reformatted.txt</span><br><span class=\"line\"></span><br><span class=\"line\">$ export2graphlan.py --skip_rows 1 -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant 100 --abundance_threshold 1 --least_biomarkers 10 --annotations 5,6 --external_annotations 7 --min_clade_size 1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘图</span></span><br><span class=\"line\">$ graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml</span><br><span class=\"line\"></span><br><span class=\"line\">$ graphlan.py --dpi 300 merged_abundance.xml merged_abundance.pdf --external_legends</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"B-2-使用metawrap对Reads进行组装\"><a href=\"#B-2-使用metawrap对Reads进行组装\" class=\"headerlink\" title=\"B.2 使用metawrap对Reads进行组装\"></a>B.2 使用metawrap对Reads进行组装</h2><h3 id=\"Step-1-激活环境-1\"><a href=\"#Step-1-激活环境-1\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metawrap</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-组装\"><a href=\"#Step-2-组装\" class=\"headerlink\" title=\"Step 2. 组装\"></a>Step 2. 组装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap assembly -1 Reads1 -2 Reads2 -o Assemble1 -m 300 -t 15 --metaspades</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP assembly [options] -1 reads_1.fastq -2 reads_2.fastq -o output_dir\n\n<ul>\n<li>Options:<ul>\n<li><p>   -1 STR          forward fastq reads</p>\n</li>\n<li><p>   -2 STR          reverse fastq reads</p>\n</li>\n<li><p>   -o STR          output directory</p>\n</li>\n<li><p>   -m INT          memory in GB (default&#x3D;24)</p>\n</li>\n<li><p>   -t INT          number of threads (defualt&#x3D;1)</p>\n</li>\n<li><p>   -l INT\t\tminimum length of assembled contigs (default&#x3D;1000)</p>\n</li>\n<li><p>   --megahit\tassemble with megahit (default)</p>\n</li>\n<li><p>--metaspades\tassemble with metaspades instead of megahit (better results but slower and higher memory requirement)</p>\n</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<p>Reads1和Reads2分别代表双端测序得到的正向和反向数据；-o指定输出目录，-m指定最大可用内存大小，超过设定值后程序会自动退出，建议设大一点，我10G的数据大概需要180G内存；-t指定线程数；–metaspades表示用metaspades进行组装，特别慢，但是组装结果相对好一些。</p>\n<h2 id=\"B-3-使用metawrap对Contigs进行Bining\"><a href=\"#B-3-使用metawrap对Contigs进行Bining\" class=\"headerlink\" title=\"B.3 使用metawrap对Contigs进行Bining\"></a>B.3 使用metawrap对Contigs进行Bining</h2><h3 id=\"Step-1-激活环境-2\"><a href=\"#Step-1-激活环境-2\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metawrap</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-Bining\"><a href=\"#Step-2-Bining\" class=\"headerlink\" title=\"Step 2. Bining\"></a>Step 2. Bining</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap binning -o Str1.INITIAL_BINNING -t 20 -m 200 --universal --run-checkm -a &lt;path of contigs&gt; --metabat2 --maxbin2 --concoct 解压的Reads1 解压的Reads2</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP binning [options] -a assembly.fa -o output_dir readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n\n<ul>\n<li><p>Note1: Make sure to provide all your separately replicate read files, not the joined file.</p>\n</li>\n<li><p>Note2: You may provide single end or interleaved reads as well with the use of the correct option</p>\n</li>\n<li><p>Note3: If the output already has the .bam alignments files from previous runs, the module will skip re-aligning the reads</p>\n</li>\n<li><p>Options:</p>\n<ul>\n<li>   -a STR          metagenomic assembly file</li>\n<li>   -o STR          output directory</li>\n<li>   -t INT          number of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tamount of RAM available (default&#x3D;4)</li>\n<li>   -l INT\t\tminimum contig length to bin (default&#x3D;1000bp). Note: metaBAT will default to 1500bp minimum</li>\n<li>   --metabat2      bin contigs with metaBAT2</li>\n<li>   --metabat1\tbin contigs with the original metaBAT</li>\n<li>   --maxbin2\tbin contigs with MaxBin2</li>\n<li>   --concoct\tbin contigs with CONCOCT</li>\n<li>--universal\tuse universal marker genes instead of bacterial markers in MaxBin2 (improves Archaea binning)</li>\n<li>   --run-checkm\timmediately run CheckM on the bin results (requires 40GB+ of memory)</li>\n<li>   --single-end\tnon-paired reads mode (provide *.fastq files)</li>\n<li>   --interleaved\tthe input read files contain interleaved paired-end reads</details>\n**注意避坑：** 这里的Reads1和Reads2需要提供解压缩后的Reads文件，不但要解压缩，还需要重命名，即后缀名必须为“\\_clean\\_1.fastq” 和 “\\_clean\\_2.fastq”，否则软件无法运行。-o指定输出目录；-t指定线程数；-m指定最大内存限制；--run-checkm表明即时检查Bining的质量；--metabat2 --maxbin2 --concoct 指定同时采用这三个分箱工具进行Bining；--universal指定MaxBin2采用universal marker 基因代替 bacterial markers  (improves Archaea binning)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"><a href=\"#Step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\" class=\"headerlink\" title=\"Step 3. 整合三种方法的bins (metabat2, maxbin2, concoct) 结果\"></a>Step 3. 整合三种方法的bins (metabat2, maxbin2, concoct) 结果</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap bin_refinement -o F01_BIN_REFINEMENT(输出目录) -t 20 -A str1.INITIAL_BINNING/metabat2_bins/ -B str1.INITIAL_BINNING/maxbin2_bins/ -C str1.INITIAL_BINNING/concoct_bins/ -c 70 -x 5</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP bin_refinement [options] -o output_dir -A bin_folderA [-B bin_folderB -C bin_folderC]\n\n<ul>\n<li><p>Note: the contig names in different bin folders must be consistant (must come from the same assembly).</p>\n</li>\n<li><p>Options:</p>\n<ul>\n<li>-o STR          output directory</li>\n<li>   -t INT          number of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tmemory available (default&#x3D;40)</li>\n<li>   -c INT          完整度minimum % completion of bins [should be &gt;50%] (default&#x3D;70)</li>\n<li>   -x INT          污染度maximum % contamination of bins that is acceptable (default&#x3D;10)</li>\n<li>   -A STR\t\tfolder with metagenomic bins (files must have .fa or .fasta extension)</li>\n<li>   -B STR\t\tanother folder with metagenomic bins</li>\n<li>   -C STR\t\tanother folder with metagenomic bins</li>\n<li>   --skip-refinement\tdont use binning_refiner to come up with refined bins based on combinations of binner outputs</li>\n<li>   --skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>   --skip-consolidation\tchoose the best version of each bin from all bin refinement iteration</li>\n<li>   --keep-ambiguous\tfor contigs that end up in more than one bin, keep them in all bins (default: keeps them only in the best bin)</li>\n<li>   --remove-ambiguous\tfor contigs that end up in more than one bin, remove them in all bins (default: keeps them only in the best bin)</li>\n<li>   --quick\t\t\tadds –reduced_tree option to checkm, reducing runtime, especially with low memory</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-4-Blobology可视化bin\"><a href=\"#Step-4-Blobology可视化bin\" class=\"headerlink\" title=\"Step 4. Blobology可视化bin\"></a>Step 4. Blobology可视化bin</h3><p><strong>一个坑：</strong> metawrap安装的blast为2.6版本，只能用Version 4 的nt库。而最新的nt库为Version 5，v4已经不再维护了。因此需要更新metawrap安装环境中的blast至2.8.0及以上版本，这里无法通过‘conda updata blast’实现更新，而是需要下载新版本的blast可执行程序，覆盖metawrap环境中的blast程度们。 如果你采用的是默认版本的blast和V5的nt库，会得到报错：“BLAST Database error: Error: Not a valid version 4 database”.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap blobology -a Result/Assemble/F01/final_assembly.fasta -t 20 -o F01.BLOBOLOGY --bins F01_BIN_REFINEMENT/metawrap_70_5_bins reads/F01_clean_1.fastq reads/F01_clean_2.fastq</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP blobology [options] -a assembly.fasta -o output_dir readsA_1.fastq readsA_2.fastq [readsB_1.fastq readsB_2.fastq ... ]\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -a STR\t\tassembly fasta file</li>\n<li>   -o STR          output directory</li>\n<li>   -t INT          number of threads</li>\n<li>   --subsamble \tINT\tNumber of contigs to run blobology on. Subsampling is randomized. (default&#x3D;ALL)</li>\n<li>   --bins\t\tSTR\tFolder containing bins. Contig names must match those of the assembly file. (default&#x3D;None)</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-5-Bins-定量\"><a href=\"#Step-5-Bins-定量\" class=\"headerlink\" title=\"Step 5. Bins 定量\"></a>Step 5. Bins 定量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap quant_bins -b F01_BIN_REFINEMENT/metawrap_70_5_bins -t 8 -o F01.QUANT_BINS -a Result/Assemble/F01/final_assembly.fasta reads/F01_clean_1.fastq reads/F01_clean_2.fastq</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP quant_bins [options] -b bins_folder -o output_dir -a assembly.fa readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -b STR          folder containing draft genomes (bins) in fasta format</li>\n<li>   -o STR          output directory</li>\n<li>   -a STR\t\tfasta file with entire metagenomic assembly (strongly recommended!)</li>\n<li>   -t INT\t\tnumber of threads</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-6-重组装\"><a href=\"#Step-6-重组装\" class=\"headerlink\" title=\"Step 6. 重组装\"></a>Step 6. 重组装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">metawrap reassemble_bins -o F01.BIN_REASSEMBLY -1 reads/F01_clean_1.fastq -2 reads/F01_clean_2.fastq -t 20 -m 400 -c 70 -x 10 -b F01_BIN_REFINEMENT/metawrap_70_5_bins</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP reassemble_bins [options] -o output_dir -b bin_folder -1 reads_1.fastq -2 reads_2.fastq\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -b STR\t\tfolder with metagenomic bins</li>\n<li>   -o STR\t\toutput directory</li>\n<li>   -1 STR          forward reads to use for reassembly</li>\n<li>   -2 STR          reverse reads to use for reassembly</li>\n<li>   -t INT\t\tnumber of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tmemory in GB (default&#x3D;40)</li>\n<li>   -c INT\t\tminimum desired bin completion % (default&#x3D;70)</li>\n<li>   -x INT\t\tmaximum desired bin contamination % (default&#x3D;10)</li>\n<li>   -l INT\t\tminimum contig length to be included in reassembly (default&#x3D;500)</li>\n<li>   --strict-cut-off\tmaximum allowed SNPs for strict read mapping (default&#x3D;2)</li>\n<li>   --permissive-cut-off\tmaximum allowed SNPs for permissive read mapping (default&#x3D;5)</li>\n<li>   --skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>   --parallel\t\trun spades reassembly in parallel, but only using 1 thread per bin</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h2 id=\"B-4-MAGs注释\"><a href=\"#B-4-MAGs注释\" class=\"headerlink\" title=\"B.4 MAGs注释\"></a>B.4 MAGs注释</h2><h3 id=\"B-4-1-GTDB-TK-进行物种分类和注释，构建系统发育树\"><a href=\"#B-4-1-GTDB-TK-进行物种分类和注释，构建系统发育树\" class=\"headerlink\" title=\"B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树\"></a>B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate gtdbtk</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"classify-wf——Classify-workflow-包括了Step-1-3\"><a href=\"#classify-wf——Classify-workflow-包括了Step-1-3\" class=\"headerlink\" title=\"classify_wf——Classify workflow (包括了Step 1-3)\"></a>classify_wf——Classify workflow (包括了Step 1-3)</h4><p>The classify workflow consists of three steps: identify, align, and classify.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk classify_wf --genome_dir metawrap_70_5_bins/ --out_dir classify_wf_output -x .fa --prefix F --cpus 6 -r --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk classify_wf (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [-x EXTENSION] [--min_perc_aa MIN_PERC_AA] [--prefix PREFIX] [--cpus CPUS]\n                          [--pplacer_cpus PPLACER_CPUS] [--force] [--scratch_dir SCRATCH_DIR] [-r] [--min_af MIN_AF] [--debug] [-h]\n\n<ul>\n<li><p>mutually exclusive required arguments:</p>\n<ul>\n<li>--genome_dir GENOME_DIR<br>               directory containing genome files in FASTA format</li>\n<li>--batchfile BATCHFILE<br>               path to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</li>\n</ul>\n</li>\n<li><p>required named arguments:</p>\n<ul>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br>                extension of files to process, gz &#x3D; gzipped (default: fna)</li>\n<li>--min_perc_aa MIN_PERC_AA<br>                exclude genomes that do not have at least this percentage of AA in the MSA (inclusive bound) (default: 10)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--pplacer_cpus PPLACER_CPUS<br>                use pplacer_cpus during placement (default: cpus)</li>\n<li>--force               continue processing if an error occurs on a single genome (default: False)</li>\n<li>--scratch_dir SCRATCH_DIR<br>                Reduce pplacer memory usage by writing to disk (slower).</li>\n<li>-r, --recalculate_red<br>                recalculate RED values based on the reference tree and all added user genomes (default: False)</li>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-1-identify——在基因组中寻找marker-genes\"><a href=\"#Step-1-identify——在基因组中寻找marker-genes\" class=\"headerlink\" title=\"Step 1: identify——在基因组中寻找marker genes\"></a>Step 1: identify——在基因组中寻找marker genes</h4><p>Translation table选择：use table 11 unless the coding density using table 4 is 5% higher than when using table 11 and the coding density under table 4 is &gt;70%.  GTDB-Tk 不会区分 tables 4和tables 5. 若用户清楚使用哪一个table，可以通过--batchfile指定。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk identify --genome_dir metawrap_70_5_bins/ --out_dir identify_output --cpus 6 --prefix F --debug -x .fa --write_single_copy_genes</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-2-align\"><a href=\"#Step-2-align\" class=\"headerlink\" title=\"Step 2: align\"></a>Step 2: align</h4><p>Create a multiple sequence alignment based on the AR122&#x2F;BAC120 marker set.<br>Time 3m50.019s</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk align --identify_dir identify_output/ --out_dir align_output --cpus 3 --prefix F --debug</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-3-classify\"><a href=\"#Step-3-classify\" class=\"headerlink\" title=\"Step 3: classify\"></a>Step 3: classify</h4><p>Determine taxonomic classification of genomes.<br>Time 118m9.386s</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk classify --genome_dir metawrap_70_5_bins/ --align_dir align_output/ --out_dir classify_output --cpus 3 --prefix F --debug -x .fa -r</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：如果内存较小，则加上“–scratch_dir”参数。</p>\n<hr>\n<h4 id=\"Step-4-export-msa-这一步不运行\"><a href=\"#Step-4-export-msa-这一步不运行\" class=\"headerlink\" title=\"Step 4: export_msa (这一步不运行)\"></a>Step 4: export_msa (这一步不运行)</h4><p>The export_msa will export the untrimmed archaeal or bacterial MSA used in the reference data.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌 0m1.503s</span></span><br><span class=\"line\">$ time gtdbtk export_msa --domain arc --output msa_arc.faa --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌 0m16.679s</span></span><br><span class=\"line\">$ time gtdbtk export_msa --domain bac --output msa_bac.faa --debug</span><br></pre></td></tr></table></figure>\n<h4 id=\"Step-5-trim-msa-这一步不运行\"><a href=\"#Step-5-trim-msa-这一步不运行\" class=\"headerlink\" title=\"Step 5: trim_msa (这一步不运行)\"></a>Step 5: trim_msa (这一步不运行)</h4><p>The trim_msa command will trim a MSA given a user-specified mask file, or the archaeal&#x2F;bacterial mask present in the reference data.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌 0m10.675s</span></span><br><span class=\"line\">$ time gtdbtk trim_msa --untrimmed_msa msa_arc.faa --output msa_arc_trim.faa --reference_mask arc --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌 3m28.793s</span></span><br><span class=\"line\">$ time gtdbtk trim_msa --untrimmed_msa msa_bac.faa --output msa_bac_trim.faa --reference_mask bac --debug</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-6-infer\"><a href=\"#Step-6-infer\" class=\"headerlink\" title=\"Step 6: infer\"></a>Step 6: infer</h4><p>Infer tree from multiple sequence alignment.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#古菌 44m54.884s</span></span><br><span class=\"line\">$ time gtdbtk infer --msa_file align_output/F.ar122.msa.fasta --out_dir infer_out_arc_F --prefix F --cpus 12 --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#细菌</span></span><br><span class=\"line\">$ time gtdbtk infer --msa_file align_output/F.bac120.msa.fasta --out_dir infer_out_bac_F --prefix F --cpus 12 --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk infer --msa_file MSA_FILE --out_dir OUT_DIR [--prot_model {JTT,WAG,LG}] [--no_support] [--gamma] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--msa_file MSA_FILE   multiple sequence alignment in FASTA format</li>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--prot_model {JTT,WAG,LG}<br>                protein substitution model for tree inference (default: WAG)</li>\n<li>--no_support          do not compute local support values using the Shimodaira-Hasegawa test (default: False)</li>\n<li>--gamma               rescale branch lengths to optimize the Gamma20 likelihood (default: False)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-7-decorate\"><a href=\"#Step-7-decorate\" class=\"headerlink\" title=\"Step 7: decorate\"></a>Step 7: decorate</h4><p>Decorate a tree with the GTDB-Tk taxonomy.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌</span></span><br><span class=\"line\">$ time gtdbtk decorate --input_tree infer_out_arc_F/F.unrooted.tree --output_tree F.decorate_unrooted_arc.tree --gtdbtk_classification_file classify_output/classify/F.ar122.summary.tsv --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌</span></span><br><span class=\"line\">$ time gtdbtk decorate --input_tree infer_out_bac_F/F.unrooted.tree --output_tree F.decorate_unrooted_brc.tree --gtdbtk_classification_file classify_output/classify/F.bac120.summary.tsv --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk decorate --input_tree INPUT_TREE --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE] [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE]\n                       [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br>                path to the unrooted tree in Newick format</li>\n<li>--output_tree OUTPUT_TREE<br>                path to output the tree</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br>                file with GTDB-Tk classifications produced by the <code>classify</code> command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br>                file indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-8-root\"><a href=\"#Step-8-root\" class=\"headerlink\" title=\"Step 8: root\"></a>Step 8: root</h4><p>Root a tree using an outgroup.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk root --input_tree input.tree --outgroup_taxon p__Nanoarchaeota --output_tree output.tree --gtdbtk_classification_file &lt;file with GTDB-Tk classifications produced by the classify <span class=\"built_in\">command</span>&gt; --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk root --input_tree INPUT_TREE --outgroup_taxon OUTGROUP_TAXON --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE]\n                   [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE] [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br>                path to the unrooted tree in Newick format</li>\n<li>--outgroup_taxon OUTGROUP_TAXON<br>                taxon to use as outgroup (e.g., p__Patescibacteria or p__Altarchaeota)</li>\n<li>--output_tree OUTPUT_TREE<br>                path to output the tree</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br>                file with GTDB-Tk classifications produced by the <code>classify</code> command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br>                file indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"Step-9-ani-rep——计算ANI值\"><a href=\"#Step-9-ani-rep——计算ANI值\" class=\"headerlink\" title=\"Step 9: ani_rep——计算ANI值\"></a>Step 9: ani_rep——计算ANI值</h4><p>Compute the ANI of input genomes to all GTDB-Tk representative genomes.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk ani_rep --genome_dir metawrap_70_5_bins/ --out_dir ani_rep/ --cpus 6 -x .fa --prefix F --debug</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ gtdbtk de_novo_wf --genome_dir metawrap_70_5_bins/ --out_dir de_novo_wf --extension .fa --bacteria --outgroup_taxon p__Patescibacteria --prefix F --cpus 6 --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk ani_rep (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [--no_mash] [--mash_k MASH_K] [--mash_s MASH_S] [--mash_d MASH_D] [--mash_v MASH_V]\n                      [--mash_db MASH_DB] [--min_af MIN_AF] [-x EXTENSION] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n\n<ul>\n<li><p>mutually exclusive required arguments:</p>\n<ul>\n<li><p>--genome_dir GENOME_DIR<br>                directory containing genome files in FASTA format</p>\n</li>\n<li><p>--batchfile BATCHFILE<br>                path to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</p>\n</li>\n<li><p>- required named arguments:</p>\n</li>\n<li><p>--out_dir OUT_DIR     directory to output files</p>\n</li>\n</ul>\n</li>\n<li><p>optional Mash arguments:</p>\n<ul>\n<li>--no_mash             skip pre-filtering of genomes using Mash (default: False)</li>\n<li>--mash_k MASH_K       k-mer size [1-32] (default: 16)</li>\n<li>--mash_s MASH_S       maximum number of non-redundant hashes (default: 5000)</li>\n<li>--mash_d MASH_D       maximum distance to keep [0-1] (default: 0.1)</li>\n<li>--mash_v MASH_V       maximum p-value to keep [0-1] (default: 1.0)</li>\n<li>--mash_db MASH_DB     path to save&#x2F;read (if exists) the Mash reference sketch database (.msh)</li>\n</ul>\n</li>\n<li><p>optional FastANI arguments:</p>\n<ul>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br>                extension of files to process, gz &#x3D; gzipped (default: fna)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message </details></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"B-4-2-EnrichM-注释\"><a href=\"#B-4-2-EnrichM-注释\" class=\"headerlink\" title=\"B.4.2 EnrichM 注释\"></a>B.4.2 EnrichM 注释</h3><h4 id=\"Step-1-annotate\"><a href=\"#Step-1-annotate\" class=\"headerlink\" title=\"Step 1. annotate\"></a>Step 1. annotate</h4><p>基因组注释管道，可以使用dbCAN将基因组与KO, PFAM, TIGRFAM和CAZY 数据库进行比对。结果将为每个基因组产生一个.gff文件，并生成每个注释类型的频率矩阵（frequency matrix），其中行是注释IDs，列是基因组。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm annotate --genome_directory metawrap_70_5_bins --output EnrichM_annotate --force --ko --ko_hmm --pfam --tigrfam --clusters --orthologs --cazy --ec --threads 30 --parallel 8 --suffix .fa --count_domains --chunk_number 8</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options (Use one):</p>\n<ul>\n<li>--genome_files GENOME_FILES [GENOME_FILES …]<br>      Space separated list of genomes to annotate</li>\n<li>--genome_directory GENOME_DIRECTORY<br>      Directory containing genomes to annotate</li>\n<li>--protein_files PROTEIN_FILES [PROTEIN_FILES …]<br>      Space separated list of .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n<li>--protein_directory PROTEIN_DIRECTORY<br>      Directory containing .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n</ul>\n</li>\n<li><p>Annotations options:</p>\n<ul>\n<li>--ko                  Annotate with KO ids</li>\n<li>--ko_hmm              Annotate with KO ids</li>\n<li>--pfam                Annotate with Pfam HMMs</li>\n<li>--tigrfam             Annotate with TIGRFAM HMMs</li>\n<li>--clusters            Annotate with cluster ids</li>\n<li>--orthologs           Annotate with ortholog ids</li>\n<li>--cazy                Annotate with dbCAN HMMs</li>\n<li>--ec                  Annotate with EC ids</li>\n</ul>\n</li>\n<li><p>Cutoff options:</p>\n<ul>\n<li>--cut_ga              For PFAM and TIGRfam searches: use profiles GA gathering cutoffs to set all thresholding</li>\n<li>--cut_nc              For PFAM and TIGRfam searches: use profiles NC noise cutoffs to set all thresholding</li>\n<li>--cut_tc              For PFAM and TIGRfam searches: use profiles TC trusted cutoffs to set all thresholding</li>\n<li>--cut_ko              For KO HMM annotation searches: use cutoffs defined by KEGG to maximise F-score.</li>\n<li>--evalue EVALUE       Use this evalue cutoff to filter false positives (default: 1e-05)</li>\n<li>--bit BIT             Use this bit score cutoff to filter false positives (default: 0)</li>\n<li>--id ID               Use this percent identity cutoff to filter false positives (default: 0.3)</li>\n<li>--aln_query ALN_QUERY<br>      This fraction of the query must align to the reference (default: 0.7)</li>\n<li>--aln_reference ALN_REFERENCE<br>      This fraction of the reference must align to the query (default: 0.7)</li>\n<li>--c C                 When clustering, use matches above this fraction of aligned (covered) query and target residues (default: 0.7)</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--threads THREADS     Use this number of threads when annotating with BLAST and HMMsearch (default: 1)</li>\n<li>--parallel PARALLEL   Run this number of jobs in parallel when annotating with HMMsearch (default: 5)</li>\n<li>--inflation INFLATION<br>     Inflation factor to use when calling clusters in ortholog (default &#x3D; 5.0)</li>\n<li>--suffix SUFFIX       Treat files ending with this suffix within the –genome_directory as genomes (default: .fna for –genome_directory and .faa for )</li>\n<li>--light               Don’t store metadata for genome files (can’t use enrichM compare downstream, default&#x3D;False)</li>\n<li>--count_domains       Fill the frequency matrix with the total number of times an annotation was detected (for example, when one domain more than once within a protein), rather than the count of proteins with with that annotation</li>\n<li>--chunk_number CHUNK_NUMBER<br>      Split loading of genomes into this many chunks (default &#x3D; 4)</li>\n<li>--chunk_max CHUNK_MAX<br>      Maximum number of genomes to load per chunk (default &#x3D; 2500)</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-2-classify\"><a href=\"#Step-2-classify\" class=\"headerlink\" title=\"Step 2. classify\"></a>Step 2. classify</h4><p>Determine what pathways a genome encodes. Classify quickly reads in KO annotations in the form of a matrix (KO IDs as rows, genomes as columns) and determines which KEGG modules are complete. Annotation matrices can be generated using the annotate function.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm classify --output EnrichM_classify/ko_hmm_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_hmm_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ko_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 以下6个命令可不必运行</span></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/cazy_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cazy_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/cluster_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cluster_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ec_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ec_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ortholog_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ortholog_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/pfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/pfam_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/tigrfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/tigrfam_frequency_table.tsv --cutoff 0</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options:</p>\n<ul>\n<li>--genome_and_annotation_matrix GENOME_AND_ANNOTATION_MATRIX<br>      Path to file containing a genome annotation matrix</li>\n<li>--custom_modules CUSTOM_MODULES<br>      Tab separated file containing module name, definition as the columns</li>\n<li>--module_rules_json MODULE_RULES_JSON<br>       json file specifying rules to interpret the annotation and guide module annotation</li>\n<li>--gff_files GFF_FILES<br>      GFF files for the genomes being classified.</li>\n</ul>\n</li>\n<li><p>Cutoff options:</p>\n<ul>\n<li>--cutoff CUTOFF       Output only modules with greater than this percent of the requied KO groups (default &#x3D; print all modules)</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--aggregate           Calculate the abundance of each pathway within each genome&#x2F;sample (column)</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-3-enrichment\"><a href=\"#Step-3-enrichment\" class=\"headerlink\" title=\"Step 3. enrichment\"></a>Step 3. enrichment</h4><p>Enrichment will read in KO or PFAM annotations in the form of a matrix (IDs as rows, genomes as columns) and a metadata file that separates genomes into groups to compare, and will run some basic stats to determine the enrichment of modules or pfam clans between and within the groups.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm enrichment --output EnrichM_enrichment/ --metadata genome.list --annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --force</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>- Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options:</p>\n<ul>\n<li>--annotate_output ANNOTATE_OUTPUT<br>     Output directory provided by enrichm annotate</li>\n<li>--metadata METADATA   Metadata file with two columns, the first with the genome name, the second with the groupings to compare.</li>\n<li>--annotation_matrix ANNOTATION_MATRIX<br>     Annotation matrix to compare.</li>\n<li>--gff_files GFF_FILES [GFF_FILES …]<br>     Gff files for genomes to compare.</li>\n<li>--abundance 基因组丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>     Metadata grouping abundance samples.</li>\n<li>--transcriptome TRANSCRIPTOME  基因组丰度矩阵</li>\n<li>--transcriptome_metadata TRANSCRIPTOME_METADATA<br>     Metadata grouping abundance samples.</li>\n</ul>\n</li>\n<li><p>Genome Taxonomy DataBase (GTDB) options:</p>\n<ul>\n<li>--batchfile BATCHFILE<br>     metadata file to compare with.</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--pval_cutoff PVAL_CUTOFF<br>     Only output results with a p-value below a this cutoff (default&#x3D;0.05).</li>\n<li>--proportions_cutoff PROPORTIONS_CUTOFF<br>     Proportion enrichment cutoff.</li>\n<li>--threshold THRESHOLD<br>     The threshold to control for in false discovery rate of familywise error rate.</li>\n<li>--multi_test_correction MULTI_TEST_CORRECTION<br>     The form of mutiple test correction to use. Uses the statsmodel module and consequently has all of its options.<br>                Default: Benjamini-Hochberg FDR (fdr_bh)<br>                Options: Bonferroni (b)<br>                     Sidak (s)<br>                     Holm (h)<br>                     Holm-Sidak (hs)<br>                     Simes-Hochberg (sh)<br>                     Hommel (ho)<br>                     FDR Benjamini-Yekutieli (fdr_by)<br>                     FDR 2-stage Benjamini-Hochberg (fdr_tsbh)<br>                     FDR 2-stage Benjamini-Krieger-Yekutieli (fdr_tsbky)<br>                     FDR adaptive Gavrilov-Benjamini-Sarkar (fdr_gbs))</li>\n<li>--processes PROCESSES  采用多少个进程进行富集分析</li>\n<li>--allow_negative_values  允许输入的矩阵中有负值</li>\n<li>--ko                    Compare KO ids (annotated with DIAMOND)</li>\n<li>--ko_hmm          Compare KO ids (annotated with HMMs)</li>\n<li>--pfam                Compare Pfam ids</li>\n<li>--tigrfam             Compare TIGRFAM ids</li>\n<li>--cluster              Compare cluster ids</li>\n<li>--ortholog            Compare ortholog ids</li>\n<li>--cazy                 Compare dbCAN ids</li>\n<li>--ec                     Compare EC ids</li>\n<li>--range RANGE         Base pair range to search for synteny within. Default &#x3D; 2500.</li>\n<li>--subblock_size SUBBLOCK_SIZE<br>                Number of genes clustered in a row to be reported. Default &#x3D; 2.</li>\n<li>--operon_mismatch_cutoff OPERON_MISMATCH_CUTOFF<br>                Number of allowed mismatches when searching for operons across genomes. Defaul</li>\n<li>--operon_match_score_cutoff OPERON_MATCH_SCORE_CUTOFF<br>                Score cutoff for operon matches</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-4-pathway\"><a href=\"#Step-4-pathway\" class=\"headerlink\" title=\"Step 4. pathway\"></a>Step 4. pathway</h4><p>Pathway reads in a KO matrix and generates a Cytoscape-readable metabolic network and metadata file. Only reactions that are possible given the KOs present in the input matrix are shown, and the modules and reactions that are included in the output can be customized（<strong>报错</strong>）.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm pathway --matrix EnrichM_annotate/ko_frequency_table.tsv --genome_metadata genome.list --output EnrichM_pathway --abundance EnrichM_enrichment/F01_vs_F02_ivg_results.cdf.tsv --abundance_metadata genome.list --force</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Input options:</p>\n<ul>\n<li>--matrix KO矩阵. 必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br>       Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>      Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--tpm_values TPM_VALUES<br>       DetectM产生的TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br>       Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--metabolome METABOLOME<br>       Metabolome CID matrix.</li>\n</ul>\n</li>\n<li><p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br>     Level of verbosity (1 - 5 - default &#x3D; 4) 5 &#x3D; Very verbose, 1 &#x3D; Silent</li>\n</ul>\n</li>\n<li><p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li><p>Pathway options:</p>\n<ul>\n<li>--limit LIMIT [LIMIT …]<br>     USE ONLY these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--filter FILTER [FILTER …]<br>     Do not use these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--enrichment_output ENRICHMENT_OUTPUT<br>      Supply an enrichment output to integrate the results into the output network.</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-5-explore\"><a href=\"#Step-5-explore\" class=\"headerlink\" title=\"Step 5. explore\"></a>Step 5. explore</h4><p>Explore is similar to pathway, but rather than generating a specified pathway it will start from a given query compound ID, and explore the possible reactions that use that compound given the enzymes present in the input KO matrix.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ </span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Input options: </p>\n<ul>\n<li>--matrix MATRIX       KO矩阵. 必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br>      Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>     Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare..</li>\n<li>--tpm_values TPM_VALUES<br>     DetectM产生的TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br>     Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare..</li>\n<li>--metabolome METABOLOME<br>     Metabolome CID matrix.</li>\n</ul>\n</li>\n<li><p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br>      Level of verbosity (1 - 5 - default &#x3D; 4) 5 &#x3D; Very verbose, 1 &#x3D; Silent</li>\n</ul>\n</li>\n<li><p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li><p>Query options:</p>\n<ul>\n<li>--queries QUERIES     A file containing the KEGG ids of the compounds from which to start in the metabolic network</li>\n<li>--depth DEPTH         Number of steps to take into the metabolic network</details></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"C-Metagenome-functional-profiling\"><a href=\"#C-Metagenome-functional-profiling\" class=\"headerlink\" title=\"C Metagenome functional profiling\"></a>C Metagenome functional profiling</h1><ul>\n<li>从宏基因组组装的contigs中预测基因——prodigal -p meta模式</li>\n<li>Metagenome-assembled genes which were not included in the MAGs were subjected to taxonomic classification using <a href=\"https://github.com/bioinformatics-centre/kaiju\">Kaiju</a></li>\n<li>eggNOG-mapper比对<a href=\"https://doi.org/10.1093/nar/gkv1248\">eggnog</a>数据库</li>\n<li>HMMER 比对<a href=\"https://doi.org/10.1093/nar/gky995\">Pfam</a></li>\n<li><a href=\"https://www.kegg.jp/blastkoala/\">GhostKOALA </a>和<a href=\"https://www.genome.jp/tools/kofamkoala/\">KofamKOALA (v1.0.0)</a>比对<a href=\"https://doi.org/10.1093/nar/28.1.27\">KEGG</a></li>\n<li>BLASTP比对<a href=\"https://doi.org/10.1093/nar/gkv1103\">TCDB</a></li>\n<li><a href=\"http://bcb.unl.edu/dbCAN2/\">dbCAN2 (v2.0.1)</a>比对<a href=\"https://doi.org/10.1093/nar/gkn663\">CAZy</a></li>\n<li>BLASTP比对<a href=\"https://www.ebi.ac.uk/merops/submit_searches.shtml\">MEROPS </a></li>\n<li><a href=\"https://github.com/Arkadiy-Garber/FeGenie\">FeGenie</a>检测Iron-related genes</li>\n<li>Fe-containing domains were characterized using <a href=\"https://doi.org/10.1073/pnas.0605798103\">Superfamily (v1.75)</a>.</li>\n<li>砷呼吸和抗性基因挖掘<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search\">https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic&#x2F;tree&#x2F;master&#x2F;HMM_search</a>，模型下载<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource\">https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource</a></li>\n</ul>\n<h1 id=\"参考资料：\"><a href=\"#参考资料：\" class=\"headerlink\" title=\"参考资料：\"></a>参考资料：</h1><ul>\n<li><a href=\"https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-3.0\">MetaPhlAn 3.0 tutorial</a></li>\n<li><a href=\"https://zouhua.top/archives/9d8099c8.html\">MetaPhlAn 3.0: 宏基因组物种组成分析软件</a></li>\n<li><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">GraPhlAn Tutorial</a></li>\n<li></li>\n</ul>\n","more":"<h1 id=\"A、软件列表及安装\"><a href=\"#A、软件列表及安装\" class=\"headerlink\" title=\"A、软件列表及安装\"></a>A、软件列表及安装</h1><h2 id=\"A-1-分类相关\"><a href=\"#A-1-分类相关\" class=\"headerlink\" title=\"A.1 分类相关\"></a>A.1 分类相关</h2><h3 id=\"A-1-1-metaphlan-3-0\"><a href=\"#A-1-1-metaphlan-3-0\" class=\"headerlink\" title=\"A.1.1 metaphlan 3.0\"></a>A.1.1 metaphlan 3.0</h3><p>MetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequencing data.</p>\n<h4 id=\"a-安装主文件\"><a href=\"#a-安装主文件\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n metaphlan python=3.7 metaphlan</span><br><span class=\"line\">$ conda activate metaphlan</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装数据库\"><a href=\"#b-安装数据库\" class=\"headerlink\" title=\"b. 安装数据库\"></a>b. 安装数据库</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metaphlan --install</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"c-安装依赖包\"><a href=\"#c-安装依赖包\" class=\"headerlink\" title=\"c. 安装依赖包\"></a>c. 安装依赖包</h4><ul>\n<li>hclust<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda install -c bioconda hclust2</span><br></pre></td></tr></table></figure></li>\n<li>R, vegan, ape <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda install r-base r-vegan r-ape</span><br></pre></td></tr></table></figure></li>\n<li>rbiom<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ R</span><br><span class=\"line\">$ install.packages(<span class=\"string\">&quot;rbiom&quot;</span>)</span><br><span class=\"line\">$ quit()</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"A-1-2-gtdbtk\"><a href=\"#A-1-2-gtdbtk\" class=\"headerlink\" title=\"A.1.2 gtdbtk\"></a>A.1.2 <a href=\"https://ecogenomics.github.io/GTDBTk/\">gtdbtk</a></h3><h4 id=\"a-Hardware-requirements\"><a href=\"#a-Hardware-requirements\" class=\"headerlink\" title=\"a. Hardware requirements\"></a>a. Hardware requirements</h4><table>\n<thead>\n<tr>\n<th>Domain</th>\n<th>Memory</th>\n<th>Storage</th>\n<th>Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Archaea</td>\n<td>~8 GB</td>\n<td>~27 GB</td>\n<td>~1 hour &#x2F; 1,000 genomes @ 64 CPUs</td>\n</tr>\n<tr>\n<td>Bacteria</td>\n<td>~150 GB</td>\n<td>~27 GB</td>\n<td>~1 hour &#x2F; 1,000 genomes @ 64 CPUs</td>\n</tr>\n</tbody></table>\n<h4 id=\"b-Install-GTDB-Tk-with-conda\"><a href=\"#b-Install-GTDB-Tk-with-conda\" class=\"headerlink\" title=\"b. Install GTDB-Tk with conda\"></a>b. Install GTDB-Tk with conda</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n gtdbtk -c conda-forge -c bioconda gtdbtk</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"c-GTDB-Tk-reference-data\"><a href=\"#c-GTDB-Tk-reference-data\" class=\"headerlink\" title=\"c. GTDB-Tk reference data\"></a>c. GTDB-Tk reference data</h4><ul>\n<li><strong>Note that different versions of the GTDB release data may not run on all versions of GTDB-Tk, below are all supported versions:</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>GTDB Release</th>\n<th>Minimum version</th>\n<th>Maximum version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>R95</td>\n<td>1.3.0</td>\n<td>N&#x2F;A</td>\n</tr>\n<tr>\n<td>R89</td>\n<td>0.3.0</td>\n<td>0.1.2</td>\n</tr>\n<tr>\n<td>R86.2</td>\n<td>0.2.1</td>\n<td>0.2.2</td>\n</tr>\n<tr>\n<td>R86</td>\n<td>0.1.0</td>\n<td>0.1.6</td>\n</tr>\n<tr>\n<td>R83</td>\n<td>0.0.6</td>\n<td>0.0.7</td>\n</tr>\n</tbody></table>\n<ul>\n<li>Download the reference data</li>\n</ul>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ wget https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/auxillary_files/gtdbtk_r95_data.tar.gz</span><br><span class=\"line\">  </span><br><span class=\"line\">$ tar xvzf gtdbtk_r95_data.tar.gz</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：GTDB-Tk requires an environment variable named GTDBTK_DATA_PATH to be set to the directory containing the unarchived GTDB-Tk reference data.</p>\n<ul>\n<li>You can automatically alias GTDBTK_DATA_PATH whenever the environment is activated by editing {gtdbtk environment path}&#x2F;etc&#x2F;conda&#x2F;activate.d&#x2F;gtdbtk.sh, e.g.:</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Determine the GTDB-Tk environment path</span></span><br><span class=\"line\">$ conda activate gtdbtk</span><br><span class=\"line\">$ <span class=\"built_in\">which</span> gtdbtk</span><br><span class=\"line\"><span class=\"comment\"># /miniconda3/envs/gtdbtk-1.3.0/bin/gtdbtk</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Edit the activate file</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">&quot;export GTDBTK_DATA_PATH=/path/to/release/package/&quot;</span> &gt; /miniconda3/envs/gtdbtk-1.3.0/etc/conda/activate.d/gtdbtk.sh</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"A-1-3-Kraken2\"><a href=\"#A-1-3-Kraken2\" class=\"headerlink\" title=\"A.1.3 Kraken2\"></a>A.1.3 <a href=\"https://github.com/DerrickWood/kraken2\">Kraken2</a></h3><h4 id=\"a-Hardware-requirements-1\"><a href=\"#a-Hardware-requirements-1\" class=\"headerlink\" title=\"a. Hardware requirements\"></a>a. Hardware requirements</h4><ul>\n<li>Disk space: Construction of a Kraken 2 standard database requires approximately 100 GB of disk space. A test on 01 Jan 2018 of the default installation showed 42 GB of disk space was used to store the genomic library files, 26 GB was used to store the taxonomy information from NCBI, and 29 GB was used to store the Kraken 2 compact hash table.</li>\n<li>Memory: To run efficiently, Kraken 2 requires enough free memory to hold the database (primarily the hash table) in RAM. While this can be accomplished with a ramdisk, Kraken 2 will by default load the database into process-local RAM; the –memory-mapping switch to kraken2 will avoid doing so. The default database size is 29 GB (as of Jan. 2018), and you will need slightly more than that in RAM if you want to build the default database.</li>\n</ul>\n<h4 id=\"b-Install-Kraken2-with-conda\"><a href=\"#b-Install-Kraken2-with-conda\" class=\"headerlink\" title=\"b. Install Kraken2 with conda\"></a>b. Install Kraken2 with conda</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n kraken2 kraken2</span><br></pre></td></tr></table></figure>\n<h4 id=\"c-Build-the-database\"><a href=\"#c-Build-the-database\" class=\"headerlink\" title=\"c. Build the database\"></a>c. Build the database</h4><ul>\n<li>下载数据库。找到一个存储空间比较大的目录并进入，运行如下命令，这里下载的数据库包括archaea，bacteria，plasmid，viral，fungi，protozoa，UniVec和UniVec_Core：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> bash -c <span class=\"string\">&#x27;for i in archaea bacteria plasmid viral fungi protozoa UniVec UniVec_Core; do kraken2-build --download-library $i --threads 24 --db db_name; done&#x27;</span> &amp;</span><br></pre></td></tr></table></figure></li>\n<li>下载分类信息<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> kraken2-build --download-taxonomy --threads 24 --db db_name &amp;</span><br></pre></td></tr></table></figure></li>\n<li>建立索引<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">nohup</span> kraken2-build --build --threads 24 --db db_name &amp;</span><br></pre></td></tr></table></figure>\n<h4 id=\"d-序列分类\"><a href=\"#d-序列分类\" class=\"headerlink\" title=\"d. 序列分类\"></a>d. 序列分类</h4></li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kraken2 --paired --threads 24 --unclassified-out unclassified<span class=\"comment\">#.fq --classified-out classified#.fq --output outfile --confidence 0.5 --memory-mapping --use-names --report reportname --report-zero-counts --db $DBNAME reads1 read2</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"A-2-组装、Bining、质量评估\"><a href=\"#A-2-组装、Bining、质量评估\" class=\"headerlink\" title=\"A.2 组装、Bining、质量评估\"></a>A.2 组装、Bining、质量评估</h2><h3 id=\"A-2-1-metawrap\"><a href=\"#A-2-1-metawrap\" class=\"headerlink\" title=\"A.2.1 metawrap\"></a>A.2.1 metawrap</h3><p>MetaWRAP is a pipeline for genome-resolved metagenomic data analysis.</p>\n<h4 id=\"a-安装主文件-1\"><a href=\"#a-安装主文件-1\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n metawrap python=2.7 metaphlan</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装其他分析工具到metawrap环境中\"><a href=\"#b-安装其他分析工具到metawrap环境中\" class=\"headerlink\" title=\"b. 安装其他分析工具到metawrap环境中\"></a>b. 安装其他分析工具到metawrap环境中</h4><ul>\n<li><strong>cd-hit</strong></li>\n<li><strong>coverm</strong> DNA read coverage and relative abundance calculator focused on metagenomics applications</li>\n<li><strong>bamm</strong> Metagenomics-focused BAM file manipulation</li>\n<li><strong>unitem</strong> Ensemble binning strategies for combining the output of multiple binning methods</li>\n<li><strong>humann2</strong> The HMP Unified Metabolic Analysis Network 2</li>\n<li><strong><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">graphlan</a></strong> </li>\n<li><strong><a href=\"https://pypi.org/project/export2graphlan/\">export2graphlan</a></strong> </li>\n<li><strong><a href=\"https://data.ace.uq.edu.au/public/CheckM_databases/\">checkm database</a></strong><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activeta metawrap</span><br><span class=\"line\">$ conda install cd-hit coverm bamm unitem humann2 graphlan export2graphlan</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 找到一个合适的目录并cd进入以便存储checkm数据库</span></span><br><span class=\"line\">$ wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz</span><br><span class=\"line\">$ tar zxvf checkm_data_2015_01_16.tar.gz</span><br><span class=\"line\">$ checkm data setRoot</span><br><span class=\"line\"><span class=\"comment\"># 随后输入数据库所在的full path</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"A-3-非冗余基因功能注释\"><a href=\"#A-3-非冗余基因功能注释\" class=\"headerlink\" title=\"A.3 非冗余基因功能注释\"></a>A.3 非冗余基因功能注释</h2><h3 id=\"A-3-1-eggNOG-mapper\"><a href=\"#A-3-1-eggNOG-mapper\" class=\"headerlink\" title=\"A.3.1 eggNOG-mapper\"></a>A.3.1 eggNOG-mapper</h3><p>功能注释，uniref, eggNOG, KEGG, GO; CAZy; VFDB; CARD; TCDB; PHI。</p>\n<h3 id=\"A-3-2-EnrichM\"><a href=\"#A-3-2-EnrichM\" class=\"headerlink\" title=\"A.3.2 EnrichM\"></a>A.3.2 EnrichM</h3><p><a href=\"https://github.com/geronimp/enrichM\">EnrichM</a> is a set of comparative genomics tools for large sets of metagenome assembled genomes (MAGs). The current functionality includes:</p>\n<ul>\n<li>A basic annotation pipeline for MAGs.</li>\n<li>A pipeline to determine the metabolic pathways that are encoded by MAGs, using KEGG modules as a reference (although custom pathways can be specified)</li>\n<li>A pipeline to identify genes or metabolic pathways that are enriched within and between user-defined groups of genomes (groups can be genomes that are related functionally, phylogenetically, recovered from different environments, etc).</li>\n<li>To construct metabolic networks from annotated population genomes.</li>\n<li>Construct random forest machine learning models from the functional composition of either MAGs, metagenomes or transcriptomes.</li>\n<li>Apply these random forest machine learning models to classify new MAGs metagenomes.</li>\n</ul>\n<h4 id=\"a-安装主文件-2\"><a href=\"#a-安装主文件-2\" class=\"headerlink\" title=\"a. 安装主文件\"></a>a. 安装主文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda create -n enrichm python=3</span><br><span class=\"line\">$ conda install enrichm</span><br></pre></td></tr></table></figure>\n<h4 id=\"b-安装数据库-1\"><a href=\"#b-安装数据库-1\" class=\"headerlink\" title=\"b. 安装数据库\"></a>b. 安装数据库</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 约5.7 G</span></span><br><span class=\"line\">$ enrichm data</span><br></pre></td></tr></table></figure>\n<p><strong>报错</strong> ：</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;data.py”, line 114, in do<br>    version_remote &#x3D; urllib.request.urlopen(self.ftp + self.VERSION).readline().strip().decode(“utf-8”)<br>AttributeError: module ‘urllib’ has no attribute ‘request’</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;bin&#x2F;enrichm”, line 342, in &lt;module&gt;<br>    run.run_enrichm(args, sys.argv)<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;run.py”, line 288, in run_enrichm<br>    d.do(args.uninstall, args.dry)<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;data.py”, line 117, in do<br>    “Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a>“)<br>Exception: Unable to find most current EnrichM database VERSION in ftp. Please complain at <a href=\"https://github.com/geronimp/enrichM\">https://github.com/geronimp/enrichM</a></p>\n</blockquote>\n<p><strong>解决方案：将data.py中的’import urllib’替换为’import urllib.request’</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim /home/hualin/miniconda3/envs/enrichm/lib/python3.6/site-packages/enrichm/data.py</span><br></pre></td></tr></table></figure>\n<h4 id=\"c-Sepcifying-the-location-of-the-EnrichM-database\"><a href=\"#c-Sepcifying-the-location-of-the-EnrichM-database\" class=\"headerlink\" title=\"c. Sepcifying the location of the EnrichM database\"></a>c. Sepcifying the location of the EnrichM database</h4><p>If you would like to store the EnrichM database outside of your home directory, move you need to tell EnrichM where to look. To do this, export a BASH variable named “ENRICHM_DB”:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">export</span> ENRICHM_DB=/path/to/database/ &gt;&gt;~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<p><strong>注意</strong> ：&#x2F;path&#x2F;to&#x2F;database&#x2F;根据实际情况而定！<br><strong>报错</strong>：</p>\n<blockquote>\n<p>$ enrichm<br>Traceback (most recent call last):<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;bin&#x2F;enrichm”, line 38, in &lt;module&gt;<br>    from enrichm.run import Run<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;run.py”, line 24, in &lt;module&gt;<br>    from enrichm.network_analyzer import NetworkAnalyser<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;network_analyzer.py”, line 22, in &lt;module&gt;<br>    from enrichm.network_builder import NetworkBuilder<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;network_builder.py”, line 24, in &lt;module&gt;<br>    from enrichm.databases import Databases<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;databases.py”, line 28, in &lt;module&gt;<br>    class Databases:<br>  File “&#x2F;home&#x2F;hualin&#x2F;miniconda3&#x2F;envs&#x2F;enrichm&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;enrichm&#x2F;databases.py”, line 36, in Databases<br>    PICKLE_VERSION &#x3D; open(os.path.join(CUR_DATABASE_DIR, ‘VERSION’)).readline().strip()<br>FileNotFoundError: [Errno 2] No such file or directory: ‘&#x2F;new_data&#x2F;hualin&#x2F;db&#x2F;enrichm_database_v10&#x2F;26-11-2018&#x2F;VERSION’</p>\n</blockquote>\n<p><strong>Solve</strong>: 将下载的数据库文件全部复制一份到“<strong>26-11-2018</strong>”目录中，否则后续运行annotaton时会提示找不到数据库文件。</p>\n<h1 id=\"B、数据分析\"><a href=\"#B、数据分析\" class=\"headerlink\" title=\"B、数据分析\"></a>B、数据分析</h1><h2 id=\"B-1-使用metaphlan从Reads中获取物种分类信息\"><a href=\"#B-1-使用metaphlan从Reads中获取物种分类信息\" class=\"headerlink\" title=\"B.1 使用metaphlan从Reads中获取物种分类信息\"></a>B.1 使用metaphlan从Reads中获取物种分类信息</h2><h3 id=\"Step-1-激活环境\"><a href=\"#Step-1-激活环境\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metaphlan</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-对paired-end-Reads进行注释\"><a href=\"#Step-2-对paired-end-Reads进行注释\" class=\"headerlink\" title=\"Step 2. 对paired-end Reads进行注释\"></a>Step 2. 对paired-end Reads进行注释</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metaphlan Reads1,Reads2 --input_type fastq --bowtie2out Str1.bowtie2.bz2 --<span class=\"built_in\">nproc</span> 10 -o Str1_profiled.txt</span><br></pre></td></tr></table></figure>\n<p>Reads1和Reads2分别代表双端测序得到的正向和反向数据；–input_type指定文件格式，我们拿到的下机数据一般为fastq格式；–bowtie2out参数将会保存运行产生的中间文件以便后续重新运行程序时作为输入文件；–nproc指定使用的线程数量；-o指定输出文件名。</p>\n<h3 id=\"Step-3-汇总所有的结果文件\"><a href=\"#Step-3-汇总所有的结果文件\" class=\"headerlink\" title=\"Step 3. 汇总所有的结果文件\"></a>Step 3. 汇总所有的结果文件</h3><p>对所有的文件均运行Step 2 ，产生了多个输出文件（*_profiled.txt），可以将它们汇总到一个文件中（merged_abundance_table.txt），便于后续对多个样品进行相互比较。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ merge_metaphlan_tables.py *_profiled.txt &gt; merged_abundance_table.txt</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-4-从合并的文件中提取种水平的分类\"><a href=\"#Step-4-从合并的文件中提取种水平的分类\" class=\"headerlink\" title=\"Step 4. 从合并的文件中提取种水平的分类\"></a>Step 4. 从合并的文件中提取种水平的分类</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ grep -E <span class=\"string\">&quot;s__|clade&quot;</span> merged_abundance_table.txt | sed <span class=\"string\">&#x27;s/^.*s__//g&#x27;</span> | <span class=\"built_in\">cut</span> -f1,3-8 | sed -e <span class=\"string\">&#x27;s/clade_name/body_site/g&#x27;</span> &gt; merged_abundance_table_species.txt</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Step-5-绘制样本间种水平的热图\"><a href=\"#Step-5-绘制样本间种水平的热图\" class=\"headerlink\" title=\"Step 5. 绘制样本间种水平的热图\"></a>Step 5. 绘制样本间种水平的热图</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hclust2.py -i merged_abundance_table_species.txt -o abundance_heatmap_species.png --ftop 50 --f_dist_f braycurtis --s_dist_f braycurtis --cell_aspect_ratio 0.5 -l --flabel_size 10 --slabel_size 10 --max_flabel_len 100 --max_slabel_len 100 --minv 0.1 --dpi 300</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-6-计算样本间的unifrac距离\"><a href=\"#Step-6-计算样本间的unifrac距离\" class=\"headerlink\" title=\"Step 6. 计算样本间的unifrac距离\"></a>Step 6. 计算样本间的unifrac距离</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载依赖的tree文件和脚本,与要分析的文件放于同一目录下</span></span><br><span class=\"line\">$ wget https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/mpa_v30_CHOCOPhlAn_201901_species_tree.nwk</span><br><span class=\"line\">$ wget https://github.com/biobakery/MetaPhlAn/blob/master/metaphlan/utils/calculate_unifrac.R</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 开始计算距离</span></span><br><span class=\"line\">$ Rscript plot_unifrac.R merged_abundance_table.txt mpa_v30_CHOCOPhlAn_201901_species_tree.nwk unifrac_merged_abundance_table.txt</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-7-绘制cladogram图\"><a href=\"#Step-7-绘制cladogram图\" class=\"headerlink\" title=\"Step 7. 绘制cladogram图\"></a>Step 7. 绘制cladogram图</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 激活依赖软件所在的环境</span></span><br><span class=\"line\">$ conda activate metawrap</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成绘图所需的文件</span></span><br><span class=\"line\">$ <span class=\"built_in\">tail</span> -n +2 merged_abundance_table.txt | <span class=\"built_in\">cut</span> -f1,3- &gt; merged_abundance_table_reformatted.txt</span><br><span class=\"line\"></span><br><span class=\"line\">$ export2graphlan.py --skip_rows 1 -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant 100 --abundance_threshold 1 --least_biomarkers 10 --annotations 5,6 --external_annotations 7 --min_clade_size 1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘图</span></span><br><span class=\"line\">$ graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml</span><br><span class=\"line\"></span><br><span class=\"line\">$ graphlan.py --dpi 300 merged_abundance.xml merged_abundance.pdf --external_legends</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"B-2-使用metawrap对Reads进行组装\"><a href=\"#B-2-使用metawrap对Reads进行组装\" class=\"headerlink\" title=\"B.2 使用metawrap对Reads进行组装\"></a>B.2 使用metawrap对Reads进行组装</h2><h3 id=\"Step-1-激活环境-1\"><a href=\"#Step-1-激活环境-1\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metawrap</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-组装\"><a href=\"#Step-2-组装\" class=\"headerlink\" title=\"Step 2. 组装\"></a>Step 2. 组装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap assembly -1 Reads1 -2 Reads2 -o Assemble1 -m 300 -t 15 --metaspades</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP assembly [options] -1 reads_1.fastq -2 reads_2.fastq -o output_dir\n\n<ul>\n<li>Options:<ul>\n<li><p>   -1 STR          forward fastq reads</p>\n</li>\n<li><p>   -2 STR          reverse fastq reads</p>\n</li>\n<li><p>   -o STR          output directory</p>\n</li>\n<li><p>   -m INT          memory in GB (default&#x3D;24)</p>\n</li>\n<li><p>   -t INT          number of threads (defualt&#x3D;1)</p>\n</li>\n<li><p>   -l INT\t\tminimum length of assembled contigs (default&#x3D;1000)</p>\n</li>\n<li><p>   --megahit\tassemble with megahit (default)</p>\n</li>\n<li><p>--metaspades\tassemble with metaspades instead of megahit (better results but slower and higher memory requirement)</p>\n</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<p>Reads1和Reads2分别代表双端测序得到的正向和反向数据；-o指定输出目录，-m指定最大可用内存大小，超过设定值后程序会自动退出，建议设大一点，我10G的数据大概需要180G内存；-t指定线程数；–metaspades表示用metaspades进行组装，特别慢，但是组装结果相对好一些。</p>\n<h2 id=\"B-3-使用metawrap对Contigs进行Bining\"><a href=\"#B-3-使用metawrap对Contigs进行Bining\" class=\"headerlink\" title=\"B.3 使用metawrap对Contigs进行Bining\"></a>B.3 使用metawrap对Contigs进行Bining</h2><h3 id=\"Step-1-激活环境-2\"><a href=\"#Step-1-激活环境-2\" class=\"headerlink\" title=\"Step 1. 激活环境\"></a>Step 1. 激活环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate metawrap</span><br></pre></td></tr></table></figure>\n<h3 id=\"Step-2-Bining\"><a href=\"#Step-2-Bining\" class=\"headerlink\" title=\"Step 2. Bining\"></a>Step 2. Bining</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap binning -o Str1.INITIAL_BINNING -t 20 -m 200 --universal --run-checkm -a &lt;path of contigs&gt; --metabat2 --maxbin2 --concoct 解压的Reads1 解压的Reads2</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP binning [options] -a assembly.fa -o output_dir readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n\n<ul>\n<li><p>Note1: Make sure to provide all your separately replicate read files, not the joined file.</p>\n</li>\n<li><p>Note2: You may provide single end or interleaved reads as well with the use of the correct option</p>\n</li>\n<li><p>Note3: If the output already has the .bam alignments files from previous runs, the module will skip re-aligning the reads</p>\n</li>\n<li><p>Options:</p>\n<ul>\n<li>   -a STR          metagenomic assembly file</li>\n<li>   -o STR          output directory</li>\n<li>   -t INT          number of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tamount of RAM available (default&#x3D;4)</li>\n<li>   -l INT\t\tminimum contig length to bin (default&#x3D;1000bp). Note: metaBAT will default to 1500bp minimum</li>\n<li>   --metabat2      bin contigs with metaBAT2</li>\n<li>   --metabat1\tbin contigs with the original metaBAT</li>\n<li>   --maxbin2\tbin contigs with MaxBin2</li>\n<li>   --concoct\tbin contigs with CONCOCT</li>\n<li>--universal\tuse universal marker genes instead of bacterial markers in MaxBin2 (improves Archaea binning)</li>\n<li>   --run-checkm\timmediately run CheckM on the bin results (requires 40GB+ of memory)</li>\n<li>   --single-end\tnon-paired reads mode (provide *.fastq files)</li>\n<li>   --interleaved\tthe input read files contain interleaved paired-end reads</details>\n**注意避坑：** 这里的Reads1和Reads2需要提供解压缩后的Reads文件，不但要解压缩，还需要重命名，即后缀名必须为“\\_clean\\_1.fastq” 和 “\\_clean\\_2.fastq”，否则软件无法运行。-o指定输出目录；-t指定线程数；-m指定最大内存限制；--run-checkm表明即时检查Bining的质量；--metabat2 --maxbin2 --concoct 指定同时采用这三个分箱工具进行Bining；--universal指定MaxBin2采用universal marker 基因代替 bacterial markers  (improves Archaea binning)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\"><a href=\"#Step-3-整合三种方法的bins-metabat2-maxbin2-concoct-结果\" class=\"headerlink\" title=\"Step 3. 整合三种方法的bins (metabat2, maxbin2, concoct) 结果\"></a>Step 3. 整合三种方法的bins (metabat2, maxbin2, concoct) 结果</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap bin_refinement -o F01_BIN_REFINEMENT(输出目录) -t 20 -A str1.INITIAL_BINNING/metabat2_bins/ -B str1.INITIAL_BINNING/maxbin2_bins/ -C str1.INITIAL_BINNING/concoct_bins/ -c 70 -x 5</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP bin_refinement [options] -o output_dir -A bin_folderA [-B bin_folderB -C bin_folderC]\n\n<ul>\n<li><p>Note: the contig names in different bin folders must be consistant (must come from the same assembly).</p>\n</li>\n<li><p>Options:</p>\n<ul>\n<li>-o STR          output directory</li>\n<li>   -t INT          number of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tmemory available (default&#x3D;40)</li>\n<li>   -c INT          完整度minimum % completion of bins [should be &gt;50%] (default&#x3D;70)</li>\n<li>   -x INT          污染度maximum % contamination of bins that is acceptable (default&#x3D;10)</li>\n<li>   -A STR\t\tfolder with metagenomic bins (files must have .fa or .fasta extension)</li>\n<li>   -B STR\t\tanother folder with metagenomic bins</li>\n<li>   -C STR\t\tanother folder with metagenomic bins</li>\n<li>   --skip-refinement\tdont use binning_refiner to come up with refined bins based on combinations of binner outputs</li>\n<li>   --skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>   --skip-consolidation\tchoose the best version of each bin from all bin refinement iteration</li>\n<li>   --keep-ambiguous\tfor contigs that end up in more than one bin, keep them in all bins (default: keeps them only in the best bin)</li>\n<li>   --remove-ambiguous\tfor contigs that end up in more than one bin, remove them in all bins (default: keeps them only in the best bin)</li>\n<li>   --quick\t\t\tadds –reduced_tree option to checkm, reducing runtime, especially with low memory</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-4-Blobology可视化bin\"><a href=\"#Step-4-Blobology可视化bin\" class=\"headerlink\" title=\"Step 4. Blobology可视化bin\"></a>Step 4. Blobology可视化bin</h3><p><strong>一个坑：</strong> metawrap安装的blast为2.6版本，只能用Version 4 的nt库。而最新的nt库为Version 5，v4已经不再维护了。因此需要更新metawrap安装环境中的blast至2.8.0及以上版本，这里无法通过‘conda updata blast’实现更新，而是需要下载新版本的blast可执行程序，覆盖metawrap环境中的blast程度们。 如果你采用的是默认版本的blast和V5的nt库，会得到报错：“BLAST Database error: Error: Not a valid version 4 database”.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap blobology -a Result/Assemble/F01/final_assembly.fasta -t 20 -o F01.BLOBOLOGY --bins F01_BIN_REFINEMENT/metawrap_70_5_bins reads/F01_clean_1.fastq reads/F01_clean_2.fastq</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP blobology [options] -a assembly.fasta -o output_dir readsA_1.fastq readsA_2.fastq [readsB_1.fastq readsB_2.fastq ... ]\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -a STR\t\tassembly fasta file</li>\n<li>   -o STR          output directory</li>\n<li>   -t INT          number of threads</li>\n<li>   --subsamble \tINT\tNumber of contigs to run blobology on. Subsampling is randomized. (default&#x3D;ALL)</li>\n<li>   --bins\t\tSTR\tFolder containing bins. Contig names must match those of the assembly file. (default&#x3D;None)</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-5-Bins-定量\"><a href=\"#Step-5-Bins-定量\" class=\"headerlink\" title=\"Step 5. Bins 定量\"></a>Step 5. Bins 定量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ metawrap quant_bins -b F01_BIN_REFINEMENT/metawrap_70_5_bins -t 8 -o F01.QUANT_BINS -a Result/Assemble/F01/final_assembly.fasta reads/F01_clean_1.fastq reads/F01_clean_2.fastq</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP quant_bins [options] -b bins_folder -o output_dir -a assembly.fa readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq]\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -b STR          folder containing draft genomes (bins) in fasta format</li>\n<li>   -o STR          output directory</li>\n<li>   -a STR\t\tfasta file with entire metagenomic assembly (strongly recommended!)</li>\n<li>   -t INT\t\tnumber of threads</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h3 id=\"Step-6-重组装\"><a href=\"#Step-6-重组装\" class=\"headerlink\" title=\"Step 6. 重组装\"></a>Step 6. 重组装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">metawrap reassemble_bins -o F01.BIN_REASSEMBLY -1 reads/F01_clean_1.fastq -2 reads/F01_clean_2.fastq -t 20 -m 400 -c 70 -x 10 -b F01_BIN_REFINEMENT/metawrap_70_5_bins</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nUsage: metaWRAP reassemble_bins [options] -o output_dir -b bin_folder -1 reads_1.fastq -2 reads_2.fastq\n\n<ul>\n<li><p>Options:</p>\n<ul>\n<li>   -b STR\t\tfolder with metagenomic bins</li>\n<li>   -o STR\t\toutput directory</li>\n<li>   -1 STR          forward reads to use for reassembly</li>\n<li>   -2 STR          reverse reads to use for reassembly</li>\n<li>   -t INT\t\tnumber of threads (default&#x3D;1)</li>\n<li>   -m INT\t\tmemory in GB (default&#x3D;40)</li>\n<li>   -c INT\t\tminimum desired bin completion % (default&#x3D;70)</li>\n<li>   -x INT\t\tmaximum desired bin contamination % (default&#x3D;10)</li>\n<li>   -l INT\t\tminimum contig length to be included in reassembly (default&#x3D;500)</li>\n<li>   --strict-cut-off\tmaximum allowed SNPs for strict read mapping (default&#x3D;2)</li>\n<li>   --permissive-cut-off\tmaximum allowed SNPs for permissive read mapping (default&#x3D;5)</li>\n<li>   --skip-checkm\t\tdont run CheckM to assess bins</li>\n<li>   --parallel\t\trun spades reassembly in parallel, but only using 1 thread per bin</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h2 id=\"B-4-MAGs注释\"><a href=\"#B-4-MAGs注释\" class=\"headerlink\" title=\"B.4 MAGs注释\"></a>B.4 MAGs注释</h2><h3 id=\"B-4-1-GTDB-TK-进行物种分类和注释，构建系统发育树\"><a href=\"#B-4-1-GTDB-TK-进行物种分类和注释，构建系统发育树\" class=\"headerlink\" title=\"B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树\"></a>B.4.1 GTDB-TK 进行物种分类和注释，构建系统发育树</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ conda activate gtdbtk</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"classify-wf——Classify-workflow-包括了Step-1-3\"><a href=\"#classify-wf——Classify-workflow-包括了Step-1-3\" class=\"headerlink\" title=\"classify_wf——Classify workflow (包括了Step 1-3)\"></a>classify_wf——Classify workflow (包括了Step 1-3)</h4><p>The classify workflow consists of three steps: identify, align, and classify.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk classify_wf --genome_dir metawrap_70_5_bins/ --out_dir classify_wf_output -x .fa --prefix F --cpus 6 -r --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk classify_wf (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [-x EXTENSION] [--min_perc_aa MIN_PERC_AA] [--prefix PREFIX] [--cpus CPUS]\n                          [--pplacer_cpus PPLACER_CPUS] [--force] [--scratch_dir SCRATCH_DIR] [-r] [--min_af MIN_AF] [--debug] [-h]\n\n<ul>\n<li><p>mutually exclusive required arguments:</p>\n<ul>\n<li>--genome_dir GENOME_DIR<br>               directory containing genome files in FASTA format</li>\n<li>--batchfile BATCHFILE<br>               path to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</li>\n</ul>\n</li>\n<li><p>required named arguments:</p>\n<ul>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br>                extension of files to process, gz &#x3D; gzipped (default: fna)</li>\n<li>--min_perc_aa MIN_PERC_AA<br>                exclude genomes that do not have at least this percentage of AA in the MSA (inclusive bound) (default: 10)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--pplacer_cpus PPLACER_CPUS<br>                use pplacer_cpus during placement (default: cpus)</li>\n<li>--force               continue processing if an error occurs on a single genome (default: False)</li>\n<li>--scratch_dir SCRATCH_DIR<br>                Reduce pplacer memory usage by writing to disk (slower).</li>\n<li>-r, --recalculate_red<br>                recalculate RED values based on the reference tree and all added user genomes (default: False)</li>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-1-identify——在基因组中寻找marker-genes\"><a href=\"#Step-1-identify——在基因组中寻找marker-genes\" class=\"headerlink\" title=\"Step 1: identify——在基因组中寻找marker genes\"></a>Step 1: identify——在基因组中寻找marker genes</h4><p>Translation table选择：use table 11 unless the coding density using table 4 is 5% higher than when using table 11 and the coding density under table 4 is &gt;70%.  GTDB-Tk 不会区分 tables 4和tables 5. 若用户清楚使用哪一个table，可以通过--batchfile指定。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk identify --genome_dir metawrap_70_5_bins/ --out_dir identify_output --cpus 6 --prefix F --debug -x .fa --write_single_copy_genes</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-2-align\"><a href=\"#Step-2-align\" class=\"headerlink\" title=\"Step 2: align\"></a>Step 2: align</h4><p>Create a multiple sequence alignment based on the AR122&#x2F;BAC120 marker set.<br>Time 3m50.019s</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk align --identify_dir identify_output/ --out_dir align_output --cpus 3 --prefix F --debug</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-3-classify\"><a href=\"#Step-3-classify\" class=\"headerlink\" title=\"Step 3: classify\"></a>Step 3: classify</h4><p>Determine taxonomic classification of genomes.<br>Time 118m9.386s</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk classify --genome_dir metawrap_70_5_bins/ --align_dir align_output/ --out_dir classify_output --cpus 3 --prefix F --debug -x .fa -r</span><br></pre></td></tr></table></figure>\n<p><strong>注意</strong>：如果内存较小，则加上“–scratch_dir”参数。</p>\n<hr>\n<h4 id=\"Step-4-export-msa-这一步不运行\"><a href=\"#Step-4-export-msa-这一步不运行\" class=\"headerlink\" title=\"Step 4: export_msa (这一步不运行)\"></a>Step 4: export_msa (这一步不运行)</h4><p>The export_msa will export the untrimmed archaeal or bacterial MSA used in the reference data.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌 0m1.503s</span></span><br><span class=\"line\">$ time gtdbtk export_msa --domain arc --output msa_arc.faa --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌 0m16.679s</span></span><br><span class=\"line\">$ time gtdbtk export_msa --domain bac --output msa_bac.faa --debug</span><br></pre></td></tr></table></figure>\n<h4 id=\"Step-5-trim-msa-这一步不运行\"><a href=\"#Step-5-trim-msa-这一步不运行\" class=\"headerlink\" title=\"Step 5: trim_msa (这一步不运行)\"></a>Step 5: trim_msa (这一步不运行)</h4><p>The trim_msa command will trim a MSA given a user-specified mask file, or the archaeal&#x2F;bacterial mask present in the reference data.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌 0m10.675s</span></span><br><span class=\"line\">$ time gtdbtk trim_msa --untrimmed_msa msa_arc.faa --output msa_arc_trim.faa --reference_mask arc --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌 3m28.793s</span></span><br><span class=\"line\">$ time gtdbtk trim_msa --untrimmed_msa msa_bac.faa --output msa_bac_trim.faa --reference_mask bac --debug</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Step-6-infer\"><a href=\"#Step-6-infer\" class=\"headerlink\" title=\"Step 6: infer\"></a>Step 6: infer</h4><p>Infer tree from multiple sequence alignment.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#古菌 44m54.884s</span></span><br><span class=\"line\">$ time gtdbtk infer --msa_file align_output/F.ar122.msa.fasta --out_dir infer_out_arc_F --prefix F --cpus 12 --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#细菌</span></span><br><span class=\"line\">$ time gtdbtk infer --msa_file align_output/F.bac120.msa.fasta --out_dir infer_out_bac_F --prefix F --cpus 12 --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk infer --msa_file MSA_FILE --out_dir OUT_DIR [--prot_model {JTT,WAG,LG}] [--no_support] [--gamma] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--msa_file MSA_FILE   multiple sequence alignment in FASTA format</li>\n<li>--out_dir OUT_DIR     directory to output files</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--prot_model {JTT,WAG,LG}<br>                protein substitution model for tree inference (default: WAG)</li>\n<li>--no_support          do not compute local support values using the Shimodaira-Hasegawa test (default: False)</li>\n<li>--gamma               rescale branch lengths to optimize the Gamma20 likelihood (default: False)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-7-decorate\"><a href=\"#Step-7-decorate\" class=\"headerlink\" title=\"Step 7: decorate\"></a>Step 7: decorate</h4><p>Decorate a tree with the GTDB-Tk taxonomy.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 古菌</span></span><br><span class=\"line\">$ time gtdbtk decorate --input_tree infer_out_arc_F/F.unrooted.tree --output_tree F.decorate_unrooted_arc.tree --gtdbtk_classification_file classify_output/classify/F.ar122.summary.tsv --debug</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 细菌</span></span><br><span class=\"line\">$ time gtdbtk decorate --input_tree infer_out_bac_F/F.unrooted.tree --output_tree F.decorate_unrooted_brc.tree --gtdbtk_classification_file classify_output/classify/F.bac120.summary.tsv --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk decorate --input_tree INPUT_TREE --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE] [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE]\n                       [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br>                path to the unrooted tree in Newick format</li>\n<li>--output_tree OUTPUT_TREE<br>                path to output the tree</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br>                file with GTDB-Tk classifications produced by the <code>classify</code> command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br>                file indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-8-root\"><a href=\"#Step-8-root\" class=\"headerlink\" title=\"Step 8: root\"></a>Step 8: root</h4><p>Root a tree using an outgroup.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk root --input_tree input.tree --outgroup_taxon p__Nanoarchaeota --output_tree output.tree --gtdbtk_classification_file &lt;file with GTDB-Tk classifications produced by the classify <span class=\"built_in\">command</span>&gt; --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk root --input_tree INPUT_TREE --outgroup_taxon OUTGROUP_TAXON --output_tree OUTPUT_TREE [--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE]\n                   [--custom_taxonomy_file CUSTOM_TAXONOMY_FILE] [--debug] [-h]\n\n<ul>\n<li><p>required named arguments:</p>\n<ul>\n<li>--input_tree INPUT_TREE<br>                path to the unrooted tree in Newick format</li>\n<li>--outgroup_taxon OUTGROUP_TAXON<br>                taxon to use as outgroup (e.g., p__Patescibacteria or p__Altarchaeota)</li>\n<li>--output_tree OUTPUT_TREE<br>                path to output the tree</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>--gtdbtk_classification_file GTDBTK_CLASSIFICATION_FILE<br>                file with GTDB-Tk classifications produced by the <code>classify</code> command</li>\n<li>--custom_taxonomy_file CUSTOM_TAXONOMY_FILE<br>                file indicating custom taxonomy strings for user genomes, that should contain any genomes belonging to the outgroup</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message</details></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"Step-9-ani-rep——计算ANI值\"><a href=\"#Step-9-ani-rep——计算ANI值\" class=\"headerlink\" title=\"Step 9: ani_rep——计算ANI值\"></a>Step 9: ani_rep——计算ANI值</h4><p>Compute the ANI of input genomes to all GTDB-Tk representative genomes.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ time gtdbtk ani_rep --genome_dir metawrap_70_5_bins/ --out_dir ani_rep/ --cpus 6 -x .fa --prefix F --debug</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ gtdbtk de_novo_wf --genome_dir metawrap_70_5_bins/ --out_dir de_novo_wf --extension .fa --bacteria --outgroup_taxon p__Patescibacteria --prefix F --cpus 6 --debug</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\nusage: gtdbtk ani_rep (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR [--no_mash] [--mash_k MASH_K] [--mash_s MASH_S] [--mash_d MASH_D] [--mash_v MASH_V]\n                      [--mash_db MASH_DB] [--min_af MIN_AF] [-x EXTENSION] [--prefix PREFIX] [--cpus CPUS] [--debug] [-h]\n\n<ul>\n<li><p>mutually exclusive required arguments:</p>\n<ul>\n<li><p>--genome_dir GENOME_DIR<br>                directory containing genome files in FASTA format</p>\n</li>\n<li><p>--batchfile BATCHFILE<br>                path to file describing genomes - tab separated in 2 or 3 columns (FASTA file, genome ID, translation table [optional])</p>\n</li>\n<li><p>- required named arguments:</p>\n</li>\n<li><p>--out_dir OUT_DIR     directory to output files</p>\n</li>\n</ul>\n</li>\n<li><p>optional Mash arguments:</p>\n<ul>\n<li>--no_mash             skip pre-filtering of genomes using Mash (default: False)</li>\n<li>--mash_k MASH_K       k-mer size [1-32] (default: 16)</li>\n<li>--mash_s MASH_S       maximum number of non-redundant hashes (default: 5000)</li>\n<li>--mash_d MASH_D       maximum distance to keep [0-1] (default: 0.1)</li>\n<li>--mash_v MASH_V       maximum p-value to keep [0-1] (default: 1.0)</li>\n<li>--mash_db MASH_DB     path to save&#x2F;read (if exists) the Mash reference sketch database (.msh)</li>\n</ul>\n</li>\n<li><p>optional FastANI arguments:</p>\n<ul>\n<li>--min_af MIN_AF       minimum alignment fraction to consider closest genome (default: 0.65)</li>\n</ul>\n</li>\n<li><p>optional arguments:</p>\n<ul>\n<li>-x, --extension EXTENSION<br>                extension of files to process, gz &#x3D; gzipped (default: fna)</li>\n<li>--prefix PREFIX       prefix for all output files (default: gtdbtk)</li>\n<li>--cpus CPUS           number of CPUs to use (default: 1)</li>\n<li>--debug               create intermediate files for debugging purposes (default: False)</li>\n<li>-h, --help            show help message </details></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"B-4-2-EnrichM-注释\"><a href=\"#B-4-2-EnrichM-注释\" class=\"headerlink\" title=\"B.4.2 EnrichM 注释\"></a>B.4.2 EnrichM 注释</h3><h4 id=\"Step-1-annotate\"><a href=\"#Step-1-annotate\" class=\"headerlink\" title=\"Step 1. annotate\"></a>Step 1. annotate</h4><p>基因组注释管道，可以使用dbCAN将基因组与KO, PFAM, TIGRFAM和CAZY 数据库进行比对。结果将为每个基因组产生一个.gff文件，并生成每个注释类型的频率矩阵（frequency matrix），其中行是注释IDs，列是基因组。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm annotate --genome_directory metawrap_70_5_bins --output EnrichM_annotate --force --ko --ko_hmm --pfam --tigrfam --clusters --orthologs --cazy --ec --threads 30 --parallel 8 --suffix .fa --count_domains --chunk_number 8</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options (Use one):</p>\n<ul>\n<li>--genome_files GENOME_FILES [GENOME_FILES …]<br>      Space separated list of genomes to annotate</li>\n<li>--genome_directory GENOME_DIRECTORY<br>      Directory containing genomes to annotate</li>\n<li>--protein_files PROTEIN_FILES [PROTEIN_FILES …]<br>      Space separated list of .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n<li>--protein_directory PROTEIN_DIRECTORY<br>      Directory containing .faa files of genomes to annotate. Protein files need to be generated by prodigal.</li>\n</ul>\n</li>\n<li><p>Annotations options:</p>\n<ul>\n<li>--ko                  Annotate with KO ids</li>\n<li>--ko_hmm              Annotate with KO ids</li>\n<li>--pfam                Annotate with Pfam HMMs</li>\n<li>--tigrfam             Annotate with TIGRFAM HMMs</li>\n<li>--clusters            Annotate with cluster ids</li>\n<li>--orthologs           Annotate with ortholog ids</li>\n<li>--cazy                Annotate with dbCAN HMMs</li>\n<li>--ec                  Annotate with EC ids</li>\n</ul>\n</li>\n<li><p>Cutoff options:</p>\n<ul>\n<li>--cut_ga              For PFAM and TIGRfam searches: use profiles GA gathering cutoffs to set all thresholding</li>\n<li>--cut_nc              For PFAM and TIGRfam searches: use profiles NC noise cutoffs to set all thresholding</li>\n<li>--cut_tc              For PFAM and TIGRfam searches: use profiles TC trusted cutoffs to set all thresholding</li>\n<li>--cut_ko              For KO HMM annotation searches: use cutoffs defined by KEGG to maximise F-score.</li>\n<li>--evalue EVALUE       Use this evalue cutoff to filter false positives (default: 1e-05)</li>\n<li>--bit BIT             Use this bit score cutoff to filter false positives (default: 0)</li>\n<li>--id ID               Use this percent identity cutoff to filter false positives (default: 0.3)</li>\n<li>--aln_query ALN_QUERY<br>      This fraction of the query must align to the reference (default: 0.7)</li>\n<li>--aln_reference ALN_REFERENCE<br>      This fraction of the reference must align to the query (default: 0.7)</li>\n<li>--c C                 When clustering, use matches above this fraction of aligned (covered) query and target residues (default: 0.7)</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--threads THREADS     Use this number of threads when annotating with BLAST and HMMsearch (default: 1)</li>\n<li>--parallel PARALLEL   Run this number of jobs in parallel when annotating with HMMsearch (default: 5)</li>\n<li>--inflation INFLATION<br>     Inflation factor to use when calling clusters in ortholog (default &#x3D; 5.0)</li>\n<li>--suffix SUFFIX       Treat files ending with this suffix within the –genome_directory as genomes (default: .fna for –genome_directory and .faa for )</li>\n<li>--light               Don’t store metadata for genome files (can’t use enrichM compare downstream, default&#x3D;False)</li>\n<li>--count_domains       Fill the frequency matrix with the total number of times an annotation was detected (for example, when one domain more than once within a protein), rather than the count of proteins with with that annotation</li>\n<li>--chunk_number CHUNK_NUMBER<br>      Split loading of genomes into this many chunks (default &#x3D; 4)</li>\n<li>--chunk_max CHUNK_MAX<br>      Maximum number of genomes to load per chunk (default &#x3D; 2500)</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-2-classify\"><a href=\"#Step-2-classify\" class=\"headerlink\" title=\"Step 2. classify\"></a>Step 2. classify</h4><p>Determine what pathways a genome encodes. Classify quickly reads in KO annotations in the form of a matrix (KO IDs as rows, genomes as columns) and determines which KEGG modules are complete. Annotation matrices can be generated using the annotate function.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm classify --output EnrichM_classify/ko_hmm_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_hmm_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ko_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 以下6个命令可不必运行</span></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/cazy_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cazy_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/cluster_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/cluster_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ec_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ec_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/ortholog_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/ortholog_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/pfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/pfam_frequency_table.tsv --cutoff 0</span><br><span class=\"line\"></span><br><span class=\"line\">$ enrichm classify --output EnrichM_classify/tigrfam_frequency_table --aggregate --genome_and_annotation_matrix EnrichM_annotate/tigrfam_frequency_table.tsv --cutoff 0</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options:</p>\n<ul>\n<li>--genome_and_annotation_matrix GENOME_AND_ANNOTATION_MATRIX<br>      Path to file containing a genome annotation matrix</li>\n<li>--custom_modules CUSTOM_MODULES<br>      Tab separated file containing module name, definition as the columns</li>\n<li>--module_rules_json MODULE_RULES_JSON<br>       json file specifying rules to interpret the annotation and guide module annotation</li>\n<li>--gff_files GFF_FILES<br>      GFF files for the genomes being classified.</li>\n</ul>\n</li>\n<li><p>Cutoff options:</p>\n<ul>\n<li>--cutoff CUTOFF       Output only modules with greater than this percent of the requied KO groups (default &#x3D; print all modules)</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--aggregate           Calculate the abundance of each pathway within each genome&#x2F;sample (column)</details></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Step-3-enrichment\"><a href=\"#Step-3-enrichment\" class=\"headerlink\" title=\"Step 3. enrichment\"></a>Step 3. enrichment</h4><p>Enrichment will read in KO or PFAM annotations in the form of a matrix (IDs as rows, genomes as columns) and a metadata file that separates genomes into groups to compare, and will run some basic stats to determine the enrichment of modules or pfam clans between and within the groups.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm enrichment --output EnrichM_enrichment/ --metadata genome.list --annotation_matrix EnrichM_annotate/ko_frequency_table.tsv --force</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>- Output options:</p>\n<ul>\n<li>--output OUTPUT       Output directory</li>\n<li>--force               Overwrite previous run</li>\n</ul>\n</li>\n<li><p>Input options:</p>\n<ul>\n<li>--annotate_output ANNOTATE_OUTPUT<br>     Output directory provided by enrichm annotate</li>\n<li>--metadata METADATA   Metadata file with two columns, the first with the genome name, the second with the groupings to compare.</li>\n<li>--annotation_matrix ANNOTATION_MATRIX<br>     Annotation matrix to compare.</li>\n<li>--gff_files GFF_FILES [GFF_FILES …]<br>     Gff files for genomes to compare.</li>\n<li>--abundance 基因组丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>     Metadata grouping abundance samples.</li>\n<li>--transcriptome TRANSCRIPTOME  基因组丰度矩阵</li>\n<li>--transcriptome_metadata TRANSCRIPTOME_METADATA<br>     Metadata grouping abundance samples.</li>\n</ul>\n</li>\n<li><p>Genome Taxonomy DataBase (GTDB) options:</p>\n<ul>\n<li>--batchfile BATCHFILE<br>     metadata file to compare with.</li>\n</ul>\n</li>\n<li><p>Runtime options:</p>\n<ul>\n<li>--pval_cutoff PVAL_CUTOFF<br>     Only output results with a p-value below a this cutoff (default&#x3D;0.05).</li>\n<li>--proportions_cutoff PROPORTIONS_CUTOFF<br>     Proportion enrichment cutoff.</li>\n<li>--threshold THRESHOLD<br>     The threshold to control for in false discovery rate of familywise error rate.</li>\n<li>--multi_test_correction MULTI_TEST_CORRECTION<br>     The form of mutiple test correction to use. Uses the statsmodel module and consequently has all of its options.<br>                Default: Benjamini-Hochberg FDR (fdr_bh)<br>                Options: Bonferroni (b)<br>                     Sidak (s)<br>                     Holm (h)<br>                     Holm-Sidak (hs)<br>                     Simes-Hochberg (sh)<br>                     Hommel (ho)<br>                     FDR Benjamini-Yekutieli (fdr_by)<br>                     FDR 2-stage Benjamini-Hochberg (fdr_tsbh)<br>                     FDR 2-stage Benjamini-Krieger-Yekutieli (fdr_tsbky)<br>                     FDR adaptive Gavrilov-Benjamini-Sarkar (fdr_gbs))</li>\n<li>--processes PROCESSES  采用多少个进程进行富集分析</li>\n<li>--allow_negative_values  允许输入的矩阵中有负值</li>\n<li>--ko                    Compare KO ids (annotated with DIAMOND)</li>\n<li>--ko_hmm          Compare KO ids (annotated with HMMs)</li>\n<li>--pfam                Compare Pfam ids</li>\n<li>--tigrfam             Compare TIGRFAM ids</li>\n<li>--cluster              Compare cluster ids</li>\n<li>--ortholog            Compare ortholog ids</li>\n<li>--cazy                 Compare dbCAN ids</li>\n<li>--ec                     Compare EC ids</li>\n<li>--range RANGE         Base pair range to search for synteny within. Default &#x3D; 2500.</li>\n<li>--subblock_size SUBBLOCK_SIZE<br>                Number of genes clustered in a row to be reported. Default &#x3D; 2.</li>\n<li>--operon_mismatch_cutoff OPERON_MISMATCH_CUTOFF<br>                Number of allowed mismatches when searching for operons across genomes. Defaul</li>\n<li>--operon_match_score_cutoff OPERON_MATCH_SCORE_CUTOFF<br>                Score cutoff for operon matches</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-4-pathway\"><a href=\"#Step-4-pathway\" class=\"headerlink\" title=\"Step 4. pathway\"></a>Step 4. pathway</h4><p>Pathway reads in a KO matrix and generates a Cytoscape-readable metabolic network and metadata file. Only reactions that are possible given the KOs present in the input matrix are shown, and the modules and reactions that are included in the output can be customized（<strong>报错</strong>）.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ enrichm pathway --matrix EnrichM_annotate/ko_frequency_table.tsv --genome_metadata genome.list --output EnrichM_pathway --abundance EnrichM_enrichment/F01_vs_F02_ivg_results.cdf.tsv --abundance_metadata genome.list --force</span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Input options:</p>\n<ul>\n<li>--matrix KO矩阵. 必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br>       Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>      Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--tpm_values TPM_VALUES<br>       DetectM产生的TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br>       Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--metabolome METABOLOME<br>       Metabolome CID matrix.</li>\n</ul>\n</li>\n<li><p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br>     Level of verbosity (1 - 5 - default &#x3D; 4) 5 &#x3D; Very verbose, 1 &#x3D; Silent</li>\n</ul>\n</li>\n<li><p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li><p>Pathway options:</p>\n<ul>\n<li>--limit LIMIT [LIMIT …]<br>     USE ONLY these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--filter FILTER [FILTER …]<br>     Do not use these reactions, or reactions within this pathway or module (space separated list).</li>\n<li>--enrichment_output ENRICHMENT_OUTPUT<br>      Supply an enrichment output to integrate the results into the output network.</li>\n</ul>\n</li>\n</ul>\n</details>\n\n<h4 id=\"Step-5-explore\"><a href=\"#Step-5-explore\" class=\"headerlink\" title=\"Step 5. explore\"></a>Step 5. explore</h4><p>Explore is similar to pathway, but rather than generating a specified pathway it will start from a given query compound ID, and explore the possible reactions that use that compound given the enzymes present in the input KO matrix.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ </span><br></pre></td></tr></table></figure>\n<details>\n<summary>点击此处查看参数</summary>\n\n<ul>\n<li><p>Input options: </p>\n<ul>\n<li>--matrix MATRIX       KO矩阵. 必须提供</li>\n<li>--genome_metadata GENOME_METADATA<br>      Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare.</li>\n<li>--abundance 丰度矩阵</li>\n<li>--abundance_metadata ABUNDANCE_METADATA<br>     Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare..</li>\n<li>--tpm_values TPM_VALUES<br>     DetectM产生的TPM values</li>\n<li>--tpm_metadata TPM_METADATA<br>     Metadata文件包含两列，第一列为基因组名字，第二列with the groupings to compare..</li>\n<li>--metabolome METABOLOME<br>     Metabolome CID matrix.</li>\n</ul>\n</li>\n<li><p>Logging options:</p>\n<ul>\n<li>--log LOG             Output logging information to this file.</li>\n<li>--verbosity VERBOSITY<br>      Level of verbosity (1 - 5 - default &#x3D; 4) 5 &#x3D; Very verbose, 1 &#x3D; Silent</li>\n</ul>\n</li>\n<li><p>Output options:</p>\n<ul>\n<li>--output             输出路径</li>\n<li>--force               覆盖之前输出的结果</li>\n</ul>\n</li>\n<li><p>Query options:</p>\n<ul>\n<li>--queries QUERIES     A file containing the KEGG ids of the compounds from which to start in the metabolic network</li>\n<li>--depth DEPTH         Number of steps to take into the metabolic network</details></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"C-Metagenome-functional-profiling\"><a href=\"#C-Metagenome-functional-profiling\" class=\"headerlink\" title=\"C Metagenome functional profiling\"></a>C Metagenome functional profiling</h1><ul>\n<li>从宏基因组组装的contigs中预测基因——prodigal -p meta模式</li>\n<li>Metagenome-assembled genes which were not included in the MAGs were subjected to taxonomic classification using <a href=\"https://github.com/bioinformatics-centre/kaiju\">Kaiju</a></li>\n<li>eggNOG-mapper比对<a href=\"https://doi.org/10.1093/nar/gkv1248\">eggnog</a>数据库</li>\n<li>HMMER 比对<a href=\"https://doi.org/10.1093/nar/gky995\">Pfam</a></li>\n<li><a href=\"https://www.kegg.jp/blastkoala/\">GhostKOALA </a>和<a href=\"https://www.genome.jp/tools/kofamkoala/\">KofamKOALA (v1.0.0)</a>比对<a href=\"https://doi.org/10.1093/nar/28.1.27\">KEGG</a></li>\n<li>BLASTP比对<a href=\"https://doi.org/10.1093/nar/gkv1103\">TCDB</a></li>\n<li><a href=\"http://bcb.unl.edu/dbCAN2/\">dbCAN2 (v2.0.1)</a>比对<a href=\"https://doi.org/10.1093/nar/gkn663\">CAZy</a></li>\n<li>BLASTP比对<a href=\"https://www.ebi.ac.uk/merops/submit_searches.shtml\">MEROPS </a></li>\n<li><a href=\"https://github.com/Arkadiy-Garber/FeGenie\">FeGenie</a>检测Iron-related genes</li>\n<li>Fe-containing domains were characterized using <a href=\"https://doi.org/10.1073/pnas.0605798103\">Superfamily (v1.75)</a>.</li>\n<li>砷呼吸和抗性基因挖掘<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/HMM_search\">https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic&#x2F;tree&#x2F;master&#x2F;HMM_search</a>，模型下载<a href=\"https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource\">https://github.com/ShadeLab/PAPER_Dunivin_meta_arsenic/tree/master/gene_targeted_assembly/gene_resource</a></li>\n</ul>\n<h1 id=\"参考资料：\"><a href=\"#参考资料：\" class=\"headerlink\" title=\"参考资料：\"></a>参考资料：</h1><ul>\n<li><a href=\"https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-3.0\">MetaPhlAn 3.0 tutorial</a></li>\n<li><a href=\"https://zouhua.top/archives/9d8099c8.html\">MetaPhlAn 3.0: 宏基因组物种组成分析软件</a></li>\n<li><a href=\"https://github.com/biobakery/biobakery/wiki/GraPhlAn\">GraPhlAn Tutorial</a></li>\n<li></li>\n</ul>","categories":[{"name":"生物信息","path":"api/categories/生物信息.json"}],"tags":[{"name":"宏基因组","path":"api/tags/宏基因组.json"}]}